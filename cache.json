{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-27T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"CSAGN: Conversational Structure Aware Graph Network for Conversational Semantic Role Labeling. (arXiv:2109.11541v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11541","description":"<p>Conversational semantic role labeling (CSRL) is believed to be a crucial step\ntowards dialogue understanding. However, it remains a major challenge for\nexisting CSRL parser to handle conversational structural information. In this\npaper, we present a simple and effective architecture for CSRL which aims to\naddress this problem. Our model is based on a conversational structure-aware\ngraph network which explicitly encodes the speaker dependent information. We\nalso propose a multi-task learning method to further improve the model.\nExperimental results on benchmark datasets show that our model with our\nproposed training objectives significantly outperforms previous baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Document Automation Architectures and Technologies: A Survey. (arXiv:2109.11603v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11603","description":"<p>This paper surveys the current state of the art in document automation (DA).\nThe objective of DA is to reduce the manual effort during the generation of\ndocuments by automatically integrating input from different sources and\nassembling documents conforming to defined templates. There have been reviews\nof commercial solutions of DA, particularly in the legal domain, but to date\nthere has been no comprehensive review of the academic research on DA\narchitectures and technologies. The current survey of DA reviews the academic\nliterature and provides a clearer definition and characterization of DA and its\nfeatures, identifies state-of-the-art DA architectures and technologies in\nacademic research, and provides ideas that can lead to new research\nopportunities within the DA field in light of recent advances in artificial\nintelligence and deep neural networks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Achachlouei_M/0/1/0/all/0/1\">Mohammad Ahmadi Achachlouei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_O/0/1/0/all/0/1\">Omkar Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_T/0/1/0/all/0/1\">Tarun Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1\">Vijayan N. Nair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"iFacetSum: Coreference-based Interactive Faceted Summarization for Multi-Document Exploration. (arXiv:2109.11621v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11621","description":"<p>We introduce iFacetSum, a web application for exploring topical document\nsets. iFacetSum integrates interactive summarization together with faceted\nsearch, by providing a novel faceted navigation scheme that yields abstractive\nsummaries for the user's selections. This approach offers both a comprehensive\noverview as well as concise details regarding subtopics of choice. Fine-grained\nfacets are automatically produced based on cross-document coreference\npipelines, rendering generic concepts, entities and statements surfacing in the\nsource texts. We analyze the effectiveness of our application through\nsmall-scale user studies, which suggest the usefulness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_E/0/1/0/all/0/1\">Eran Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eirew_A/0/1/0/all/0/1\">Alon Eirew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shapira_O/0/1/0/all/0/1\">Ori Shapira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1\">Arie Cattan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernst_O/0/1/0/all/0/1\">Ori Ernst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1\">Ramakanth Pasunuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronen_H/0/1/0/all/0/1\">Hadar Ronen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting the Uniform Information Density Hypothesis. (arXiv:2109.11635v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11635","description":"<p>The uniform information density (UID) hypothesis posits a preference among\nlanguage users for utterances structured such that information is distributed\nuniformly across a signal. While its implications on language production have\nbeen well explored, the hypothesis potentially makes predictions about language\ncomprehension and linguistic acceptability as well. Further, it is unclear how\nuniformity in a linguistic signal -- or lack thereof -- should be measured, and\nover which linguistic unit, e.g., the sentence or language level, this\nuniformity should hold. Here we investigate these facets of the UID hypothesis\nusing reading time and acceptability data. While our reading time results are\ngenerally consistent with previous work, they are also consistent with a weakly\nsuper-linear effect of surprisal, which would be compatible with UID's\npredictions. For acceptability judgments, we find clearer evidence that\nnon-uniformity in information density is predictive of lower acceptability. We\nthen explore multiple operationalizations of UID, motivated by different\ninterpretations of the original hypothesis, and analyze the scope over which\nthe pressure towards uniformity is exerted. The explanatory power of a subset\nof the proposed operationalizations suggests that the strongest trend may be a\nregression towards a mean surprisal across the language, rather than the\nphrase, sentence, or document -- a finding that supports a typical\ninterpretation of UID, namely that it is the byproduct of language users\nmaximizing the use of a (hypothetical) communication channel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haller_P/0/1/0/all/0/1\">Patrick Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jager_L/0/1/0/all/0/1\">Lena J&#xe4;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1\">Roger Levy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simple and Effective Zero-shot Cross-lingual Phoneme Recognition. (arXiv:2109.11680v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11680","description":"<p>Recent progress in self-training, self-supervised pretraining and\nunsupervised learning enabled well performing speech recognition systems\nwithout any labeled data. However, in many cases there is labeled data\navailable for related languages which is not utilized by these methods. This\npaper extends previous work on zero-shot cross-lingual transfer learning by\nfine-tuning a multilingually pretrained wav2vec 2.0 model to transcribe unseen\nlanguages. This is done by mapping phonemes of the training languages to the\ntarget language using articulatory features. Experiments show that this simple\nmethod significantly outperforms prior work which introduced task-specific\narchitectures and used only part of a monolingually pretrained model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detect and Perturb: Neutral Rewriting of Biased and Sensitive Text via Gradient-based Decoding. (arXiv:2109.11708v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11708","description":"<p>Written language carries explicit and implicit biases that can distract from\nmeaningful signals. For example, letters of reference may describe male and\nfemale candidates differently, or their writing style may indirectly reveal\ndemographic characteristics. At best, such biases distract from the meaningful\ncontent of the text; at worst they can lead to unfair outcomes. We investigate\nthe challenge of re-generating input sentences to 'neutralize' sensitive\nattributes while maintaining the semantic meaning of the original text (e.g. is\nthe candidate qualified?). We propose a gradient-based rewriting framework,\nDetect and Perturb to Neutralize (DEPEN), that first detects sensitive\ncomponents and masks them for regeneration, then perturbs the generation model\nat decoding time under a neutralizing constraint that pushes the (predicted)\ndistribution of sensitive attributes towards a uniform distribution. Our\nexperiments in two different scenarios show that DEPEN can regenerate fluent\nalternatives that are neutral in the sensitive attribute while maintaining the\nsemantics of other attributes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zexue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumder_B/0/1/0/all/0/1\">Bodhisattwa Prasad Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AES Are Both Overstable And Oversensitive: Explaining Why And Proposing Defenses. (arXiv:2109.11728v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11728","description":"<p>Deep-learning based Automatic Essay Scoring (AES) systems are being actively\nused by states and language testing agencies alike to evaluate millions of\ncandidates for life-changing decisions ranging from college applications to\nvisa approvals. However, little research has been put to understand and\ninterpret the black-box nature of deep-learning based scoring algorithms.\nPrevious studies indicate that scoring models can be easily fooled. In this\npaper, we explore the reason behind their surprising adversarial brittleness.\nWe utilize recent advances in interpretability to find the extent to which\nfeatures such as coherence, content, vocabulary, and relevance are important\nfor automated scoring mechanisms. We use this to investigate the\noversensitivity i.e., large change in output score with a little change in\ninput essay content) and overstability i.e., little change in output scores\nwith large changes in input essay content) of AES. Our results indicate that\nautoscoring models, despite getting trained as \"end-to-end\" models with rich\ncontextual embeddings such as BERT, behave like bag-of-words models. A few\nwords determine the essay score without the requirement of any context making\nthe model largely overstable. This is in stark contrast to recent probing\nstudies on pre-trained representation learning models, which show that rich\nlinguistic features such as parts-of-speech and morphology are encoded by them.\nFurther, we also find that the models have learnt dataset biases, making them\noversensitive. To deal with these issues, we propose detection-based protection\nmodels that can detect oversensitivity and overstability causing samples with\nhigh accuracies. We find that our proposed models are able to detect unusual\nattribution patterns and flag adversarial samples successfully.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1\">Yaman Kumar Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_S/0/1/0/all/0/1\">Swapnil Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Somesh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DACT-BERT: Differentiable Adaptive Computation Time for an Efficient BERT Inference. (arXiv:2109.11745v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11745","description":"<p>Large-scale pre-trained language models have shown remarkable results in\ndiverse NLP applications. Unfortunately, these performance gains have been\naccompanied by a significant increase in computation time and model size,\nstressing the need to develop new or complementary strategies to increase the\nefficiency of these models. In this paper we propose DACT-BERT, a\ndifferentiable adaptive computation time strategy for BERT-like models.\nDACT-BERT adds an adaptive computational mechanism to BERT's regular processing\npipeline, which controls the number of Transformer blocks that need to be\nexecuted at inference time. By doing this, the model learns to combine the most\nappropriate intermediate representations for the task at hand. Our experiments\ndemonstrate that our approach, when compared to the baselines, excels on a\nreduced computational regime and is competitive in other less restrictive ones.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eyzaguirre_C/0/1/0/all/0/1\">Crist&#xf3;bal Eyzaguirre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rio_F/0/1/0/all/0/1\">Felipe del R&#xed;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araujo_V/0/1/0/all/0/1\">Vladimir Araujo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">&#xc1;lvaro Soto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lacking the embedding of a word? Look it up into a traditional dictionary. (arXiv:2109.11763v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11763","description":"<p>Word embeddings are powerful dictionaries, which may easily capture language\nvariations. However, these dictionaries fail to give sense to rare words, which\nare surprisingly often covered by traditional dictionaries. In this paper, we\npropose to use definitions retrieved in traditional dictionaries to produce\nword embeddings for rare words. For this purpose, we introduce two methods:\nDefinition Neural Network (DefiNNet) and Define BERT (DefBERT). In our\nexperiments, DefiNNet and DefBERT significantly outperform state-of-the-art as\nwell as baseline methods devised for producing embeddings of unknown words. In\nfact, DefiNNet significantly outperforms FastText, which implements a method\nfor the same task-based on n-grams, and DefBERT significantly outperforms the\nBERT method for OOV words. Then, definitions in traditional dictionaries are\nuseful to build word embeddings for rare words.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruzzetti_E/0/1/0/all/0/1\">Elena Sofia Ruzzetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranaldi_L/0/1/0/all/0/1\">Leonardo Ranaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mastromattei_M/0/1/0/all/0/1\">Michele Mastromattei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fallucchi_F/0/1/0/all/0/1\">Francesca Fallucchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanzotto_F/0/1/0/all/0/1\">Fabio Massimo Zanzotto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dense Contrastive Visual-Linguistic Pretraining. (arXiv:2109.11778v1 [cs.CV])","link":"http://arxiv.org/abs/2109.11778","description":"<p>Inspired by the success of BERT, several multimodal representation learning\napproaches have been proposed that jointly represent image and text. These\napproaches achieve superior performance by capturing high-level semantic\ninformation from large-scale multimodal pretraining. In particular, LXMERT and\nUNITER adopt visual region feature regression and label classification as\npretext tasks. However, they tend to suffer from the problems of noisy labels\nand sparse semantic annotations, based on the visual features having been\npretrained on a crowdsourced dataset with limited and inconsistent semantic\nlabeling. To overcome these issues, we propose unbiased Dense Contrastive\nVisual-Linguistic Pretraining (DCVLP), which replaces the region regression and\nclassification with cross-modality region contrastive learning that requires no\nannotations. Two data augmentation strategies (Mask Perturbation and\nIntra-/Inter-Adversarial Perturbation) are developed to improve the quality of\nnegative samples used in contrastive learning. Overall, DCVLP allows\ncross-modality dense region contrastive learning in a self-supervised setting\nindependent of any object annotations. We compare our method against prior\nvisual-linguistic pretraining frameworks to validate the superiority of dense\ncontrastive learning on multimodal representation learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Lei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shuang_K/0/1/0/all/0/1\">Kai Shuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Shijie Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zuohui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1\">Gerard de Melo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunpeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Sen Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models. (arXiv:2109.11797v1 [cs.CV])","link":"http://arxiv.org/abs/2109.11797","description":"<p>Pre-Trained Vision-Language Models (VL-PTMs) have shown promising\ncapabilities in grounding natural language in image data, facilitating a broad\nvariety of cross-modal tasks. However, we note that there exists a significant\ngap between the objective forms of model pre-training and fine-tuning,\nresulting in a need for quantities of labeled data to stimulate the visual\ngrounding capability of VL-PTMs for downstream tasks. To address the challenge,\nwe present Cross-modal Prompt Tuning (CPT, alternatively, Colorful Prompt\nTuning), a novel paradigm for tuning VL-PTMs, which reformulates visual\ngrounding into a fill-in-the-blank problem with color-based co-referential\nmarkers in image and text, maximally mitigating the gap. In this way, our\nprompt tuning approach enables strong few-shot and even zero-shot visual\ngrounding capabilities of VL-PTMs. Comprehensive experimental results show that\nprompt tuned VL-PTMs outperform their fine-tuned counterparts by a large margin\n(e.g., 17.3% absolute accuracy improvement, and 73.8% relative standard\ndeviation reduction on average with one shot in RefCOCO evaluation). All the\ndata and code will be available to facilitate future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Ao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View. (arXiv:2109.11800v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11800","description":"<p>Knowledge Graph Embedding (KGE) aims to learn representations for entities\nand relations. Most KGE models have gained great success, especially on\nextrapolation scenarios. Specifically, given an unseen triple (h, r, t), a\ntrained model can still correctly predict t from (h, r, ?), or h from (?, r,\nt), such extrapolation ability is impressive. However, most existing KGE works\nfocus on the design of delicate triple modeling function, which mainly tell us\nhow to measure the plausibility of observed triples, but we have limited\nunderstanding of why the methods can extrapolate to unseen data, and what are\nthe important factors to help KGE extrapolate. Therefore in this work, we\nattempt to, from a data relevant view, study KGE extrapolation of two problems:\n1. How does KGE extrapolate to unseen data? 2. How to design the KGE model with\nbetter extrapolation ability? For the problem 1, we first discuss the impact\nfactors for extrapolation and from relation, entity and triple level\nrespectively, propose three Semantic Evidences (SEs), which can be observed\nfrom training set and provide important semantic information for extrapolation\nto unseen data. Then we verify the effectiveness of SEs through extensive\nexperiments on several typical KGE methods, and demonstrate that SEs serve as\nan important role for understanding the extrapolation ability of KGE. For the\nproblem 2, to make better use of the SE information for more extrapolative\nknowledge representation, we propose a novel GNN-based KGE model, called\nSemantic Evidence aware Graph Neural Network (SE-GNN). Finally, through\nextensive experiments on FB15k-237 and WN18RR datasets, we show that SE-GNN\nachieves state-of-the-art performance on Knowledge Graph Completion task and\nperform a better extrapolation ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ren Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qiannan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_G/0/1/0/all/0/1\">Guanqun Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1\">Fang Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Diversity-Enhanced and Constraints-Relaxed Augmentation for Low-Resource Classification. (arXiv:2109.11834v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11834","description":"<p>Data augmentation (DA) aims to generate constrained and diversified data to\nimprove classifiers in Low-Resource Classification (LRC). Previous studies\nmostly use a fine-tuned Language Model (LM) to strengthen the constraints but\nignore the fact that the potential of diversity could improve the effectiveness\nof generated data. In LRC, strong constraints but weak diversity in DA result\nin the poor generalization ability of classifiers. To address this dilemma, we\npropose a {D}iversity-{E}nhanced and {C}onstraints-\\{R}elaxed {A}ugmentation\n(DECRA). Our DECRA has two essential components on top of a transformer-based\nbackbone model. 1) A k-beta augmentation, an essential component of DECRA, is\nproposed to enhance the diversity in generating constrained data. It expands\nthe changing scope and improves the degree of complexity of the generated data.\n2) A masked language model loss, instead of fine-tuning, is used as a\nregularization. It relaxes constraints so that the classifier can be trained\nwith more scattered generated data. The combination of these two components\ngenerates data that can reach or approach category boundaries and hence help\nthe classifier generalize better. We evaluate our DECRA on three public\nbenchmark datasets under low-resource settings. Extensive experiments\ndemonstrate that our DECRA outperforms state-of-the-art approaches by 3.8% in\nthe overall score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hailong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuzhao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Weiguo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianping Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robustness and Sensitivity of BERT Models Predicting Alzheimer's Disease from Text. (arXiv:2109.11888v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11888","description":"<p>Understanding robustness and sensitivity of BERT models predicting\nAlzheimer's disease from text is important for both developing better\nclassification models and for understanding their capabilities and limitations.\nIn this paper, we analyze how a controlled amount of desired and undesired text\nalterations impacts performance of BERT. We show that BERT is robust to natural\nlinguistic variations in text. On the other hand, we show that BERT is not\nsensitive to removing clinically important information from text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Novikova_J/0/1/0/all/0/1\">Jekaterina Novikova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Crowd Sourcing for Semantic Similarity. (arXiv:2109.11969v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11969","description":"<p>Estimation of semantic similarity is crucial for a variety of natural\nlanguage processing (NLP) tasks. In the absence of a general theory of semantic\ninformation, many papers rely on human annotators as the source of ground truth\nfor semantic similarity estimation. This paper investigates the ambiguities\ninherent in crowd-sourced semantic labeling. It shows that annotators that\ntreat semantic similarity as a binary category (two sentences are either\nsimilar or not similar and there is no middle ground) play the most important\nrole in the labeling. The paper offers heuristics to filter out unreliable\nannotators and stimulates further discussions on human perception of semantic\nsimilarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Solomon_S/0/1/0/all/0/1\">Shaul Solomon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_A/0/1/0/all/0/1\">Adam Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenblum_H/0/1/0/all/0/1\">Hernan Rosenblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hershkovitz_C/0/1/0/all/0/1\">Chezi Hershkovitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamshchikov_I/0/1/0/all/0/1\">Ivan P. Yamshchikov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction. (arXiv:2109.12008v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12008","description":"<p>State-of-the-art NLP models can adopt shallow heuristics that limit their\ngeneralization capability (McCoy et al., 2019). Such heuristics include lexical\noverlap with the training set in Named-Entity Recognition (Taill\\'e et al.,\n2020) and Event or Type heuristics in Relation Extraction (Rosenman et al.,\n2020). In the more realistic end-to-end RE setting, we can expect yet another\nheuristic: the mere retention of training relation triples. In this paper, we\npropose several experiments confirming that retention of known facts is a key\nfactor of performance on standard benchmarks. Furthermore, one experiment\nsuggests that a pipeline model able to use intermediate type representations is\nless prone to over-rely on retention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Taille_B/0/1/0/all/0/1\">Bruno Taill&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1\">Vincent Guigue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1\">Geoffrey Scoutheeten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Translation of German--Lower Sorbian: Exploring Training and Novel Transfer Methods on a Low-Resource Language. (arXiv:2109.12012v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12012","description":"<p>This paper describes the methods behind the systems submitted by the\nUniversity of Groningen for the WMT 2021 Unsupervised Machine Translation task\nfor German--Lower Sorbian (DE--DSB): a high-resource language to a low-resource\none. Our system uses a transformer encoder-decoder architecture in which we\nmake three changes to the standard training procedure. First, our training\nfocuses on two languages at a time, contrasting with a wealth of research on\nmultilingual systems. Second, we introduce a novel method for initializing the\nvocabulary of an unseen language, achieving improvements of 3.2 BLEU for\nDE$\\rightarrow$DSB and 4.0 BLEU for DSB$\\rightarrow$DE. Lastly, we experiment\nwith the order in which offline and online back-translation are used to train\nan unsupervised system, finding that using online back-translation first works\nbetter for DE$\\rightarrow$DSB by 2.76 BLEU. Our submissions ranked first (tied\nwith another team) for DSB$\\rightarrow$DE and third for DE$\\rightarrow$DSB.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Edman_L/0/1/0/all/0/1\">Lukas Edman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ustun_A/0/1/0/all/0/1\">Ahmet &#xdc;st&#xfc;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toral_A/0/1/0/all/0/1\">Antonio Toral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noord_G/0/1/0/all/0/1\">Gertjan van Noord</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Indirectly Supervised English Sentence Break Prediction Using Paragraph Break Probability Estimates. (arXiv:2109.12023v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12023","description":"<p>This report explores the use of paragraph break probability estimates to help\npredict the location of sentence breaks in English natural language text. We\nshow that a sentence break predictor based almost solely on paragraph break\nprobability estimates can achieve high accuracy on this task. This sentence\nbreak predictor is trained almost entirely on a large amount of naturally\noccurring text without sentence break annotations, with only a small amount of\nannotated data needed to tune two hyperparameters. We also show that even\nbetter results can be achieved across in-domain and out-of-domain test data, if\nparagraph break probability signals are combined with a support vector machine\nclassifier trained on a somewhat larger amount of sentence-break-annotated\ndata. Numerous related issues are addressed along the way.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moore_R/0/1/0/all/0/1\">Robert C. Moore</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Post-pretraining Representation Alignment for Cross-Lingual Question Answering. (arXiv:2109.12028v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12028","description":"<p>Human knowledge is collectively encoded in the roughly 6500 languages spoken\naround the world, but it is not distributed equally across languages. Hence,\nfor information-seeking question answering (QA) systems to adequately serve\nspeakers of all languages, they need to operate cross-lingually. In this work\nwe investigate the capabilities of multilingually pre-trained language models\non cross-lingual QA. We find that explicitly aligning the representations\nacross languages with a post-hoc fine-tuning step generally leads to improved\nperformance. We additionally investigate the effect of data size as well as the\nlanguage choice in this fine-tuning step, also releasing a dataset for\nevaluating cross-lingual QA systems. Code and dataset are publicly available\nhere: https://github.com/ffaisal93/aligned_qa\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformers Generalize Linearly. (arXiv:2109.12036v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12036","description":"<p>Natural language exhibits patterns of hierarchically governed dependencies,\nin which relations between words are sensitive to syntactic structure rather\nthan linear ordering. While re-current network models often fail to generalize\nin a hierarchically sensitive way (McCoy et al.,2020) when trained on ambiguous\ndata, the improvement in performance of newer Trans-former language models\n(Vaswani et al., 2017)on a range of syntactic benchmarks trained on large data\nsets (Goldberg, 2019; Warstadtet al., 2019) opens the question of whether these\nmodels might exhibit hierarchical generalization in the face of impoverished\ndata.In this paper we examine patterns of structural generalization for\nTransformer sequence-to-sequence models and find that not only do Transformers\nfail to generalize hierarchically across a wide variety of grammatical mapping\ntasks, but they exhibit an even stronger preference for linear generalization\nthan comparable recurrent networks\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petty_J/0/1/0/all/0/1\">Jackson Petty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_R/0/1/0/all/0/1\">Robert Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Monolingual and Cross-Lingual Acceptability Judgments with the Italian CoLA corpus. (arXiv:2109.12053v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12053","description":"<p>The development of automated approaches to linguistic acceptability has been\ngreatly fostered by the availability of the English CoLA corpus, which has also\nbeen included in the widely used GLUE benchmark. However, this kind of research\nfor languages other than English, as well as the analysis of cross-lingual\napproaches, has been hindered by the lack of resources with a comparable size\nin other languages. We have therefore developed the ItaCoLA corpus, containing\nalmost 10,000 sentences with acceptability judgments, which has been created\nfollowing the same approach and the same steps as the English one. In this\npaper we describe the corpus creation, we detail its content, and we present\nthe first experiments on this new resource. We compare in-domain and\nout-of-domain classification, and perform a specific evaluation of nine\nlinguistic phenomena. We also present the first cross-lingual experiments,\naimed at assessing whether multilingual transformerbased approaches can benefit\nfrom using sentences in two languages during fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Trotta_D/0/1/0/all/0/1\">Daniela Trotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guarasci_R/0/1/0/all/0/1\">Raffaele Guarasci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonardelli_E/0/1/0/all/0/1\">Elisa Leonardelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonelli_S/0/1/0/all/0/1\">Sara Tonelli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AraT5: Text-to-Text Transformers for Arabic Language Understanding and Generation. (arXiv:2109.12068v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12068","description":"<p>Transfer learning with a unified Transformer framework (T5) that converts all\nlanguage problems into a text-to-text format has recently been proposed as a\nsimple, yet effective, transfer learning approach. Although a multilingual\nversion of the T5 model (mT5) has been introduced, it is not clear how well it\ncan fare on non-English tasks involving diverse data. To investigate this\nquestion, we apply mT5 on a language with a wide variety of dialects--Arabic.\nFor evaluation, we use an existing benchmark for Arabic language understanding\nand introduce a new benchmark for Arabic language generation (ARGEN). We also\npre-train three powerful Arabic-specific text-to-text Transformer based models\nand evaluate them on the two benchmarks. Our new models perform significantly\nbetter than mT5 and exceed MARBERT, the current state-of-the-art Arabic\nBERT-based model, on Arabic language understanding. The models also set new\nSOTA on the generation benchmark. Our new models and are publicly released at\nhttps://github.com/UBC-NLP/araT5 and ARLGE will be released through the same\nrepository.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SD-QA: Spoken Dialectal Question Answering for the Real World. (arXiv:2109.12072v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12072","description":"<p>Question answering (QA) systems are now available through numerous commercial\napplications for a wide variety of domains, serving millions of users that\ninteract with them via speech interfaces. However, current benchmarks in QA\nresearch do not account for the errors that speech recognition models might\nintroduce, nor do they consider the language variations (dialects) of the\nusers. To address this gap, we augment an existing QA dataset to construct a\nmulti-dialect, spoken QA benchmark on five languages (Arabic, Bengali, English,\nKiswahili, Korean) with more than 68k audio prompts in 24 dialects from 255\nspeakers. We provide baseline results showcasing the real-world performance of\nQA systems and analyze the effect of language variety and other sensitive\nspeaker attributes on downstream performance. Last, we study the fairness of\nthe ASR and QA models with respect to the underlying user populations. The\ndataset, model outputs, and code for reproducing all our experiments are\navailable: https://github.com/ffaisal93/SD-QA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keshava_S/0/1/0/all/0/1\">Sharlina Keshava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Md Mahfuz ibn Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Progressive Adversarial Learning for Bootstrapping: A Case Study on Entity Set Expansion. (arXiv:2109.12082v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12082","description":"<p>Bootstrapping has become the mainstream method for entity set expansion.\nConventional bootstrapping methods mostly define the expansion boundary using\nseed-based distance metrics, which heavily depend on the quality of selected\nseeds and are hard to be adjusted due to the extremely sparse supervision. In\nthis paper, we propose BootstrapGAN, a new learning method for bootstrapping\nwhich jointly models the bootstrapping process and the boundary learning\nprocess in a GAN framework. Specifically, the expansion boundaries of different\nbootstrapping iterations are learned via different discriminator networks; the\nbootstrapping network is the generator to generate new positive entities, and\nthe discriminator networks identify the expansion boundaries by trying to\ndistinguish the generated entities from known positive entities. By iteratively\nperforming the above adversarial learning, the generator and the discriminators\ncan reinforce each other and be progressively refined along the whole\nbootstrapping process. Experiments show that BootstrapGAN achieves the new\nstate-of-the-art entity set expansion performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1\">Lingyong Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-based NP Enrichment. (arXiv:2109.12085v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12085","description":"<p>Understanding the relations between entities denoted by NPs in text is a\ncritical part of human-like natural language understanding. However, only a\nfraction of such relations is covered by NLP tasks and models nowadays. In this\nwork, we establish the task of text-based NP enrichment (TNE), that is,\nenriching each NP with all the preposition-mediated relations that hold between\nthis and the other NPs in the text. The relations are represented as triplets,\neach denoting two NPs linked via a preposition. Humans recover such relations\nseamlessly, while current state-of-the-art models struggle with them due to the\nimplicit nature of the problem. We build the first large-scale dataset for the\nproblem, provide the formal framing and scope of annotation, analyze the data,\nand report the result of fine-tuned neural language models on the task,\ndemonstrating the challenge it poses to current technology. We created a\nwebpage with the data, data-exploration UI, code, models, and demo to foster\nfurther research into this challenging text understanding problem at\nyanaiela.github.io/TNE/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elazar_Y/0/1/0/all/0/1\">Yanai Elazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basmov_V/0/1/0/all/0/1\">Victoria Basmov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsarfaty_R/0/1/0/all/0/1\">Reut Tsarfaty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction. (arXiv:2109.12093v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12093","description":"<p>Stepping from sentence-level to document-level relation extraction, the\nresearch community confronts increasing text length and more complicated entity\ninteractions. Consequently, it is more challenging to encode the key sources of\ninformation--relevant contexts and entity types. However, existing methods only\nimplicitly learn to model these critical information sources while being\ntrained for relation extraction. As a result, they suffer the problems of\nineffective supervision and uninterpretable model predictions. In contrast, we\npropose to explicitly teach the model to capture relevant contexts and entity\ntypes by supervising and augmenting intermediate steps (SAIS) for relation\nextraction. Based on a broad spectrum of carefully designed tasks, our proposed\nSAIS method not only extracts relations of better quality due to more effective\nsupervision, but also retrieves the corresponding supporting evidence more\naccurately so as to enhance interpretability. By assessing model uncertainty,\nSAIS further boosts the performance via evidence-based data augmentation and\nensemble inference while reducing the computational cost. Eventually, SAIS\ndelivers state-of-the-art relation extraction results on three benchmarks\n(DocRED, CDR, and GDA) and achieves 5.04% relative gains in F1 score compared\nto the runner-up in evidence retrieval on DocRED.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zecheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLIPort: What and Where Pathways for Robotic Manipulation. (arXiv:2109.12098v1 [cs.RO])","link":"http://arxiv.org/abs/2109.12098","description":"<p>How can we imbue robots with the ability to manipulate objects precisely but\nalso to reason about them in terms of abstract concepts? Recent works in\nmanipulation have shown that end-to-end networks can learn dexterous skills\nthat require precise spatial reasoning, but these methods often fail to\ngeneralize to new goals or quickly learn transferable concepts across tasks. In\nparallel, there has been great progress in learning generalizable semantic\nrepresentations for vision and language by training on large-scale internet\ndata, however these representations lack the spatial understanding necessary\nfor fine-grained manipulation. To this end, we propose a framework that\ncombines the best of both worlds: a two-stream architecture with semantic and\nspatial pathways for vision-based manipulation. Specifically, we present\nCLIPort, a language-conditioned imitation-learning agent that combines the\nbroad semantic understanding (what) of CLIP [1] with the spatial precision\n(where) of Transporter [2]. Our end-to-end framework is capable of solving a\nvariety of language-specified tabletop tasks from packing unseen objects to\nfolding cloths, all without any explicit representations of object poses,\ninstance segmentations, memory, symbolic states, or syntactic structures.\nExperiments in simulated and real-world settings show that our approach is data\nefficient in few-shot settings and generalizes effectively to seen and unseen\nsemantic concepts. We even learn one multi-task policy for 10 simulated and 9\nreal-world tasks that is better or comparable to single-task policies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shridhar_M/0/1/0/all/0/1\">Mohit Shridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manuelli_L/0/1/0/all/0/1\">Lucas Manuelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1\">Dieter Fox</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GERNERMED -- An Open German Medical NER Model. (arXiv:2109.12104v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12104","description":"<p>The current state of adoption of well-structured electronic health records\nand integration of digital methods for storing medical patient data in\nstructured formats can often considered as inferior compared to the use of\ntraditional, unstructured text based patient data documentation. Data mining in\nthe field of medical data analysis often needs to rely solely on processing of\nunstructured data to retrieve relevant data. In natural language processing\n(NLP), statistical models have been shown successful in various tasks like\npart-of-speech tagging, relation extraction (RE) and named entity recognition\n(NER). In this work, we present GERNERMED, the first open, neural NLP model for\nNER tasks dedicated to detect medical entity types in German text data. Here,\nwe avoid the conflicting goals of protection of sensitive patient data from\ntraining data extraction and the publication of the statistical model weights\nby training our model on a custom dataset that was translated from publicly\navailable datasets in foreign language by a pretrained neural machine\ntranslation model. The sample code and the statistical model is available at:\nhttps://github.com/frankkramer-lab/GERNERMED\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Frei_J/0/1/0/all/0/1\">Johann Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramer_F/0/1/0/all/0/1\">Frank Kramer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Faithful Target Attribute Prediction in Neural Machine Translation. (arXiv:2109.12105v1 [cs.CL])","link":"http://arxiv.org/abs/2109.12105","description":"<p>The training data used in NMT is rarely controlled with respect to specific\nattributes, such as word casing or gender, which can cause errors in\ntranslations. We argue that predicting the target word and attributes\nsimultaneously is an effective way to ensure that translations are more\nfaithful to the training data distribution with respect to these attributes.\nExperimental results on two tasks, uppercased input translation and gender\nprediction, show that this strategy helps mirror the training data distribution\nin testing. It also facilitates data augmentation on the task of uppercased\ninput translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1\">Xing Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinu_G/0/1/0/all/0/1\">Georgiana Dinu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathur_P/0/1/0/all/0/1\">Prashant Mathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Currey_A/0/1/0/all/0/1\">Anna Currey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Source Code Search: A Study of the Past and a Glimpse at the Future. (arXiv:1908.06738v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/1908.06738","description":"<p>With the recent explosion in the size and complexity of source codebases and\nsoftware projects, the need for efficient source code search engines has\nincreased dramatically. Unfortunately, existing information retrieval-based\nmethods fail to capture the query semantics and perform well only when the\nquery contains syntax-based keywords. Consequently, such methods will perform\npoorly when given high-level natural language queries. In this paper, we review\nexisting methods for building code search engines. We also outline the open\nresearch directions and the various obstacles that stand in the way of having a\nuniversal source code search engine.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_M/0/1/0/all/0/1\">Muhammad Khalifa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SOLID: A Large-Scale Semi-Supervised Dataset for Offensive Language Identification. (arXiv:2004.14454v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.14454","description":"<p>The widespread use of offensive content in social media has led to an\nabundance of research in detecting language such as hate speech, cyberbullying,\nand cyber-aggression. Recent work presented the OLID dataset, which follows a\ntaxonomy for offensive language identification that provides meaningful\ninformation for understanding the type and the target of offensive messages.\nHowever, it is limited in size and it might be biased towards offensive\nlanguage as it was collected using keywords. In this work, we present SOLID, an\nexpanded dataset, where the tweets were collected in a more principled manner.\nSOLID contains over nine million English tweets labeled in a semi-supervised\nfashion. We demonstrate that using SOLID along with OLID yields sizable\nperformance gains on the OLID test set for two different models, especially for\nthe lower levels of the taxonomy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rosenthal_S/0/1/0/all/0/1\">Sara Rosenthal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atanasova_P/0/1/0/all/0/1\">Pepa Atanasova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karadzhov_G/0/1/0/all/0/1\">Georgi Karadzhov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1\">Marcos Zampieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across Languages and Over Centuries. (arXiv:2006.03950v4 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2006.03950","description":"<p>Word embeddings learn implicit biases from linguistic regularities captured\nby word co-occurrence statistics. By extending methods that quantify human-like\nbiases in word embeddings, we introduceValNorm, a novel intrinsic evaluation\ntask and method to quantify the valence dimension of affect in human-rated word\nsets from social psychology. We apply ValNorm on static word embeddings from\nseven languages (Chinese, English, German, Polish, Portuguese, Spanish, and\nTurkish) and from historical English text spanning 200 years. ValNorm achieves\nconsistently high accuracy in quantifying the valence of non-discriminatory,\nnon-social group word sets. Specifically, ValNorm achieves a Pearson\ncorrelation of r=0.88 for human judgment scores of valence for 399 words\ncollected to establish pleasantness norms in English. In contrast, we measure\ngender stereotypes using the same set of word embeddings and find that social\nbiases vary across languages. Our results indicate that valence associations of\nnon-discriminatory, non-social group words represent widely-shared\nassociations, in seven languages and over 200 years.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toney_Wails_A/0/1/0/all/0/1\">Autumn Toney-Wails</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caliskan_A/0/1/0/all/0/1\">Aylin Caliskan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Calling Out Bluff: Evaluation Toolkit For Robustness Testing Of Automatic Essay Scoring Systems. (arXiv:2007.06796v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2007.06796","description":"<p>Automatic scoring engines have been used for scoring approximately fifteen\nmillion test-takers in just the last three years. This number is increasing\nfurther due to COVID-19 and the associated automation of education and testing.\nDespite such wide usage, the AI-based testing literature of these \"intelligent\"\nmodels is highly lacking. Most of the papers proposing new models rely only on\nquadratic weighted kappa (QWK) based agreement with human raters for showing\nmodel efficacy. However, this effectively ignores the highly multi-feature\nnature of essay scoring. Essay scoring depends on features like coherence,\ngrammar, relevance, sufficiency and, vocabulary. To date, there has been no\nstudy testing Automated Essay Scoring: AES systems holistically on all these\nfeatures. With this motivation, we propose a model agnostic adversarial\nevaluation scheme and associated metrics for AES systems to test their natural\nlanguage understanding capabilities and overall robustness. We evaluate the\ncurrent state-of-the-art AES models using the proposed scheme and report the\nresults on five recent models. These models range from\nfeature-engineering-based approaches to the latest deep learning algorithms. We\nfind that AES models are highly overstable. Even heavy modifications(as much as\n25%) with content unrelated to the topic of the questions do not decrease the\nscore produced by the models. On the other hand, irrelevant content, on\naverage, increases the scores, thus showing that the model evaluation strategy\nand rubrics should be reconsidered. We also ask 200 human raters to score both\nan original and adversarial response to seeing if humans can detect differences\nbetween the two and whether they agree with the scores assigned by auto scores.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kabra_A/0/1/0/all/0/1\">Anubha Kabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_M/0/1/0/all/0/1\">Mehar Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_Y/0/1/0/all/0/1\">Yaman Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jessy Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpenAttack: An Open-source Textual Adversarial Attack Toolkit. (arXiv:2009.09191v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.09191","description":"<p>Textual adversarial attacking has received wide and increasing attention in\nrecent years. Various attack models have been proposed, which are enormously\ndistinct and implemented with different programming frameworks and settings.\nThese facts hinder quick utilization and fair comparison of attack models. In\nthis paper, we present an open-source textual adversarial attack toolkit named\nOpenAttack to solve these issues. Compared with existing other textual\nadversarial attack toolkits, OpenAttack has its unique strengths in support for\nall attack types, multilinguality, and parallel processing. Currently,\nOpenAttack includes 15 typical attack models that cover all attack types. Its\nhighly inclusive modular design not only supports quick utilization of existing\nattack models, but also enables great flexibility and extensibility. OpenAttack\nhas broad uses including comparing and evaluating attack models, measuring\nrobustness of a model, assisting in developing new attack models, and\nadversarial training. Source code and documentation can be obtained at\nhttps://github.com/thunlp/OpenAttack.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1\">Guoyang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qianrui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tingji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zixian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1\">Bairu Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1\">Yuan Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Char2Subword: Extending the Subword Embedding Space Using Robust Character Compositionality. (arXiv:2010.12730v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.12730","description":"<p>Byte-pair encoding (BPE) is a ubiquitous algorithm in the subword\ntokenization process of language models as it provides multiple benefits.\nHowever, this process is solely based on pre-training data statistics, making\nit hard for the tokenizer to handle infrequent spellings. On the other hand,\nthough robust to misspellings, pure character-level models often lead to\nunreasonably long sequences and make it harder for the model to learn\nmeaningful words. To alleviate these challenges, we propose a character-based\nsubword module (char2subword) that learns the subword embedding table in\npre-trained models like BERT. Our char2subword module builds representations\nfrom characters out of the subword vocabulary, and it can be used as a drop-in\nreplacement of the subword embedding table. The module is robust to\ncharacter-level alterations such as misspellings, word inflection, casing, and\npunctuation. We integrate it further with BERT through pre-training while\nkeeping BERT transformer parameters fixed--and thus, providing a practical\nmethod. Finally, we show that incorporating our module to mBERT significantly\nimproves the performance on the social media linguistic code-switching\nevaluation (LinCE) benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aguilar_G/0/1/0/all/0/1\">Gustavo Aguilar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCann_B/0/1/0/all/0/1\">Bryan McCann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1\">Tong Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajani_N/0/1/0/all/0/1\">Nazneen Rajani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keskar_N/0/1/0/all/0/1\">Nitish Keskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solorio_T/0/1/0/all/0/1\">Thamar Solorio</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Sequence-to-Sequence Pre-training via Sequence Span Rewriting. (arXiv:2101.00416v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.00416","description":"<p>In this paper, we generalize text infilling (e.g., masked language models) by\nproposing Sequence Span Rewriting (SSR) as a self-supervised\nsequence-to-sequence (seq2seq) pre-training objective. SSR provides more\nfine-grained learning signals for text representations by supervising the model\nto rewrite imperfect spans to ground truth, and it is more consistent than text\ninfilling with many downstream seq2seq tasks that rewrite a source sentences\ninto a target sentence. Our experiments with T5 models on various seq2seq tasks\nshow that SSR can substantially improve seq2seq pre-training. Moreover, we\nobserve SSR is especially helpful to improve pre-training a small-size seq2seq\nmodel with a powerful imperfect span generator, which indicates a new\nperspective of transferring knowledge from a large model to a smaller model for\nseq2seq pre-training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advances and Challenges in Conversational Recommender Systems: A Survey. (arXiv:2101.09459v7 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2101.09459","description":"<p>Recommender systems exploit interaction history to estimate user preference,\nhaving been heavily used in a wide range of industry applications. However,\nstatic recommendation models are difficult to answer two important questions\nwell due to inherent shortcomings: (a) What exactly does a user like? (b) Why\ndoes a user like an item? The shortcomings are due to the way that static\nmodels learn user preference, i.e., without explicit instructions and active\nfeedback from users. The recent rise of conversational recommender systems\n(CRSs) changes this situation fundamentally. In a CRS, users and the system can\ndynamically communicate through natural language interactions, which provide\nunprecedented opportunities to explicitly obtain the exact preference of users.\n</p>\n<p>Considerable efforts, spread across disparate settings and applications, have\nbeen put into developing CRSs. Existing models, technologies, and evaluation\nmethods for CRSs are far from mature. In this paper, we provide a systematic\nreview of the techniques used in current CRSs. We summarize the key challenges\nof developing CRSs in five directions: (1) Question-based user preference\nelicitation. (2) Multi-turn conversational recommendation strategies. (3)\nDialogue understanding and generation. (4) Exploitation-exploration trade-offs.\n(5) Evaluation and user simulation. These research directions involve multiple\nresearch fields like information retrieval (IR), natural language processing\n(NLP), and human-computer interaction (HCI). Based on these research\ndirections, we discuss some future challenges and opportunities. We provide a\nroad map for researchers from multiple communities to get started in this area.\nWe hope this survey can help to identify and address challenges in CRSs and\ninspire future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongming Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1\">Wenqiang Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Statistically significant detection of semantic shifts using contextual word embeddings. (arXiv:2104.03776v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.03776","description":"<p>Detecting lexical semantic change in smaller data sets, e.g. in historical\nlinguistics and digital humanities, is challenging due to a lack of statistical\npower. This issue is exacerbated by non-contextual embedding models that\nproduce one embedding per word and, therefore, mask the variability present in\nthe data. In this article, we propose an approach to estimate semantic shift by\ncombining contextual word embeddings with permutation-based statistical tests.\nWe use the false discovery rate procedure to address the large number of\nhypothesis tests being conducted simultaneously. We demonstrate the performance\nof this approach in simulation where it achieves consistently high precision by\nsuppressing false positives. We additionally analyze real-world data from\nSemEval-2020 Task 1 and the Liverpool FC subreddit corpus. We show that by\ntaking sample variation into account, we can improve the robustness of\nindividual semantic shift estimates without degrading overall performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medlar_A/0/1/0/all/0/1\">Alan Medlar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glowacka_D/0/1/0/all/0/1\">Dorota Glowacka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer. (arXiv:2106.01732v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.01732","description":"<p>Multilingual pre-trained models have achieved remarkable performance on\ncross-lingual transfer learning. Some multilingual models such as mBERT, have\nbeen pre-trained on unlabeled corpora, therefore the embeddings of different\nlanguages in the models may not be aligned very well. In this paper, we aim to\nimprove the zero-shot cross-lingual transfer performance by proposing a\npre-training task named Word-Exchange Aligning Model (WEAM), which uses the\nstatistical alignment information as the prior knowledge to guide cross-lingual\nword prediction. We evaluate our model on multilingual machine reading\ncomprehension task MLQA and natural language interface task XNLI. The results\nshow that WEAM can significantly improve the zero-shot performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wentao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yiming Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiani Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shijin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learned Token Pruning for Transformers. (arXiv:2107.00910v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.00910","description":"<p>Deploying transformer models in practice is challenging due to their\ninference cost, which scales quadratically with input sequence length. To\naddress this, we present a novel Learned Token Pruning (LTP) method which\nadaptively removes unimportant tokens as an input sequence passes through\ntransformer layers. In particular, LTP prunes tokens with an attention score\nbelow a threshold value which is learned for each layer during training. Our\nthreshold-based method allows the length of the pruned sequence to vary\nadaptively based on the input sequence, and avoids algorithmically expensive\noperations such as top-k token selection. We extensively test the performance\nof LTP on GLUE tasks and show that our method outperforms the prior\nstate-of-the-art token pruning methods by up to ~2.5% higher accuracy with the\nsame amount of FLOPs. In particular, LTP achieves up to 2.1x FLOPs reduction\nwith less than 1% accuracy drop, which results in up to 1.9x and 2.0x\nthroughput improvement on Intel Haswell CPUs and NVIDIA V100 GPUs,\nrespectively. Furthermore, we demonstrate that LTP is more robust than prior\nmethods to variations on input sentence lengths. Our code has been developed in\nPyTorch and has been open-sourced.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Sheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorsley_D/0/1/0/all/0/1\">David Thorsley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1\">Amir Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_W/0/1/0/all/0/1\">Woosuk Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassoun_J/0/1/0/all/0/1\">Joseph Hassoun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Natural Language Understanding Pipeline for Bangla Conversational Agent. (arXiv:2107.05541v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.05541","description":"<p>Chatbots are intelligent software built to be used as a replacement for human\ninteraction. Existing studies typically do not provide enough support for\nlow-resource languages like Bangla. Due to the increasing popularity of social\nmedia, we can also see the rise of interactions in Bangla transliteration\n(mostly in English) among the native Bangla speakers. In this paper, we propose\na novel approach to build a Bangla chatbot aimed to be used as a business\nassistant which can communicate in Bangla and Bangla Transliteration in English\nwith high confidence consistently. Since annotated data was not available for\nthis purpose, we had to work on the whole machine learning life cycle (data\npreparation, machine learning modeling, and model deployment) using Rasa Open\nSource Framework, fastText embeddings, Polyglot embeddings, Flask, and other\nsystems as building blocks. While working with the skewed annotated dataset, we\ntry out different setups and pipelines to evaluate which works best and provide\npossible reasoning behind the observed results. Finally, we present a pipeline\nfor intent classification and entity extraction which achieves reasonable\nperformance (accuracy: 83.02%, precision: 80.82%, recall: 83.02%, F1-score:\n80%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahim Shahriar Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mushabbir_M/0/1/0/all/0/1\">Mueeze Al Mushabbir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irbaz_M/0/1/0/all/0/1\">Mohammad Sabik Irbaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasim_M/0/1/0/all/0/1\">MD Abdullah Al Nasim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Summary Explorer: Visualizing the State of the Art in Text Summarization. (arXiv:2108.01879v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.01879","description":"<p>This paper introduces Summary Explorer, a new tool to support the manual\ninspection of text summarization systems by compiling the outputs of\n55~state-of-the-art single document summarization approaches on three benchmark\ndatasets, and visually exploring them during a qualitative assessment. The\nunderlying design of the tool considers three well-known summary quality\ncriteria (coverage, faithfulness, and position bias), encapsulated in a guided\nassessment based on tailored visualizations. The tool complements existing\napproaches for locally debugging summarization models and improves upon them.\nThe tool is available at https://tldr.webis.de/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Syed_S/0/1/0/all/0/1\">Shahbaz Syed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yousef_T/0/1/0/all/0/1\">Tariq Yousef</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Khatib_K/0/1/0/all/0/1\">Khalid Al-Khatib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janicke_S/0/1/0/all/0/1\">Stefan J&#xe4;nicke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1\">Martin Potthast</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sequence Level Contrastive Learning for Text Summarization. (arXiv:2109.03481v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.03481","description":"<p>Contrastive learning models have achieved great success in unsupervised\nvisual representation learning, which maximize the similarities between feature\nrepresentations of different views of the same image, while minimize the\nsimilarities between feature representations of views of different images. In\ntext summarization, the output summary is a shorter form of the input document\nand they have similar meanings. In this paper, we propose a contrastive\nlearning model for supervised abstractive text summarization, where we view a\ndocument, its gold summary and its model generated summaries as different views\nof the same mean representation and maximize the similarities between them\nduring training. We improve over a strong sequence-to-sequence text generation\nmodel (i.e., BART) on three different summarization datasets. Human evaluation\nalso shows that our model achieves better faithfulness ratings compared to its\ncounterpart without contrastive objectives.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shusheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Forget me not: A Gentle Reminder to Mind the Simple Multi-Layer Perceptron Baseline for Text Classification. (arXiv:2109.03777v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.03777","description":"<p>Graph neural networks have triggered a resurgence of graph-based text\nclassification. We show that already a simple MLP baseline achieves comparable\nperformance on benchmark datasets, questioning the importance of synthetic\ngraph structures. When considering an inductive scenario, i. e., when adding\nnew documents to a corpus, a simple MLP even outperforms the recent graph-based\nmodels TextGCN and HeteGCN and is comparable with HyperGAT. We further\nfine-tune DistilBERT and find that it outperforms all state-of-the-art models.\nWe suggest that future studies use at least an MLP baseline to contextualize\nthe results. We provide recommendations for the design and training of such a\nbaseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Galke_L/0/1/0/all/0/1\">Lukas Galke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherp_A/0/1/0/all/0/1\">Ansgar Scherp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NADE: A Benchmark for Robust Adverse Drug Events Extraction in Face of Negations. (arXiv:2109.10080v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.10080","description":"<p>Adverse Drug Event (ADE) extraction models can rapidly examine large\ncollections of social media texts, detecting mentions of drug-related adverse\nreactions and trigger medical investigations. However, despite the recent\nadvances in NLP, it is currently unknown if such models are robust in face of\nnegation, which is pervasive across language varieties.\n</p>\n<p>In this paper we evaluate three state-of-the-art systems, showing their\nfragility against negation, and then we introduce two possible strategies to\nincrease the robustness of these models: a pipeline approach, relying on a\nspecific component for negation detection; an augmentation of an ADE extraction\ndataset to artificially create negated samples and further train the models.\n</p>\n<p>We show that both strategies bring significant increases in performance,\nlowering the number of spurious entities predicted by the models. Our dataset\nand code will be publicly released to encourage research on the topic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scaboro_S/0/1/0/all/0/1\">Simone Scaboro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portelli_B/0/1/0/all/0/1\">Beatrice Portelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chersoni_E/0/1/0/all/0/1\">Emmanuele Chersoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santus_E/0/1/0/all/0/1\">Enrico Santus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serra_G/0/1/0/all/0/1\">Giuseppe Serra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diarisation using location tracking with agglomerative clustering. (arXiv:2109.10598v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2109.10598","description":"<p>Previous works have shown that spatial location information can be\ncomplementary to speaker embeddings for a speaker diarisation task. However,\nthe models used often assume that speakers are fairly stationary throughout a\nmeeting. This paper proposes to relax this assumption, by explicitly modelling\nthe movements of speakers within an Agglomerative Hierarchical Clustering (AHC)\ndiarisation framework. Kalman filters, which track the locations of speakers,\nare used to compute log-likelihood ratios that contribute to the cluster\naffinity computations for the AHC merging and stopping decisions. Experiments\nshow that the proposed approach is able to yield improvements on a Microsoft\nrich meeting transcription task, compared to methods that do not use location\ninformation or that make stationarity assumptions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Jeremy H. M. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abramovski_I/0/1/0/all/0/1\">Igor Abramovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alzheimers Dementia Detection using Acoustic & Linguistic features and Pre-Trained BERT. (arXiv:2109.11010v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.11010","description":"<p>Alzheimers disease is a fatal progressive brain disorder that worsens with\ntime. It is high time we have inexpensive and quick clinical diagnostic\ntechniques for early detection and care. In previous studies, various Machine\nLearning techniques and Pre-trained Deep Learning models have been used in\nconjunction with the extraction of various acoustic and linguistic features.\nOur study focuses on three models for the classification task in the ADReSS\n(The Alzheimers Dementia Recognition through Spontaneous Speech) 2021\nChallenge. We use the well-balanced dataset provided by the ADReSS Challenge\nfor training and validating our models. Model 1 uses various acoustic features\nfrom the eGeMAPs feature-set, Model 2 uses various linguistic features that we\ngenerated from auto-generated transcripts and Model 3 uses the auto-generated\ntranscripts directly to extract features using a Pre-trained BERT and TF-IDF.\nThese models are described in detail in the models section.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Valsaraj_A/0/1/0/all/0/1\">Akshay Valsaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madala_I/0/1/0/all/0/1\">Ithihas Madala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_N/0/1/0/all/0/1\">Nikhil Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baths_V/0/1/0/all/0/1\">Veeky Baths</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Volctrans GLAT System: Non-autoregressive Translation Meets WMT21. (arXiv:2109.11247v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.11247","description":"<p>This paper describes the Volctrans' submission to the WMT21 news translation\nshared task for German-&gt;English translation. We build a parallel (i.e.,\nnon-autoregressive) translation system using the Glancing Transformer, which\nenables fast and accurate parallel decoding in contrast to the currently\nprevailing autoregressive models. To the best of our knowledge, this is the\nfirst parallel translation system that can be scaled to such a practical\nscenario like WMT competition. More importantly, our parallel translation\nsystem achieves the best BLEU score (35.0) on German-&gt;English translation task,\noutperforming all strong autoregressive counterparts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_L/0/1/0/all/0/1\">Lihua Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaoming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zehui Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiangtao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shanbo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-26T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}