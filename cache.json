{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-29T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Visually Grounded Reasoning across Languages and Cultures. (arXiv:2109.13238v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13238","description":"<p>The design of widespread vision-and-language datasets and pre-trained\nencoders directly adopts, or draws inspiration from, the concepts and images of\nImageNet. While one can hardly overestimate how much this benchmark contributed\nto progress in computer vision, it is mostly derived from lexical databases and\nimage queries in English, resulting in source material with a North American or\nWestern European bias. Therefore, we devise a new protocol to construct an\nImageNet-style hierarchy representative of more languages and cultures. In\nparticular, we let the selection of both concepts and images be entirely driven\nby native speakers, rather than scraping them automatically. Specifically, we\nfocus on a typologically diverse set of languages, namely, Indonesian, Mandarin\nChinese, Swahili, Tamil, and Turkish. On top of the concepts and images\nobtained through this new protocol, we create a multilingual dataset for\n{M}ulticultur{a}l {R}easoning over {V}ision and {L}anguage (MaRVL) by eliciting\nstatements from native speaker annotators about pairs of images. The task\nconsists of discriminating whether each grounded statement is true or false. We\nestablish a series of baselines using state-of-the-art models and find that\ntheir cross-lingual transfer performance lags dramatically behind supervised\nperformance in English. These results invite us to reassess the robustness and\naccuracy of current state-of-the-art models beyond a narrow domain, but also\nopen up new exciting challenges for the development of truly multilingual and\nmulticultural systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bugliarello_E/0/1/0/all/0/1\">Emanuele Bugliarello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo Maria Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_D/0/1/0/all/0/1\">Desmond Elliott</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation. (arXiv:2109.13296v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13296","description":"<p>Recent progress in generative language models has enabled machines to\ngenerate astonishingly realistic texts. While there are many legitimate\napplications of such models, there is also a rising need to distinguish\nmachine-generated texts from human-written ones (e.g., fake news detection).\nHowever, to our best knowledge, there is currently no benchmark environment\nwith datasets and tasks to systematically study the so-called \"Turing Test\"\nproblem for neural text generation methods. In this work, we present the\nTuringBench benchmark environment, which is comprised of (1) a dataset with\n200K human- or machine-generated samples across 20 labels {Human, GPT-1,\nGPT-2_small, GPT-2_medium, GPT-2_large, GPT-2_xl, GPT-2_PyTorch, GPT-3,\nGROVER_base, GROVER_large, GROVER_mega, CTRL, XLM, XLNET_base, XLNET_large,\nFAIR_wmt19, FAIR_wmt20, TRANSFORMER_XL, PPLM_distil, PPLM_gpt2}, (2) two\nbenchmark tasks -- i.e., Turing Test (TT) and Authorship Attribution (AA), and\n(3) a website with leaderboards. Our preliminary experimental results using\nTuringBench show that FAIR_wmt20 and GPT-3 are the current winners, among all\nlanguage models tested, in generating the most human-like indistinguishable\ntexts with the lowest F1 score by five state-of-the-art TT detection models.\nThe TuringBench is available at: https://turingbench.ist.psu.edu/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Uchendu_A/0/1/0/all/0/1\">Adaku Uchendu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zeyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Thai Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongwon Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Isotropy Calibration of Transformers. (arXiv:2109.13304v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13304","description":"<p>Different studies of the embedding space of transformer models suggest that\nthe distribution of contextual representations is highly anisotropic - the\nembeddings are distributed in a narrow cone. Meanwhile, static word\nrepresentations (e.g., Word2Vec or GloVe) have been shown to benefit from\nisotropic spaces. Therefore, previous work has developed methods to calibrate\nthe embedding space of transformers in order to ensure isotropy. However, a\nrecent study (Cai et al. 2021) shows that the embedding space of transformers\nis locally isotropic, which suggests that these models are already capable of\nexploiting the expressive capacity of their embedding space. In this work, we\nconduct an empirical evaluation of state-of-the-art methods for isotropy\ncalibration on transformers and find that they do not provide consistent\nimprovements across models and tasks. These results support the thesis that,\ngiven the local isotropy, transformers do not benefit from additional isotropy\ncalibration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yue Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinkus_K/0/1/0/all/0/1\">Karolis Martinkus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pascual_D/0/1/0/all/0/1\">Damian Pascual</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clematide_S/0/1/0/all/0/1\">Simon Clematide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stochastic Transformer Networks with Linear Competing Units: Application to end-to-end SL Translation. (arXiv:2109.13318v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13318","description":"<p>Automating sign language translation (SLT) is a challenging real world\napplication. Despite its societal importance, though, research progress in the\nfield remains rather poor. Crucially, existing methods that yield viable\nperformance necessitate the availability of laborious to obtain gloss sequence\ngroundtruth. In this paper, we attenuate this need, by introducing an\nend-to-end SLT model that does not entail explicit use of glosses; the model\nonly needs text groundtruth. This is in stark contrast to existing end-to-end\nmodels that use gloss sequence groundtruth, either in the form of a modality\nthat is recognized at an intermediate model stage, or in the form of a parallel\noutput process, jointly trained with the SLT model. Our approach constitutes a\nTransformer network with a novel type of layers that combines: (i) local\nwinner-takes-all (LWTA) layers with stochastic winner sampling, instead of\nconventional ReLU layers, (ii) stochastic weights with posterior distributions\nestimated via variational inference, and (iii) a weight compression technique\nat inference time that exploits estimated posterior variance to perform\nmassive, almost lossless compression. We demonstrate that our approach can\nreach the currently best reported BLEU-4 score on the PHOENIX 2014T benchmark,\nbut without making use of glosses for model training, and with a memory\nfootprint reduced by more than 70%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Voskou_A/0/1/0/all/0/1\">Andreas Voskou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panousis_K/0/1/0/all/0/1\">Konstantinos P. Panousis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosmopoulos_D/0/1/0/all/0/1\">Dimitrios Kosmopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1\">Dimitris N. Metaxas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzis_S/0/1/0/all/0/1\">Sotirios Chatzis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Biomedical BERT Models for Vocabulary Alignment at Scale in the UMLS Metathesaurus. (arXiv:2109.13348v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13348","description":"<p>The current UMLS (Unified Medical Language System) Metathesaurus construction\nprocess for integrating over 200 biomedical source vocabularies is expensive\nand error-prone as it relies on the lexical algorithms and human editors for\ndeciding if the two biomedical terms are synonymous. Recent advances in Natural\nLanguage Processing such as Transformer models like BERT and its biomedical\nvariants with contextualized word embeddings have achieved state-of-the-art\n(SOTA) performance on downstream tasks. We aim to validate if these approaches\nusing the BERT models can actually outperform the existing approaches for\npredicting synonymy in the UMLS Metathesaurus. In the existing Siamese Networks\nwith LSTM and BioWordVec embeddings, we replace the BioWordVec embeddings with\nthe biomedical BERT embeddings extracted from each BERT model using different\nways of extraction. In the Transformer architecture, we evaluate the use of the\ndifferent biomedical BERT models that have been pre-trained using different\ndatasets and tasks. Given the SOTA performance of these BERT models for other\ndownstream tasks, our experiments yield surprisingly interesting results: (1)\nin both model architectures, the approaches employing these biomedical\nBERT-based models do not outperform the existing approaches using Siamese\nNetwork with BioWordVec embeddings for the UMLS synonymy prediction task, (2)\nthe original BioBERT large model that has not been pre-trained with the UMLS\noutperforms the SapBERT models that have been pre-trained with the UMLS, and\n(3) using the Siamese Networks yields better performance for synonymy\nprediction when compared to using the biomedical BERT models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_G/0/1/0/all/0/1\">Goonmeet Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vinh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wijesiriwardene_T/0/1/0/all/0/1\">Thilini Wijesiriwardene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yip_H/0/1/0/all/0/1\">Hong Yung Yip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javangula_V/0/1/0/all/0/1\">Vishesh Javangula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathy_S/0/1/0/all/0/1\">Srinivasan Parthasarathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodenreider_O/0/1/0/all/0/1\">Olivier Bodenreider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SYGMA: System for Generalizable Modular Question Answering OverKnowledge Bases. (arXiv:2109.13430v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13430","description":"<p>Knowledge Base Question Answering (KBQA) tasks that in-volve complex\nreasoning are emerging as an important re-search direction. However, most KBQA\nsystems struggle withgeneralizability, particularly on two dimensions: (a)\nacrossmultiple reasoning types where both datasets and systems haveprimarily\nfocused on multi-hop reasoning, and (b) across mul-tiple knowledge bases, where\nKBQA approaches are specif-ically tuned to a single knowledge base. In this\npaper, wepresent SYGMA, a modular approach facilitating general-izability\nacross multiple knowledge bases and multiple rea-soning types. Specifically,\nSYGMA contains three high levelmodules: 1) KB-agnostic question understanding\nmodule thatis common across KBs 2) Rules to support additional reason-ing types\nand 3) KB-specific question mapping and answeringmodule to address the\nKB-specific aspects of the answer ex-traction. We demonstrate effectiveness of\nour system by evalu-ating on datasets belonging to two distinct knowledge\nbases,DBpedia and Wikidata. In addition, to demonstrate extensi-bility to\nadditional reasoning types we evaluate on multi-hopreasoning datasets and a new\nTemporal KBQA benchmarkdataset on Wikidata, namedTempQA-WD1, introduced in\nthispaper. We show that our generalizable approach has bettercompetetive\nperformance on multiple datasets on DBpediaand Wikidata that requires both\nmulti-hop and temporal rea-soning\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Neelam_S/0/1/0/all/0/1\">Sumit Neelam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_U/0/1/0/all/0/1\">Udit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karanam_H/0/1/0/all/0/1\">Hima Karanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikbal_S/0/1/0/all/0/1\">Shajith Ikbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1\">Pavan Kapanipathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelaziz_I/0/1/0/all/0/1\">Ibrahim Abdelaziz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1\">Nandana Mihindukulasooriya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Young-Suk Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Santosh Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pendus_C/0/1/0/all/0/1\">Cezar Pendus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dana_S/0/1/0/all/0/1\">Saswati Dana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_D/0/1/0/all/0/1\">Dinesh Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fokoue_A/0/1/0/all/0/1\">Achille Fokoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargav_G/0/1/0/all/0/1\">G P Shrivatsa Bhargav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_D/0/1/0/all/0/1\">Dinesh Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravishankar_S/0/1/0/all/0/1\">Srinivas Ravishankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurajada_S/0/1/0/all/0/1\">Sairam Gurajada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Maria Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uceda_Sosa_R/0/1/0/all/0/1\">Rosario Uceda-Sosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1\">Salim Roukos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1\">Alexander Gray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riegel_G/0/1/0/all/0/1\">Guilherme LimaRyan Riegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luus_F/0/1/0/all/0/1\">Francois Luus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramaniam_L/0/1/0/all/0/1\">L Venkata Subramaniam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When in Doubt: Improving Classification Performance with Alternating Normalization. (arXiv:2109.13449v1 [cs.LG])","link":"http://arxiv.org/abs/2109.13449","description":"<p>We introduce Classification with Alternating Normalization (CAN), a\nnon-parametric post-processing step for classification. CAN improves\nclassification accuracy for challenging examples by re-adjusting their\npredicted class probability distribution using the predicted class\ndistributions of high-confidence validation examples. CAN is easily applicable\nto any probabilistic classifier, with minimal computation overhead. We analyze\nthe properties of CAN using simulated experiments, and empirically demonstrate\nits effectiveness across a diverse set of classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1\">Menglin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reiter_A/0/1/0/all/0/1\">Austin Reiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Ser-Nam Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1\">Yoav Artzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1\">Claire Cardie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Teacher-Student Learning Approach for Multi-lingual Speech-to-Intent Classification. (arXiv:2109.13486v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13486","description":"<p>End-to-end speech-to-intent classification has shown its advantage in\nharvesting information from both text and speech. In this paper, we study a\ntechnique to develop such an end-to-end system that supports multiple\nlanguages. To overcome the scarcity of multi-lingual speech corpus, we exploit\nknowledge from a pre-trained multi-lingual natural language processing model.\nMulti-lingual bidirectional encoder representations from transformers (mBERT)\nmodels are trained on multiple languages and hence expected to perform well in\nthe multi-lingual scenario. In this work, we employ a teacher-student learning\napproach to sufficiently extract information from an mBERT model to train a\nmulti-lingual speech model. In particular, we use synthesized speech generated\nfrom an English-Mandarin text corpus for analysis and training of a\nmulti-lingual intent classification model. We also demonstrate that the\nteacher-student learning approach obtains an improved performance (91.02%) over\nthe traditional end-to-end (89.40%) intent classification approach in a\npractical multi-lingual scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_B/0/1/0/all/0/1\">Bidisha Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhavi_M/0/1/0/all/0/1\">Maulik Madhavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xuehao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"How Robust r u?\": Evaluating Task-Oriented Dialogue Systems on Spoken Conversations. (arXiv:2109.13489v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13489","description":"<p>Most prior work in dialogue modeling has been on written conversations mostly\nbecause of existing data sets. However, written dialogues are not sufficient to\nfully capture the nature of spoken conversations as well as the potential\nspeech recognition errors in practical spoken dialogue systems. This work\npresents a new benchmark on spoken task-oriented conversations, which is\nintended to study multi-domain dialogue state tracking and knowledge-grounded\ndialogue modeling. We report that the existing state-of-the-art models trained\non written conversations are not performing well on our spoken data, as\nexpected. Furthermore, we observe improvements in task performances when\nleveraging n-best speech recognition hypotheses such as by combining\npredictions based on individual hypotheses. Our data set enables speech-based\nbenchmarking of task-oriented dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seokhwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papangelis_A/0/1/0/all/0/1\">Alexandros Papangelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Karthik Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedayatnia_B/0/1/0/all/0/1\">Behnam Hedayatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instance-Based Neural Dependency Parsing. (arXiv:2109.13497v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13497","description":"<p>Interpretable rationales for model predictions are crucial in practical\napplications. We develop neural models that possess an interpretable inference\nprocess for dependency parsing. Our models adopt instance-based inference,\nwhere dependency edges are extracted and labeled by comparing them to edges in\na training set. The training edges are explicitly used for the predictions;\nthus, it is easy to grasp the contribution of each edge to the predictions. Our\nexperiments show that our instance-based models achieve competitive accuracy\nwith standard neural models and have the reasonable plausibility of\ninstance-based explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ouchi_H/0/1/0/all/0/1\">Hiroki Ouchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_J/0/1/0/all/0/1\">Jun Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_S/0/1/0/all/0/1\">Sosuke Kobayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yokoi_S/0/1/0/all/0/1\">Sho Yokoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuribayashi_T/0/1/0/all/0/1\">Tatsuki Kuribayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_M/0/1/0/all/0/1\">Masashi Yoshikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1\">Kentaro Inui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VoxCeleb Enrichment for Age and Gender Recognition. (arXiv:2109.13510v1 [cs.LG])","link":"http://arxiv.org/abs/2109.13510","description":"<p>VoxCeleb datasets are widely used in speaker recognition studies. Our work\nserves two purposes. First, we provide speaker age labels and (an alternative)\nannotation of speaker gender. Second, we demonstrate the use of this metadata\nby constructing age and gender recognition models with different features and\nclassifiers. We query different celebrity databases and apply consensus rules\nto derive age and gender labels. We also compare the original VoxCeleb gender\nlabels with our labels to identify records that might be mislabeled in the\noriginal VoxCeleb data. On modeling side, we design a comprehensive study of\nmultiple features and models for recognizing gender and age. Our best system,\nusing i-vector features, achieved an F1-score of 0.9829 for gender recognition\ntask using logistic regression, and the lowest mean absolute error (MAE) in age\nregression, 9.443 years, is obtained with ridge regression. This indicates\nchallenge in age estimation from in-the-wild style speech data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hechmi_K/0/1/0/all/0/1\">Khaled Hechmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trong_T/0/1/0/all/0/1\">Trung Ngo Trong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hautamaki_V/0/1/0/all/0/1\">Ville Hautamaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1\">Tomi Kinnunen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Template-free Prompt Tuning for Few-shot NER. (arXiv:2109.13532v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13532","description":"<p>Prompt-based methods have been successfully applied in sentence-level\nfew-shot learning tasks, mostly owing to the sophisticated design of templates\nand label words. However, when applied to token-level labeling tasks such as\nNER, it would be time-consuming to enumerate the template queries over all\npotential entity spans. In this work, we propose a more elegant method to\nreformulate NER tasks as LM problems without any templates. Specifically, we\ndiscard the template construction process while maintaining the word prediction\nparadigm of pre-training models to predict a class-related pivot word (or label\nword) at the entity position. Meanwhile, we also explore principled ways to\nautomatically search for appropriate label words that the pre-trained models\ncan easily adapt to. While avoiding complicated template-based process, the\nproposed LM objective also reduces the gap between different objectives used in\npre-training and fine-tuning, thus it can better benefit the few-shot\nperformance. Experimental results demonstrate the effectiveness of the proposed\nmethod over bert-tagger and template-based method under few-shot setting.\nMoreover, the decoding speed of the proposed method is up to 1930.12 times\nfaster than the template-based method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1\">Ruotian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">Yiding Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Agreeing to Disagree: Annotating Offensive Language Datasets with Annotators' Disagreement. (arXiv:2109.13563v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13563","description":"<p>Since state-of-the-art approaches to offensive language detection rely on\nsupervised learning, it is crucial to quickly adapt them to the continuously\nevolving scenario of social media. While several approaches have been proposed\nto tackle the problem from an algorithmic perspective, so to reduce the need\nfor annotated data, less attention has been paid to the quality of these data.\nFollowing a trend that has emerged recently, we focus on the level of agreement\namong annotators while selecting data to create offensive language datasets, a\ntask involving a high level of subjectivity. Our study comprises the creation\nof three novel datasets of English tweets covering different topics and having\nfive crowd-sourced judgments each. We also present an extensive set of\nexperiments showing that selecting training and test data according to\ndifferent levels of annotators' agreement has a strong effect on classifiers\nperformance and robustness. Our findings are further validated in cross-domain\nexperiments and studied using a popular benchmark dataset. We show that such\nhard cases, where low agreement is present, are not necessarily due to\npoor-quality annotation and we advocate for a higher presence of ambiguous\ncases in future datasets, particularly in test sets, to better account for the\ndifferent points of view expressed online.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Leonardelli_E/0/1/0/all/0/1\">Elisa Leonardelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menini_S/0/1/0/all/0/1\">Stefano Menini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aprosio_A/0/1/0/all/0/1\">Alessio Palmero Aprosio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerini_M/0/1/0/all/0/1\">Marco Guerini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonelli_S/0/1/0/all/0/1\">Sara Tonelli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating texts under constraint through discriminator-guided MCTS. (arXiv:2109.13582v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13582","description":"<p>Large pre-trained language models (LM) based on Transformers allow to\ngenerate very plausible long texts. In this paper, we explore how this\ngeneration can be further controlled to satisfy certain constraints (eg. being\nnon-toxic, positive or negative, convey certain emotions, etc.) without\nfine-tuning the LM. Precisely, we formalize constrained generation as a tree\nexploration process guided by a discriminator according to how well the\nassociated sequence respects the constraint. Using a discriminator to guide\nthis generation, rather than fine-tuning the LM, in addition to be easier and\ncheaper to train, allows to apply the constraint more finely and dynamically.\nWe propose several original methods to search this generation tree, notably the\nMonte Carlo Tree Search (MCTS) which provides theoretical guarantees on the\nsearch efficiency, but also simpler methods based on re-ranking a pool of\ndiverse sequences using the discriminator scores. We evaluate these methods on\ntwo types of constraints and languages: review polarity and emotion control in\nFrench and English. We show that MCTS achieves state-of-the-art results in\nconstrained generation, without having to tune the language model, in both\ntasks and languages. We also demonstrate that our other proposed methods based\non re-ranking can be really effective when diversity among the generated\npropositions is encouraged.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chaffin_A/0/1/0/all/0/1\">Antoine Chaffin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Claveau_V/0/1/0/all/0/1\">Vincent Claveau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1\">Ewa Kijak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Learning for Argument Mining: A Practical Approach. (arXiv:2109.13611v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13611","description":"<p>Despite considerable recent progress, the creation of well-balanced and\ndiverse resources remains a time-consuming and costly challenge in Argument\nMining. Active Learning reduces the amount of data necessary for the training\nof machine learning models by querying the most informative samples for\nannotation and therefore is a promising method for resource creation. In a\nlarge scale comparison of several Active Learning methods, we show that Active\nLearning considerably decreases the effort necessary to get good deep learning\nperformance on the task of Argument Unit Recognition and Classification (AURC).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Solmsdorf_N/0/1/0/all/0/1\">Nikolai Solmsdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trautmann_D/0/1/0/all/0/1\">Dietrich Trautmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-lingual Intermediate Fine-tuning improves Dialogue State Tracking. (arXiv:2109.13620v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13620","description":"<p>Recent progress in task-oriented neural dialogue systems is largely focused\non a handful of languages, as annotation of training data is tedious and\nexpensive. Machine translation has been used to make systems multilingual, but\nthis can introduce a pipeline of errors. Another promising solution is using\ncross-lingual transfer learning through pretrained multilingual models.\nExisting methods train multilingual models with additional code-mixed task data\nor refine the cross-lingual representations through parallel ontologies. In\nthis work, we enhance the transfer learning process by intermediate fine-tuning\nof pretrained multilingual models, where the multilingual models are fine-tuned\nwith different but related data and/or tasks. Specifically, we use parallel and\nconversational movie subtitles datasets to design cross-lingual intermediate\ntasks suitable for downstream dialogue tasks. We use only 200K lines of\nparallel data for intermediate fine-tuning which is already available for 1782\nlanguage pairs. We test our approach on the cross-lingual dialogue state\ntracking task for the parallel MultiWoZ (English -&gt; Chinese, Chinese -&gt;\nEnglish) and Multilingual WoZ (English -&gt; German, English -&gt; Italian) datasets.\nWe achieve impressive improvements (&gt; 20% on joint goal accuracy) on the\nparallel MultiWoZ dataset and the Multilingual WoZ dataset over the vanilla\nbaseline with only 10% of the target language task data and zero-shot setup\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moghe_N/0/1/0/all/0/1\">Nikita Moghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steedman_M/0/1/0/all/0/1\">Mark Steedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeepPSL: End-to-end perception and reasoning with applications to zero shot learning. (arXiv:2109.13662v1 [eess.SY])","link":"http://arxiv.org/abs/2109.13662","description":"<p>We introduce DeepPSL a variant of Probabilistic Soft Logic (PSL) to produce\nan end-to-end trainable system that integrates reasoning and perception. PSL\nrepresents first-order logic in terms of a convex graphical model -- Hinge Loss\nMarkov random fields (HL-MRFs). PSL stands out among probabilistic logic\nframeworks due to its tractability having been applied to systems of more than\n1 billion ground rules. The key to our approach is to represent predicates in\nfirst-order logic using deep neural networks and then to approximately\nback-propagate through the HL-MRF and thus train every aspect of the\nfirst-order system being represented. We believe that this approach represents\nan interesting direction for the integration of deep learning and reasoning\ntechniques with applications to knowledge base learning, multi-task learning,\nand explainability. We evaluate DeepPSL on a zero shot learning problem in\nimage classification. State of the art results demonstrate the utility and\nflexibility of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Duffy_N/0/1/0/all/0/1\">Nigel Duffy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Puranam_S/0/1/0/all/0/1\">Sai Akhil Puranam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dasaratha_S/0/1/0/all/0/1\">Sridhar Dasaratha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Phogat_K/0/1/0/all/0/1\">Karmvir Singh Phogat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tiyyagura_S/0/1/0/all/0/1\">Sunil Reddy Tiyyagura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Counter Narrative Type Classification. (arXiv:2109.13664v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13664","description":"<p>The growing interest in employing counter narratives for hatred intervention\nbrings with it a focus on dataset creation and automation strategies. In this\nscenario, learning to recognize counter narrative types from natural text is\nexpected to be useful for applications such as hate speech countering, where\noperators from non-governmental organizations are supposed to answer to hate\nwith several and diverse arguments that can be mined from online sources. This\npaper presents the first multilingual work on counter narrative type\nclassification, evaluating SoTA pre-trained language models in monolingual,\nmultilingual and cross-lingual settings. When considering a fine-grained\nannotation of counter narrative classes, we report strong baseline\nclassification results for the majority of the counter narrative types,\nespecially if we translate every language to English before cross-lingual\nprediction. This suggests that knowledge about counter narratives can be\nsuccessfully transferred across languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1\">Yi-Ling Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerini_M/0/1/0/all/0/1\">Marco Guerini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nana-HDR: A Non-attentive Non-autoregressive Hybrid Model for TTS. (arXiv:2109.13673v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13673","description":"<p>This paper presents Nana-HDR, a new non-attentive non-autoregressive model\nwith hybrid Transformer-based Dense-fuse encoder and RNN-based decoder for TTS.\nIt mainly consists of three parts: Firstly, a novel Dense-fuse encoder with\ndense connections between basic Transformer blocks for coarse feature fusion\nand a multi-head attention layer for fine feature fusion. Secondly, a\nsingle-layer non-autoregressive RNN-based decoder. Thirdly, a duration\npredictor instead of an attention model that connects the above hybrid encoder\nand decoder. Experiments indicate that Nana-HDR gives full play to the\nadvantages of each component, such as strong text encoding ability of\nTransformer-based encoder, stateful decoding without being bothered by exposure\nbias and local information preference, and stable alignment provided by\nduration predictor. Due to these advantages, Nana-HDR achieves competitive\nperformance in naturalness and robustness on two Mandarin corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shilun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wenchao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1\">Li Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_F/0/1/0/all/0/1\">Fenglong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Li Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CIDEr-R: Robust Consensus-based Image Description Evaluation. (arXiv:2109.13701v1 [cs.CV])","link":"http://arxiv.org/abs/2109.13701","description":"<p>This paper shows that CIDEr-D, a traditional evaluation metric for image\ndescription, does not work properly on datasets where the number of words in\nthe sentence is significantly greater than those in the MS COCO Captions\ndataset. We also show that CIDEr-D has performance hampered by the lack of\nmultiple reference sentences and high variance of sentence length. To bypass\nthis problem, we introduce CIDEr-R, which improves CIDEr-D, making it more\nflexible in dealing with datasets with high sentence length variance. We\ndemonstrate that CIDEr-R is more accurate and closer to human judgment than\nCIDEr-D; CIDEr-R is more robust regarding the number of available references.\nOur results reveal that using Self-Critical Sequence Training to optimize\nCIDEr-R generates descriptive captions. In contrast, when CIDEr-D is optimized,\nthe generated captions' length tends to be similar to the reference length.\nHowever, the models also repeat several times the same word to increase the\nsentence length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Santos_G/0/1/0/all/0/1\">Gabriel Oliveira dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colombini_E/0/1/0/all/0/1\">Esther Luna Colombini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avila_S/0/1/0/all/0/1\">Sandra Avila</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One to rule them all: Towards Joint Indic Language Hate Speech Detection. (arXiv:2109.13711v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13711","description":"<p>This paper is a contribution to the Hate Speech and Offensive Content\nIdentification in Indo-European Languages (HASOC) 2021 shared task. Social\nmedia today is a hotbed of toxic and hateful conversations, in various\nlanguages. Recent news reports have shown that current models struggle to\nautomatically identify hate posted in minority languages. Therefore,\nefficiently curbing hate speech is a critical challenge and problem of\ninterest. We present a multilingual architecture using state-of-the-art\ntransformer language models to jointly learn hate and offensive speech\ndetection across three languages namely, English, Hindi, and Marathi. On the\nprovided testing corpora, we achieve Macro F1 scores of 0.7996, 0.7748, 0.8651\nfor sub-task 1A and 0.6268, 0.5603 during the fine-grained classification of\nsub-task 1B. These results show the efficacy of exploiting a multilingual\ntraining scheme.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_M/0/1/0/all/0/1\">Mehar Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotia_T/0/1/0/all/0/1\">Tenzin Singhay Bhotia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Akshat Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_P/0/1/0/all/0/1\">Prakash Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shubham Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shridhar_K/0/1/0/all/0/1\">Kumar Shridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laumann_F/0/1/0/all/0/1\">Felix Laumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dash_A/0/1/0/all/0/1\">Ayushman Dash</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing the Use of Character-Level Translation with Sparse and Noisy Datasets. (arXiv:2109.13723v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13723","description":"<p>This paper provides an analysis of character-level machine translation models\nused in pivot-based translation when applied to sparse and noisy datasets, such\nas crowdsourced movie subtitles. In our experiments, we find that such\ncharacter-level models cut the number of untranslated words by over 40% and are\nespecially competitive (improvements of 2-3 BLEU points) in the case of limited\ntraining data. We explore the impact of character alignment, phrase table\nfiltering, bitext size and the choice of pivot language on translation quality.\nWe further compare cascaded translation models to the use of synthetic training\ndata via multiple pivots, and we find that the latter works significantly\nbetter. Finally, we demonstrate that neither word-nor character-BLEU correlate\nperfectly with human judgments, due to BLEU's sensitivity to length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tiedemann_J/0/1/0/all/0/1\">J&#xf6;rg Tiedemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Translating from Morphologically Complex Languages: A Paraphrase-Based Approach. (arXiv:2109.13724v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13724","description":"<p>We propose a novel approach to translating from a morphologically complex\nlanguage. Unlike previous research, which has targeted word inflections and\nconcatenations, we focus on the pairwise relationship between morphologically\nrelated words, which we treat as potential paraphrases and handle using\nparaphrasing techniques at the word, phrase, and sentence level. An important\nadvantage of this framework is that it can cope with derivational morphology,\nwhich has so far remained largely beyond the capabilities of statistical\nmachine translation systems. Our experiments translating from Malay, whose\nmorphology is mostly derivational, into English show significant improvements\nover rivaling approaches based on five automatic evaluation measures (for\n320,000 sentence pairs; 9.5 million English word tokens).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_H/0/1/0/all/0/1\">Hwee Tou Ng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentiment Analysis in Twitter for Macedonian. (arXiv:2109.13725v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13725","description":"<p>We present work on sentiment analysis in Twitter for Macedonian. As this is\npioneering work for this combination of language and genre, we created suitable\nresources for training and evaluating a system for sentiment analysis of\nMacedonian tweets. In particular, we developed a corpus of tweets annotated\nwith tweet-level sentiment polarity (positive, negative, and neutral), as well\nas with phrase-level sentiment, which we made freely available for research\npurposes. We further bootstrapped several large-scale sentiment lexicons for\nMacedonian, motivated by previous work for English. The impact of several\ndifferent pre-processing steps as well as of various features is shown in\nexperiments that represent the first attempt to build a system for sentiment\nanalysis in Twitter for the morphologically rich Macedonian language. Overall,\nour experimental results show an F1-score of 92.16, which is very strong and is\non par with the best results for English, which were achieved in recent SemEval\ncompetitions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jovanoski_D/0/1/0/all/0/1\">Dame Jovanoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pachovski_V/0/1/0/all/0/1\">Veno Pachovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exposing Paid Opinion Manipulation Trolls. (arXiv:2109.13726v1 [cs.LG])","link":"http://arxiv.org/abs/2109.13726","description":"<p>Recently, Web forums have been invaded by opinion manipulation trolls. Some\ntrolls try to influence the other users driven by their own convictions, while\nin other cases they can be organized and paid, e.g., by a political party or a\nPR agency that gives them specific instructions what to write. Finding paid\ntrolls automatically using machine learning is a hard task, as there is no\nenough training data to train a classifier; yet some test data is possible to\nobtain, as these trolls are sometimes caught and widely exposed. In this paper,\nwe solve the training data problem by assuming that a user who is called a\ntroll by several different people is likely to be such, and one who has never\nbeen called a troll is unlikely to be such. We compare the profiles of (i) paid\ntrolls vs. (ii)\"mentioned\" trolls vs. (iii) non-trolls, and we further show\nthat a classifier trained to distinguish (ii) from (iii) does quite well also\nat telling apart (i) from (iii).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mihaylov_T/0/1/0/all/0/1\">Todor Mihaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koychev_I/0/1/0/all/0/1\">Ivan Koychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgiev_G/0/1/0/all/0/1\">Georgi Georgiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Task Triplet Loss for Named Entity Recognition using Supplementary Text. (arXiv:2109.13736v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13736","description":"<p>Retail item data contains many different forms of text like the title of an\nitem, the description of an item, item name and reviews. It is of interest to\nidentify the item name in the other forms of text using a named entity tagger.\nHowever, the title of an item and its description are syntactically different\n(but semantically similar) in that the title is not necessarily a well formed\nsentence while the description is made up of well formed sentences. In this\nwork, we use a triplet loss to contrast the embeddings of the item title with\nthe description to establish a proof of concept. We find that using the triplet\nloss in a multi-task NER algorithm improves both the precision and recall by a\nsmall percentage. While the improvement is small, we think it is a step in the\nright direction of using various forms of text in a multi-task algorithm. In\naddition to precision and recall, the multi task triplet loss method is also\nfound to significantly improve the exact match accuracy i.e. the accuracy of\ntagging the entire set of tokens in the text with correct tags.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Siskind_R/0/1/0/all/0/1\">Ryan Siskind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Shalin Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Homophony and R\\'enyi Entropy. (arXiv:2109.13766v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13766","description":"<p>Homophony's widespread presence in natural languages is a controversial\ntopic. Recent theories of language optimality have tried to justify its\nprevalence, despite its negative effects on cognitive processing time; e.g.,\nPiantadosi et al. (2012) argued homophony enables the reuse of efficient\nwordforms and is thus beneficial for languages. This hypothesis has recently\nbeen challenged by Trott and Bergen (2020), who posit that good wordforms are\nmore often homophonous simply because they are more phonotactically probable.\nIn this paper, we join in on the debate. We first propose a new\ninformation-theoretic quantification of a language's homophony: the sample\nR\\'enyi entropy. Then, we use this quantification to revisit Trott and Bergen's\nclaims. While their point is theoretically sound, a specific methodological\nissue in their experiments raises doubts about their results. After addressing\nthis issue, we find no clear pressure either towards or against homophony -- a\nmuch more nuanced result than either Piantadosi et al.'s or Trott and Bergen's\nfindings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teufel_S/0/1/0/all/0/1\">Simone Teufel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying and Mitigating Gender Bias in Hyperbolic Word Embeddings. (arXiv:2109.13767v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13767","description":"<p>Euclidean word embedding models such as GloVe and Word2Vec have been shown to\nreflect human-like gender biases. In this paper, we extend the study of gender\nbias to the recently popularized hyperbolic word embeddings. We propose\ngyrocosine bias, a novel measure for quantifying gender bias in hyperbolic word\nrepresentations and observe a significant presence of gender bias. To address\nthis problem, we propose Poincar\\'e Gender Debias (PGD), a novel debiasing\nprocedure for hyperbolic word representations. Experiments on a suit of\nevaluation tests show that PGD effectively reduces bias while adding a minimal\nsemantic offset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vaibhav Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotia_T/0/1/0/all/0/1\">Tenzin Singhay Bhotia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vaibhav Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Micromodels for Efficient, Explainable, and Reusable Systems: A Case Study on Mental Health. (arXiv:2109.13770v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13770","description":"<p>Many statistical models have high accuracy on test benchmarks, but are not\nexplainable, struggle in low-resource scenarios, cannot be reused for multiple\ntasks, and cannot easily integrate domain expertise. These factors limit their\nuse, particularly in settings such as mental health, where it is difficult to\nannotate datasets and model outputs have significant impact. We introduce a\nmicromodel architecture to address these challenges. Our approach allows\nresearchers to build interpretable representations that embed domain knowledge\nand provide explanations throughout the model's decision process. We\ndemonstrate the idea on multiple mental health tasks: depression\nclassification, PTSD classification, and suicidal risk assessment. Our systems\nconsistently produce strong results, even in low-resource scenarios, and are\nmore interpretable than alternative methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Andrew Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kummerfeld_J/0/1/0/all/0/1\">Jonathan K. Kummerfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_L/0/1/0/all/0/1\">Lawrence C. An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chekhov's Gun Recognition. (arXiv:2109.13855v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13855","description":"<p>Chekhov's gun is a dramatic principle stating that every element in a story\nmust be necessary, and irrelevant elements should be removed. This paper\npresents a new natural language processing task - Chekhov's gun recognition or\n(CGR) - recognition of entities that are pivotal for the development of the\nplot. Though similar to classical Named Entity Recognition (NER) it has\nprofound differences and is crucial for the tasks of narrative processing,\nsince Chekhov's guns have a profound impact on the causal relationship in a\nstory. The paper presents a new benchmark dataset for the CGR task that\nincludes 5550 descriptions with one or more Chekhov's Gun in each and validates\nthe task on two more datasets available in the natural language processing\n(NLP) literature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamshchikov_I/0/1/0/all/0/1\">Ivan P. Yamshchikov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Expectation-based Minimalist Grammars. (arXiv:2109.13871v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13871","description":"<p>Expectation-based Minimalist Grammars (e-MGs) are simplified versions of the\n(Conflated) Minimalist Grammars, (C)MGs, formalized by Stabler (Stabler, 2011,\n2013, 1997) and Phase-based Minimalist Grammars, PMGs (Chesi, 2005, 2007;\nStabler, 2011). The crucial simplification consists of driving structure\nbuilding only by relying on lexically encoded categorial top-down expectations.\nThe commitment on a top-down derivation (as in e-MGs and PMGs, as opposed to\n(C)MGs, Chomsky, 1995; Stabler, 2011) allows us to define a core derivation\nthat should be the same in both parsing and generation (Momma &amp; Phillips,\n2018).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chesi_C/0/1/0/all/0/1\">Cristiano Chesi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Single-dataset Experts for Multi-dataset Question Answering. (arXiv:2109.13880v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13880","description":"<p>Many datasets have been created for training reading comprehension models,\nand a natural question is whether we can combine them to build models that (1)\nperform better on all of the training datasets and (2) generalize and transfer\nbetter to new datasets. Prior work has addressed this goal by training one\nnetwork simultaneously on multiple datasets, which works well on average but is\nprone to over- or under-fitting different sub-distributions and might transfer\nworse compared to source models with more overlap with the target dataset. Our\napproach is to model multi-dataset question answering with a collection of\nsingle-dataset experts, by training a collection of lightweight,\ndataset-specific adapter modules (Houlsby et al., 2019) that share an\nunderlying Transformer model. We find that these Multi-Adapter Dataset Experts\n(MADE) outperform all our baselines in terms of in-distribution accuracy, and\nsimple methods based on parameter-averaging lead to better zero-shot\ngeneralization and few-shot transfer performance, offering a strong and\nversatile starting point for building new reading comprehension systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Friedman_D/0/1/0/all/0/1\">Dan Friedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodge_B/0/1/0/all/0/1\">Ben Dodge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Different Text-preprocessing Techniques Using The BERT Model Affect The Gender Profiling of Authors. (arXiv:2109.13890v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13890","description":"<p>Forensic author profiling plays an important role in indicating possible\nprofiles for suspects. Among the many automated solutions recently proposed for\nauthor profiling, transfer learning outperforms many other state-of-the-art\ntechniques in natural language processing. Nevertheless, the sophisticated\ntechnique has yet to be fully exploited for author profiling. At the same time,\nwhereas current methods of author profiling, all largely based on features\nengineering, have spawned significant variation in each model used, transfer\nlearning usually requires a preprocessed text to be fed into the model. We\nreviewed multiple references in the literature and determined the most common\npreprocessing techniques associated with authors' genders profiling.\nConsidering the variations in potential preprocessing techniques, we conducted\nan experimental study that involved applying five such techniques to measure\neach technique's effect while using the BERT model, chosen for being one of the\nmost-used stock pretrained models. We used the Hugging face transformer library\nto implement the code for each preprocessing case. In our five experiments, we\nfound that BERT achieves the best accuracy in predicting the gender of the\nauthor when no preprocessing technique is applied. Our best case achieved\n86.67% accuracy in predicting the gender of authors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alzahrani_E/0/1/0/all/0/1\">Esam Alzahrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jololian_L/0/1/0/all/0/1\">Leon Jololian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Temporal Information and Event Markup Language: TIE-ML Markup Process and Schema Version 1.0. (arXiv:2109.13892v1 [cs.CL])","link":"http://arxiv.org/abs/2109.13892","description":"<p>Temporal Information and Event Markup Language (TIE-ML) is a markup strategy\nand annotation schema to improve the productivity and accuracy of temporal and\nevent related annotation of corpora to facilitate machine learning based model\ntraining. For the annotation of events, temporal sequencing, and durations, it\nis significantly simpler by providing an extremely reduced tag set for just\ntemporal relations and event enumeration. In comparison to other standards, as\nfor example the Time Markup Language (TimeML), it is much easier to use by\ndropping sophisticated formalisms, theoretical concepts, and annotation\napproaches. Annotations of corpora using TimeML can be mapped to TIE-ML with a\nloss, and TIE-ML annotations can be fully mapped to TimeML with certain\nunder-specification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cavar_D/0/1/0/all/0/1\">Damir Cavar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickson_B/0/1/0/all/0/1\">Billy Dickson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aljubailan_A/0/1/0/all/0/1\">Ali Aljubailan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Soyoung Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsolved Problems in ML Safety. (arXiv:2109.13916v1 [cs.LG])","link":"http://arxiv.org/abs/2109.13916","description":"<p>Machine learning (ML) systems are rapidly increasing in size, are acquiring\nnew capabilities, and are increasingly deployed in high-stakes settings. As\nwith other powerful technologies, safety for ML should be a leading research\npriority. In response to emerging safety challenges in ML, such as those\nintroduced by recent large-scale models, we provide a new roadmap for ML Safety\nand refine the technical problems that the field needs to address. We present\nfour problems ready for research, namely withstanding hazards (\"Robustness\"),\nidentifying hazards (\"Monitoring\"), steering ML systems (\"Alignment\"), and\nreducing risks to how ML systems are handled (\"External Safety\"). Throughout,\nwe clarify each problem's motivation and provide concrete research directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulman_J/0/1/0/all/0/1\">John Schulman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Word Equations: Inherently Interpretable Sparse Word Embeddingsthrough Sparse Coding. (arXiv:2004.13847v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.13847","description":"<p>Word embeddings are a powerful natural language processing technique, but\nthey are extremely difficult to interpret. To enable interpretable NLP models,\nwe create vectors where each dimension is inherently interpretable. By\ninherently interpretable, we mean a system where each dimension is associated\nwith some human understandable hint that can describe the meaning of that\ndimension. In order to create more interpretable word embeddings, we transform\npretrained dense word embeddings into sparse embeddings. These new embeddings\nare inherently interpretable: each of their dimensions is created from and\nrepresents a natural language word or specific grammatical concept. We\nconstruct these embeddings through sparse coding, where each vector in the\nbasis set is itself a word embedding. Therefore, each dimension of our sparse\nvectors corresponds to a natural language word. We also show that models\ntrained using these sparse embeddings can achieve good performance and are more\ninterpretable in practice, including through human evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Templeton_A/0/1/0/all/0/1\">Adly Templeton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Open Knowledge Graphs Canonicalization using Variational Autoencoders. (arXiv:2012.04780v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.04780","description":"<p>Noun phrases and Relation phrases in open knowledge graphs are not\ncanonicalized, leading to an explosion of redundant and ambiguous\nsubject-relation-object triples. Existing approaches to solve this problem take\na two-step approach. First, they generate embedding representations for both\nnoun and relation phrases, then a clustering algorithm is used to group them\nusing the embeddings as features. In this work, we propose Canonicalizing Using\nVariational Autoencoders (CUVA), a joint model to learn both embeddings and\ncluster assignments in an end-to-end approach, which leads to a better vector\nrepresentation for the noun and relation phrases. Our evaluation over multiple\nbenchmarks shows that CUVA outperforms the existing state-of-the-art\napproaches. Moreover, we introduce CanonicNell, a novel dataset to evaluate\nentity canonicalization systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dash_S/0/1/0/all/0/1\">Sarthak Dash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1\">Gaetano Rossiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1\">Nandana Mihindukulasooriya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagchi_S/0/1/0/all/0/1\">Sugato Bagchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models. (arXiv:2102.07988v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2102.07988","description":"<p>Model parallelism has become a necessity for training modern large-scale deep\nlanguage models. In this work, we identify a new and orthogonal dimension from\nexisting model parallel approaches: it is possible to perform pipeline\nparallelism within a single training sequence for Transformer-based language\nmodels thanks to its autoregressive property. This enables a more fine-grained\npipeline compared with previous work. With this key idea, we design TeraPipe, a\nhigh-performance token-level pipeline parallel algorithm for synchronous\nmodel-parallel training of Transformer-based language models. We develop a\nnovel dynamic programming-based algorithm to calculate the optimal pipelining\nexecution scheme given a specific model and cluster configuration. We show that\nTeraPipe can speed up the training by 5.0x for the largest GPT-3 model with 175\nbillion parameters on an AWS cluster with 48 p3.16xlarge instances compared\nwith state-of-the-art model-parallel methods. The code for reproduction can be\nfound at https://github.com/zhuohan123/terapipe\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuohan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_S/0/1/0/all/0/1\">Siyuan Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shiyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_D/0/1/0/all/0/1\">Danyang Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving and Simplifying Pattern Exploiting Training. (arXiv:2103.11955v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.11955","description":"<p>Recently, pre-trained language models (LMs) have achieved strong performance\nwhen fine-tuned on difficult benchmarks like SuperGLUE. However, performance\ncan suffer when there are very few labeled examples available for fine-tuning.\nPattern Exploiting Training (PET) is a recent approach that leverages patterns\nfor few-shot learning. However, PET uses task-specific unlabeled data. In this\npaper, we focus on few-shot learning without any unlabeled data and introduce\nADAPET, which modifies PET's objective to provide denser supervision during\nfine-tuning. As a result, ADAPET outperforms PET on SuperGLUE without any\ntask-specific unlabeled data. Our code can be found at\nhttps://github.com/rrmenon10/ADAPET.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tam_D/0/1/0/all/0/1\">Derek Tam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_R/0/1/0/all/0/1\">Rakesh R Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shashank Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intent Recognition and Unsupervised Slot Identification for Low Resourced Spoken Dialog Systems. (arXiv:2104.01287v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.01287","description":"<p>Intent Recognition and Slot Identification are crucial components in spoken\nlanguage understanding (SLU) systems. In this paper, we present a novel\napproach towards both these tasks in the context of low resourced and unwritten\nlanguages. We present an acoustic based SLU system that converts speech to its\nphonetic transcription using a universal phone recognition system. We build a\nword-free natural language understanding module that does intent recognition\nand slot identification from these phonetic transcription. Our proposed SLU\nsystem performs competitively for resource rich scenarios and significantly\noutperforms existing approaches as the amount of available data reduces. We\nobserve more than 10% improvement for intent classification in Tamil and more\nthan 5% improvement for intent classification in Sinhala. We also present a\nnovel approach towards unsupervised slot identification using normalized\nattention scores. This approach can be used for unsupervised slot labelling,\ndata augmentation and to generate data for a new slot in a one-shot way with\nonly one speech recording\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Akshat Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_O/0/1/0/all/0/1\">Olivia Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kushwaha_A/0/1/0/all/0/1\">Akruti Kushwaha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1\">Saloni Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">William Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rallabandi_S/0/1/0/all/0/1\">Sai Krishna Rallabandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hidden Backdoors in Human-Centric Language Models. (arXiv:2105.00164v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.00164","description":"<p>Natural language processing (NLP) systems have been proven to be vulnerable\nto backdoor attacks, whereby hidden features (backdoors) are trained into a\nlanguage model and may only be activated by specific inputs (called triggers),\nto trick the model into producing unexpected behaviors. In this paper, we\ncreate covert and natural triggers for textual backdoor attacks, \\textit{hidden\nbackdoors}, where triggers can fool both modern language models and human\ninspection. We deploy our hidden backdoors through two state-of-the-art trigger\nembedding methods. The first approach via homograph replacement, embeds the\ntrigger into deep neural networks through the visual spoofing of lookalike\ncharacter replacement. The second approach uses subtle differences between text\ngenerated by language models and real natural text to produce trigger sentences\nwith correct grammar and high fluency. We demonstrate that the proposed hidden\nbackdoors can be effective across three downstream security-critical NLP tasks,\nrepresentative of modern human-centric NLP systems, including toxic comment\ndetection, neural machine translation (NMT), and question answering (QA). Our\ntwo hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at\nleast $97\\%$ with an injection rate of only $3\\%$ in toxic comment detection,\n$95.1\\%$ ASR in NMT with less than $0.5\\%$ injected data, and finally $91.12\\%$\nASR against QA updated with only 27 poisoning data samples on a model\npreviously trained with 92,024 samples (0.029\\%). We are able to demonstrate\nthe adversary's high success rate of attacks, while maintaining functionality\nfor regular users, with triggers inconspicuous by the human administrators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaofeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_T/0/1/0/all/0/1\">Tian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Benjamin Zi Hao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1\">Minhui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Haojin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jialiang Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Low-resource Reading Comprehension via Cross-lingual Transposition Rethinking. (arXiv:2107.05002v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.05002","description":"<p>Extractive Reading Comprehension (ERC) has made tremendous advances enabled\nby the availability of large-scale high-quality ERC training data. Despite of\nsuch rapid progress and widespread application, the datasets in languages other\nthan high-resource languages such as English remain scarce. To address this\nissue, we propose a Cross-Lingual Transposition ReThinking (XLTT) model by\nmodelling existing high-quality extractive reading comprehension datasets in a\nmultilingual environment. To be specific, we present multilingual adaptive\nattention (MAA) to combine intra-attention and inter-attention to learn more\ngeneral generalizable semantic and lexical knowledge from each pair of language\nfamilies. Furthermore, to make full use of existing datasets, we adopt a new\ntraining framework to train our model by calculating task-level similarities\nbetween each existing dataset and target dataset. The experimental results show\nthat our XLTT model surpasses six baselines on two multilingual ERC benchmarks,\nespecially more effective for low-resource languages with 3.9 and 4.1 average\nimprovement in F1 and EM, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Gaochen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yuxin Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fei Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bangchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hongwen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1\">Dejie Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Arabic aspect based sentiment analysis using BERT. (arXiv:2107.13290v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.13290","description":"<p>Aspect-based sentiment analysis(ABSA) is a textual analysis methodology that\ndefines the polarity of opinions on certain aspects related to specific\ntargets. The majority of research on ABSA is in English, with a small amount of\nwork available in Arabic. Most previous Arabic research has relied on deep\nlearning models that depend primarily on context-independent word embeddings\n(e.g.word2vec), where each word has a fixed representation independent of its\ncontext. This article explores the modeling capabilities of contextual\nembeddings from pre-trained language models, such as BERT, and making use of\nsentence pair input on Arabic ABSA tasks. In particular, we are building a\nsimple but effective BERT-based neural baseline to handle this task. Our BERT\narchitecture with a simple linear classification layer surpassed the\nstate-of-the-art works, according to the experimental results on the\nbenchmarked Arabic hotel reviews dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdelgwad_M/0/1/0/all/0/1\">Mohammed M.Abdelgwad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SeqScore: Addressing Barriers to Reproducible Named Entity Recognition Evaluation. (arXiv:2107.14154v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.14154","description":"<p>To address a looming crisis of unreproducible evaluation for named entity\nrecognition, we propose guidelines and introduce SeqScore, a software package\nto improve reproducibility. The guidelines we propose are extremely simple and\ncenter around transparency regarding how chunks are encoded and scored. We\ndemonstrate that despite the apparent simplicity of NER evaluation, unreported\ndifferences in the scoring procedure can result in changes to scores that are\nboth of noticeable magnitude and statistically significant. We describe\nSeqScore, which addresses many of the issues that cause replication failures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Palen_Michel_C/0/1/0/all/0/1\">Chester Palen-Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holley_N/0/1/0/all/0/1\">Nolan Holley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lignos_C/0/1/0/all/0/1\">Constantine Lignos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HeadlineCause: A Dataset of News Headlines for Detecting Causalities. (arXiv:2108.12626v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12626","description":"<p>Detecting implicit causal relations in texts is a task that requires both\ncommon sense and world knowledge. Existing datasets are focused either on\ncommonsense causal reasoning or explicit causal relations. In this work, we\npresent HeadlineCause, a dataset for detecting implicit causal relations\nbetween pairs of news headlines. The dataset includes over 5000 headline pairs\nfrom English news and over 9000 headline pairs from Russian news labeled\nthrough crowdsourcing. The pairs vary from totally unrelated or belonging to\nthe same general topic to the ones including causation and refutation\nrelations. We also present a set of models and experiments that demonstrates\nthe dataset validity, including a multilingual XLM-RoBERTa based model for\ncausality detection and a GPT-2 based model for possible effects prediction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gusev_I/0/1/0/all/0/1\">Ilya Gusev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Task Difficulty for Few-Shot Relation Extraction. (arXiv:2109.05473v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05473","description":"<p>Few-shot relation extraction (FSRE) focuses on recognizing novel relations by\nlearning with merely a handful of annotated instances. Meta-learning has been\nwidely adopted for such a task, which trains on randomly generated few-shot\ntasks to learn generic data representations. Despite impressive results\nachieved, existing models still perform suboptimally when handling hard FSRE\ntasks, where the relations are fine-grained and similar to each other. We argue\nthis is largely because existing models do not distinguish hard tasks from easy\nones in the learning process. In this paper, we introduce a novel approach\nbased on contrastive learning that learns better representations by exploiting\nrelation label information. We further design a method that allows the model to\nadaptively learn how to focus on hard tasks. Experiments on two standard\ndatasets demonstrate the effectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiale Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Something Old, Something New: Grammar-based CCG Parsing with Transformer Models. (arXiv:2109.10044v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.10044","description":"<p>This report describes the parsing problem for Combinatory Categorial Grammar\n(CCG), showing how a combination of Transformer-based neural models and a\nsymbolic CCG grammar can lead to substantial gains over existing approaches.\nThe report also documents a 20-year research program, showing how NLP methods\nhave evolved over this time. The staggering accuracy improvements provided by\nneural models for CCG parsing can be seen as a reflection of the improvements\nseen in NLP more generally. The report provides a minimal introduction to CCG\nand CCG parsing, with many pointers to the relevant literature. It then\ndescribes the CCG supertagging problem, and some recent work from Tian et al.\n(2020) which applies Transformer-based models to supertagging with great\neffect. I use this existing model to develop a CCG multitagger, which can serve\nas a front-end to an existing CCG parser. Simply using this new multitagger\nprovides substantial gains in parsing accuracy. I then show how a\nTransformer-based model from the parsing literature can be combined with the\ngrammar-based CCG parser, setting a new state-of-the-art for the CCGbank\nparsing task of almost 93% F-score for labelled dependencies, with complete\nsentence accuracies of over 50%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Clark_S/0/1/0/all/0/1\">Stephen Clark</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recursively Summarizing Books with Human Feedback. (arXiv:2109.10862v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.10862","description":"<p>A major challenge for scaling machine learning is training models to perform\ntasks that are very difficult or time-consuming for humans to evaluate. We\npresent progress on this problem on the task of abstractive summarization of\nentire fiction novels. Our method combines learning from human feedback with\nrecursive task decomposition: we use models trained on smaller parts of the\ntask to assist humans in giving feedback on the broader task. We collect a\nlarge volume of demonstrations and comparisons from human labelers, and\nfine-tune GPT-3 using behavioral cloning and reward modeling to do\nsummarization recursively. At inference time, the model first summarizes small\nsections of the book and then recursively summarizes these summaries to produce\na summary of the entire book. Our human labelers are able to supervise and\nevaluate the models quickly, despite not having read the entire books\nthemselves. Our resulting model generates sensible summaries of entire books,\neven matching the quality of human-written summaries in a few cases ($\\sim5\\%$\nof books). We achieve state-of-the-art results on the recent BookSum dataset\nfor book-length summarization. A zero-shot question-answering model using these\nsummaries achieves state-of-the-art results on the challenging NarrativeQA\nbenchmark for answering questions about books and movie scripts. We release\ndatasets of samples from our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jeff Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_L/0/1/0/all/0/1\">Long Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziegler_D/0/1/0/all/0/1\">Daniel M. Ziegler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiennon_N/0/1/0/all/0/1\">Nisan Stiennon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowe_R/0/1/0/all/0/1\">Ryan Lowe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leike_J/0/1/0/all/0/1\">Jan Leike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christiano_P/0/1/0/all/0/1\">Paul Christiano</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AES Systems Are Both Overstable And Oversensitive: Explaining Why And Proposing Defenses. (arXiv:2109.11728v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.11728","description":"<p>Deep-learning based Automatic Essay Scoring (AES) systems are being actively\nused by states and language testing agencies alike to evaluate millions of\ncandidates for life-changing decisions ranging from college applications to\nvisa approvals. However, little research has been put to understand and\ninterpret the black-box nature of deep-learning based scoring algorithms.\nPrevious studies indicate that scoring models can be easily fooled. In this\npaper, we explore the reason behind their surprising adversarial brittleness.\nWe utilize recent advances in interpretability to find the extent to which\nfeatures such as coherence, content, vocabulary, and relevance are important\nfor automated scoring mechanisms. We use this to investigate the\noversensitivity i.e., large change in output score with a little change in\ninput essay content) and overstability i.e., little change in output scores\nwith large changes in input essay content) of AES. Our results indicate that\nautoscoring models, despite getting trained as \"end-to-end\" models with rich\ncontextual embeddings such as BERT, behave like bag-of-words models. A few\nwords determine the essay score without the requirement of any context making\nthe model largely overstable. This is in stark contrast to recent probing\nstudies on pre-trained representation learning models, which show that rich\nlinguistic features such as parts-of-speech and morphology are encoded by them.\nFurther, we also find that the models have learnt dataset biases, making them\noversensitive. To deal with these issues, we propose detection-based protection\nmodels that can detect oversensitivity and overstability causing samples with\nhigh accuracies. We find that our proposed models are able to detect unusual\nattribution patterns and flag adversarial samples successfully.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_Y/0/1/0/all/0/1\">Yaman Singla Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_S/0/1/0/all/0/1\">Swapnil Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Somesh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpenViDial 2.0: A Larger-Scale, Open-Domain Dialogue Generation Dataset with Visual Contexts. (arXiv:2109.12761v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.12761","description":"<p>In order to better simulate the real human conversation process, models need\nto generate dialogue utterances based on not only preceding textual contexts\nbut also visual contexts. However, with the development of multi-modal dialogue\nlearning, the dataset scale gradually becomes a bottleneck. In this report, we\nrelease OpenViDial 2.0, a larger-scale open-domain multi-modal dialogue dataset\ncompared to the previous version OpenViDial 1.0. OpenViDial 2.0 contains a\ntotal number of 5.6 million dialogue turns extracted from either movies or TV\nseries from different resources, and each dialogue turn is paired with its\ncorresponding visual context. We hope this large-scale dataset can help\nfacilitate future researches on open-domain multi-modal dialog generation,\ne.g., multi-modal pretraining for dialogue generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yuxian Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_R/0/1/0/all/0/1\">Rongbin Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations. (arXiv:2109.13059v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.13059","description":"<p>In NLP, a large volume of tasks involve pairwise comparison between two\nsequences (e.g. sentence similarity and paraphrase identification).\nPredominantly, two formulations are used for sentence-pair tasks: bi-encoders\nand cross-encoders. Bi-encoders produce fixed-dimensional sentence\nrepresentations and are computationally efficient, however, they usually\nunderperform cross-encoders. Cross-encoders can leverage their attention heads\nto exploit inter-sentence interactions for better performance but they require\ntask fine-tuning and are computationally more expensive. In this paper, we\npresent a completely unsupervised sentence representation model termed as\nTrans-Encoder that combines the two learning paradigms into an iterative joint\nframework to simultaneously learn enhanced bi- and cross-encoders.\nSpecifically, on top of a pre-trained Language Model (PLM), we start with\nconverting it to an unsupervised bi-encoder, and then alternate between the bi-\nand cross-encoder task formulations. In each alternation, one task formulation\nwill produce pseudo-labels which are used as learning signals for the other\ntask formulation. We then propose an extension to conduct such\nself-distillation approach on multiple PLMs in parallel and use the average of\ntheir pseudo-labels for mutual-distillation. Trans-Encoder creates, to the best\nof our knowledge, the first completely unsupervised cross-encoder and also a\nstate-of-the-art unsupervised bi-encoder for sentence similarity. Both the\nbi-encoder and cross-encoder formulations of Trans-Encoder outperform recently\nproposed state-of-the-art unsupervised sentence encoders such as Mirror-BERT\nand SimCSE by up to 5% on the sentence similarity benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1\">Yunlong Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massiah_J/0/1/0/all/0/1\">Jordan Massiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_E/0/1/0/all/0/1\">Emine Yilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havrylov_S/0/1/0/all/0/1\">Serhii Havrylov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prefix-to-SQL: Text-to-SQL Generation from Incomplete User Questions. (arXiv:2109.13066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.13066","description":"<p>Existing text-to-SQL research only considers complete questions as the input,\nbut lay-users might strive to formulate a complete question. To build a smarter\nnatural language interface to database systems (NLIDB) that also processes\nincomplete questions, we propose a new task, prefix-to-SQL which takes question\nprefix from users as the input and predicts the intended SQL. We construct a\nnew benchmark called PAGSAS that contains 124K user question prefixes and the\nintended SQL for 5 sub-tasks Advising, GeoQuery, Scholar, ATIS, and Spider.\nAdditionally, we propose a new metric SAVE to measure how much effort can be\nsaved by users. Experimental results show that PAGSAS is challenging even for\nstrong baseline models such as T5. As we observe the difficulty of\nprefix-to-SQL is related to the number of omitted tokens, we incorporate\ncurriculum learning of feeding examples with an increasing number of omitted\ntokens. This improves scores on various sub-tasks by as much as 9% recall\nscores on sub-task GeoQuery in PAGSAS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_N/0/1/0/all/0/1\">Naihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shuaichen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1\">Peng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Generation of Word Problems for Academic Education via Natural Language Processing (NLP). (arXiv:2109.13123v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.13123","description":"<p>Digital learning platforms enable students to learn on a flexible and\nindividual schedule as well as providing instant feedback mechanisms. The field\nof STEM education requires students to solve numerous training exercises to\ngrasp underlying concepts. It is apparent that there are restrictions in\ncurrent online education in terms of exercise diversity and individuality. Many\nexercises show little variance in structure and content, hindering the adoption\nof abstraction capabilities by students. This thesis proposes an approach to\ngenerate diverse, context rich word problems. In addition to requiring the\ngenerated language to be grammatically correct, the nature of word problems\nimplies additional constraints on the validity of contents. The proposed\napproach is proven to be effective in generating valid word problems for\nmathematical statistics. The experimental results present a tradeoff between\ngeneration time and exercise validity. The system can easily be parametrized to\nhandle this tradeoff according to the requirements of specific use cases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Keller_S/0/1/0/all/0/1\">Stanley Uros Keller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-28T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}