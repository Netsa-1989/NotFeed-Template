{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.1","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-08-20T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks. (arXiv:2108.08375v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08375","description":"<p>This paper studies the relative importance of attention heads in\nTransformer-based models to aid their interpretability in cross-lingual and\nmulti-lingual tasks. Prior research has found that only a few attention heads\nare important in each mono-lingual Natural Language Processing (NLP) task and\npruning the remaining heads leads to comparable or improved performance of the\nmodel. However, the impact of pruning attention heads is not yet clear in\ncross-lingual and multi-lingual tasks. Through extensive experiments, we show\nthat (1) pruning a number of attention heads in a multi-lingual\nTransformer-based model has, in general, positive effects on its performance in\ncross-lingual and multi-lingual tasks and (2) the attention heads to be pruned\ncan be ranked using gradients and identified with a few trial experiments. Our\nexperiments focus on sequence labeling tasks, with potential applicability on\nother cross-lingual and multi-lingual tasks. For comprehensiveness, we examine\ntwo pre-trained multi-lingual models, namely multi-lingual BERT (mBERT) and\nXLM-R, on three tasks across 9 languages each. We also discuss the validity of\nour findings and their extensibility to truly resource-scarce languages and\nother task settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Weicheng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_R/0/1/0/all/0/1\">Renze Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lili Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Dialog History into End-to-End Spoken Language Understanding Systems. (arXiv:2108.08405v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08405","description":"<p>End-to-end spoken language understanding (SLU) systems that process\nhuman-human or human-computer interactions are often context independent and\nprocess each turn of a conversation independently. Spoken conversations on the\nother hand, are very much context dependent, and dialog history contains useful\ninformation that can improve the processing of each conversational turn. In\nthis paper, we investigate the importance of dialog history and how it can be\neffectively integrated into end-to-end SLU systems. While processing a spoken\nutterance, our proposed RNN transducer (RNN-T) based SLU model has access to\nits dialog history in the form of decoded transcripts and SLU labels of\nprevious turns. We encode the dialog history as BERT embeddings, and use them\nas an additional input to the SLU model along with the speech features for the\ncurrent utterance. We evaluate our approach on a recently released spoken\ndialog data set, the HarperValleyBank corpus. We observe significant\nimprovements: 8% for dialog action and 30% for caller intent recognition tasks,\nin comparison to a competitive context independent end-to-end baseline system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ganhotra_J/0/1/0/all/0/1\">Jatin Ganhotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1\">Samuel Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hong-Kwang J. Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Sachindra Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saon_G/0/1/0/all/0/1\">George Saon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuske_Z/0/1/0/all/0/1\">Zolt&#xe1;n T&#xfc;ske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1\">Brian Kingsbury</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FeelsGoodMan: Inferring Semantics of Twitch Neologisms. (arXiv:2108.08411v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08411","description":"<p>Twitch chats pose a unique problem in natural language understanding due to a\nlarge presence of neologisms, specifically emotes. There are a total of 8.06\nmillion emotes, over 400k of which were used in the week studied. There is\nvirtually no information on the meaning or sentiment of emotes, and with a\nconstant influx of new emotes and drift in their frequencies, it becomes\nimpossible to maintain an updated manually-labeled dataset. Our paper makes a\ntwo fold contribution. First we establish a new baseline for sentiment analysis\non Twitch data, outperforming the previous supervised benchmark by 7.9% points.\nSecondly, we introduce a simple but powerful unsupervised framework based on\nword embeddings and k-NN to enrich existing models with out-of-vocabulary\nknowledge. This framework allows us to auto-generate a pseudo-dictionary of\nemotes and we show that we can nearly match the supervised benchmark above even\nwhen injecting such emote knowledge into sentiment classifiers trained on\nextraneous datasets such as movie reviews or Twitter.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dolin_P/0/1/0/all/0/1\">Pavel Dolin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+dHauthuille_L/0/1/0/all/0/1\">Luc d&#x27;Hauthuille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vattani_A/0/1/0/all/0/1\">Andrea Vattani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MvSR-NAT: Multi-view Subset Regularization for Non-Autoregressive Machine Translation. (arXiv:2108.08447v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08447","description":"<p>Conditional masked language models (CMLM) have shown impressive progress in\nnon-autoregressive machine translation (NAT). They learn the conditional\ntranslation model by predicting the random masked subset in the target\nsentence. Based on the CMLM framework, we introduce Multi-view Subset\nRegularization (MvSR), a novel regularization method to improve the performance\nof the NAT model. Specifically, MvSR consists of two parts: (1) \\textit{shared\nmask consistency}: we forward the same target with different mask strategies,\nand encourage the predictions of shared mask positions to be consistent with\neach other. (2) \\textit{model consistency}, we maintain an exponential moving\naverage of the model weights, and enforce the predictions to be consistent\nbetween the average model and the online model. Without changing the CMLM-based\narchitecture, our approach achieves remarkable performance on three public\nbenchmarks with 0.36-1.14 BLEU gains over previous NAT models. Moreover,\ncompared with the stronger Transformer baseline, we reduce the gap to 0.01-0.44\nBLEU scores on small datasets (WMT16 RO$\\leftrightarrow$EN and IWSLT\nDE$\\rightarrow$EN).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zexian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaohui Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmenting Slot Values and Contexts for Spoken Language Understanding with Pretrained Models. (arXiv:2108.08451v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08451","description":"<p>Spoken Language Understanding (SLU) is one essential step in building a\ndialogue system. Due to the expensive cost of obtaining the labeled data, SLU\nsuffers from the data scarcity problem. Therefore, in this paper, we focus on\ndata augmentation for slot filling task in SLU. To achieve that, we aim at\ngenerating more diverse data based on existing data. Specifically, we try to\nexploit the latent language knowledge from pretrained language models by\nfinetuning them. We propose two strategies for finetuning process: value-based\nand context-based augmentation. Experimental results on two public SLU datasets\nhave shown that compared with existing data augmentation methods, our proposed\nmethod can generate more diverse sentences and significantly improve the\nperformance on SLU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haitao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1\">Lu Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_C/0/1/0/all/0/1\">Chengqing Zong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction. (arXiv:2108.08468v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08468","description":"<p>We study the problem of query attribute value extraction, which aims to\nidentify named entities from user queries as diverse surface form attribute\nvalues and afterward transform them into formally canonical forms. Such a\nproblem consists of two phases: {named entity recognition (NER)} and {attribute\nvalue normalization (AVN)}. However, existing works only focus on the NER phase\nbut neglect equally important AVN. To bridge this gap, this paper proposes a\nunified query attribute value extraction system in e-commerce search named\nQUEACO, which involves both two phases. Moreover, by leveraging large-scale\nweakly-labeled behavior data, we further improve the extraction performance\nwith less supervision cost. Specifically, for the NER phase, QUEACO adopts a\nnovel teacher-student network, where a teacher network that is trained on the\nstrongly-labeled data generates pseudo-labels to refine the weakly-labeled data\nfor training a student network. Meanwhile, the teacher network can be\ndynamically adapted by the feedback of the student's performance on\nstrongly-labeled data to maximally denoise the noisy supervisions from the weak\nlabels. For the AVN phase, we also leverage the weakly-labeled\nquery-to-attribute behavior data to normalize surface form attribute values\nfrom queries into canonical forms from products. Extensive experiments on a\nreal-world large-scale E-commerce dataset demonstrate the effectiveness of\nQUEACO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Danqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1\">Tianyu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1\">Chen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tony Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yiwei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Model Augmented Relevance Score. (arXiv:2108.08485v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08485","description":"<p>Although automated metrics are commonly used to evaluate NLG systems, they\noften correlate poorly with human judgements. Newer metrics such as BERTScore\nhave addressed many weaknesses in prior metrics such as BLEU and ROUGE, which\nrely on n-gram matching. These newer methods, however, are still limited in\nthat they do not consider the generation context, so they cannot properly\nreward generated text that is correct but deviates from the given reference.\n</p>\n<p>In this paper, we propose Language Model Augmented Relevance Score (MARS), a\nnew context-aware metric for NLG evaluation. MARS leverages off-the-shelf\nlanguage models, guided by reinforcement learning, to create augmented\nreferences that consider both the generation context and available human\nreferences, which are then used as additional references to score generated\ntext. Compared with seven existing metrics in three common NLG tasks, MARS not\nonly achieves higher correlation with human reference judgements, but also\ndifferentiates well-formed candidates from adversarial samples to a larger\ndegree.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attentive fine-tuning of Transformers for Translation of low-resourced languages @LoResMT 2021. (arXiv:2108.08556v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08556","description":"<p>This paper reports the Machine Translation (MT) systems submitted by the\nIIITT team for the English-&gt;Marathi and English-&gt;Irish language pairs LoResMT\n2021 shared task. The task focuses on getting exceptional translations for\nrather low-resourced languages like Irish and Marathi. We fine-tune IndicTrans,\na pretrained multilingual NMT model for English-&gt;Marathi, using external\nparallel corpus as input for additional training. We have used a pretrained\nHelsinki-NLP Opus MT English-&gt;Irish model for the latter language pair. Our\napproaches yield relatively promising results on the BLEU metrics. Under the\nteam name IIITT, our systems ranked 1, 1, and 2 in English-&gt;Marathi,\nIrish-&gt;English, and English-&gt;Irish, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Puranik_K/0/1/0/all/0/1\">Karthik Puranik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hande_A/0/1/0/all/0/1\">Adeep Hande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1\">Ruba Priyadharshini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durairaj_T/0/1/0/all/0/1\">Thenmozi Durairaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sampath_A/0/1/0/all/0/1\">Anbukkarasi Sampath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thamburaj_K/0/1/0/all/0/1\">Kingston Pal Thamburaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1\">Bharathi Raja Chakravarthi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Contextualization using Top-k Operators for Question Answering over Knowledge Graphs. (arXiv:2108.08597v1 [cs.IR])","link":"http://arxiv.org/abs/2108.08597","description":"<p>Answering complex questions over knowledge bases (KB-QA) faces huge input\ndata with billions of facts, involving millions of entities and thousands of\npredicates. For efficiency, QA systems first reduce the answer search space by\nidentifying a set of facts that is likely to contain all answers and relevant\ncues. The most common technique is to apply named entity disambiguation (NED)\nsystems to the question, and retrieve KB facts for the disambiguated entities.\nThis work presents ECQA, an efficient method that prunes irrelevant parts of\nthe search space using KB-aware signals. ECQA is based on top-k query\nprocessing over score-ordered lists of KB items that combine signals about\nlexical matching, relevance to the question, coherence among candidate items,\nand connectivity in the KB graph. Experiments with two recent QA benchmarks\ndemonstrate the superiority of ECQA over state-of-the-art baselines with\nrespect to answer presence, size of the search space, and runtimes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Christmann_P/0/1/0/all/0/1\">Philipp Christmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rishiraj Saha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weikum_G/0/1/0/all/0/1\">Gerhard Weikum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text. (arXiv:2108.08614v1 [cs.IR])","link":"http://arxiv.org/abs/2108.08614","description":"<p>Question answering over knowledge graphs and other RDF data has been greatly\nadvanced, with a number of good systems providing crisp answers for natural\nlanguage questions or telegraphic queries. Some of these systems incorporate\ntextual sources as additional evidence for the answering process, but cannot\ncompute answers that are present in text alone. Conversely, systems from the IR\nand NLP communities have addressed QA over text, but barely utilize semantic\ndata and knowledge. This paper presents the first QA system that can seamlessly\noperate over RDF datasets and text corpora, or both together, in a unified\nframework. Our method, called UNIQORN, builds a context graph on the fly, by\nretrieving question-relevant triples from the RDF data and/or the text corpus,\nwhere the latter case is handled by automatic information extraction. The\nresulting graph is typically rich but highly noisy. UNIQORN copes with this\ninput by advanced graph algorithms for Group Steiner Trees, that identify the\nbest answer candidates in the context graph. Experimental results on several\nbenchmarks of complex questions with multiple entities and relations, show that\nUNIQORN, an unsupervised method with only five parameters, produces results\ncomparable to the state-of-the-art on KGs, text corpora, and heterogeneous\nsources. The graph-based methodology provides user-interpretable evidence for\nthe complete answering process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pramanik_S/0/1/0/all/0/1\">Soumajit Pramanik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1\">Jesujoba Alabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rishiraj Saha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weikum_G/0/1/0/all/0/1\">Gerhard Weikum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Grained Element Identification in Complaint Text of Internet Fraud. (arXiv:2108.08676v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08676","description":"<p>Existing system dealing with online complaint provides a final decision\nwithout explanations. We propose to analyse the complaint text of internet\nfraud in a fine-grained manner. Considering the complaint text includes\nmultiple clauses with various functions, we propose to identify the role of\neach clause and classify them into different types of fraud element. We\nconstruct a large labeled dataset originated from a real finance service\nplatform. We build an element identification model on top of BERT and propose\nadditional two modules to utilize the context of complaint text for better\nelement label classification, namely, global context encoder and label refiner.\nExperimental results show the effectiveness of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jingchao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Heng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liaosa Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1\">Weiqiang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Legislative Recipe: Syntax for Machine-Readable Legislation. (arXiv:2108.08678v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08678","description":"<p>Legal interpretation is a linguistic venture. In judicial opinions, for\nexample, courts are often asked to interpret the text of statutes and\nlegislation. As time has shown, this is not always as easy as it sounds.\nMatters can hinge on vague or inconsistent language and, under the surface,\nhuman biases can impact the decision-making of judges. This raises an important\nquestion: what if there was a method of extracting the meaning of statutes\nconsistently? That is, what if it were possible to use machines to encode\nlegislation in a mathematically precise form that would permit clearer\nresponses to legal questions? This article attempts to unpack the notion of\nmachine-readability, providing an overview of both its historical and recent\ndevelopments. The paper will reflect on logic syntax and symbolic language to\nassess the capacity and limits of representing legal knowledge. In doing so,\nthe paper seeks to move beyond existing literature to discuss the implications\nof various approaches to machine-readable legislation. Importantly, this study\nhopes to highlight the challenges encountered in this burgeoning ecosystem of\nmachine-readable legislation against existing human-readable counterparts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Megan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_B/0/1/0/all/0/1\">Bryan Wilson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Language-Image Pre-training for the Italian Language. (arXiv:2108.08688v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08688","description":"<p>CLIP (Contrastive Language-Image Pre-training) is a very recent multi-modal\nmodel that jointly learns representations of images and texts. The model is\ntrained on a massive amount of English data and shows impressive performance on\nzero-shot classification tasks. Training the same model on a different language\nis not trivial, since data in other languages might be not enough and the model\nneeds high-quality translations of the texts to guarantee a good performance.\nIn this paper, we present the first CLIP model for the Italian Language\n(CLIP-Italian), trained on more than 1.4 million image-text pairs. Results show\nthat CLIP-Italian outperforms the multilingual CLIP model on the tasks of image\nretrieval and zero-shot classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1\">Federico Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attanasio_G/0/1/0/all/0/1\">Giuseppe Attanasio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pisoni_R/0/1/0/all/0/1\">Raphael Pisoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Terragni_S/0/1/0/all/0/1\">Silvia Terragni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarti_G/0/1/0/all/0/1\">Gabriele Sarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakshmi_S/0/1/0/all/0/1\">Sri Lakshmi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Czech News Dataset for Semanic Textual Similarity. (arXiv:2108.08708v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08708","description":"<p>This paper describes a novel dataset consisting of sentences with semantic\nsimilarity annotations. The data originate from the journalistic domain in the\nCzech language. We describe the process of collecting and annotating the data\nin detail. The dataset contains 138,556 human annotations divided into train\nand test sets. In total, 485 journalism students participated in the creation\nprocess. To increase the reliability of the test set, we compute the annotation\nas an average of 9 individual annotations. We evaluate the quality of the\ndataset by measuring inter and intra annotation annotators' agreements. Beside\nagreement numbers, we provide detailed statistics of the collected dataset. We\nconclude our paper with a baseline experiment of building a system for\npredicting the semantic similarity of sentences. Due to the massive number of\ntraining annotations (116 956), the model can perform significantly better than\nan average annotator (0,92 versus 0,86 of Person's correlation coefficients).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sido_J/0/1/0/all/0/1\">Jakub Sido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sejak_M/0/1/0/all/0/1\">Michal Sej&#xe1;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prazak_O/0/1/0/all/0/1\">Ond&#x159;ej Pra&#x17e;&#xe1;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konopik_M/0/1/0/all/0/1\">Miloslav Konop&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moravec_V/0/1/0/all/0/1\">V&#xe1;clav Moravec</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DESYR: Definition and Syntactic Representation Based Claim Detection on the Web. (arXiv:2108.08759v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08759","description":"<p>The formulation of a claim rests at the core of argument mining. To demarcate\nbetween a claim and a non-claim is arduous for both humans and machines, owing\nto latent linguistic variance between the two and the inadequacy of extensive\ndefinition-based formalization. Furthermore, the increase in the usage of\nonline social media has resulted in an explosion of unsolicited information on\nthe web presented as informal text. To account for the aforementioned, in this\npaper, we proposed DESYR. It is a framework that intends on annulling the said\nissues for informal web-based text by leveraging a combination of hierarchical\nrepresentation learning (dependency-inspired Poincare embedding),\ndefinition-based alignment, and feature projection. We do away with fine-tuning\ncomputer-heavy language models in favor of fabricating a more domain-centric\nbut lighter approach. Experimental results indicate that DESYR builds upon the\nstate-of-the-art system across four benchmark claim datasets, most of which\nwere constructed with informal texts. We see an increase of 3 claim-F1 points\non the LESA-Twitter dataset, an increase of 1 claim-F1 point and 9 macro-F1\npoints on the Online Comments(OC) dataset, an increase of 24 claim-F1 points\nand 17 macro-F1 points on the Web Discourse(WD) dataset, and an increase of 8\nclaim-F1 points and 5 macro-F1 points on the Micro Texts(MT) dataset. We also\nperform an extensive analysis of the results. We make a 100-D pre-trained\nversion of our Poincare-variant along with the source code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sundriyal_M/0/1/0/all/0/1\">Megha Sundriyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Parantak Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1\">Shubhashis Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval. (arXiv:2108.08787v1 [cs.CL])","link":"http://arxiv.org/abs/2108.08787","description":"<p>We present Mr. TyDi, a multi-lingual benchmark dataset for mono-lingual\nretrieval in eleven typologically diverse languages, designed to evaluate\nranking with learned dense representations. The goal of this resource is to\nspur research in dense retrieval techniques in non-English languages, motivated\nby recent observations that existing techniques for representation learning\nperform poorly when applied to out-of-distribution data. As a starting point,\nwe provide zero-shot baselines for this new dataset based on a multi-lingual\nadaptation of DPR that we call \"mDPR\". Experiments show that although the\neffectiveness of mDPR is much lower than BM25, dense representations\nnevertheless appear to provide valuable relevance signals, improving BM25\nresults in sparse-dense hybrids. In addition to analyses of our results, we\nalso discuss future challenges and present a research agenda in multi-lingual\ndense retrieval. Mr. TyDi can be downloaded at\nhttps://github.com/castorini/mr.tydi.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xueguang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1\">Peng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"e-SNLI-VE: Corrected Visual-Textual Entailment with Natural Language Explanations. (arXiv:2004.03744v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.03744","description":"<p>The recently proposed SNLI-VE corpus for recognising visual-textual\nentailment is a large, real-world dataset for fine-grained multimodal\nreasoning. However, the automatic way in which SNLI-VE has been assembled (via\ncombining parts of two related datasets) gives rise to a large number of errors\nin the labels of this corpus. In this paper, we first present a data collection\neffort to correct the class with the highest error rate in SNLI-VE. Secondly,\nwe re-evaluate an existing model on the corrected corpus, which we call\nSNLI-VE-2.0, and provide a quantitative comparison with its performance on the\nnon-corrected corpus. Thirdly, we introduce e-SNLI-VE, which appends\nhuman-written natural language explanations to SNLI-VE-2.0. Finally, we train\nmodels that learn from these explanations at training time, and output such\nexplanations at testing time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Do_V/0/1/0/all/0/1\">Virginie Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camburu_O/0/1/0/all/0/1\">Oana-Maria Camburu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1\">Zeynep Akata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pretrained Transformers for Text Ranking: BERT and Beyond. (arXiv:2010.06467v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2010.06467","description":"<p>The goal of text ranking is to generate an ordered list of texts retrieved\nfrom a corpus in response to a query. Although the most common formulation of\ntext ranking is search, instances of the task can also be found in many natural\nlanguage processing applications. This survey provides an overview of text\nranking with neural network architectures known as transformers, of which BERT\nis the best-known example. The combination of transformers and self-supervised\npretraining has been responsible for a paradigm shift in natural language\nprocessing (NLP), information retrieval (IR), and beyond. In this survey, we\nprovide a synthesis of existing work as a single point of entry for\npractitioners who wish to gain a better understanding of how to apply\ntransformers to text ranking problems and researchers who wish to pursue work\nin this area. We cover a wide range of modern techniques, grouped into two\nhigh-level categories: transformer models that perform reranking in multi-stage\narchitectures and dense retrieval techniques that perform ranking directly.\nThere are two themes that pervade our survey: techniques for handling long\ndocuments, beyond typical sentence-by-sentence processing in NLP, and\ntechniques for addressing the tradeoff between effectiveness (i.e., result\nquality) and efficiency (e.g., query latency, model and index size). Although\ntransformer architectures and pretraining techniques are recent innovations,\nmany aspects of how they are applied to text ranking are relatively well\nunderstood and represent mature techniques. However, there remain many open\nresearch questions, and thus in addition to laying out the foundations of\npretrained transformers for text ranking, this survey also attempts to\nprognosticate where the field is heading.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1\">Rodrigo Nogueira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yates_A/0/1/0/all/0/1\">Andrew Yates</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning From How Human Correct. (arXiv:2102.00225v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.00225","description":"<p>In industry NLP application, our manually labeled data has a certain number\nof noisy data. We present a simple method to find the noisy data and relabel\nthem manually, meanwhile we collect the correction information. Then we present\nnovel method to incorporate the human correction information into deep learning\nmodel. Human know how to correct noisy data. So the correction information can\nbe inject into deep learning model. We do the experiment on our own text\nclassification dataset, which is manually labeled, because we relabel the noisy\ndata in our dataset for our industry application. The experiment result shows\nthat our method improve the classification accuracy from 91.7% to 92.5%. The\n91.7% baseline is based on BERT training on the corrected dataset, which is\nhard to surpass.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Document Representations by Generating Pseudo Query Embeddings for Dense Retrieval. (arXiv:2105.03599v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2105.03599","description":"<p>Recently, the retrieval models based on dense representations have been\ngradually applied in the first stage of the document retrieval tasks, showing\nbetter performance than traditional sparse vector space models. To obtain high\nefficiency, the basic structure of these models is Bi-encoder in most cases.\nHowever, this simple structure may cause serious information loss during the\nencoding of documents since the queries are agnostic. To address this problem,\nwe design a method to mimic the queries on each of the documents by an\niterative clustering process and represent the documents by multiple pseudo\nqueries (i.e., the cluster centroids). To boost the retrieval process using\napproximate nearest neighbor search library, we also optimize the matching\nfunction with a two-step score calculation procedure. Experimental results on\nseveral popular ranking and QA datasets show that our model can achieve\nstate-of-the-art results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hongyin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xingwu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Beihong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stylized Story Generation with Style-Guided Planning. (arXiv:2105.08625v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.08625","description":"<p>Current storytelling systems focus more ongenerating stories with coherent\nplots regard-less of the narration style, which is impor-tant for controllable\ntext generation. There-fore, we propose a new task, stylized story gen-eration,\nnamely generating stories with speci-fied style given a leading context. To\ntacklethe problem, we propose a novel generationmodel that first plans the\nstylized keywordsand then generates the whole story with theguidance of the\nkeywords. Besides, we pro-pose two automatic metrics to evaluate theconsistency\nbetween the generated story andthe specified style. Experiments\ndemonstratesthat our model can controllably generateemo-tion-driven\norevent-driven stories based onthe ROCStories dataset (Mostafazadeh et\nal.,2016). Our study presents insights for stylizedstory generation in further\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1\">Xiangzhe Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jialiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tung_Z/0/1/0/all/0/1\">Ziquan Tung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1\">Jian Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation. (arXiv:2106.04632v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2106.04632","description":"<p>Most existing video-and-language (VidL) research focuses on a single dataset,\nor multiple datasets of a single task. In reality, a truly useful VidL system\nis expected to be easily generalizable to diverse tasks, domains, and datasets.\nTo facilitate the evaluation of such systems, we introduce Video-And-Language\nUnderstanding Evaluation (VALUE) benchmark, an assemblage of 11 VidL datasets\nover 3 popular tasks: (i) text-to-video retrieval; (ii) video question\nanswering; and (iii) video captioning. VALUE benchmark aims to cover a broad\nrange of video genres, video lengths, data volumes, and task difficulty levels.\nRather than focusing on single-channel videos with visual information only,\nVALUE promotes models that leverage information from both video frames and\ntheir associated subtitles, as well as models that share knowledge across\nmultiple tasks. We evaluate various baseline methods with and without\nlarge-scale VidL pre-training, and systematically investigate the impact of\nvideo input channels, fusion methods, and different video representations. We\nalso study the transferability between tasks, and conduct multi-task learning\nunder different settings. The significant gap between our best model and human\nperformance calls for future study for advanced VidL models. VALUE is available\nat https://value-benchmark.github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Licheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1\">Rohit Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara Lee Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"More but Correct: Generating Diversified and Entity-revised Medical Response. (arXiv:2108.01266v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.01266","description":"<p>Medical Dialogue Generation (MDG) is intended to build a medical dialogue\nsystem for intelligent consultation, which can communicate with patients in\nreal-time, thereby improving the efficiency of clinical diagnosis with broad\napplication prospects. This paper presents our proposed framework for the\nChinese MDG organized by the 2021 China conference on knowledge graph and\nsemantic computing (CCKS) competition, which requires generating\ncontext-consistent and medically meaningful responses conditioned on the\ndialogue history. In our framework, we propose a pipeline system composed of\nentity prediction and entity-aware dialogue generation, by adding predicted\nentities to the dialogue model with a fusion mechanism, thereby utilizing\ninformation from different sources. At the decoding stage, we propose a new\ndecoding mechanism named Entity-revised Diverse Beam Search (EDBS) to improve\nentity correctness and promote the length and quality of the final response.\nThe proposed method wins both the CCKS and the International Conference on\nLearning Representations (ICLR) 2021 Workshop Machine Learning for Preventing\nand Combating Pandemics (MLPCP) Track 1 Entity-aware MED competitions, which\ndemonstrate the practicality and effectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Encheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongru Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Y/0/1/0/all/0/1\">Yixuan Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Bin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shutao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yongping Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Meiling Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Single and Multiple Representations in Dense Passage Retrieval. (arXiv:2108.06279v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2108.06279","description":"<p>The advent of contextualised language models has brought gains in search\neffectiveness, not just when applied for re-ranking the output of classical\nweighting models such as BM25, but also when used directly for passage indexing\nand retrieval, a technique which is called dense retrieval. In the existing\nliterature in neural ranking, two dense retrieval families have become\napparent: single representation, where entire passages are represented by a\nsingle embedding (usually BERT's [CLS] token, as exemplified by the recent ANCE\napproach), or multiple representations, where each token in a passage is\nrepresented by its own embedding (as exemplified by the recent ColBERT\napproach). These two families have not been directly compared. However, because\nof the likely importance of dense retrieval moving forward, a clear\nunderstanding of their advantages and disadvantages is paramount. To this end,\nthis paper contributes a direct study on their comparative effectiveness,\nnoting situations where each method under/over performs w.r.t. each other, and\nw.r.t. a BM25 baseline. We observe that, while ANCE is more efficient than\nColBERT in terms of response time and memory usage, multiple representations\nare statistically more effective than the single representations for MAP and\nMRR@10. We also show that multiple representations obtain better improvements\nthan single representations for queries that are the hardest for BM25, as well\nas for definitional queries, and those with complex information needs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1\">Craig Macdonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonellotto_N/0/1/0/all/0/1\">Nicola Tonellotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1\">Iadh Ounis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Annotation Guidelines for the Turku Paraphrase Corpus. (arXiv:2108.07499v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.07499","description":"<p>This document describes the annotation guidelines used to construct the Turku\nParaphrase Corpus. These guidelines were developed together with the corpus\nannotation, revising and extending the guidelines regularly during the\nannotation work. Our paraphrase annotation scheme uses the base scale 1-4,\nwhere labels 1 and 2 are used for negative candidates (not paraphrases), while\nlabels 3 and 4 are paraphrases at least in the given context if not everywhere.\nIn addition to base labeling, the scheme is enriched with additional\nsubcategories (flags) for categorizing different types of paraphrases inside\nthe two positive labels, making the annotation scheme suitable for more\nfine-grained paraphrase categorization. The annotation scheme is used to\nannotate over 100,000 Finnish paraphrase pairs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kanerva_J/0/1/0/all/0/1\">Jenna Kanerva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginter_F/0/1/0/all/0/1\">Filip Ginter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_L/0/1/0/all/0/1\">Li-Hsin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastas_I/0/1/0/all/0/1\">Iiro Rastas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skantsi_V/0/1/0/all/0/1\">Valtteri Skantsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kilpelainen_J/0/1/0/all/0/1\">Jemina Kilpel&#xe4;inen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kupari_H/0/1/0/all/0/1\">Hanna-Mari Kupari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piirto_A/0/1/0/all/0/1\">Aurora Piirto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saarni_J/0/1/0/all/0/1\">Jenna Saarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sevon_M/0/1/0/all/0/1\">Maija Sev&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarkka_O/0/1/0/all/0/1\">Otto Tarkka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-08-19T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/"}}]}]}