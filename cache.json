{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.1","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-02T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Working Memory Connections for LSTM. (arXiv:2109.00020v1 [cs.LG])","link":"http://arxiv.org/abs/2109.00020","description":"<p>Recurrent Neural Networks with Long Short-Term Memory (LSTM) make use of\ngating mechanisms to mitigate exploding and vanishing gradients when learning\nlong-term dependencies. For this reason, LSTMs and other gated RNNs are widely\nadopted, being the standard de facto for many sequence modeling tasks. Although\nthe memory cell inside the LSTM contains essential information, it is not\nallowed to influence the gating mechanism directly. In this work, we improve\nthe gate potential by including information coming from the internal cell\nstate. The proposed modification, named Working Memory Connection, consists in\nadding a learnable nonlinear projection of the cell content into the network\ngates. This modification can fit into the classical LSTM gates without any\nassumption on the underlying task, being particularly effective when dealing\nwith longer sequences. Previous research effort in this direction, which goes\nback to the early 2000s, could not bring a consistent improvement over vanilla\nLSTM. As part of this paper, we identify a key issue tied to previous\nconnections that heavily limits their effectiveness, hence preventing a\nsuccessful integration of the knowledge coming from the internal cell state. We\nshow through extensive experimental evaluation that Working Memory Connections\nconstantly improve the performance of LSTMs on a variety of tasks. Numerical\nresults suggest that the cell state contains useful information that is worth\nincluding in the gate structure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Landi_F/0/1/0/all/0/1\">Federico Landi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1\">Marcella Cornia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1\">Rita Cucchiara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine-Learning media bias. (arXiv:2109.00024v1 [cs.CY])","link":"http://arxiv.org/abs/2109.00024","description":"<p>We present an automated method for measuring media bias. Inferring which\nnewspaper published a given article, based only on the frequencies with which\nit uses different phrases, leads to a conditional probability distribution\nwhose analysis lets us automatically map newspapers and phrases into a bias\nspace. By analyzing roughly a million articles from roughly a hundred\nnewspapers for bias in dozens of news topics, our method maps newspapers into a\ntwo-dimensional bias landscape that agrees well with previous bias\nclassifications based on human judgement. One dimension can be interpreted as\ntraditional left-right bias, the other as establishment bias. This means that\nalthough news bias is inherently political, its measurement need not be.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DAlonzo_S/0/1/0/all/0/1\">Samantha D&#x27;Alonzo</a> (MIT), <a href=\"http://arxiv.org/find/cs/1/au:+Tegmark_M/0/1/0/all/0/1\">Max Tegmark</a> (MIT)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sense representations for Portuguese: experiments with sense embeddings and deep neural language models. (arXiv:2109.00025v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00025","description":"<p>Sense representations have gone beyond word representations like Word2Vec,\nGloVe and FastText and achieved innovative performance on a wide range of\nnatural language processing tasks. Although very useful in many applications,\nthe traditional approaches for generating word embeddings have a strict\ndrawback: they produce a single vector representation for a given word ignoring\nthe fact that ambiguous words can assume different meanings. In this paper, we\nexplore unsupervised sense representations which, different from traditional\nword embeddings, are able to induce different senses of a word by analyzing its\ncontextual semantics in a text. The unsupervised sense representations\ninvestigated in this paper are: sense embeddings and deep neural language\nmodels. We present the first experiments carried out for generating sense\nembeddings for Portuguese. Our experiments show that the sense embedding model\n(Sense2vec) outperformed traditional word embeddings in syntactic and semantic\nanalogies task, proving that the language resource generated here can improve\nthe performance of NLP tasks in Portuguese. We also evaluated the performance\nof pre-trained deep neural language models (ELMo and BERT) in two transfer\nlearning approaches: feature based and fine-tuning, in the semantic textual\nsimilarity task. Our experiments indicate that the fine tuned Multilingual and\nPortuguese BERT language models were able to achieve better accuracy than the\nELMo model and baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1\">Jessica Rodrigues da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caseli_H/0/1/0/all/0/1\">Helena de Medeiros Caseli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentence Bottleneck Autoencoders from Transformer Language Models. (arXiv:2109.00055v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00055","description":"<p>Representation learning for text via pretraining a language model on a large\ncorpus has become a standard starting point for building NLP systems. This\napproach stands in contrast to autoencoders, also trained on raw text, but with\nthe objective of learning to encode each input as a vector that allows full\nreconstruction. Autoencoders are attractive because of their latent space\nstructure and generative properties. We therefore explore the construction of a\nsentence-level autoencoder from a pretrained, frozen transformer language\nmodel. We adapt the masked language modeling objective as a generative,\ndenoising one, while only training a sentence bottleneck and a single-layer\nmodified transformer decoder. We demonstrate that the sentence representations\ndiscovered by our model achieve better quality than previous methods that\nextract representations from pretrained transformers on text similarity tasks,\nstyle transfer (an example of controlled generation), and single-sentence\nclassification tasks in the GLUE benchmark, while using fewer parameters than\nlarge pretrained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Montero_I/0/1/0/all/0/1\">Ivan Montero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_N/0/1/0/all/0/1\">Nikolaos Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effectiveness of Deep Networks in NLP using BiDAF as an example architecture. (arXiv:2109.00074v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00074","description":"<p>Question Answering with NLP has progressed through the evolution of advanced\nmodel architectures like BERT and BiDAF and earlier word, character, and\ncontext-based embeddings. As BERT has leapfrogged the accuracy of models, an\nelement of the next frontier can be the introduction of deep networks and an\neffective way to train them. In this context, I explored the effectiveness of\ndeep networks focussing on the model encoder layer of BiDAF. BiDAF with its\nheterogeneous layers provides the opportunity not only to explore the\neffectiveness of deep networks but also to evaluate whether the refinements\nmade in lower layers are additive to the refinements made in the upper layers\nof the model architecture. I believe the next greatest model in NLP will in\nfact fold in a solid language modeling like BERT with a composite architecture\nwhich will bring in refinements in addition to generic language modeling and\nwill have a more extensive layered architecture. I experimented with the Bypass\nnetwork, Residual Highway network, and DenseNet architectures. In addition, I\nevaluated the effectiveness of ensembling the last few layers of the network. I\nalso studied the difference character embeddings make in adding them to the\nword embeddings, and whether the effects are additive with deep networks. My\nstudies indicate that deep networks are in fact effective in giving a boost.\nAlso, the refinements in the lower layers like embeddings are passed on\nadditively to the gains made through deep networks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Soumyendu Sarkar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interactive Machine Comprehension with Dynamic Knowledge Graphs. (arXiv:2109.00077v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00077","description":"<p>Interactive machine reading comprehension (iMRC) is machine comprehension\ntasks where knowledge sources are partially observable. An agent must interact\nwith an environment sequentially to gather necessary knowledge in order to\nanswer a question. We hypothesize that graph representations are good inductive\nbiases, which can serve as an agent's memory mechanism in iMRC tasks. We\nexplore four different categories of graphs that can capture text information\nat various levels. We describe methods that dynamically build and update these\ngraphs during information gathering, as well as neural models to encode graph\nrepresentations in RL agents. Extensive experiments on iSQuAD suggest that\ngraph representations can result in significant performance improvements for RL\nagents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xingdi Yuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MergeBERT: Program Merge Conflict Resolution via Neural Transformers. (arXiv:2109.00084v1 [cs.SE])","link":"http://arxiv.org/abs/2109.00084","description":"<p>Collaborative software development is an integral part of the modern software\ndevelopment life cycle, essential to the success of large-scale software\nprojects. When multiple developers make concurrent changes around the same\nlines of code, a merge conflict may occur. Such conflicts stall pull requests\nand continuous integration pipelines for hours to several days, seriously\nhurting developer productivity.\n</p>\n<p>In this paper, we introduce MergeBERT, a novel neural program merge framework\nbased on the token-level three-way differencing and a transformer encoder\nmodel. Exploiting restricted nature of merge conflict resolutions, we\nreformulate the task of generating the resolution sequence as a classification\ntask over a set of primitive merge patterns extracted from real-world merge\ncommit data.\n</p>\n<p>Our model achieves 64--69% precision of merge resolution synthesis, yielding\nnearly a 2x performance improvement over existing structured and neural program\nmerge tools. Finally, we demonstrate versatility of our model, which is able to\nperform program merge in a multilingual setting with Java, JavaScript,\nTypeScript, and C# programming languages, generalizing zero-shot to unseen\nlanguages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Svyatkovskiy_A/0/1/0/all/0/1\">Alexey Svyatkovskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mytcowicz_T/0/1/0/all/0/1\">Todd Mytcowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghorbani_N/0/1/0/all/0/1\">Negar Ghorbani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhoury_S/0/1/0/all/0/1\">Sarah Fakhoury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinella_E/0/1/0/all/0/1\">Elizabeth Dinella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bird_C/0/1/0/all/0/1\">Christian Bird</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahiri_S/0/1/0/all/0/1\">Shuvendu Lahiri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"It's not Rocket Science : Interpreting Figurative Language in Narratives. (arXiv:2109.00087v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00087","description":"<p>Figurative language is ubiquitous in English. Yet, the vast majority of NLP\nresearch focuses on literal language. Existing text representations by design\nrely on compositionality, while figurative language is often non-compositional.\nIn this paper, we study the interpretation of two non-compositional figurative\nlanguages (idioms and similes). We collected datasets of fictional narratives\ncontaining a figurative expression along with crowd-sourced plausible and\nimplausible continuations relying on the correct interpretation of the\nexpression. We then trained models to choose or generate the plausible\ncontinuation. Our experiments show that models based solely on pre-trained\nlanguage models perform substantially worse than humans on these tasks. We\nadditionally propose knowledge-enhanced models, adopting human strategies for\ninterpreting figurative language: inferring meaning from the context and\nrelying on the constituent word's literal meanings. The knowledge-enhanced\nmodels improve the performance on both the discriminative and generative tasks,\nfurther bridging the gap from human performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarty_T/0/1/0/all/0/1\">Tuhin Chakrabarty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FinQA: A Dataset of Numerical Reasoning over Financial Data. (arXiv:2109.00122v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00122","description":"<p>The sheer volume of financial statements makes it difficult for humans to\naccess and analyze a business's financials. Robust numerical reasoning likewise\nfaces unique challenges in this domain. In this work, we focus on answering\ndeep questions over financial data, aiming to automate the analysis of a large\ncorpus of financial documents. In contrast to existing tasks on general domain,\nthe finance domain includes complex numerical reasoning and understanding of\nheterogeneous representations. To facilitate analytical progress, we propose a\nnew large-scale dataset, FinQA, with Question-Answering pairs over Financial\nreports, written by financial experts. We also annotate the gold reasoning\nprograms to ensure full explainability. We further introduce baselines and\nconduct comprehensive experiments in our dataset. The results demonstrate that\npopular, large, pre-trained models fall far short of expert humans in acquiring\nfinance knowledge and in complex multi-step numerical reasoning on that\nknowledge. Our dataset -- the first of its kind -- should therefore enable\nsignificant, new community research into complex application domains. The\ndataset and code are publicly available\\url{https://github.com/czyssrs/FinQA}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smiley_C/0/1/0/all/0/1\">Charese Smiley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sameena Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borova_I/0/1/0/all/0/1\">Iana Borova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langdon_D/0/1/0/all/0/1\">Dylan Langdon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moussa_R/0/1/0/all/0/1\">Reema Moussa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beane_M/0/1/0/all/0/1\">Matt Beane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Ting-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Routledge_B/0/1/0/all/0/1\">Bryan Routledge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Unsupervised Method for Building Sentence Simplification Corpora in Multiple Languages. (arXiv:2109.00165v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00165","description":"<p>The availability of parallel sentence simplification (SS) is scarce for\nneural SS modelings. We propose an unsupervised method to build SS corpora from\nlarge-scale bilingual translation corpora, alleviating the need for SS\nsupervised corpora. Our method is motivated by the following two findings:\nneural machine translation model usually tends to generate more high-frequency\ntokens and the difference of text complexity levels exists between the source\nand target language of a translation corpus. By taking the pair of the source\nsentences of translation corpus and the translations of their references in a\nbridge language, we can construct large-scale pseudo parallel SS data. Then, we\nkeep these sentence pairs with a higher complexity difference as SS sentence\npairs. The building SS corpora with an unsupervised approach can satisfy the\nexpectations that the aligned sentences preserve the same meanings and have\ndifference in text complexity levels. Experimental results show that SS methods\ntrained by our corpora achieve the state-of-the-art results and significantly\noutperform the results on English benchmark WikiLarge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xinyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_J/0/1/0/all/0/1\">Jipeng Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yunhao Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Have Been Learned & What Should Be Learned? An Empirical Study of How to Selectively Augment Text for Classification. (arXiv:2109.00175v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00175","description":"<p>Text augmentation techniques are widely used in text classification problems\nto improve the performance of classifiers, especially in low-resource\nscenarios. Whilst lots of creative text augmentation methods have been\ndesigned, they augment the text in a non-selective manner, which means the less\nimportant or noisy words have the same chances to be augmented as the\ninformative words, and thereby limits the performance of augmentation. In this\nwork, we systematically summarize three kinds of role keywords, which have\ndifferent functions for text classification, and design effective methods to\nextract them from the text. Based on these extracted role keywords, we propose\nSTA (Selective Text Augmentation) to selectively augment the text, where the\ninformative, class-indicating words are emphasized but the irrelevant or noisy\nwords are diminished. Extensive experiments on four English and Chinese text\nclassification benchmark datasets demonstrate that STA can substantially\noutperform the non-selective text augmentation methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1\">Biyang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Sonqiao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hailiang Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Problem Learning: Towards the Free Will of Machines. (arXiv:2109.00177v1 [cs.AI])","link":"http://arxiv.org/abs/2109.00177","description":"<p>A machine intelligence pipeline usually consists of six components: problem,\nrepresentation, model, loss, optimizer and metric. Researchers have worked hard\ntrying to automate many components of the pipeline. However, one key component\nof the pipeline--problem definition--is still left mostly unexplored in terms\nof automation. Usually, it requires extensive efforts from domain experts to\nidentify, define and formulate important problems in an area. However,\nautomatically discovering research or application problems for an area is\nbeneficial since it helps to identify valid and potentially important problems\nhidden in data that are unknown to domain experts, expand the scope of tasks\nthat we can do in an area, and even inspire completely new findings.\n</p>\n<p>This paper describes Problem Learning, which aims at learning to discover and\ndefine valid and ethical problems from data or from the machine's interaction\nwith the environment. We formalize problem learning as the identification of\nvalid and ethical problems in a problem space and introduce several possible\napproaches to problem learning. In a broader sense, problem learning is an\napproach towards the free will of intelligent machines. Currently, machines are\nstill limited to solving the problems defined by humans, without the ability or\nflexibility to freely explore various possible problems that are even unknown\nto humans. Though many machine learning techniques have been developed and\nintegrated into intelligent systems, they still focus on the means rather than\nthe purpose in that machines are still solving human defined problems. However,\nproposing good problems is sometimes even more important than solving problems,\nbecause a good problem can help to inspire new ideas and gain deeper\nunderstandings. The paper also discusses the ethical implications of problem\nlearning under the background of Responsible AI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapted End-to-End Coreference Resolution System for Anaphoric Identities in Dialogues. (arXiv:2109.00185v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00185","description":"<p>We present an effective system adapted from the end-to-end neural coreference\nresolution model, targeting on the task of anaphora resolution in dialogues.\nThree aspects are specifically addressed in our approach, including the support\nof singletons, encoding speakers and turns throughout dialogue interactions,\nand knowledge transfer utilizing existing resources. Despite the simplicity of\nour adaptation strategies, they are shown to bring significant impact to the\nfinal performance, with up to 27 F1 improvement over the baseline. Our final\nsystem ranks the 1st place on the leaderboard of the anaphora resolution track\nin the CRAC 2021 shared task, and achieves the best evaluation results on all\nfour datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Predictive Uncertainty under Distributional Shift on Dialogue Dataset. (arXiv:2109.00186v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00186","description":"<p>In open-domain dialogues, predictive uncertainties are mainly evaluated in a\ndomain shift setting to cope with out-of-distribution inputs. However, in\nreal-world conversations, there could be more extensive distributional shifted\ninputs than the out-of-distribution. To evaluate this, we first propose two\nmethods, Unknown Word (UW) and Insufficient Context (IC), enabling gradual\ndistributional shifts by corruption on the dialogue dataset. We then\ninvestigate the effect of distributional shifts on accuracy and calibration.\nOur experiments show that the performance of existing uncertainty estimation\nmethods consistently degrades with intensifying the shift. The results suggest\nthat the proposed methods could be useful for evaluating the calibration of\ndialogue systems under distributional shifts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nyoungwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">ChaeHun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Ho-Jin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting Cross-Lingual Transfer via Self-Learning with Uncertainty Estimation. (arXiv:2109.00194v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00194","description":"<p>Recent multilingual pre-trained language models have achieved remarkable\nzero-shot performance, where the model is only finetuned on one source language\nand directly evaluated on target languages. In this work, we propose a\nself-learning framework that further utilizes unlabeled data of target\nlanguages, combined with uncertainty estimation in the process to select\nhigh-quality silver labels. Three different uncertainties are adapted and\nanalyzed specifically for the cross lingual transfer: Language\nHeteroscedastic/Homoscedastic Uncertainty (LEU/LOU), Evidential Uncertainty\n(EVI). We evaluate our framework with uncertainties on two cross-lingual tasks\nincluding Named Entity Recognition (NER) and Natural Language Inference (NLI)\ncovering 40 languages in total, which outperforms the baselines significantly\nby 10 F1 on average for NER and 2.5 accuracy score for NLI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xujiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pattern-based Acquisition of Scientific Entities from Scholarly Article Titles. (arXiv:2109.00199v1 [cs.IR])","link":"http://arxiv.org/abs/2109.00199","description":"<p>We describe a rule-based approach for the automatic acquisition of scientific\nentities from scholarly article titles. Two observations motivated the\napproach: (i) noting the concentration of an article's contribution information\nin its title; and (ii) capturing information pattern regularities via a system\nof rules that alleviate the human annotation task in creating gold standards\nthat annotate single instances at a time. We identify a set of lexico-syntactic\npatterns that are easily recognizable, that occur frequently, and that\ngenerally indicates the scientific entity type of interest about the scholarly\ncontribution.\n</p>\n<p>A subset of the acquisition algorithm is implemented for article titles in\nthe Computational Linguistics (CL) scholarly domain. The tool called\nORKG-Title-Parser, in its first release, identifies the following six concept\ntypes of scientific terminology from the CL paper titles, viz. research\nproblem, solution, resource, language, tool, and method. It has been\nempirically evaluated on a collection of 50,237 titles that cover nearly all\narticles in the ACL Anthology. It has extracted 19,799 research problems;\n18,111 solutions; 20,033 resources; 1,059 languages; 6,878 tools; and 21,687\nmethods at an average extraction precision of 75%. The code and related data\nresources are publicly available at\nhttps://gitlab.com/TIBHannover/orkg/orkg-title-parser.\n</p>\n<p>Finally, in the article, we discuss extensions and applications to areas such\nas scholarly knowledge graph (SKG) creation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1\">Jennifer D&#x27;Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1\">Soeren Auer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dataset for Identification of Homophobia and Transophobia in Multilingual YouTube Comments. (arXiv:2109.00227v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00227","description":"<p>The increased proliferation of abusive content on social media platforms has\na negative impact on online users. The dread, dislike, discomfort, or mistrust\nof lesbian, gay, transgender or bisexual persons is defined as\nhomophobia/transphobia. Homophobic/transphobic speech is a type of offensive\nlanguage that may be summarized as hate speech directed toward LGBT+ people,\nand it has been a growing concern in recent years. Online\nhomophobia/transphobia is a severe societal problem that can make online\nplatforms poisonous and unwelcome to LGBT+ people while also attempting to\neliminate equality, diversity, and inclusion. We provide a new hierarchical\ntaxonomy for online homophobia and transphobia, as well as an expert-labelled\ndataset that will allow homophobic/transphobic content to be automatically\nidentified. We educated annotators and supplied them with comprehensive\nannotation rules because this is a sensitive issue, and we previously\ndiscovered that untrained crowdsourcing annotators struggle with diagnosing\nhomophobia due to cultural and other prejudices. The dataset comprises 15,141\nannotated multilingual comments. This paper describes the process of building\nthe dataset, qualitative analysis of data, and inter-annotator agreement. In\naddition, we create baseline models for the dataset. To the best of our\nknowledge, our dataset is the first such dataset created. Warning: This paper\ncontains explicit statements of homophobia, transphobia, stereotypes which may\nbe distressing to some readers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1\">Bharathi Raja Chakravarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1\">Ruba Priyadharshini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponnusamy_R/0/1/0/all/0/1\">Rahul Ponnusamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaresan_P/0/1/0/all/0/1\">Prasanna Kumar Kumaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sampath_K/0/1/0/all/0/1\">Kayalvizhi Sampath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thenmozhi_D/0/1/0/all/0/1\">Durairaj Thenmozhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thangasamy_S/0/1/0/all/0/1\">Sathiyaraj Thangasamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nallathambi_R/0/1/0/all/0/1\">Rajendran Nallathambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCrae_J/0/1/0/all/0/1\">John Phillip McCrae</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OptAGAN: Entropy-based finetuning on text VAE-GAN. (arXiv:2109.00239v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00239","description":"<p>Transfer learning through large pre-trained models has changed the landscape\nof current applications in natural language processing (NLP). Recently Optimus,\na variational autoencoder (VAE) which combines two pre-trained models, BERT and\nGPT-2, has been released, and its combination with generative adversial\nnetworks (GANs) has been shown to produce novel, yet very human-looking text.\nThe Optimus and GANs combination avoids the troublesome application of GANs to\nthe discrete domain of text, and prevents the exposure bias of standard maximum\nlikelihood methods. We combine the training of GANs in the latent space, with\nthe finetuning of the decoder of Optimus for single word generation. This\napproach lets us model both the high-level features of the sentences, and the\nlow-level word-by-word generation. We finetune using reinforcement learning\n(RL) by exploiting the structure of GPT-2 and by adding entropy-based\nintrinsically motivated rewards to balance between quality and diversity. We\nbenchmark the results of the VAE-GAN model, and show the improvements brought\nby our RL finetuning on three widely used datasets for text generation, with\nresults that greatly surpass the current state-of-the-art for the quality of\nthe generated texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tirotta_P/0/1/0/all/0/1\">Paolo Tirotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lodi_S/0/1/0/all/0/1\">Stefano Lodi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Cross-lingual Sentence Representations with Dual Momentum Contrast. (arXiv:2109.00253v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00253","description":"<p>In this paper, we propose to align sentence representations from different\nlanguages into a unified embedding space, where semantic similarities (both\ncross-lingual and monolingual) can be computed with a simple dot product.\nPre-trained language models are fine-tuned with the translation ranking task.\nExisting work (Feng et al., 2020) uses sentences within the same batch as\nnegatives, which can suffer from the issue of easy negatives. We adapt MoCo (He\net al., 2020) to further improve the quality of alignment. As the experimental\nresults show, the sentence representations produced by our model achieve the\nnew state-of-the-art on several tasks, including Tatoeba en-zh similarity\nsearch (Artetxe and Schwenk, 2019b), BUCC en-zh bitext mining, and semantic\ntextual similarity on 7 datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wei Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingming Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extracting all Aspect-polarity Pairs Jointly in a Text with Relation Extraction Approach. (arXiv:2109.00256v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00256","description":"<p>Extracting aspect-polarity pairs from texts is an important task of\nfine-grained sentiment analysis. While the existing approaches to this task\nhave gained many progresses, they are limited at capturing relationships among\naspect-polarity pairs in a text, thus degrading the extraction performance.\nMoreover, the existing state-of-the-art approaches, namely token-based\nse-quence tagging and span-based classification, have their own defects such as\npolarity inconsistency resulted from separately tagging tokens in the former\nand the heterogeneous categorization in the latter where aspect-related and\npolarity-related labels are mixed. In order to remedy the above defects,\nin-spiring from the recent advancements in relation extraction, we propose to\ngenerate aspect-polarity pairs directly from a text with relation extraction\ntechnology, regarding aspect-pairs as unary relations where aspects are\nenti-ties and the corresponding polarities are relations. Based on the\nperspective, we present a position- and aspect-aware sequence2sequence model\nfor joint extraction of aspect-polarity pairs. The model is characterized with\nits ability to capture not only relationships among aspect-polarity pairs in a\ntext through the sequence decoding, but also correlations between an aspect and\nits polarity through the position- and aspect-aware attentions. The\nexperi-ments performed on three benchmark datasets demonstrate that our model\noutperforms the existing state-of-the-art approaches, making significant\nim-provement over them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bu_L/0/1/0/all/0/1\">Lingmei Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yongmei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhonghua Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Structured Context and High-Coverage Grammar for Conversational Question Answering over Knowledge Graphs. (arXiv:2109.00269v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00269","description":"<p>We tackle the problem of weakly-supervised conversational Question Answering\nover large Knowledge Graphs using a neural semantic parsing approach. We\nintroduce a new Logical Form (LF) grammar that can model a wide range of\nqueries on the graph while remaining sufficiently simple to generate\nsupervision data efficiently. Our Transformer-based model takes a JSON-like\nstructure as input, allowing us to easily incorporate both Knowledge Graph and\nconversational contexts. This structured input is transformed to lists of\nembeddings and then fed to standard attention layers. We validate our approach,\nboth in terms of grammar coverage and LF execution accuracy, on two publicly\navailable datasets, CSQA and ConvQuestions, both grounded in Wikidata. On CSQA,\nour approach increases the coverage from $80\\%$ to $96.2\\%$, and the LF\nexecution accuracy from $70.6\\%$ to $75.6\\%$, with respect to previous\nstate-of-the-art results. On ConvQuestions, we achieve competitive results with\nrespect to the state-of-the-art.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marion_P/0/1/0/all/0/1\">Pierre Marion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowak_P/0/1/0/all/0/1\">Pawe&#x142; Krzysztof Nowak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piccinno_F/0/1/0/all/0/1\">Francesco Piccinno</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Discovering Representation Sprachbund For Multilingual Pre-Training. (arXiv:2109.00271v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00271","description":"<p>Multilingual pre-trained models have demonstrated their effectiveness in many\nmultilingual NLP tasks and enabled zero-shot or few-shot transfer from\nhigh-resource languages to low resource ones. However, due to significant\ntypological differences and contradictions between some languages, such models\nusually perform poorly on many languages and cross-lingual settings, which\nshows the difficulty of learning a single model to handle massive diverse\nlanguages well at the same time. To alleviate this issue, we present a new\nmultilingual pre-training pipeline. We propose to generate language\nrepresentation from multilingual pre-trained models and conduct linguistic\nanalysis to show that language representation similarity reflect linguistic\nsimilarity from multiple perspectives, including language family, geographical\nsprachbund, lexicostatistics and syntax. Then we cluster all the target\nlanguages into multiple groups and name each group as a representation\nsprachbund. Thus, languages in the same representation sprachbund are supposed\nto boost each other in both pre-training and fine-tuning as they share rich\nlinguistic similarity. We pre-train one multilingual model for each\nrepresentation sprachbund. Experiments are conducted on cross-lingual\nbenchmarks and significant improvements are achieved compared to strong\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yimin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaobo Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muzio_A/0/1/0/all/0/1\">Alexandre Muzio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassan_H/0/1/0/all/0/1\">Hany Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Houqiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Ming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Discourse Analysis of Covid-19 in Persian Twitter Social Networks Using Graph Mining and Natural Language Processing. (arXiv:2109.00298v1 [cs.SI])","link":"http://arxiv.org/abs/2109.00298","description":"<p>One of the new scientific ways of understanding discourse dynamics is\nanalyzing the public data of social networks. This research's aim is\nPost-structuralist Discourse Analysis (PDA) of Covid-19 phenomenon (inspired by\nLaclau and Mouffe's Discourse Theory) by using Intelligent Data Mining for\nPersian Society. The examined big data is five million tweets from 160,000\nusers of the Persian Twitter network to compare two discourses. Besides\nanalyzing the tweet texts individually, a social network graph database has\nbeen created based on retweets relationships. We use the VoteRank algorithm to\nintroduce and rank people whose posts become word of mouth, provided that the\ntotal information spreading scope is maximized over the network. These users\nare also clustered according to their word usage pattern (the Gaussian Mixture\nModel is used). The constructed discourse of influential spreaders is compared\nto the most active users. This analysis is done based on Covid-related posts\nover eight episodes. Also, by relying on the statistical content analysis and\npolarity of tweet words, discourse analysis is done for the whole mentioned\nsubpopulations, especially for the top individuals. The most important result\nof this research is that the Twitter subjects' discourse construction is\ngovernment-based rather than community-based. The analyzed Iranian society does\nnot consider itself responsible for the Covid-19 wicked problem, does not\nbelieve in participation, and expects the government to solve all problems. The\nmost active and most influential users' similarity is that political, national,\nand critical discourse construction is the predominant one. In addition to the\nadvantages of its research methodology, it is necessary to pay attention to the\nstudy's limitations. Suggestion for future encounters of Iranian society with\nsimilar crises is given.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shokrollahi_O/0/1/0/all/0/1\">Omid Shokrollahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_N/0/1/0/all/0/1\">Niloofar Hashemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mohammad Dehghani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"$\\infty$-former: Infinite Memory Transformer. (arXiv:2109.00301v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00301","description":"<p>Transformers struggle when attending to long contexts, since the amount of\ncomputation grows with the context length, and therefore they cannot model\nlong-term memories effectively. Several variations have been proposed to\nalleviate this problem, but they all have a finite memory capacity, being\nforced to drop old information. In this paper, we propose the $\\infty$-former,\nwhich extends the vanilla transformer with an unbounded long-term memory. By\nmaking use of a continuous-space attention mechanism to attend over the\nlong-term memory, the $\\infty$-former's attention complexity becomes\nindependent of the context length. Thus, it is able to model arbitrarily long\ncontexts and maintain \"sticky memories\" while keeping a fixed computation\nbudget. Experiments on a synthetic sorting task demonstrate the ability of the\n$\\infty$-former to retain information from long sequences. We also perform\nexperiments on language modeling, by training a model from scratch and by\nfine-tuning a pre-trained language model, which show benefits of unbounded\nlong-term memories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martins_P/0/1/0/all/0/1\">Pedro Henrique Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinho_Z/0/1/0/all/0/1\">Zita Marinho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring deep learning methods for recognizing rare diseases and their clinical manifestations from texts. (arXiv:2109.00343v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00343","description":"<p>Although rare diseases are characterized by low prevalence, approximately 300\nmillion people are affected by a rare disease. The early and accurate diagnosis\nof these conditions is a major challenge for general practitioners, who do not\nhave enough knowledge to identify them. In addition to this, rare diseases\nusually show a wide variety of manifestations, which might make the diagnosis\neven more difficult. A delayed diagnosis can negatively affect the patient's\nlife. Therefore, there is an urgent need to increase the scientific and medical\nknowledge about rare diseases. Natural Language Processing (NLP) and Deep\nLearning can help to extract relevant information about rare diseases to\nfacilitate their diagnosis and treatments. The paper explores the use of\nseveral deep learning techniques such as Bidirectional Long Short Term Memory\n(BiLSTM) networks or deep contextualized word representations based on\nBidirectional Encoder Representations from Transformers (BERT) to recognize\nrare diseases and their clinical manifestations (signs and symptoms) in the\nRareDis corpus. This corpus contains more than 5,000 rare diseases and almost\n6,000 clinical manifestations. BioBERT, a domain-specific language\nrepresentation based on BERT and trained on biomedical corpora, obtains the\nbest results. In particular, this model obtains an F1-score of 85.2% for rare\ndiseases, outperforming all the other models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Segura_Bedmar_I/0/1/0/all/0/1\">Isabel Segura-Bedmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camino_Perdonas_D/0/1/0/all/0/1\">David Camino-Perdonas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrero_Aspizua_S/0/1/0/all/0/1\">Sara Guerrero-Aspizua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConRPG: Paraphrase Generation using Contexts as Regularizer. (arXiv:2109.00363v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00363","description":"<p>A long-standing issue with paraphrase generation is how to obtain reliable\nsupervision signals. In this paper, we propose an unsupervised paradigm for\nparaphrase generation based on the assumption that the probabilities of\ngenerating two sentences with the same meaning given the same context should be\nthe same. Inspired by this fundamental idea, we propose a pipelined system\nwhich consists of paraphrase candidate generation based on contextual language\nmodels, candidate filtering using scoring functions, and paraphrase model\ntraining based on the selected candidates. The proposed paradigm offers merits\nover existing paraphrase generation methods: (1) using the context regularizer\non meanings, the model is able to generate massive amounts of high-quality\nparaphrase pairs; and (2) using human-interpretable scoring functions to select\nparaphrase pairs from candidates, the proposed framework provides a channel for\ndevelopers to intervene with the data generation process, leading to a more\ncontrollable model. Experimental results across different tasks and datasets\ndemonstrate that the effectiveness of the proposed model in both supervised and\nunsupervised setups.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yuxian Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1\">Xiang Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1\">Qinghong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+fan_C/0/1/0/all/0/1\">Chun fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chronic Pain and Language: A Topic Modelling Approach to Personal Pain Descriptions. (arXiv:2109.00402v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00402","description":"<p>Chronic pain is recognized as a major health problem, with impacts not only\nat the economic, but also at the social, and individual levels. Being a private\nand subjective experience, it is impossible to externally and impartially\nexperience, describe, and interpret chronic pain as a purely noxious stimulus\nthat would directly point to a causal agent and facilitate its mitigation,\ncontrary to acute pain, the assessment of which is usually straightforward.\nVerbal communication is, thus, key to convey relevant information to health\nprofessionals that would otherwise not be accessible to external entities,\nnamely, intrinsic qualities about the painful experience and the patient. We\npropose and discuss a topic modelling approach to recognize patterns in verbal\ndescriptions of chronic pain, and use these patterns to quantify and qualify\nexperiences of pain. Our approaches allow for the extraction of novel insights\non chronic pain experiences from the obtained topic models and latent spaces.\nWe argue that our results are clinically relevant for the assessment and\nmanagement of chronic pain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nunes_D/0/1/0/all/0/1\">Diogo A. P. Nunes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matos_D/0/1/0/all/0/1\">David Martins de Matos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_J/0/1/0/all/0/1\">Joana Ferreira Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neto_F/0/1/0/all/0/1\">Fani Neto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Multimodal Fusion with Hierarchical Mutual Information Maximization for Multimodal Sentiment Analysis. (arXiv:2109.00412v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00412","description":"<p>In multimodal sentiment analysis (MSA), the performance of a model highly\ndepends on the quality of synthesized embeddings. These embeddings are\ngenerated from the upstream process called multimodal fusion, which aims to\nextract and combine the input unimodal raw data to produce a richer multimodal\nrepresentation. Previous work either back-propagates the task loss or\nmanipulates the geometric property of feature spaces to produce favorable\nfusion results, which neglects the preservation of critical task-related\ninformation that flows from input to the fusion results. In this work, we\npropose a framework named MultiModal InfoMax (MMIM), which hierarchically\nmaximizes the Mutual Information (MI) in unimodal input pairs (inter-modality)\nand between multimodal fusion result and unimodal input in order to maintain\ntask-related information through multimodal fusion. The framework is jointly\ntrained with the main task (MSA) to improve the performance of the downstream\nMSA task. To address the intractable issue of MI bounds, we further formulate a\nset of computationally simple parametric and non-parametric methods to\napproximate their truth value. Experimental results on the two widely used\ndatasets demonstrate the efficacy of our approach. The implementation of this\nwork is publicly available at\nhttps://github.com/declare-lab/Multimodal-Infomax.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Masked Adversarial Generation for Neural Machine Translation. (arXiv:2109.00417v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00417","description":"<p>Attacking Neural Machine Translation models is an inherently combinatorial\ntask on discrete sequences, solved with approximate heuristics. Most methods\nuse the gradient to attack the model on each sample independently. Instead of\nmechanically applying the gradient, could we learn to produce meaningful\nadversarial attacks ? In contrast to existing approaches, we learn to attack a\nmodel by training an adversarial generator based on a language model. We\npropose the Masked Adversarial Generation (MAG) model, that learns to perturb\nthe translation model throughout the training process. The experiments show\nthat it improves the robustness of machine translation models, while being\nfaster than competing methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Idrissi_B/0/1/0/all/0/1\">Badr Youbi Idrissi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clinchant_S/0/1/0/all/0/1\">St&#xe9;phane Clinchant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"M^2-MedDialog: A Dataset and Benchmarks for Multi-domain Multi-service Medical Dialogues. (arXiv:2109.00430v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00430","description":"<p>Medical dialogue systems (MDSs) aim to assist doctors and patients with a\nrange of professional medical services, i.e., diagnosis, consultation, and\ntreatment. However, one-stop MDS is still unexplored because: (1) no dataset\nhas so large-scale dialogues contains both multiple medical services and\nfine-grained medical labels (i.e., intents, slots, values); (2) no model has\naddressed a MDS based on multiple-service conversations in a unified framework.\nIn this work, we first build a Multiple-domain Multiple-service medical\ndialogue (M^2-MedDialog)dataset, which contains 1,557 conversations between\ndoctors and patients, covering 276 types of diseases, 2,468 medical entities,\nand 3 specialties of medical services. To the best of our knowledge, it is the\nonly medical dialogue dataset that includes both multiple medical services and\nfine-grained medical labels. Then, we formulate a one-stop MDS as a\nsequence-to-sequence generation problem. We unify a MDS with causal language\nmodeling and conditional causal language modeling, respectively. Specifically,\nwe employ several pretrained models (i.e., BERT-WWM, BERT-MED, GPT2, and MT5)\nand their variants to get benchmarks on M^2-MedDialog dataset. We also propose\npseudo labeling and natural perturbation methods to expand M2-MedDialog dataset\nand enhance the state-of-the-art pretrained models. We demonstrate the results\nachieved by the benchmarks so far through extensive experiments on\nM2-MedDialog. We release the dataset, the code, as well as the evaluation\nscripts to facilitate future research in this important research direction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_G/0/1/0/all/0/1\">Guojun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jiahuan Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhumin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Huasheng Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Position Masking for Improved Layout-Aware Document Understanding. (arXiv:2109.00442v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00442","description":"<p>Natural language processing for document scans and PDFs has the potential to\nenormously improve the efficiency of business processes. Layout-aware word\nembeddings such as LayoutLM have shown promise for classification of and\ninformation extraction from such documents. This paper proposes a new\npre-training task called that can improve performance of layout-aware word\nembeddings that incorporate 2-D position embeddings. We compare models\npre-trained with only language masking against models pre-trained with both\nlanguage masking and position masking, and we find that position masking\nimproves performance by over 5% on a form understanding task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Anik Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finegan_Dollak_C/0/1/0/all/0/1\">Catherine Finegan-Dollak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1\">Ashish Verma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Capturing Stance Dynamics in Social Media: Open Challenges and Research Directions. (arXiv:2109.00475v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00475","description":"<p>Social media platforms provide a goldmine for mining public opinion on issues\nof wide societal interest. Opinion mining is a problem that can be\noperationalised by capturing and aggregating the stance of individual social\nmedia posts as supporting, opposing or being neutral towards the issue at hand.\nWhile most prior work in stance detection has investigated datasets with\nlimited time coverage, interest in investigating longitudinal datasets has\nrecently increased. Evolving dynamics in linguistic and behavioural patterns\nobserved in new data require in turn adapting stance detection systems to deal\nwith the changes. In this survey paper, we investigate the intersection between\ncomputational linguistics and the temporal evolution of human communication in\ndigital media. We perform a critical review in emerging research considering\ndynamics, exploring different semantic and pragmatic factors that impact\nlinguistic data in general, and stance particularly. We further discuss current\ndirections in capturing stance dynamics in social media. We organise the\nchallenges of dealing with stance dynamics, identify open challenges and\ndiscuss future directions in three key dimensions: utterance, context and\ninfluence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alkhalifa_R/0/1/0/all/0/1\">Rabab Alkhalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Survey of Low-Resource Machine Translation. (arXiv:2109.00486v1 [cs.CL])","link":"http://arxiv.org/abs/2109.00486","description":"<p>We present a survey covering the state of the art in low-resource machine\ntranslation. There are currently around 7000 languages spoken in the world and\nalmost all language pairs lack significant resources for training machine\ntranslation models. There has been increasing interest in research addressing\nthe challenge of producing useful translation models when very little\ntranslated training data is available. We present a high level summary of this\ntopical field and provide an overview of best practices.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Haddow_B/0/1/0/all/0/1\">Barry Haddow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bawden_R/0/1/0/all/0/1\">Rachel Bawden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barone_A/0/1/0/all/0/1\">Antonio Valerio Miceli Barone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helcl_J/0/1/0/all/0/1\">Jind&#x159;ich Helcl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Iterative Knowledge Transfer Network with Routing for Aspect-based Sentiment Analysis. (arXiv:2004.01935v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.01935","description":"<p>Aspect-based sentiment analysis (ABSA) mainly involves three subtasks: aspect\nterm extraction, opinion term extraction, and aspect-level sentiment\nclassification, which are typically handled in a separate or joint manner.\nHowever, previous approaches do not well exploit the interactive relations\namong three subtasks and do not pertinently leverage the easily available\ndocument-level labeled domain/sentiment knowledge, which restricts their\nperformances. To address these issues, we propose a novel Iterative\nMulti-Knowledge Transfer Network (IMKTN) for end-to-end ABSA. For one thing,\nthrough the interactive correlations between the ABSA subtasks, our IMKTN\ntransfers the task-specific knowledge from any two of the three subtasks to\nanother one at the token level by utilizing a well-designed routing algorithm,\nthat is, any two of the three subtasks will help the third one. For another,\nour IMKTN pertinently transfers the document-level knowledge, i.e.,\ndomain-specific and sentiment-related knowledge, to the aspect-level subtasks\nto further enhance the corresponding performance. Experimental results on three\nbenchmark datasets demonstrate the effectiveness and superiority of our\napproach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yunlong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speaker anonymisation using the McAdams coefficient. (arXiv:2011.01130v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2011.01130","description":"<p>Anonymisation has the goal of manipulating speech signals in order to degrade\nthe reliability of automatic approaches to speaker recognition, while\npreserving other aspects of speech, such as those relating to intelligibility\nand naturalness. This paper reports an approach to anonymisation that, unlike\nother current approaches, requires no training data, is based upon well-known\nsignal processing techniques and is both efficient and effective. The proposed\nsolution uses the McAdams coefficient to transform the spectral envelope of\nspeech signals. Results derived using common VoicePrivacy 2020 databases and\nprotocols show that random, optimised transformations can outperform competing\nsolutions in terms of anonymisation while causing only modest, additional\ndegradations to intelligibility, even in the case of a semi-informed privacy\nadversary.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Patino_J/0/1/0/all/0/1\">Jose Patino</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tomashenko_N/0/1/0/all/0/1\">Natalia Tomashenko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Todisco_M/0/1/0/all/0/1\">Massimiliano Todisco</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nautsch_A/0/1/0/all/0/1\">Andreas Nautsch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Evans_N/0/1/0/all/0/1\">Nicholas Evans</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Evolution of Word Order. (arXiv:2101.09579v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.09579","description":"<p>Most natural languages have a predominant or fixed word order. For example in\nEnglish the word order is usually Subject-Verb-Object. This work attempts to\nexplain this phenomenon as well as other typological findings regarding word\norder from a functional perspective. In particular, we examine whether fixed\nword order provides a functional advantage, explaining why these languages are\nprevalent. To this end, we consider an evolutionary model of language and\ndemonstrate, both theoretically and using genetic algorithms, that a language\nwith a fixed word order is optimal. We also show that adding information to the\nsentence, such as case markers and noun-verb distinction, reduces the need for\nfixed word order, in accordance with the typological findings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rejwan_I/0/1/0/all/0/1\">Idan Rejwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emotion Dynamics in Movie Dialogues. (arXiv:2103.01345v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.01345","description":"<p>Emotion dynamics is a framework for measuring how an individual's emotions\nchange over time. It is a powerful tool for understanding how we behave and\ninteract with the world. In this paper, we introduce a framework to track\nemotion dynamics through one's utterances. Specifically we introduce a number\nof utterance emotion dynamics (UED) metrics inspired by work in Psychology. We\nuse this approach to trace emotional arcs of movie characters. We analyze\nthousands of such character arcs to test hypotheses that inform our broader\nunderstanding of stories. Notably, we show that there is a tendency for\ncharacters to use increasingly more negative words and become increasingly\nemotionally discordant with each other until about 90 percent of the narrative\nlength. UED also has applications in behavior studies, social sciences, and\npublic health.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hipson_W/0/1/0/all/0/1\">Will E. Hipson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Data-Centric Framework for Composable NLP Workflows. (arXiv:2103.01834v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.01834","description":"<p>Empirical natural language processing (NLP) systems in application domains\n(e.g., healthcare, finance, education) involve interoperation among multiple\ncomponents, ranging from data ingestion, human annotation, to text retrieval,\nanalysis, generation, and visualization. We establish a unified open-source\nframework to support fast development of such sophisticated NLP workflows in a\ncomposable manner. The framework introduces a uniform data representation to\nencode heterogeneous results by a wide range of NLP tasks. It offers a large\nrepository of processors for NLP tasks, visualization, and annotation, which\ncan be easily assembled with full interoperability under the unified\nrepresentation. The highly extensible framework allows plugging in custom\nprocessors from external off-the-shelf NLP and deep learning libraries. The\nwhole framework is delivered through two modularized yet integratable\nopen-source projects, namely Forte (for workflow infrastructure and NLP\nfunction processors) and Stave (for user interaction, visualization, and\nannotation).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1\">Guanxiong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bukkittu_A/0/1/0/all/0/1\">Avinash Bukkittu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Mansi Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Pengzhi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1\">Atif Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singhavi_S/0/1/0/all/0/1\">Swapnil Singhavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zecong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haoran Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1\">Teruko Mitamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SciCo: Hierarchical Cross-Document Coreference for Scientific Concepts. (arXiv:2104.08809v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08809","description":"<p>Determining coreference of concept mentions across multiple documents is a\nfundamental task in natural language understanding. Previous work on\ncross-document coreference resolution (CDCR) typically considers mentions of\nevents in the news, which seldom involve abstract technical concepts that are\nprevalent in science and technology. These complex concepts take diverse or\nambiguous forms and have many hierarchical levels of granularity (e.g., tasks\nand subtasks), posing challenges for CDCR. We present a new task of\nHierarchical CDCR (H-CDCR) with the goal of jointly inferring coreference\nclusters and hierarchy between them. We create SciCo, an expert-annotated\ndataset for H-CDCR in scientific papers, 3X larger than the prominent ECB+\nresource. We study strong baseline models that we customize for H-CDCR, and\nhighlight challenges for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1\">Arie Cattan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_S/0/1/0/all/0/1\">Sophie Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1\">Daniel Weld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-training for Spoken Language Understanding with Joint Textual and Phonetic Representation Learning. (arXiv:2104.10357v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.10357","description":"<p>In the traditional cascading architecture for spoken language understanding\n(SLU), it has been observed that automatic speech recognition errors could be\ndetrimental to the performance of natural language understanding. End-to-end\n(E2E) SLU models have been proposed to directly map speech input to desired\nsemantic frame with a single model, hence mitigating ASR error propagation.\nRecently, pre-training technologies have been explored for these E2E models. In\nthis paper, we propose a novel joint textual-phonetic pre-training approach for\nlearning spoken language representations, aiming at exploring the full\npotentials of phonetic information to improve SLU robustness to ASR errors. We\nexplore phoneme labels as high-level speech features, and design and compare\npre-training tasks based on conditional masked language model objectives and\ninter-sentence relation objectives. We also investigate the efficacy of\ncombining textual and phonetic information during fine-tuning. Experimental\nresults on spoken language understanding benchmarks, Fluent Speech Commands and\nSNIPS, show that the proposed approach significantly outperforms strong\nbaseline models and improves robustness of spoken language understanding to ASR\nerrors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-NERD: A Few-Shot Named Entity Recognition Dataset. (arXiv:2105.07464v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.07464","description":"<p>Recently, considerable literature has grown up around the theme of few-shot\nnamed entity recognition (NER), but little published benchmark data\nspecifically focused on the practical and challenging task. Current approaches\ncollect existing supervised NER datasets and re-organize them to the few-shot\nsetting for empirical study. These strategies conventionally aim to recognize\ncoarse-grained entity types with few examples, while in practice, most unseen\nentity types are fine-grained. In this paper, we present Few-NERD, a\nlarge-scale human-annotated few-shot NER dataset with a hierarchy of 8\ncoarse-grained and 66 fine-grained entity types. Few-NERD consists of 188,238\nsentences from Wikipedia, 4,601,160 words are included and each is annotated as\ncontext or a part of a two-level entity type. To the best of our knowledge,\nthis is the first few-shot NER dataset and the largest human-crafted NER\ndataset. We construct benchmark tasks with different emphases to\ncomprehensively assess the generalization capability of models. Extensive\nempirical results and analysis show that Few-NERD is challenging and the\nproblem requires further research. We make Few-NERD public at\nhttps://ningding97.github.io/fewnerd/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Ning Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guangwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yulin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaobin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sequence-Level Training for Non-Autoregressive Neural Machine Translation. (arXiv:2106.08122v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.08122","description":"<p>In recent years, Neural Machine Translation (NMT) has achieved notable\nresults in various translation tasks. However, the word-by-word generation\nmanner determined by the autoregressive mechanism leads to high translation\nlatency of the NMT and restricts its low-latency applications.\nNon-Autoregressive Neural Machine Translation (NAT) removes the autoregressive\nmechanism and achieves significant decoding speedup through generating target\nwords independently and simultaneously. Nevertheless, NAT still takes the\nword-level cross-entropy loss as the training objective, which is not optimal\nbecause the output of NAT cannot be properly evaluated due to the multimodality\nproblem. In this article, we propose using sequence-level training objectives\nto train NAT models, which evaluate the NAT outputs as a whole and correlates\nwell with the real translation quality. Firstly, we propose training NAT models\nto optimize sequence-level evaluation metrics (e.g., BLEU) based on several\nnovel reinforcement algorithms customized for NAT, which outperforms the\nconventional method by reducing the variance of gradient estimation. Secondly,\nwe introduce a novel training objective for NAT models, which aims to minimize\nthe Bag-of-Ngrams (BoN) difference between the model output and the reference\nsentence. The BoN training objective is differentiable and can be calculated\nefficiently without doing any approximations. Finally, we apply a three-stage\ntraining strategy to combine these two methods to train the NAT model. We\nvalidate our approach on four translation tasks (WMT14 En$\\leftrightarrow$De,\nWMT16 En$\\leftrightarrow$Ro), which shows that our approach largely outperforms\nNAT baselines and achieves remarkable performance on all translation tasks. The\nsource code is available at https://github.com/ictnlp/Seq-NAT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement Learning Agents. (arXiv:2107.00956v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2107.00956","description":"<p>Building embodied autonomous agents capable of participating in social\ninteractions with humans is one of the main challenges in AI. Within the Deep\nReinforcement Learning (DRL) field, this objective motivated multiple works on\nembodied language use. However, current approaches focus on language as a\ncommunication tool in very simplified and non-diverse social situations: the\n\"naturalness\" of language is reduced to the concept of high vocabulary size and\nvariability. In this paper, we argue that aiming towards human-level AI\nrequires a broader set of key social skills: 1) language use in complex and\nvariable social contexts; 2) beyond language, complex embodied communication in\nmultimodal settings within constantly evolving social worlds. We explain how\nconcepts from cognitive sciences could help AI to draw a roadmap towards\nhuman-like intelligence, with a focus on its social dimensions. As a first\nstep, we propose to expand current research to a broader set of core social\nskills. To do this, we present SocialAI, a benchmark to assess the acquisition\nof social skills of DRL agents using multiple grid-world environments featuring\nother (scripted) social agents. We then study the limits of a recent SOTA DRL\napproach when tested on SocialAI and discuss important next steps towards\nproficient social agents. Videos and code are available at\nhttps://sites.google.com/view/socialai.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1\">Grgur Kova&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1\">R&#xe9;my Portelas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Higher-Order Concurrency for Microcontrollers. (arXiv:2108.07805v2 [cs.PL] UPDATED)","link":"http://arxiv.org/abs/2108.07805","description":"<p>Programming microcontrollers involves low-level interfacing with hardware and\nperipherals that are concurrent and reactive. Such programs are typically\nwritten in a mixture of C and assembly using concurrent language extensions\n(like $\\texttt{FreeRTOS tasks}$ and $\\texttt{semaphores}$), resulting in\nunsafe, callback-driven, error-prone and difficult-to-maintain code.\n</p>\n<p>We address this challenge by introducing $\\texttt{SenseVM}$ - a\nbytecode-interpreted virtual machine that provides a message-passing based\n$\\textit{higher-order concurrency}$ model, originally introduced by Reppy, for\nmicrocontroller programming. This model treats synchronous operations as\nfirst-class values (called $\\texttt{Events}$) akin to the treatment of\nfirst-class functions in functional languages. This primarily allows the\nprogrammer to compose and tailor their own concurrency abstractions and,\nadditionally, abstracts away unsafe memory operations, common in shared-memory\nconcurrency models, thereby making microcontroller programs safer, composable\nand easier-to-maintain.\n</p>\n<p>Our VM is made portable via a low-level $\\textit{bridge}$ interface, built\natop the embedded OS - Zephyr. The bridge is implemented by all drivers and\ndesigned such that programming in response to a software message or a hardware\ninterrupt remains uniform and indistinguishable. In this paper we demonstrate\nthe features of our VM through an example, written in a Caml-like functional\nlanguage, running on the $\\texttt{nRF52840}$ and $\\texttt{STM32F4}$\nmicrocontrollers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1\">Abhiroop Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krook_R/0/1/0/all/0/1\">Robert Krook</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svensson_B/0/1/0/all/0/1\">Bo Joel Svensson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheeran_M/0/1/0/all/0/1\">Mary Sheeran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attentive fine-tuning of Transformers for Translation of low-resourced languages @LoResMT 2021. (arXiv:2108.08556v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.08556","description":"<p>This paper reports the Machine Translation (MT) systems submitted by the\nIIITT team for the English-&gt;Marathi and English-&gt;Irish language pairs LoResMT\n2021 shared task. The task focuses on getting exceptional translations for\nrather low-resourced languages like Irish and Marathi. We fine-tune IndicTrans,\na pretrained multilingual NMT model for English-&gt;Marathi, using external\nparallel corpus as input for additional training. We have used a pretrained\nHelsinki-NLP Opus MT English-&gt;Irish model for the latter language pair. Our\napproaches yield relatively promising results on the BLEU metrics. Under the\nteam name IIITT, our systems ranked 1, 1, and 2 in English-&gt;Marathi,\nIrish-&gt;English, and English-&gt;Irish, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Puranik_K/0/1/0/all/0/1\">Karthik Puranik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hande_A/0/1/0/all/0/1\">Adeep Hande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1\">Ruba Priyadharshini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durairaj_T/0/1/0/all/0/1\">Thenmozhi Durairaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sampath_A/0/1/0/all/0/1\">Anbukkarasi Sampath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thamburaj_K/0/1/0/all/0/1\">Kingston Pal Thamburaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1\">Bharathi Raja Chakravarthi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.09084","description":"<p>Transformer is a powerful model for text understanding. However, it is\ninefficient due to its quadratic complexity to input sequence length. Although\nthere are many methods on Transformer acceleration, they are still either\ninefficient on long sequences or not effective enough. In this paper, we\npropose Fastformer, which is an efficient Transformer model based on additive\nattention. In Fastformer, instead of modeling the pair-wise interactions\nbetween tokens, we first use additive attention mechanism to model global\ncontexts, and then further transform each token representation based on its\ninteraction with global context representations. In this way, Fastformer can\nachieve effective context modeling with linear complexity. Extensive\nexperiments on five datasets show that Fastformer is much more efficient than\nmany existing Transformer models and can meanwhile achieve comparable or even\nbetter long text modeling performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring Wikipedia Article Quality in One Dimension by Extending ORES with Ordinal Regression. (arXiv:2108.10684v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.10684","description":"<p>Organizing complex peer production projects and advancing scientific\nknowledge of open collaboration each depend on the ability to measure quality.\nArticle quality ratings on English language Wikipedia have been widely used by\nboth Wikipedia community members and academic researchers for purposes like\ntracking knowledge gaps and studying how political polarization shapes\ncollaboration. Even so, measuring quality presents many methodological\nchallenges. The most widely used systems use labels on discrete ordinal scales\nwhen assessing quality, but such labels can be inconvenient for statistics and\nmachine learning. Prior work handles this by assuming that different levels of\nquality are \"evenly spaced\" from one another. This assumption runs counter to\nintuitions about the relative degrees of effort needed to raise Wikipedia\nencyclopedia articles to different quality levels. Furthermore, models from\nprior work are fit to datasets that oversample high-quality articles. This\nlimits their accuracy for representative samples of articles or revisions. I\ndescribe a technique extending the Wikimedia Foundations' ORES article quality\nmodel to address these limitations. My method uses weighted ordinal regression\nmodels to construct one-dimensional continuous measures of quality. While\nscores from my technique and from prior approaches are correlated, my approach\nimproves accuracy for research datasets and provides evidence that the \"evenly\nspaced\" assumption is unfounded in practice on English Wikipedia. I conclude\nwith recommendations for using quality scores in future research and include\nthe full code, data, and models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+TeBlunthuis_N/0/1/0/all/0/1\">Nathan TeBlunthuis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Why Intermediate-Task Fine-Tuning Works. (arXiv:2108.11696v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.11696","description":"<p>Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a\nwidely applied technique, which first fine-tunes the pretrained language models\non an intermediate task before on the target task of interest. While STILTs is\nable to further improve the performance of pretrained language models, it is\nstill unclear why and when it works. Previous research shows that those\nintermediate tasks involving complex inference, such as commonsense reasoning,\nwork especially well for RoBERTa. In this paper, we discover that the\nimprovement from an intermediate task could be orthogonal to it containing\nreasoning or other complex skills -- a simple real-fake discrimination task\nsynthesized by GPT2 can benefit diverse target tasks. We conduct extensive\nexperiments to study the impact of different factors on STILTs. These findings\nsuggest rethinking the role of intermediate fine-tuning in the STILTs pipeline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Ting-Yun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chi-Jen Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Position-Invariant Truecasing with a Word-and-Character Hierarchical Recurrent Neural Network. (arXiv:2108.11943v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.11943","description":"<p>Truecasing is the task of restoring the correct case (uppercase or lowercase)\nof noisy text generated either by an automatic system for speech recognition or\nmachine translation or by humans. It improves the performance of downstream NLP\ntasks such as named entity recognition and language modeling. We propose a\nfast, accurate and compact two-level hierarchical word-and-character-based\nrecurrent neural network model, the first of its kind for this problem. Using\nsequence distillation, we also address the problem of truecasing while ignoring\ntoken positions in the sentence, i.e. in a position-invariant manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">You-Chi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathews_R/0/1/0/all/0/1\">Rajiv Mathews</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task-Oriented Dialogue System as Natural Language Generation. (arXiv:2108.13679v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.13679","description":"<p>In this paper, we propose to formulate the task-oriented dialogue system as\nthe purely natural language generation task, so as to fully leverage the\nlarge-scale pre-trained models like GPT-2 and simplify complicated\ndelexicalization prepossessing. However, directly applying this method heavily\nsuffers from the dialogue entity inconsistency caused by the removal of\ndelexicalized tokens, as well as the catastrophic forgetting problem of the\npre-trained model during fine-tuning, leading to unsatisfactory performance. To\nalleviate these problems, we design a novel GPT-Adapter-CopyNet network, which\nincorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve\nbetter performance on transfer learning and dialogue entity generation.\nExperimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ\ndataset demonstrate that our proposed approach significantly outperforms\nbaseline models with a remarkable performance on automatic and human\nevaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weizhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Junliang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yinpei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Boxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-01T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}