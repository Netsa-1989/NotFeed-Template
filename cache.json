{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.1","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-08-17T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"A New Entity Extraction Method Based on Machine Reading Comprehension. (arXiv:2108.06444v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06444","description":"<p>Entity extraction is a key technology for obtaining information from massive\ntexts in natural language processing. The further interaction between them does\nnot meet the standards of human reading comprehension, thus limiting the\nunderstanding of the model, and also the omission or misjudgment of the answer\n(ie the target entity) due to the reasoning question. An effective MRC-based\nentity extraction model-MRC-I2DP, which uses the proposed gated\nattention-attracting mechanism to adjust the restoration of each part of the\ntext pair, creating problems and thinking for multi-level interactive attention\ncalculations to increase the target entity It also uses the proposed 2D\nprobability coding module, TALU function and mask mechanism to strengthen the\ndetection of all possible targets of the target, thereby improving the\nprobability and accuracy of prediction. Experiments have proved that MRC-I2DP\nrepresents an overall state-of-the-art model in 7 from the scientific and\npublic domains, achieving a performance improvement of 2.1% ~ 10.4% compared to\nthe model model in F1.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaobo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Kun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jiajun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_G/0/1/0/all/0/1\">Guangyu Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Bias In Automatic Toxic Comment Detection: An Empirical Study. (arXiv:2108.06487v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06487","description":"<p>With surge in online platforms, there has been an upsurge in the user\nengagement on these platforms via comments and reactions. A large portion of\nsuch textual comments are abusive, rude and offensive to the audience. With\nmachine learning systems in-place to check such comments coming onto platform,\nbiases present in the training data gets passed onto the classifier leading to\ndiscrimination against a set of classes, religion and gender. In this work, we\nevaluate different classifiers and feature to estimate the bias in these\nclassifiers along with their performance on downstream task of toxicity\nclassification. Results show that improvement in performance of automatic toxic\ncomment detection models is positively correlated to mitigating biases in these\nmodels. In our work, LSTM with attention mechanism proved to be a better\nmodelling strategy than a CNN model. Further analysis shows that fasttext\nembeddings is marginally preferable than glove embeddings on training models\nfor toxicity comment detection. Deeper analysis reveals the findings that such\nautomatic models are particularly biased to specific identity groups even\nthough the model has a high AUC score. Finally, in effort to mitigate bias in\ntoxicity detection models, a multi-task setup trained with auxiliary task of\ntoxicity sub-types proved to be useful leading to upto 0.26% (6% relative) gain\nin AUC scores.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ayush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratik Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Sample Named Entity Recognition for Security Vulnerability Reports by Fine-Tuning Pre-Trained Language Models. (arXiv:2108.06590v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06590","description":"<p>Public security vulnerability reports (e.g., CVE reports) play an important\nrole in the maintenance of computer and network systems. Security companies and\nadministrators rely on information from these reports to prioritize tasks on\ndeveloping and deploying patches to their customers. Since these reports are\nunstructured texts, automatic information extraction (IE) can help scale up the\nprocessing by converting the unstructured reports to structured forms, e.g.,\nsoftware names and versions and vulnerability types. Existing works on\nautomated IE for security vulnerability reports often rely on a large number of\nlabeled training samples. However, creating massive labeled training set is\nboth expensive and time consuming. In this work, for the first time, we propose\nto investigate this problem where only a small number of labeled training\nsamples are available. In particular, we investigate the performance of\nfine-tuning several state-of-the-art pre-trained language models on our small\ntraining dataset. The results show that with pre-trained language models and\ncarefully tuned hyperparameters, we have reached or slightly outperformed the\nstate-of-the-art system on this task. Consistent with previous two-step process\nof first fine-tuning on main category and then transfer learning to others as\nin [7], if otherwise following our proposed approach, the number of required\nlabeled samples substantially decrease in both stages: 90% reduction in\nfine-tuning from 5758 to 576,and 88.8% reduction in transfer learning with 64\nlabeled samples per category. Our experiments thus demonstrate the\neffectiveness of few-sample learning on NER for security vulnerability report.\nThis result opens up multiple research opportunities for few-sample learning\nfor security vulnerability reports, which is discussed in the paper. Code:\nhttps://github.com/guanqun-yang/FewVulnerability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guanqun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dineen_S/0/1/0/all/0/1\">Shay Dineen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhipeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xueqing Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Findings of the LoResMT 2021 Shared Task on COVID and Sign Language for Low-resource Languages. (arXiv:2108.06598v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06598","description":"<p>We present the findings of the LoResMT 2021 shared task which focuses on\nmachine translation (MT) of COVID-19 data for both low-resource spoken and sign\nlanguages. The organization of this task was conducted as part of the fourth\nworkshop on technologies for machine translation of low resource languages\n(LoResMT). Parallel corpora is presented and publicly available which includes\nthe following directions: English$\\leftrightarrow$Irish,\nEnglish$\\leftrightarrow$Marathi, and Taiwanese Sign\nlanguage$\\leftrightarrow$Traditional Chinese. Training data consists of 8112,\n20933 and 128608 segments, respectively. There are additional monolingual data\nsets for Marathi and English that consist of 21901 segments. The results\npresented here are based on entries from a total of eight teams. Three teams\nsubmitted systems for English$\\leftrightarrow$Irish while five teams submitted\nsystems for English$\\leftrightarrow$Marathi. Unfortunately, there were no\nsystems submissions for the Taiwanese Sign language$\\leftrightarrow$Traditional\nChinese task. Maximum system performance was computed using BLEU and follow as\n36.0 for English--Irish, 34.6 for Irish--English, 24.2 for English--Marathi,\nand 31.3 for Marathi--English.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ojha_A/0/1/0/all/0/1\">Atul Kr. Ojha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chao-Hong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortega_J/0/1/0/all/0/1\">John Ortega</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shatam_S/0/1/0/all/0/1\">Sheetal Shatam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fransen_T/0/1/0/all/0/1\">Theodorus Fransen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The SelectGen Challenge: Finding the Best Training Samples for Few-Shot Neural Text Generation. (arXiv:2108.06614v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06614","description":"<p>We propose a shared task on training instance selection for few-shot neural\ntext generation. Large-scale pretrained language models have led to dramatic\nimprovements in few-shot text generation. Nonetheless, almost all previous work\nsimply applies random sampling to select the few-shot training instances.\nLittle to no attention has been paid to the selection strategies and how they\nwould affect model performance. The study of the selection strategy can help us\nto (1) make the most use of our annotation budget in downstream tasks and (2)\nbetter benchmark few-shot text generative models. We welcome submissions that\npresent their selection strategies and the effects on the generation quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1\">Ernie Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marin_A/0/1/0/all/0/1\">Alex Marin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1\">Vera Demberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DEXTER: Deep Encoding of External Knowledge for Named Entity Recognition in Virtual Assistants. (arXiv:2108.06633v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06633","description":"<p>Named entity recognition (NER) is usually developed and tested on text from\nwell-written sources. However, in intelligent voice assistants, where NER is an\nimportant component, input to NER may be noisy because of user or speech\nrecognition error. In applications, entity labels may change frequently, and\nnon-textual properties like topicality or popularity may be needed to choose\namong alternatives.\n</p>\n<p>We describe a NER system intended to address these problems. We test and\ntrain this system on a proprietary user-derived dataset. We compare with a\nbaseline text-only NER system; the baseline enhanced with external gazetteers;\nand the baseline enhanced with the search and indirect labelling techniques we\ndescribe below. The final configuration gives around 6% reduction in NER error\nrate. We also show that this technique improves related tasks, such as semantic\nparsing, with an improvement of up to 5% in error rate.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muralidharan_D/0/1/0/all/0/1\">Deepak Muralidharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1\">Joel Ruben Antony Moniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weicheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pulman_S/0/1/0/all/0/1\">Stephen Pulman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_M/0/1/0/all/0/1\">Megan Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jingjing Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1\">Jason Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acero_A/0/1/0/all/0/1\">Alex Acero</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SAPPHIRE: Approaches for Enhanced Concept-to-Text Generation. (arXiv:2108.06643v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06643","description":"<p>We motivate and propose a suite of simple but effective improvements for\nconcept-to-text generation called SAPPHIRE: Set Augmentation and Post-hoc\nPHrase Infilling and REcombination. We demonstrate their effectiveness on\ngenerative commonsense reasoning, a.k.a. the CommonGen task, through\nexperiments using both BART and T5 models. Through extensive automatic and\nhuman evaluation, we show that SAPPHIRE noticeably improves model performance.\nAn in-depth qualitative analysis illustrates that SAPPHIRE effectively\naddresses many issues of the baseline model generations, including lack of\ncommonsense, insufficient specificity, and poor fluency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Steven Y. Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_J/0/1/0/all/0/1\">Jessica Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narisetty_C/0/1/0/all/0/1\">Chaitanya Narisetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1\">Varun Gangal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Accurate, yet inconsistent? Consistency Analysis on Language Understanding Models. (arXiv:2108.06665v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06665","description":"<p>Consistency, which refers to the capability of generating the same\npredictions for semantically similar contexts, is a highly desirable property\nfor a sound language understanding model. Although recent pretrained language\nmodels (PLMs) deliver outstanding performance in various downstream tasks, they\nshould exhibit consistent behaviour provided the models truly understand\nlanguage. In this paper, we propose a simple framework named consistency\nanalysis on language understanding models (CALUM)} to evaluate the model's\nlower-bound consistency ability. Through experiments, we confirmed that current\nPLMs are prone to generate inconsistent predictions even for semantically\nidentical inputs. We also observed that multi-task training with paraphrase\nidentification tasks is of benefit to improve consistency, increasing the\nconsistency by 13% on average.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jang_M/0/1/0/all/0/1\">Myeongjun Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_D/0/1/0/all/0/1\">Deuk Sin Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Complex Knowledge Base Question Answering: A Survey. (arXiv:2108.06688v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06688","description":"<p>Knowledge base question answering (KBQA) aims to answer a question over a\nknowledge base (KB). Early studies mainly focused on answering simple questions\nover KBs and achieved great success. However, their performance on complex\nquestions is still far from satisfactory. Therefore, in recent years,\nresearchers propose a large number of novel methods, which looked into the\nchallenges of answering complex questions. In this survey, we review recent\nadvances on KBQA with the focus on solving complex questions, which usually\ncontain multiple subjects, express compound relations, or involve numerical\noperations. In detail, we begin with introducing the complex KBQA task and\nrelevant background. Then, we describe benchmark datasets for complex KBQA task\nand introduce the construction process of these datasets. Next, we present two\nmainstream categories of methods for complex KBQA, namely semantic\nparsing-based (SP-based) methods and information retrieval-based (IR-based)\nmethods. Specifically, we illustrate their procedures with flow designs and\ndiscuss their major differences and similarities. After that, we summarize the\nchallenges that these two categories of methods encounter when answering\ncomplex questions, and explicate advanced solutions and techniques used in\nexisting work. Finally, we conclude and discuss several promising directions\nrelated to complex KBQA for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yunshi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_G/0/1/0/all/0/1\">Gaole He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jinhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation. (arXiv:2108.06712v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06712","description":"<p>Tables are often created with hierarchies, but existing works on table\nreasoning mainly focus on flat tables and neglect hierarchical tables.\nHierarchical tables challenge existing methods by hierarchical indexing, as\nwell as implicit relationships of calculation and semantics. This work presents\nHiTab, a free and open dataset for the research community to study question\nanswering (QA) and natural language generation (NLG) over hierarchical tables.\nHiTab is a cross-domain dataset constructed from a wealth of statistical\nreports and Wikipedia pages, and has unique characteristics: (1) nearly all\ntables are hierarchical, and (2) both target sentences for NLG and questions\nfor QA are revised from high-quality descriptions in statistical reports that\nare meaningful and diverse. (3) HiTab provides fine-grained annotations on both\nentity and quantity alignment. Targeting hierarchical structure, we devise a\nnovel hierarchy-aware logical form for symbolic reasoning over tables, which\nshows high effectiveness. Then given annotations of entity and quantity\nalignment, we propose partially supervised training, which helps models to\nlargely reduce spurious predictions in the QA task. In the NLG task, we find\nthat entity and quantity alignment also helps NLG models to generate better\nresults in a conditional generation setting. Experiment results of\nstate-of-the-art baselines suggest that this dataset presents a strong\nchallenge and a valuable benchmark for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zhoujun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Haoyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiruo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ran Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiaqi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-Guang Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Generalization Ability of Pretrained Language Models on Arithmetic and Logical Reasoning. (arXiv:2108.06743v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06743","description":"<p>To quantitatively and intuitively explore the generalization ability of\npre-trained language models (PLMs), we have designed several tasks of\narithmetic and logical reasoning. We both analyse how well PLMs generalize when\nthe test data is in the same distribution as the train data and when it is\ndifferent, for the latter analysis, we have also designed a cross-distribution\ntest set other than the in-distribution test set. We conduct experiments on one\nof the most advanced and publicly released generative PLM - BART. Our research\nfinds that the PLMs can easily generalize when the distribution is the same,\nhowever, it is still difficult for them to generalize out of the distribution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Boyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1\">Yuchen Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What can Neural Referential Form Selectors Learn?. (arXiv:2108.06806v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06806","description":"<p>Despite achieving encouraging results, neural Referring Expression Generation\nmodels are often thought to lack transparency. We probed neural Referential\nForm Selection (RFS) models to find out to what extent the linguistic features\ninfluencing the RE form are learnt and captured by state-of-the-art RFS models.\nThe results of 8 probing tasks show that all the defined features were learnt\nto some extent. The probing tasks pertaining to referential status and\nsyntactic position exhibited the highest performance. The lowest performance\nwas achieved by the probing models designed to predict discourse structure\nproperties beyond the sentence level.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Same_F/0/1/0/all/0/1\">Fahime Same</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deemter_K/0/1/0/all/0/1\">Kees van Deemter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Maps Search Misspelling Detection Leveraging Domain-Augmented Contextual Representations. (arXiv:2108.06842v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06842","description":"<p>Building an independent misspelling detector and serve it before correction\ncan bring multiple benefits to speller and other search components, which is\nparticularly true for the most commonly deployed noisy-channel based speller\nsystems. With rapid development of deep learning and substantial advancement in\ncontextual representation learning such as BERTology, building a decent\nmisspelling detector without having to rely on hand-crafted features associated\nwith noisy-channel architecture becomes more-than-ever accessible. However\nBERTolgy models are trained with natural language corpus but Maps Search is\nhighly domain specific, would BERTology continue its success. In this paper we\ndesign 4 stages of models for misspeling detection ranging from the most basic\nLSTM to single-domain augmented fine-tuned BERT. We found for Maps Search in\nour case, other advanced BERTology family model such as RoBERTa does not\nnecessarily outperform BERT, and a classic cross-domain fine-tuned full BERT\neven underperforms a smaller single-domain fine-tuned BERT. We share more\nfindings through comprehensive modeling experiments and analysis, we also\nbriefly cover the data generation algorithm breakthrough.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yutong Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clustering Filipino Disaster-Related Tweets Using Incremental and Density-Based Spatiotemporal Algorithm with Support Vector Machines for Needs Assessment 2. (arXiv:2108.06853v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06853","description":"<p>Social media has played a huge part on how people get informed and\ncommunicate with one another. It has helped people express their needs due to\ndistress especially during disasters. Because posts made through it are\npublicly accessible by default, Twitter is among the most helpful social media\nsites in times of disaster. With this, the study aims to assess the needs\nexpressed during calamities by Filipinos on Twitter. Data were gathered and\nclassified as either disaster-related or unrelated with the use of Na\\\"ive\nBayes classifier. After this, the disaster-related tweets were clustered per\ndisaster type using Incremental Clustering Algorithm, and then sub-clustered\nbased on the location and time of the tweet using Density-based Spatiotemporal\nClustering Algorithm. Lastly, using Support Vector Machines, the tweets were\nclassified according to the expressed need, such as shelter, rescue, relief,\ncash, prayer, and others. After conducting the study, results showed that the\nIncremental Clustering Algorithm and Density-Based Spatiotemporal Clustering\nAlgorithm were able to cluster the tweets with f-measure scores of 47.20% and\n82.28% respectively. Also, the Na\\\"ive Bayes and Support Vector Machines were\nable to classify with an average f-measure score of 97% and an average accuracy\nof 77.57% respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barba_O/0/1/0/all/0/1\">Ocean M. Barba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calbay_F/0/1/0/all/0/1\">Franz Arvin T. Calbay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francisco_A/0/1/0/all/0/1\">Angelica Jane S. Francisco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_A/0/1/0/all/0/1\">Angel Luis D. Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponay_C/0/1/0/all/0/1\">Charmaine S. Ponay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoChart: A Dataset for Chart-to-Text Generation Task. (arXiv:2108.06897v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06897","description":"<p>The analytical description of charts is an exciting and important research\narea with many applications in academia and industry. Yet, this challenging\ntask has received limited attention from the computational linguistics research\ncommunity. This paper proposes \\textsf{AutoChart}, a large dataset for the\nanalytical description of charts, which aims to encourage more research into\nthis important area. Specifically, we offer a novel framework that generates\nthe charts and their analytical description automatically. We conducted\nextensive human and machine evaluations on the generated charts and\ndescriptions and demonstrate that the generated texts are informative,\ncoherent, and relevant to the corresponding charts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiawen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ran_J/0/1/0/all/0/1\">Jinye Ran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Roy Ka-wei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_K/0/1/0/all/0/1\">Kenny Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextual Mood Analysis with Knowledge Graph Representation for Hindi Song Lyrics in Devanagari Script. (arXiv:2108.06947v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06947","description":"<p>Lyrics play a significant role in conveying the song's mood and are\ninformation to understand and interpret music communication. Conventional\nnatural language processing approaches use translation of the Hindi text into\nEnglish for analysis. This approach is not suitable for lyrics as it is likely\nto lose the inherent intended contextual meaning. Thus, the need was identified\nto develop a system for Devanagari text analysis. The data set of 300 song\nlyrics with equal distribution in five different moods is used for the\nexperimentation. The proposed system performs contextual mood analysis of Hindi\nsong lyrics in Devanagari text format. The contextual analysis is stored as a\nknowledge base, updated using an incremental learning approach with new data.\nContextual knowledge graph with moods and associated important contextual terms\nprovides the graphical representation of the lyric data set used. The testing\nresults show 64% accuracy for the mood prediction. This work can be easily\nextended to applications related to Hindi literary work such as summarization,\nindexing, contextual retrieval, context-based classification and grouping of\ndocuments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Velankar_M/0/1/0/all/0/1\">Makarand Velankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotian_R/0/1/0/all/0/1\">Rachita Kotian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_P/0/1/0/all/0/1\">Parag Kulkarni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MobIE: A German Dataset for Named Entity Recognition, Entity Linking and Relation Extraction in the Mobility Domain. (arXiv:2108.06955v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06955","description":"<p>We present MobIE, a German-language dataset, which is human-annotated with 20\ncoarse- and fine-grained entity types and entity linking information for\ngeographically linkable entities. The dataset consists of 3,232 social media\ntexts and traffic reports with 91K tokens, and contains 20.5K annotated\nentities, 13.1K of which are linked to a knowledge base. A subset of the\ndataset is human-annotated with seven mobility-related, n-ary relation types,\nwhile the remaining documents are annotated using a weakly-supervised labeling\napproach implemented with the Snorkel framework. To the best of our knowledge,\nthis is the first German-language dataset that combines annotations for NER, EL\nand RE, and thus can be used for joint and multi-task learning of these\nfundamental information extraction tasks. We make MobIE public at\nhttps://github.com/dfki-nlp/mobie.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hennig_L/0/1/0/all/0/1\">Leonhard Hennig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_P/0/1/0/all/0/1\">Phuc Tran Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabryszak_A/0/1/0/all/0/1\">Aleksandra Gabryszak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Effective System for Multi-format Information Extraction. (arXiv:2108.06957v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06957","description":"<p>The multi-format information extraction task in the 2021 Language and\nIntelligence Challenge is designed to comprehensively evaluate information\nextraction from different dimensions. It consists of an multiple slots relation\nextraction subtask and two event extraction subtasks that extract events from\nboth sentence-level and document-level. Here we describe our system for this\nmulti-format information extraction competition task. Specifically, for the\nrelation extraction subtask, we convert it to a traditional triple extraction\ntask and design a voting based method that makes full use of existing models.\nFor the sentence-level event extraction subtask, we convert it to a NER task\nand use a pointer labeling based method for extraction. Furthermore,\nconsidering the annotated trigger information may be helpful for event\nextraction, we design an auxiliary trigger recognition model and use the\nmulti-task learning mechanism to integrate the trigger features into the event\nextraction model. For the document-level event extraction subtask, we design an\nEncoder-Decoder based method and propose a Transformer-alike decoder.\nFinally,our system ranks No.4 on the test set leader-board of this multi-format\ninformation extraction task, and its F1 scores for the subtasks of relation\nextraction, event extractions of sentence-level and document-level are 79.887%,\n85.179%, and 70.828% respectively. The codes of our model are available at\n{https://github.com/neukg/MultiIE}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaduo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Longhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1\">Shujuan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaofeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_F/0/1/0/all/0/1\">Feiliang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Single Example Can Improve Zero-Shot Data Generation. (arXiv:2108.06991v1 [cs.CL])","link":"http://arxiv.org/abs/2108.06991","description":"<p>Sub-tasks of intent classification, such as robustness to distribution shift,\nadaptation to specific user groups and personalization, out-of-domain\ndetection, require extensive and flexible datasets for experiments and\nevaluation. As collecting such datasets is time- and labor-consuming, we\npropose to use text generation methods to gather datasets. The generator should\nbe trained to generate utterances that belong to the given intent. We explore\ntwo approaches to generating task-oriented utterances. In the zero-shot\napproach, the model is trained to generate utterances from seen intents and is\nfurther used to generate utterances for intents unseen during training. In the\none-shot approach, the model is presented with a single utterance from a test\nintent. We perform a thorough automatic, and human evaluation of the dataset\ngenerated utilizing two proposed approaches. Our results reveal that the\nattributes of the generated data are close to original test sets, collected via\ncrowd-sourcing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Burnyshev_P/0/1/0/all/0/1\">Pavel Burnyshev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malykh_V/0/1/0/all/0/1\">Valentin Malykh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bout_A/0/1/0/all/0/1\">Andrey Bout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1\">Ekaterina Artemova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piontkovskaya_I/0/1/0/all/0/1\">Irina Piontkovskaya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Effective Non-Autoregressive Model for Spoken Language Understanding. (arXiv:2108.07005v1 [cs.CL])","link":"http://arxiv.org/abs/2108.07005","description":"<p>Spoken Language Understanding (SLU), a core component of the task-oriented\ndialogue system, expects a shorter inference latency due to the impatience of\nhumans. Non-autoregressive SLU models clearly increase the inference speed but\nsuffer uncoordinated-slot problems caused by the lack of sequential dependency\ninformation among each slot chunk. To gap this shortcoming, in this paper, we\npropose a novel non-autoregressive SLU model named Layered-Refine Transformer,\nwhich contains a Slot Label Generation (SLG) task and a Layered Refine\nMechanism (LRM). SLG is defined as generating the next slot label with the\ntoken sequence and generated slot labels. With SLG, the non-autoregressive\nmodel can efficiently obtain dependency information during training and spend\nno extra time in inference. LRM predicts the preliminary SLU results from\nTransformer's middle states and utilizes them to guide the final prediction.\nExperiments on two public datasets indicate that our model significantly\nimproves SLU performance (1.5\\% on Overall accuracy) while substantially speed\nup (more than 10 times) the inference process over the state-of-the-art\nbaseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lizhi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1\">Weijia Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenmian Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ROSITA: Enhancing Vision-and-Language Semantic Alignments via Cross- and Intra-modal Knowledge Integration. (arXiv:2108.07073v1 [cs.CV])","link":"http://arxiv.org/abs/2108.07073","description":"<p>Vision-and-language pretraining (VLP) aims to learn generic multimodal\nrepresentations from massive image-text pairs. While various successful\nattempts have been proposed, learning fine-grained semantic alignments between\nimage-text pairs plays a key role in their approaches. Nevertheless, most\nexisting VLP approaches have not fully utilized the intrinsic knowledge within\nthe image-text pairs, which limits the effectiveness of the learned alignments\nand further restricts the performance of their models. To this end, we\nintroduce a new VLP method called ROSITA, which integrates the cross- and\nintra-modal knowledge in a unified scene graph to enhance the semantic\nalignments. Specifically, we introduce a novel structural knowledge masking\n(SKM) strategy to use the scene graph structure as a priori to perform masked\nlanguage (region) modeling, which enhances the semantic alignments by\neliminating the interference information within and across modalities.\nExtensive ablation studies and comprehensive analysis verifies the\neffectiveness of ROSITA in semantic alignments. Pretrained with both in-domain\nand out-of-domain datasets, ROSITA significantly outperforms existing\nstate-of-the-art VLP methods on three typical vision-and-language tasks over\nsix benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yuhao Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chunqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhongzhou Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jun Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Learning for Massively Parallel Translation of Constrained Text into Low Resource Languages. (arXiv:2108.07127v1 [cs.CL])","link":"http://arxiv.org/abs/2108.07127","description":"<p>We translate a closed text that is known in advance and available in many\nlanguages into a new and severely low resource language. Most human translation\nefforts adopt a portion-based approach to translate consecutive pages/chapters\nin order, which may not suit machine translation. We compare the portion-based\napproach that optimizes coherence of the text locally with the random sampling\napproach that increases coverage of the text globally. Our results show that\nthe random sampling approach performs better. When training on a seed corpus of\n~1,000 lines from the Bible and testing on the rest of the Bible (~30,000\nlines), random sampling gives a performance gain of +11.0 BLEU using English as\na simulated low resource language, and +4.9 BLEU using Eastern Pokomchi, a\nMayan language. Furthermore, we compare three ways of updating machine\ntranslation models with increasing amount of human post-edited data through\niterations. We find that adding newly post-edited data to training after\nvocabulary update without self-supervision performs the best. We propose an\nalgorithm for human and machine to work together seamlessly to translate a\nclosed text into a severely low resource language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alex Waibel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Label-Agnostic Sequence Labeling by Copying Nearest Neighbors. (arXiv:1906.04225v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1906.04225","description":"<p>Retrieve-and-edit based approaches to structured prediction, where structures\nassociated with retrieved neighbors are edited to form new structures, have\nrecently attracted increased interest. However, much recent work merely\nconditions on retrieved structures (e.g., in a sequence-to-sequence framework),\nrather than explicitly manipulating them. We show we can perform accurate\nsequence labeling by explicitly (and only) copying labels from retrieved\nneighbors. Moreover, because this copying is label-agnostic, we can achieve\nimpressive performance in zero-shot sequence-labeling tasks. We additionally\nconsider a dynamic programming approach to sequence labeling in the presence of\nretrieved neighbors, which allows for controlling the number of distinct\n(copied) segments used to form a prediction, and leads to both more\ninterpretable and accurate predictions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wiseman_S/0/1/0/all/0/1\">Sam Wiseman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stratos_K/0/1/0/all/0/1\">Karl Stratos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2007.01777","description":"<p>We propose a novel interpretable deep neural network for text classification,\ncalled ProtoryNet, based on a new concept of prototype trajectories. Motivated\nby the prototype theory in modern linguistics, ProtoryNet makes a prediction by\nfinding the most similar prototype for each sentence in a text sequence and\nfeeding an RNN backbone with the proximity of each sentence to the\ncorresponding active prototype. The RNN backbone then captures the temporal\npattern of the prototypes, which we refer to as prototype trajectories.\nPrototype trajectories enable intuitive and fine-grained interpretation of the\nreasoning process of the RNN model, in resemblance to how humans analyze texts.\nWe also design a prototype pruning procedure to reduce the total number of\nprototypes used by the model for better interpretability. Experiments on\nmultiple public data sets show that ProtoryNet is more accurate than the\nbaseline prototype-based deep neural net and reduces the performance gap\ncompared to state-of-the-art black-box models. In addition, after prototype\npruning, the resulting ProtoryNet models only need less than or around 20\nprototypes for all datasets, which significantly benefits interpretability.\nFurthermore, we report a survey result indicating that human users find\nProtoryNet more intuitive and easier to understand than other prototype-based\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Dat Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1\">Stephen S. Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Streaming Approach For Efficient Batched Beam Search. (arXiv:2010.02164v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.02164","description":"<p>We propose an efficient batching strategy for variable-length decoding on GPU\narchitectures. During decoding, when candidates terminate or are pruned\naccording to heuristics, our streaming approach periodically \"refills\" the\nbatch before proceeding with a selected subset of candidates. We apply our\nmethod to variable-width beam search on a state-of-the-art machine translation\nmodel. Our method decreases runtime by up to 71% compared to a fixed-width beam\nsearch baseline and 17% compared to a variable-width baseline, while matching\nbaselines' BLEU. Finally, experiments show that our method can speed up\ndecoding in other domains, such as semantic and syntactic parsing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kevin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_V/0/1/0/all/0/1\">Violet Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeNero_J/0/1/0/all/0/1\">John DeNero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-Based Construction of Confusion Matrices for Multi-Label Classification Algorithms using Semantic Similarity Measures. (arXiv:2011.00109v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2011.00109","description":"<p>So far, multi-label classification algorithms have been evaluated using\nstatistical methods that do not consider the semantics of the considered\nclasses and that fully depend on abstract computations such as Bayesian\nReasoning. Currently, there are several attempts to develop ontology-based\nmethods for a better assessment of supervised classification algorithms. In\nthis research paper, we define a novel approach that aligns expected labels\nwith predicted labels in multi-label classification using ontology-driven\nfeature-based semantic similarity measures and we use it to develop a method\nfor creating precise confusion matrices for a more effective evaluation of\nmulti-label classification algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Turki_H/0/1/0/all/0/1\">Houcemeddine Turki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taieb_M/0/1/0/all/0/1\">Mohamed Ali Hadj Taieb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aouicha_M/0/1/0/all/0/1\">Mohamed Ben Aouicha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lessons from Computational Modelling of Reference Production in Mandarin and English. (arXiv:2011.07398v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2011.07398","description":"<p>Referring expression generation (REG) algorithms offer computational models\nof the production of referring expressions. In earlier work, a corpus of\nreferring expressions (REs) in Mandarin was introduced. In the present paper,\nwe annotate this corpus, evaluate classic REG algorithms on it, and compare the\nresults with earlier results on the evaluation of REG for English referring\nexpressions. Next, we offer an in-depth analysis of the corpus, focusing on\nissues that arise from the grammar of Mandarin. We discuss shortcomings of\nprevious REG evaluations that came to light during our investigation and we\nhighlight some surprising results. Perhaps most strikingly, we found a much\nhigher proportion of under-specified expressions than previous studies had\nsuggested, not just in Mandarin but in English as well.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deemter_K/0/1/0/all/0/1\">Kees van Deemter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Integrated Approach for Improving Brand Consistency of Web Content: Modeling, Analysis and Recommendation. (arXiv:2011.09754v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2011.09754","description":"<p>A consumer-dependent (business-to-consumer) organization tends to present\nitself as possessing a set of human qualities, which is termed as the brand\npersonality of the company. The perception is impressed upon the consumer\nthrough the content, be it in the form of advertisement, blogs or magazines,\nproduced by the organization. A consistent brand will generate trust and retain\ncustomers over time as they develop an affinity towards regularity and common\npatterns. However, maintaining a consistent messaging tone for a brand has\nbecome more challenging with the virtual explosion in the amount of content\nwhich needs to be authored and pushed to the Internet to maintain an edge in\nthe era of digital marketing. To understand the depth of the problem, we\ncollect around 300K web page content from around 650 companies. We develop\ntrait-specific classification models by considering the linguistic features of\nthe content. The classifier automatically identifies the web articles which are\nnot consistent with the mission and vision of a company and further helps us to\ndiscover the conditions under which the consistency cannot be maintained. To\naddress the brand inconsistency issue, we then develop a sentence ranking\nsystem that outputs the top three sentences that need to be changed for making\na web article more consistent with the company's brand personality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Soumyadeep Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sural_S/0/1/0/all/0/1\">Shamik Sural</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhaya_N/0/1/0/all/0/1\">Niyati Chhaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_A/0/1/0/all/0/1\">Anandhavelu Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1\">Niloy Ganguly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VLG-Net: Video-Language Graph Matching Network for Video Grounding. (arXiv:2011.10132v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2011.10132","description":"<p>Grounding language queries in videos aims at identifying the time interval\n(or moment) semantically relevant to a language query. The solution to this\nchallenging task demands understanding videos' and queries' semantic content\nand the fine-grained reasoning about their multi-modal interactions. Our key\nidea is to recast this challenge into an algorithmic graph matching problem.\nFueled by recent advances in Graph Neural Networks, we propose to leverage\nGraph Convolutional Networks to model video and textual information as well as\ntheir semantic alignment. To enable the mutual exchange of information across\nthe modalities, we design a novel Video-Language Graph Matching Network\n(VLG-Net) to match video and query graphs. Core ingredients include\nrepresentation graphs built atop video snippets and query tokens separately and\nused to model intra-modality relationships. A Graph Matching layer is adopted\nfor cross-modal context modeling and multi-modal fusion. Finally, moment\ncandidates are created using masked moment attention pooling by fusing the\nmoment's enriched snippet features. We demonstrate superior performance over\nstate-of-the-art grounding methods on three widely used datasets for temporal\nlocalization of moments in videos with language queries: ActivityNet-Captions,\nTACoS, and DiDeMo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Soldan_M/0/1/0/all/0/1\">Mattia Soldan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengmeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1\">Sisi Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1\">Jesper Tegner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vocabulary Learning via Optimal Transport for Neural Machine Translation. (arXiv:2012.15671v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.15671","description":"<p>The choice of token vocabulary affects the performance of machine\ntranslation. This paper aims to figure out what is a good vocabulary and\nwhether one can find the optimal vocabulary without trial training. To answer\nthese questions, we first provide an alternative understanding of the role of\nvocabulary from the perspective of information theory. Motivated by this, we\nformulate the quest of vocabularization -- finding the best token dictionary\nwith a proper size -- as an optimal transport (OT) problem. We propose VOLT, a\nsimple and efficient solution without trial training. Empirical results show\nthat VOLT outperforms widely-used vocabularies in diverse scenarios, including\nWMT-14 English-German and TED's 52 translation directions. For example, VOLT\nachieves almost 70% vocabulary size reduction and 0.5 BLEU gain on\nEnglish-German translation. Also, compared to BPE-search, VOLT reduces the\nsearch time from 384 GPU hours to 30 GPU hours on English-German translation.\nCodes are available at https://github.com/Jingjing-NLP/VOLT .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chun Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In Defense of Scene Graphs for Image Captioning. (arXiv:2102.04990v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2102.04990","description":"<p>The mainstream image captioning models rely on Convolutional Neural Network\n(CNN) image features to generate captions via recurrent models. Recently, image\nscene graphs have been used to augment captioning models so as to leverage\ntheir structural semantics, such as object entities, relationships and\nattributes. Several studies have noted that the naive use of scene graphs from\na black-box scene graph generator harms image captioning performance and that\nscene graph-based captioning models have to incur the overhead of explicit use\nof image features to generate decent captions. Addressing these challenges, we\npropose \\textbf{SG2Caps}, a framework that utilizes only the scene graph labels\nfor competitive image captioning performance. The basic idea is to close the\nsemantic gap between the two scene graphs - one derived from the input image\nand the other from its caption. In order to achieve this, we leverage the\nspatial location of objects and the Human-Object-Interaction (HOI) labels as an\nadditional HOI graph. SG2Caps outperforms existing scene graph-only captioning\nmodels by a large margin, indicating scene graphs as a promising representation\nfor image captioning. Direct utilization of scene graph labels avoids expensive\ngraph convolutions over high-dimensional CNN features resulting in 49% fewer\ntrainable parameters. Our code is available at:\nhttps://github.com/Kien085/SG2Caps\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kien Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Subarna Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bang Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_T/0/1/0/all/0/1\">Tanaya Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Truong Q. Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transferability of Neural Network-based De-identification Systems. (arXiv:2102.08517v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.08517","description":"<p>Methods and Materials: We investigated transferability of neural\nnetwork-based de-identification sys-tems with and without domain\ngeneralization. We used two domain generalization approaches: a novel approach\nJoint-Domain Learning (JDL) as developed in this paper, and a state-of-the-art\ndomain general-ization approach Common-Specific Decomposition (CSD) from the\nliterature. First, we measured trans-ferability from a single external source.\nSecond, we used two external sources and evaluated whether domain\ngeneralization can improve transferability of de-identification models across\ndomains which rep-resent different note types from the same institution. Third,\nusing two external sources with in-domain training data, we studied whether\nexternal source data are useful even in cases where sufficient in-domain\ntraining data are available. Finally, we investigated transferability of the\nde-identification mod-els across institutions. Results and Conclusions: We\nfound transferability from a single external source gave inconsistent re-sults.\nUsing additional external sources consistently yielded an F1-score of\napproximately 80%, but domain generalization was not always helpful to improve\ntransferability. We also found that external sources were useful even in cases\nwhere in-domain training data were available by reducing the amount of needed\nin-domain training data or by improving performance. Transferability across\ninstitutions was differed by note type and annotation label. External sources\nfrom a different institution were also useful to further improve performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kahyun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobbins_N/0/1/0/all/0/1\">Nicholas J. Dobbins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McInnes_B/0/1/0/all/0/1\">Bridget McInnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1\">Meliha Yetisgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uzuner_O/0/1/0/all/0/1\">&#xd6;zlem Uzuner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Effect of Domain and Diacritics in Yor\\`ub\\'a-English Neural Machine Translation. (arXiv:2103.08647v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.08647","description":"<p>Massively multilingual machine translation (MT) has shown impressive\ncapabilities, including zero and few-shot translation between low-resource\nlanguage pairs. However, these models are often evaluated on high-resource\nlanguages with the assumption that they generalize to low-resource ones. The\ndifficulty of evaluating MT models on low-resource pairs is often due to lack\nof standardized evaluation datasets. In this paper, we present MENYO-20k, the\nfirst multi-domain parallel corpus with a special focus on clean orthography\nfor Yor\\`ub\\'a--English with standardized train-test splits for benchmarking.\nWe provide several neural MT benchmarks and compare them to the performance of\npopular pre-trained (massively multilingual) MT models both for the\nheterogeneous test set and its subdomains. Since these pre-trained models use\nhuge amounts of data with uncertain quality, we also analyze the effect of\ndiacritics, a major characteristic of Yor\\`ub\\'a, in the training data. We\ninvestigate how and when this training condition affects the final quality and\nintelligibility of a translation. Our models outperform massively multilingual\nmodels such as Google ($+8.7$ BLEU) and Facebook M2M ($+9.1$ BLEU) when\ntranslating to Yor\\`ub\\'a, setting a high quality benchmark for future\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David I. Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiter_D/0/1/0/all/0/1\">Dana Ruiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1\">Jesujoba O. Alabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adebonojo_D/0/1/0/all/0/1\">Damilola Adebonojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayeni_A/0/1/0/all/0/1\">Adesina Ayeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeyemi_M/0/1/0/all/0/1\">Mofe Adeyemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awokoya_A/0/1/0/all/0/1\">Ayodele Awokoya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Espana_Bonet_C/0/1/0/all/0/1\">Cristina Espa&#xf1;a-Bonet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM. (arXiv:2104.04473v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.04473","description":"<p>Large language models have led to state-of-the-art accuracies across a range\nof tasks. However, training these models efficiently is challenging for two\nreasons: a) GPU memory capacity is limited, making it impossible to fit large\nmodels on even a multi-GPU server, and b) the number of compute operations\nrequired to train these models can result in unrealistically long training\ntimes. Consequently, new methods of model parallelism such as tensor and\npipeline parallelism have been proposed. Unfortunately, naive usage of these\nmethods leads to fundamental scaling issues at thousands of GPUs, e.g., due to\nexpensive cross-node communication or devices spending significant time waiting\non other devices to make progress.\n</p>\n<p>In this paper, we show how different types of parallelism methods (tensor,\npipeline, and data parallelism) can be composed to scale to thousands of GPUs\nand models with trillions of parameters. We survey techniques for pipeline\nparallelism and propose a novel interleaved pipeline parallelism schedule that\ncan improve throughput by 10+% with memory footprint comparable to existing\napproaches. We quantitatively study the trade-offs between tensor, pipeline,\nand data parallelism, and provide intuition as to how to configure distributed\ntraining of a large model. Our approach allows us to perform training\niterations on a model with 1 trillion parameters at 502 petaFLOP/s on 3072 GPUs\nwith achieved per-GPU throughput of 52% of theoretical peak. Our code is open\nsourced at https://github.com/nvidia/megatron-lm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_D/0/1/0/all/0/1\">Deepak Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casper_J/0/1/0/all/0/1\">Jared Casper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeGresley_P/0/1/0/all/0/1\">Patrick LeGresley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwary_M/0/1/0/all/0/1\">Mostofa Patwary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korthikanti_V/0/1/0/all/0/1\">Vijay Anand Korthikanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vainbrand_D/0/1/0/all/0/1\">Dmitri Vainbrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashinkunti_P/0/1/0/all/0/1\">Prethvi Kashinkunti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernauer_J/0/1/0/all/0/1\">Julie Bernauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phanishayee_A/0/1/0/all/0/1\">Amar Phanishayee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FUDGE: Controlled Text Generation With Future Discriminators. (arXiv:2104.05218v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.05218","description":"<p>We propose Future Discriminators for Generation (FUDGE), a flexible and\nmodular method for controlled text generation. Given a pre-existing model G for\ngenerating text from a distribution of interest, FUDGE enables conditioning on\na desired attribute a (for example, formality) while requiring access only to\nG's output logits. FUDGE learns an attribute predictor operating on a partial\nsequence, and uses this predictor's outputs to adjust G's original\nprobabilities. We show that FUDGE models terms corresponding to a Bayesian\ndecomposition of the conditional distribution of G given attribute a. Moreover,\nFUDGE can easily compose predictors for multiple desired attributes. We\nevaluate FUDGE on three tasks -- couplet completion in poetry, topic control in\nlanguage generation, and formality change in machine translation -- and observe\ngains in all three tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kevin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition. (arXiv:2104.09106v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.09106","description":"<p>Subword units are commonly used for end-to-end automatic speech recognition\n(ASR), while a fully acoustic-oriented subword modeling approach is somewhat\nmissing. We propose an acoustic data-driven subword modeling (ADSM) approach\nthat adapts the advantages of several text-based and acoustic-based subword\nmethods into one pipeline. With a fully acoustic-oriented label design and\nlearning process, ADSM produces acoustic-structured subword units and\nacoustic-matched target sequence for further ASR training. The obtained ADSM\nlabels are evaluated with different end-to-end ASR approaches including CTC,\nRNN-Transducer and attention models. Experiments on the LibriSpeech corpus show\nthat ADSM clearly outperforms both byte pair encoding (BPE) and\npronunciation-assisted subword modeling (PASM) in all cases. Detailed analysis\nshows that ADSM achieves acoustically more logical word segmentation and more\nbalanced sequence length, and thus, is suitable for both time-synchronous and\nlabel-synchronous models. We also briefly describe how to apply acoustic-based\nsubword regularization and unseen text segmentation using ADSM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zuoyun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection. (arXiv:2104.09261v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2104.09261","description":"<p>The existence of multiple datasets for sarcasm detection prompts us to apply\ntransfer learning to exploit their commonality. The adversarial neural transfer\n(ANT) framework utilizes multiple loss terms that encourage the source-domain\nand the target-domain feature distributions to be similar while optimizing for\ndomain-specific performance. However, these objectives may be in conflict,\nwhich can lead to optimization difficulties and sometimes diminished transfer.\nWe propose a generalized latent optimization strategy that allows different\nlosses to accommodate each other and improves training dynamics. The proposed\nmethod outperforms transfer learning and meta-learning baselines. In\nparticular, we achieve 10.02% absolute performance gain over the previous state\nof the art on the iSarcasm dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MathBERT: A Pre-trained Language Model for General NLP Tasks in Mathematics Education. (arXiv:2106.07340v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.07340","description":"<p>Since the introduction of the original BERT (i.e., BASE BERT), researchers\nhave developed various customized BERT models with improved performance for\nspecific domains and tasks by exploiting the benefits of {\\em transfer\nlearning}. Due to the nature of mathematical texts, which often use domain\nspecific vocabulary along with equations and math symbols, we posit that the\ndevelopment of a new BERT model for mathematics would be useful for many\nmathematical downstream tasks. In this resource paper, we introduce our\nmulti-institutional effort (i.e., two learning platforms and three academic\ninstitutions in the US) toward this need: MathBERT, a model created by\npre-training the BASE BERT model on a large mathematical corpus ranging from\npre-kindergarten (pre-k), to high-school, to college graduate level\nmathematical content. In addition, we select three general NLP tasks that are\noften used in mathematics education: prediction of knowledge component,\nauto-grading open-ended Q\\&amp;A, and knowledge tracing, to demonstrate the\nsuperiority of MathBERT over BASE BERT. Our experiments show that MathBERT\noutperforms prior best methods by 1.2-22\\% and BASE BERT by 2-8\\% on these\ntasks. In addition, we build a mathematics specific vocabulary `mathVocab' to\ntrain with MathBERT. We discover that MathBERT pre-trained with `mathVocab'\noutperforms MathBERT trained with the BASE BERT vocabulary (i.e., `origVocab').\nMathBERT is currently being adopted at the participated leaning platforms:\nStride, Inc, a commercial educational resource provider, and ASSISTments.org, a\nfree online educational platform. We release MathBERT for public usage at:\nhttps://github.com/tbs17/MathBERT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jia Tracy Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_M/0/1/0/all/0/1\">Michiharu Yamashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prihar_E/0/1/0/all/0/1\">Ethan Prihar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heffernan_N/0/1/0/all/0/1\">Neil Heffernan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xintao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graff_B/0/1/0/all/0/1\">Ben Graff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongwon Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task. (arXiv:2107.06959v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.06959","description":"<p>In this paper, we describe our end-to-end multilingual speech translation\nsystem submitted to the IWSLT 2021 evaluation campaign on the Multilingual\nSpeech Translation shared task. Our system is built by leveraging transfer\nlearning across modalities, tasks and languages. First, we leverage\ngeneral-purpose multilingual modules pretrained with large amounts of\nunlabelled and labelled data. We further enable knowledge transfer from the\ntext task to the speech task by training two tasks jointly. Finally, our\nmultilingual model is finetuned on speech translation task-specific data to\nachieve the best translation results. Experimental results show our system\noutperforms the reported systems, including both end-to-end and cascaded based\napproaches, by a large margin.\n</p>\n<p>In some translation directions, our speech translation results evaluated on\nthe public Multilingual TEDx test set are even comparable with the ones from a\nstrong text-to-text translation system, which uses the oracle speech\ntranscripts as input.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yun Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1\">Hongyu Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Changhan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pino_J/0/1/0/all/0/1\">Juan Pino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwenk_H/0/1/0/all/0/1\">Holger Schwenk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Naman Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical Relation Extraction Using Transformer-based Models. (arXiv:2107.08957v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.08957","description":"<p>The newly emerged transformer technology has a tremendous impact on NLP\nresearch. In the general English domain, transformer-based models have achieved\nstate-of-the-art performances on various NLP benchmarks. In the clinical\ndomain, researchers also have investigated transformer models for clinical\napplications. The goal of this study is to systematically explore three widely\nused transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical\nrelation extraction and develop an open-source package with clinical\npre-trained transformer-based models to facilitate information extraction in\nthe clinical domain. We developed a series of clinical RE models based on three\ntransformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these\nmodels using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2\nchallenges. We compared two classification strategies (binary vs. multi-class\nclassification) and investigated two approaches to generate candidate relations\nin different experimental settings. In this study, we compared three\ntransformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We\ndemonstrated that the RoBERTa-clinical RE model achieved the best performance\non the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2\ndataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our\nresults indicated that the binary classification strategy consistently\noutperformed the multi-class classification strategy for clinical relation\nextraction. Our methods and models are publicly available at\nhttps://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction.\nWe believe this work will improve current practice on clinical relation\nextraction and other related NLP tasks in the biomedical domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zehao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yonghui Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network. (arXiv:2108.03857v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2108.03857","description":"<p>\"Art is the lie that enables us to realize the truth.\" - Pablo Picasso. For\ncenturies, humans have dedicated themselves to producing arts to convey their\nimagination. The advancement in technology and deep learning in particular, has\ncaught the attention of many researchers trying to investigate whether art\ngeneration is possible by computers and algorithms. Using generative\nadversarial networks (GANs), applications such as synthesizing photorealistic\nhuman faces and creating captions automatically from images were realized. This\nsurvey takes a comprehensive look at the recent works using GANs for generating\nvisual arts, music, and literary text. A performance comparison and description\nof the various GAN architecture are also presented. Finally, some of the key\nchallenges in art generation using GANs are highlighted along with\nrecommendations for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1\">Sakib Shahriar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Noisy Channel Language Model Prompting for Few-Shot Text Classification. (arXiv:2108.04106v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.04106","description":"<p>We introduce a noisy channel approach for language model prompting in\nfew-shot text classification. Instead of computing the likelihood of the label\ngiven the input (referred as direct models), channel models compute the\nconditional probability of the input given the label, and are thereby required\nto explain every word in the input. We use channel models for recently proposed\nfew-shot learning methods with no or very limited updates to the language model\nparameters, via either in-context demonstration or prompt tuning. Our\nexperiments show that, for both methods, channel models significantly\noutperform their direct counterparts, which we attribute to their stability,\ni.e., lower variance and higher worst-case accuracy. We also present extensive\nablations that provide recommendations for when to use channel prompt tuning\ninstead of other competitive models (e.g., direct head tuning): channel prompt\ntuning is preferred when the number of training examples is small, labels in\nthe training data are imbalanced, or generalization to unseen labels is\nrequired.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generation Challenges: Results of the Accuracy Evaluation Shared Task. (arXiv:2108.05644v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.05644","description":"<p>The Shared Task on Evaluating Accuracy focused on techniques (both manual and\nautomatic) for evaluating the factual accuracy of texts produced by neural NLG\nsystems, in a sports-reporting domain. Four teams submitted evaluation\ntechniques for this task, using very different approaches and techniques. The\nbest-performing submissions did encouragingly well at this difficult task.\nHowever, all automatic submissions struggled to detect factual errors which are\nsemantically or pragmatically complex (for example, based on incorrect\ncomputation or inference).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thomson_C/0/1/0/all/0/1\">Craig Thomson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reiter_E/0/1/0/all/0/1\">Ehud Reiter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-08-16T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/"}}]}]}