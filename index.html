<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
</head>

<body>
<a href="https://github.com/NotCraft/NotFeed" style="margin: 0 auto;padding: 0.5em 1em;">NotCraft/NotFeed</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datetime="2021-08-10">2021-08-10</time></h2>
        <ul class="sources card">
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.CL updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Facebook AI WMT21 News Translation Task Submission.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1">Chau Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1">Shruti Bhosale</a>, <a href="http://arxiv.org/find/cs/1/au:+Cross_J/0/1/0/all/0/1">James Cross</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1">Philipp Koehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Edunov_S/0/1/0/all/0/1">Sergey Edunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1">Angela Fan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03265">
                                        <div class="article-summary-box-inner">
                                            <span><p>We describe Facebook's multilingual model submission to the WMT2021 shared
task on news translation. We participate in 14 language directions: English to
and from Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese. To
develop systems covering all these directions, we focus on multilingual models.
We utilize data from all available sources --- WMT, large-scale data mining,
and in-domain backtranslation --- to create high quality bilingual and
multilingual baselines. Subsequently, we investigate strategies for scaling
multilingual model size, such that one system has sufficient capacity for high
quality representations of all eight languages. Our final submission is an
ensemble of dense and sparse Mixture-of-Expert multilingual translation models,
followed by finetuning on in-domain news data and noisy channel reranking.
Compared to previous year's winning submissions, our multilingual system
improved the translation quality on all language directions, with an average
improvement of 2.0 BLEU. In the WMT2021 task, our system ranks first in 10
directions based on automatic evaluation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Offensive Language and Hate Speech Detection with Deep Learning and Transfer Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wei_B/0/1/0/all/0/1">Bencheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jason Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Ajay Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Umair_H/0/1/0/all/0/1">Hafiza Umair</a>, <a href="http://arxiv.org/find/cs/1/au:+Vovor_A/0/1/0/all/0/1">Atsu Vovor</a>, <a href="http://arxiv.org/find/cs/1/au:+Durzynski_N/0/1/0/all/0/1">Natalie Durzynski</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03305">
                                        <div class="article-summary-box-inner">
                                            <span><p>Toxic online speech has become a crucial problem nowadays due to an
exponential increase in the use of internet by people from different cultures
and educational backgrounds. Differentiating if a text message belongs to hate
speech and offensive language is a key challenge in automatic detection of
toxic text content. In this paper, we propose an approach to automatically
classify tweets into three classes: Hate, offensive and Neither. Using public
tweet data set, we first perform experiments to build BI-LSTM models from empty
embedding and then we also try the same neural network architecture with
pre-trained Glove embedding. Next, we introduce a transfer learning approach
for hate speech detection using an existing pre-trained language model BERT
(Bidirectional Encoder Representations from Transformers), DistilBert
(Distilled version of BERT) and GPT-2 (Generative Pre-Training). We perform
hyper parameters tuning analysis of our best model (BI-LSTM) considering
different neural network architectures, learn-ratings and normalization methods
etc. After tuning the model and with the best combination of parameters, we
achieve over 92 percent accuracy upon evaluating it on test data. We also
create a class module which contains main functionality including text
classification, sentiment checking and text data augmentation. This model could
serve as an intermediate module between user and Twitter.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Towards Zero-shot Language Modeling.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1">Edoardo Maria Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03334">
                                        <div class="article-summary-box-inner">
                                            <span><p>Can we construct a neural model that is inductively biased towards learning
human languages? Motivated by this question, we aim at constructing an
informative prior over neural weights, in order to adapt quickly to held-out
languages in the task of character-level language modeling. We infer this
distribution from a sample of typologically diverse training languages via
Laplace approximation. The use of such a prior outperforms baseline models with
an uninformative prior (so-called "fine-tuning") in both zero-shot and few-shot
settings. This shows that the prior is imbued with universal phonological
knowledge. Moreover, we harness additional language-specific side information
as distant supervision for held-out languages. Specifically, we condition
language models on features from typological databases, by concatenating them
to hidden states or generating weights with hyper-networks. These features
appear beneficial in the few-shot setting, but not in the zero-shot setting.
Since the paucity of digital texts affects the majority of the world's
languages, we hope that these findings will help broaden the scope of
applications for language technology.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Tiny Neural Models for Seq2Seq.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kandoor_A/0/1/0/all/0/1">Arun Kandoor</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03340">
                                        <div class="article-summary-box-inner">
                                            <span><p>Semantic parsing models with applications in task oriented dialog systems
require efficient sequence to sequence (seq2seq) architectures to be run
on-device. To this end, we propose a projection based encoder-decoder model
referred to as pQRNN-MAtt. Studies based on projection methods were restricted
to encoder-only models, and we believe this is the first study extending it to
seq2seq architectures. The resulting quantized models are less than 3.5MB in
size and are well suited for on-device latency critical applications. We show
that on MTOP, a challenging multilingual semantic parsing dataset, the average
model performance surpasses LSTM based seq2seq model that uses pre-trained
embeddings despite being 85x smaller. Furthermore, the model can be an
effective student for distilling large pre-trained models such as T5/BERT.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ What do Bias Measures Measure?.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1">Sunipa Dev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_E/0/1/0/all/0/1">Emily Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jieyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yu Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanseverino_M/0/1/0/all/0/1">Mattie Sanseverino</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jiin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03362">
                                        <div class="article-summary-box-inner">
                                            <span><p>Natural Language Processing (NLP) models propagate social biases about
protected attributes such as gender, race, and nationality. To create
interventions and mitigate these biases and associated harms, it is vital to be
able to detect and measure such biases. While many existing works propose bias
evaluation methodologies for different tasks, there remains a need to
cohesively understand what biases and normative harms each of these measures
captures and how different measures compare. To address this gap, this work
presents a comprehensive survey of existing bias measures in NLP as a function
of the associated NLP tasks, metrics, datasets, and social biases and
corresponding harms. This survey also organizes metrics into different
categories to present advantages and disadvantages. Finally, we propose a
documentation standard for bias measures to aid their development,
categorization, and appropriate usage.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Generating Personalized <span class="highlight_title">Dialogue</span> via Multi-Task Meta-Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jing Yang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kong Aik Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1">Woon Seng Gan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03377">
                                        <div class="article-summary-box-inner">
                                            <span><p>Conventional approaches to personalized dialogue generation typically require
a large corpus, as well as predefined persona information. However, in a
real-world setting, neither a large corpus of training data nor persona
information are readily available. To address these practical limitations, we
propose a novel multi-task meta-learning approach which involves training a
model to adapt to new personas without relying on a large corpus, or on any
predefined persona information. Instead, the model is tasked with generating
personalized responses based on only the dialogue context. Unlike prior work,
our approach leverages on the provided persona information only during training
via the introduction of an auxiliary persona reconstruction task. In this
paper, we introduce 2 frameworks that adopt the proposed multi-task
meta-learning approach: the Multi-Task Meta-Learning (MTML) framework, and the
Alternating Multi-Task Meta-Learning (AMTML) framework. Experimental results
show that utilizing MTML and AMTML results in dialogue responses with greater
persona consistency.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Controllable Summarization with Constrained Markov Decision Process.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1">Hou Pong Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03405">
                                        <div class="article-summary-box-inner">
                                            <span><p>We study controllable text summarization which allows users to gain control
on a particular attribute (e.g., length limit) of the generated summaries. In
this work, we propose a novel training framework based on Constrained Markov
Decision Process (CMDP), which conveniently includes a reward function along
with a set of constraints, to facilitate better summarization control. The
reward function encourages the generation to resemble the human-written
reference, while the constraints are used to explicitly prevent the generated
summaries from violating user-imposed requirements. Our framework can be
applied to control important attributes of summarization, including length,
covered entities, and abstractiveness, as we devise specific constraints for
each of these aspects. Extensive experiments on popular benchmarks show that
our CMDP framework helps generate informative summaries while complying with a
given attribute's requirement.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ An empirical assessment of deep learning approaches to task-oriented dialog management.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Matej%5Cr%7Bu%7D_L/0/1/0/all/0/1">Luk&#xe1;&#x161; Mat&#x11b;j&#x16f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Griol_D/0/1/0/all/0/1">David Griol</a>, <a href="http://arxiv.org/find/cs/1/au:+Callejas_Z/0/1/0/all/0/1">Zoraida Callejas</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_J/0/1/0/all/0/1">Jos&#xe9; Manuel Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchis_A/0/1/0/all/0/1">Araceli Sanchis</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03478">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep learning is providing very positive results in areas related to
conversational interfaces, such as speech recognition, but its potential
benefit for dialog management has still not been fully studied. In this paper,
we perform an assessment of different configurations for deep-learned dialog
management with three dialog corpora from different application domains and
varying in size, dimensionality and possible system responses. Our results have
allowed us to identify several aspects that can have an impact on accuracy,
including the approaches used for feature extraction, input representation,
context consideration and the hyper-parameters of the deep neural networks
employed.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Fine-tuning <span class="highlight_title">GPT</span>-3 for Russian Text Summarization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nikolich_A/0/1/0/all/0/1">Alexandr Nikolich</a>, <a href="http://arxiv.org/find/cs/1/au:+Puchkova_A/0/1/0/all/0/1">Arina Puchkova</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03502">
                                        <div class="article-summary-box-inner">
                                            <span><p>Automatic summarization techniques aim to shorten and generalize information
given in the text while preserving its core message and the most relevant
ideas. This task can be approached and treated with a variety of methods,
however, not many attempts have been made to produce solutions specifically for
the Russian language despite existing localizations of the state-of-the-art
models. In this paper, we aim to showcase ruGPT3 ability to summarize texts,
fine-tuning it on the corpora of Russian news with their corresponding
human-generated summaries. Additionally, we employ hyperparameter tuning so
that the model's output becomes less random and more tied to the original text.
We evaluate the resulting texts with a set of metrics, showing that our
solution can surpass the state-of-the-art model's performance without
additional changes in architecture or loss function. Despite being able to
produce sensible summaries, our model still suffers from a number of flaws,
namely, it is prone to altering Named Entities present in the original text
(such as surnames, places, dates), deviating from facts stated in the given
document, and repeating the information in the summary.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Multilingual Compositional Wikidata Questions.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1">Ruixiang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1">Rahul Aralikatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Lent_H/0/1/0/all/0/1">Heather Lent</a>, <a href="http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1">Daniel Hershcovich</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03509">
                                        <div class="article-summary-box-inner">
                                            <span><p>Semantic parsing allows humans to leverage vast knowledge resources through
natural interaction. However, parsers are mostly designed for and evaluated on
English resources, such as CFQ (Keysers et al., 2020), the current standard
benchmark based on English data generated from grammar rules and oriented
towards Freebase, an outdated knowledge base. We propose a method for creating
a multilingual, parallel dataset of question-query pairs, grounded in Wikidata,
and introduce such a dataset called Compositional Wikidata Questions (CWQ). We
utilize this data to train and evaluate semantic parsers for Hebrew, Kannada,
Chinese and English, to better understand the current strengths and weaknesses
of multilingual semantic parsing. Experiments on zero-shot cross-lingual
transfer demonstrate that models fail to generate valid queries even with
pretrained multilingual encoders. Our methodology, dataset and results will
facilitate future research on semantic parsing in more realistic and diverse
settings than has been possible with existing resources.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Improving Similar Language Translation With Transfer Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Adebara_I/0/1/0/all/0/1">Ife Adebara</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03533">
                                        <div class="article-summary-box-inner">
                                            <span><p>We investigate transfer learning based on pre-trained neural machine
translation models to translate between (low-resource) similar languages. This
work is part of our contribution to the WMT 2021 Similar Languages Translation
Shared Task where we submitted models for different language pairs, including
French-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions. Our
models for Catalan-Spanish ($82.79$ BLEU) and Portuguese-Spanish ($87.11$ BLEU)
rank top 1 in the official shared task evaluation, and we are the only team to
submit models for the French-Bambara pairs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Language Model Evaluation in Open-ended Text Generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">An Nguyen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03578">
                                        <div class="article-summary-box-inner">
                                            <span><p>Although current state-of-the-art language models have achieved impressive
results in numerous natural language processing tasks, still they could not
solve the problem of producing repetitive, dull and sometimes inconsistent text
in open-ended text generation. Studies often attribute this problem to the
maximum likelihood training objective, and propose alternative approaches by
using stochastic decoding methods or altering the training objective. However,
there is still a lack of consistent evaluation metrics to directly compare the
efficacy of these solutions. In this work, we study different evaluation
metrics that have been proposed to evaluate quality, diversity and consistency
of machine-generated text. From there, we propose a practical pipeline to
evaluate language models in open-ended generation task, and research on how to
improve the model's performance in all dimensions by leveraging different
auxiliary training objectives.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ #StayHome or #Marathon? Social Media Enhanced Pandemic Surveillance on Spatial-temporal Dynamic Graphs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yichao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jyun-yu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiusi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03670">
                                        <div class="article-summary-box-inner">
                                            <span><p>COVID-19 has caused lasting damage to almost every domain in public health,
society, and economy. To monitor the pandemic trend, existing studies rely on
the aggregation of traditional statistical models and epidemic spread theory.
In other words, historical statistics of COVID-19, as well as the population
mobility data, become the essential knowledge for monitoring the pandemic
trend. However, these solutions can barely provide precise prediction and
satisfactory explanations on the long-term disease surveillance while the
ubiquitous social media resources can be the key enabler for solving this
problem. For example, serious discussions may occur on social media before and
after some breaking events take place. These events, such as marathon and
parade, may impact the spread of the virus. To take advantage of the social
media data, we propose a novel framework, Social Media enhAnced pandemic
suRveillance Technique (SMART), which is composed of two modules: (i)
information extraction module to construct heterogeneous knowledge graphs based
on the extracted events and relationships among them; (ii) time series
prediction module to provide both short-term and long-term forecasts of the
confirmed cases and fatality at the state-level in the United States and to
discover risk factors for COVID-19 interventions. Extensive experiments show
that our method largely outperforms the state-of-the-art baselines by 7.3% and
7.4% in confirmed case/fatality prediction, respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Leveraging Commonsense Knowledge on Classifying False News and Determining Checkworthiness of Claims.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Schlicht_I/0/1/0/all/0/1">Ipek Baris Schlicht</a>, <a href="http://arxiv.org/find/cs/1/au:+Sezerer_E/0/1/0/all/0/1">Erhan Sezerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tekir_S/0/1/0/all/0/1">Selma Tekir</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_O/0/1/0/all/0/1">Oul Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukhers_Z/0/1/0/all/0/1">Zeyd Boukhers</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03731">
                                        <div class="article-summary-box-inner">
                                            <span><p>Widespread and rapid dissemination of false news has made fact-checking an
indispensable requirement. Given its time-consuming and labor-intensive nature,
the task calls for an automated support to meet the demand. In this paper, we
propose to leverage commonsense knowledge for the tasks of false news
classification and check-worthy claim detection. Arguing that commonsense
knowledge is a factor in human believability, we fine-tune the BERT language
model with a commonsense question answering task and the aforementioned tasks
in a multi-task learning environment. For predicting fine-grained false news
types, we compare the proposed fine-tuned model's performance with the false
news classification models on a public dataset as well as a newly collected
dataset. We compare the model's performance with the single-task BERT model and
a state-of-the-art check-worthy claim detection tool to evaluate the
check-worthy claim detection. Our experimental analysis demonstrates that
commonsense knowledge can improve performance in both tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Machine Translation of Low-Resource Indo-European Languages.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei-Rui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03739">
                                        <div class="article-summary-box-inner">
                                            <span><p>Transfer learning has been an important technique for low-resource neural
machine translation. In this work, we build two systems to study how
relatedness can benefit the translation performance. The primary system adopts
machine translation model pre-trained on related language pair and the
contrastive system adopts that pre-trained on unrelated language pair. We show
that relatedness is not required for transfer learning to work but does benefit
the performance.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ The HW-TSC's Offline Speech Translation Systems for IWSLT 2021 Evaluation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Minghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxia Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiaxin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yingtao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yujia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1">Shimin Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xingshan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liangyou Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Ying Qin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03845">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper describes our work in participation of the IWSLT-2021 offline
speech translation task. Our system was built in a cascade form, including a
speaker diarization module, an Automatic Speech Recognition (ASR) module and a
Machine Translation (MT) module. We directly use the LIUM SpkDiarization tool
as the diarization module. The ASR module is trained with three ASR datasets
from different sources, by multi-source training, using a modified Transformer
encoder. The MT module is pretrained on the large-scale WMT news translation
dataset and fine-tuned on the TED corpus. Our method achieves 24.6 BLEU score
on the 2021 test set.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                        <div class="article-summary-box-inner">
                                            <span><p>"Art is the lie that enables us to realize the truth." - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Knowledge Graph Augmented Political Perspective Detection in News Media.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shangbin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zilong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Minnan Luo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03861">
                                        <div class="article-summary-box-inner">
                                            <span><p>Identifying political perspective in news media has become an important task
due to the rapid growth of political commentary and the increasingly polarized
ideologies. Previous approaches only focus on leveraging the semantic
information and leaves out the rich social and political context that helps
individuals understand political stances. In this paper, we propose a
perspective detection method that incorporates external knowledge of real-world
politics. Specifically, we construct a contemporary political knowledge graph
with 1,071 entities and 10,703 triples. We then build a heterogeneous
information network for each news document that jointly models article
semantics and external knowledge in knowledge graphs. Finally, we apply gated
relational graph convolutional networks and conduct political perspective
detection as graph-level classification. Extensive experiments show that our
method achieves the best performance and outperforms state-of-the-art methods
by 5.49\%. Numerous ablation studies further bear out the necessity of external
knowledge and the effectiveness of our graph-based approach.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Encoding Heterogeneous Social and Political Context for Entity Stance Prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shangbin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zilong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Peisheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Minnan Luo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03881">
                                        <div class="article-summary-box-inner">
                                            <span><p>Political stance detection has become an important task due to the
increasingly polarized political ideologies. Most existing works focus on
identifying perspectives in news articles or social media posts, while social
entities, such as individuals and organizations, produce these texts and
actually take stances. In this paper, we propose the novel task of entity
stance prediction, which aims to predict entities' stances given their social
and political context. Specifically, we retrieve facts from Wikipedia about
social entities regarding contemporary U.S. politics. We then annotate social
entities' stances towards political ideologies with the help of domain experts.
After defining the task of entity stance prediction, we propose a graph-based
solution, which constructs a heterogeneous information network from collected
facts and adopts gated relational graph convolutional networks for
representation learning. Our model is then trained with a combination of
supervised, self-supervised and unsupervised loss functions, which are
motivated by multiple social and political phenomenons. We conduct extensive
experiments to compare our method with existing text and graph analysis
baselines. Our model achieves highest stance detection accuracy and yields
inspiring insights regarding social entity stances. We further conduct ablation
study and parameter analysis to study the mechanism and effectiveness of our
proposed approach.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Do Images really do the Talking? Analysing the significance of Images in Tamil Troll meme classification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hegde_S/0/1/0/all/0/1">Siddhanth U Hegde</a>, <a href="http://arxiv.org/find/cs/1/au:+Hande_A/0/1/0/all/0/1">Adeep Hande</a>, <a href="http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1">Ruba Priyadharshini</a>, <a href="http://arxiv.org/find/cs/1/au:+Thavareesan_S/0/1/0/all/0/1">Sajeetha Thavareesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakuntharaj_R/0/1/0/all/0/1">Ratnasingam Sakuntharaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Thangasamy_S/0/1/0/all/0/1">Sathiyaraj Thangasamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharathi_B/0/1/0/all/0/1">B Bharathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03886">
                                        <div class="article-summary-box-inner">
                                            <span><p>A meme is an part of media created to share an opinion or emotion across the
internet. Due to its popularity, memes have become the new forms of
communication on social media. However, due to its nature, they are being used
in harmful ways such as trolling and cyberbullying progressively. Various data
modelling methods create different possibilities in feature extraction and
turning them into beneficial information. The variety of modalities included in
data plays a significant part in predicting the results. We try to explore the
significance of visual features of images in classifying memes. Memes are a
blend of both image and text, where the text is embedded into the image. We try
to incorporate the memes as troll and non-trolling memes based on the images
and the text on them. However, the images are to be analysed and combined with
the text to increase performance. Our work illustrates different textual
analysis methods and contrasting multimodal methods ranging from simple merging
to cross attention to utilising both worlds' - best visual and textual
features. The fine-tuned cross-lingual language model, XLM, performed the best
in textual analysis, and the multimodal transformer performs the best in
multimodal analysis.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ On the Transferability of Neural Models of Morphological Analogies.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Alsaidi_S/0/1/0/all/0/1">Safa Alsaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_A/0/1/0/all/0/1">Amandine Decker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lay_P/0/1/0/all/0/1">Puthineath Lay</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquer_E/0/1/0/all/0/1">Esteban Marquer</a>, <a href="http://arxiv.org/find/cs/1/au:+Murena_P/0/1/0/all/0/1">Pierre-Alexandre Murena</a>, <a href="http://arxiv.org/find/cs/1/au:+Couceiro_M/0/1/0/all/0/1">Miguel Couceiro</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03938">
                                        <div class="article-summary-box-inner">
                                            <span><p>Analogical proportions are statements expressed in the form "A is to B as C
is to D" and are used for several reasoning and classification tasks in
artificial intelligence and natural language processing (NLP). In this paper,
we focus on morphological tasks and we propose a deep learning approach to
detect morphological analogies. We present an empirical study to see how our
framework transfers across languages, and that highlights interesting
similarities and differences between these languages. In view of these results,
we also discuss the possibility of building a multilingual morphological model.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Neural Approach for Detecting Morphological Analogies.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Alsaidi_S/0/1/0/all/0/1">Safa Alsaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_A/0/1/0/all/0/1">Amandine Decker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lay_P/0/1/0/all/0/1">Puthineath Lay</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquer_E/0/1/0/all/0/1">Esteban Marquer</a>, <a href="http://arxiv.org/find/cs/1/au:+Murena_P/0/1/0/all/0/1">Pierre-Alexandre Murena</a>, <a href="http://arxiv.org/find/cs/1/au:+Couceiro_M/0/1/0/all/0/1">Miguel Couceiro</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03945">
                                        <div class="article-summary-box-inner">
                                            <span><p>Analogical proportions are statements of the form "A is to B as C is to D"
that are used for several reasoning and classification tasks in artificial
intelligence and natural language processing (NLP). For instance, there are
analogy based approaches to semantics as well as to morphology. In fact,
symbolic approaches were developed to solve or to detect analogies between
character strings, e.g., the axiomatic approach as well as that based on
Kolmogorov complexity. In this paper, we propose a deep learning approach to
detect morphological analogies, for instance, with reinflexion or conjugation.
We present empirical results that show that our framework is competitive with
the above-mentioned state of the art symbolic approaches. We also explore
empirically its transferability capacity across languages, which highlights
interesting similarities between them.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Not quite there yet: Combining analogical patterns and encoder-decoder networks for cognitively plausible inflection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Calderone_B/0/1/0/all/0/1">Basilio Calderone</a> (CLLE), <a href="http://arxiv.org/find/cs/1/au:+Hathout_N/0/1/0/all/0/1">Nabil Hathout</a> (CLLE), <a href="http://arxiv.org/find/cs/1/au:+Bonami_O/0/1/0/all/0/1">Olivier Bonami</a> (LLF UMR7110), ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03968">
                                        <div class="article-summary-box-inner">
                                            <span><p>The paper presents four models submitted to Part 2 of the SIGMORPHON 2021
Shared Task 0, which aims at replicating human judgements on the inflection of
nonce lexemes. Our goal is to explore the usefulness of combining pre-compiled
analogical patterns with an encoder-decoder architecture. Two models are
designed using such patterns either in the input or the output of the network.
Two extra models controlled for the role of raw similarity of nonce inflected
forms to existing inflected forms in the same paradigm cell, and the role of
the type frequency of analogical patterns. Our strategy is entirely endogenous
in the sense that the models appealing solely to the data provided by the
SIGMORPHON organisers, without using external resources. Our model 2 ranks
second among all submitted systems, suggesting that the inclusion of analogical
patterns in the network architecture is useful in mimicking speakers'
predictions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ <span class="highlight_title">BERT</span>-based distractor generation for Swedish reading comprehension questions using a small-scale dataset.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kalpakchi_D/0/1/0/all/0/1">Dmytro Kalpakchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Boye_J/0/1/0/all/0/1">Johan Boye</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03973">
                                        <div class="article-summary-box-inner">
                                            <span><p>An important part when constructing multiple-choice questions (MCQs) for
reading comprehension assessment are the distractors, the incorrect but
preferably plausible answer options. In this paper, we present a new BERT-based
method for automatically generating distractors using only a small-scale
dataset. We also release a new such dataset of Swedish MCQs (used for training
the model), and propose a methodology for assessing the generated distractors.
Evaluation shows that from a student's perspective, our method generated one or
more plausible distractors for more than 50% of the MCQs in our test set. From
a teacher's perspective, about 50% of the generated distractors were deemed
appropriate. We also do a thorough analysis of the results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Image Retrieval on Real-life Images with <span class="highlight_title">Pre-train</span>ed <span class="highlight_title">Vision-and-Language</span> Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Opazo_C/0/1/0/all/0/1">Cristian Rodriguez-Opazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1">Damien Teney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04024">
                                        <div class="article-summary-box-inner">
                                            <span><p>We extend the task of composed image retrieval, where an input query consists
of an image and short textual description of how to modify the image. Existing
methods have only been applied to non-complex images within narrow domains,
such as fashion products, thereby limiting the scope of study on in-depth
visual reasoning in rich image and language contexts. To address this issue, we
collect the Compose Image Retrieval on Real-life images (CIRR) dataset, which
consists of over 36,000 pairs of crowd-sourced, open-domain images with
human-generated modifying text. To extend current methods to the open-domain,
we propose CIRPLANT, a transformer based model that leverages rich pre-trained
vision-and-language (V&amp;L) knowledge for modifying visual features conditioned
on natural language. Retrieval is then done by nearest neighbor lookup on the
modified features. We demonstrate that with a relatively simple architecture,
CIRPLANT outperforms existing methods on open-domain images, while matching
state-of-the-art accuracy on the existing narrow datasets, such as fashion.
Together with the release of CIRR, we believe this work will inspire further
research on composed image retrieval.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Multi-modal Retrieval of Tables and Texts Using Tri-encoder Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kostic_B/0/1/0/all/0/1">Bogdan Kosti&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04049">
                                        <div class="article-summary-box-inner">
                                            <span><p>Open-domain extractive question answering works well on textual data by first
retrieving candidate texts and then extracting the answer from those
candidates. However, some questions cannot be answered by text alone but
require information stored in tables. In this paper, we present an approach for
retrieving both texts and tables relevant to a question by jointly encoding
texts, tables and questions into a single vector space. To this end, we create
a new multi-modal dataset based on text and table datasets from related work
and compare the retrieval performance of different encoding schemata. We find
that dense vector embeddings of transformer models outperform sparse embeddings
on four out of six evaluation datasets. Comparing different dense embedding
models, tri-encoders, with one encoder for each question, text and table,
increase retrieval performance compared to bi-encoders with one encoder for the
question and one for both text and tables. We release the newly created
multi-modal dataset to the community so that it can be used for training and
evaluation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Extracting and categorising the reactions to COVID-19 by the South African public -- A social media study.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>, <a href="http://arxiv.org/find/cs/1/au:+Moodley_A/0/1/0/all/0/1">Avashlin Moodley</a>, <a href="http://arxiv.org/find/cs/1/au:+Saba_A/0/1/0/all/0/1">Athandiwe Saba</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06336">
                                        <div class="article-summary-box-inner">
                                            <span><p>Social Media can be used to extract discussion topics during a disaster. With
the COVID-19 pandemic impact on South Africa, we need to understand how the law
and regulation promulgated by the government in response to the pandemic
contrasts with discussion topics social media users have been engaging in. In
this work, we expand on traditional media analysis by using Social Media
discussions driven by or directed to South African government officials. We
find topics that are similar as well as different in some cases. The findings
can inform further study into social media during disaster settings in South
Africa and beyond. This paper sets a framework for future analysis in
understanding the opinions of the public during a pandemic and how these
opinions can be distilled [in a semi-automated approach] to inform government
communication in the future.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Generation-Augmented Retrieval for Open-domain Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1"><span class="highlight_author">Jianfeng Gao</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"><span class="highlight_author">Jiawei Han</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08553">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose Generation-Augmented Retrieval (GAR) for answering open-domain
questions, which augments a query through text generation of heuristically
discovered relevant contexts without external resources as supervision. We
demonstrate that the generated contexts substantially enrich the semantics of
the queries and GAR with sparse representations (BM25) achieves comparable or
better performance than state-of-the-art dense retrieval methods such as DPR.
We show that generating diverse contexts for a query is beneficial as fusing
their results consistently yields better retrieval accuracy. Moreover, as
sparse and dense representations are often complementary, GAR can be easily
combined with DPR to achieve even better performance. GAR achieves
state-of-the-art performance on Natural Questions and TriviaQA datasets under
the extractive QA setup when equipped with an extractive reader, and
consistently outperforms other retrieval methods when the same generative
reader is used.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Taille_B/0/1/0/all/0/1">Bruno Taill&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1">Vincent Guigue</a>, <a href="http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1">Geoffrey Scoutheeten</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10684">
                                        <div class="article-summary-box-inner">
                                            <span><p>Despite efforts to distinguish three different evaluation setups (Bekoulis et
al., 2018), numerous end-to-end Relation Extraction (RE) articles present
unreliable performance comparison to previous work. In this paper, we first
identify several patterns of invalid comparisons in published papers and
describe them to avoid their propagation. We then propose a small empirical
study to quantify the impact of the most common mistake and evaluate it leads
to overestimating the final RE performance by around 5% on ACE05. We also seize
this opportunity to study the unexplored ablations of two recent developments:
the use of language model pretraining (specifically BERT) and span-level NER.
This meta-analysis emphasizes the need for rigor in the report of both the
evaluation setting and the datasets statistics and we call for unifying the
evaluation setting in end-to-end RE.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Notes on Coalgebras in Stylometry.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Doat_J/0/1/0/all/0/1">Jo&#xeb;l A. Doat</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02733">
                                        <div class="article-summary-box-inner">
                                            <span><p>The syntactic behaviour of texts can highly vary depending on their contexts
(e.g. author, genre, etc.). From the standpoint of stylometry, it can be
helpful to objectively measure this behaviour. In this paper, we discuss how
coalgebras are used to formalise the notion of behaviour by embedding syntactic
features of a given text into probabilistic transition systems. By introducing
the behavioural distance, we are then able to quantitatively measure
differences between points in these systems and thus, comparing features of
different texts. Furthermore, the behavioural distance of points can be
approximated by a polynomial-time algorithm.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced Bengali Language.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Md. Rezaul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1">Sumon Kanti Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1">Sagor Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_M/0/1/0/all/0/1">Mehadi Hasan Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_K/0/1/0/all/0/1">Kabir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md. Azam Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_S/0/1/0/all/0/1">Stefan Decker</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14353">
                                        <div class="article-summary-box-inner">
                                            <span><p>The exponential growths of social media and micro-blogging sites not only
provide platforms for empowering freedom of expressions and individual voices,
but also enables people to express anti-social behaviour like online
harassment, cyberbullying, and hate speech. Numerous works have been proposed
to utilize textual data for social and anti-social behaviour analysis, by
predicting the contexts mostly for highly-resourced languages like English.
However, some languages are under-resourced, e.g., South Asian languages like
Bengali, that lack computational resources for accurate natural language
processing (NLP). In this paper, we propose an explainable approach for hate
speech detection from the under-resourced Bengali language, which we called
DeepHateExplainer. Bengali texts are first comprehensively preprocessed, before
classifying them into political, personal, geopolitical, and religious hates
using a neural ensemble method of transformer-based neural architectures (i.e.,
monolingual Bangla BERT-base, multilingual BERT-cased/uncased, and
XLM-RoBERTa). Important(most and least) terms are then identified using
sensitivity analysis and layer-wise relevance propagation(LRP), before
providing human-interpretable explanations. Finally, we compute
comprehensiveness and sufficiency scores to measure the quality of explanations
w.r.t faithfulness. Evaluations against machine learning~(linear and tree-based
models) and neural networks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word
embeddings) baselines yield F1-scores of 78%, 91%, 89%, and 84%, for political,
personal, geopolitical, and religious hates, respectively, outperforming both
ML and DNN baselines.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Rider: Reader-Guided Passage Reranking for Open-Domain Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1"><span class="highlight_author">Jianfeng Gao</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"><span class="highlight_author">Jiawei Han</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00294">
                                        <div class="article-summary-box-inner">
                                            <span><p>Current open-domain question answering systems often follow a
Retriever-Reader architecture, where the retriever first retrieves relevant
passages and the reader then reads the retrieved passages to form an answer. In
this paper, we propose a simple and effective passage reranking method, named
Reader-guIDEd Reranker (RIDER), which does not involve training and reranks the
retrieved passages solely based on the top predictions of the reader before
reranking. We show that RIDER, despite its simplicity, achieves 10 to 20
absolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) gains
without refining the retriever or reader. In addition, RIDER, without any
training, outperforms state-of-the-art transformer-based supervised rerankers.
Remarkably, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 EM
on the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are
used as the reader input after passage reranking.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ NeurIPS 2020 NLC2CMD Competition: Translating Natural Language to Bash Commands.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Agarwal_M/0/1/0/all/0/1">Mayank Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborti_T/0/1/0/all/0/1">Tathagata Chakraborti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1">Quchen Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gros_D/0/1/0/all/0/1">David Gros</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xi Victoria Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Maene_J/0/1/0/all/0/1">Jaron Maene</a>, <a href="http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1">Kartik Talamadupula</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1">Zhongwei Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1">Jules White</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02523">
                                        <div class="article-summary-box-inner">
                                            <span><p>The NLC2CMD Competition hosted at NeurIPS 2020 aimed to bring the power of
natural language processing to the command line. Participants were tasked with
building models that can transform descriptions of command line tasks in
English to their Bash syntax. This is a report on the competition with details
of the task, metrics, data, attempted solutions, and lessons learned.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ExKaldi-RT: A Real-Time Automatic Speech Recognition Extension Toolkit of Kaldi.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Leow_C/0/1/0/all/0/1">Chee Siang Leow</a>, <a href="http://arxiv.org/find/eess/1/au:+Kobayashi_A/0/1/0/all/0/1">Akio Kobayashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Utsuro_T/0/1/0/all/0/1">Takehito Utsuro</a>, <a href="http://arxiv.org/find/eess/1/au:+Nishizaki_H/0/1/0/all/0/1">Hiromitsu Nishizaki</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01384">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper describes the ExKaldi-RT online automatic speech recognition (ASR)
toolkit that is implemented based on the Kaldi ASR toolkit and Python language.
ExKaldi-RT provides tools for building online recognition pipelines. While
similar tools are available built on Kaldi, a key feature of ExKaldi-RT that it
works on Python, which has an easy-to-use interface that allows online ASR
system developers to develop original research, such as by applying neural
network-based signal processing and by decoding model trained with deep
learning frameworks. We performed benchmark experiments on the minimum
LibriSpeech corpus, and it showed that ExKaldi-RT could achieve competitive ASR
performance in real-time recognition.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Identifying Offensive Expressions of Opinion in Context.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1">Francielle Alves Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_I/0/1/0/all/0/1">Isabelle Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Goes_F/0/1/0/all/0/1">Fabiana Rodrigues de G&#xf3;es</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12227">
                                        <div class="article-summary-box-inner">
                                            <span><p>Classic information extraction techniques consist in building questions and
answers about the facts. Indeed, it is still a challenge to subjective
information extraction systems to identify opinions and feelings in context. In
sentiment-based NLP tasks, there are few resources to information extraction,
above all offensive or hateful opinions in context. To fill this important gap,
this short paper provides a new cross-lingual and contextual offensive lexicon,
which consists of explicit and implicit offensive and swearing expressions of
opinion, which were annotated in two different classes: context dependent and
context-independent offensive. In addition, we provide markers to identify hate
speech. Annotation approach was evaluated at the expression-level and achieves
high human inter-annotator agreement. The provided offensive lexicon is
available in Portuguese and English languages.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Do Context-Aware Translation Models Pay the Right Attention?.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kayo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1">Patrick Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1">Danish Pruthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1">Aditi Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; F. T. Martins</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1"><span class="highlight_author">Graham Neubig</span></a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06977">
                                        <div class="article-summary-box-inner">
                                            <span><p>Context-aware machine translation models are designed to leverage contextual
information, but often fail to do so. As a result, they inaccurately
disambiguate pronouns and polysemous words that require context for resolution.
In this paper, we ask several questions: What contexts do human translators use
to resolve ambiguous words? Are models paying large amounts of attention to the
same context? What if we explicitly train them to do so? To answer these
questions, we introduce SCAT (Supporting Context for Ambiguous Translations), a
new English-French dataset comprising supporting context words for 14K
translations that professional translators found useful for pronoun
disambiguation. Using SCAT, we perform an in-depth analysis of the context used
to disambiguate, examining positional and lexical characteristics of the
supporting words. Furthermore, we measure the degree of alignment between the
model's attention scores and the supporting context from SCAT, and apply a
guided attention strategy to encourage agreement between the two.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ M6-T: Exploring Sparse Expert Models and Beyond.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">An Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Junyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Le Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xianyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Ang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiamang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Di Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Lin Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15082">
                                        <div class="article-summary-box-inner">
                                            <span><p>Mixture-of-Experts (MoE) models can achieve promising results with outrageous
large amount of parameters but constant computation cost, and thus it has
become a trend in model scaling. Still it is a mystery how MoE layers bring
quality gains by leveraging the parameters with sparse activation. In this
work, we investigate several key factors in sparse expert models. We observe
that load imbalance may not be a significant problem affecting model quality,
contrary to the perspectives of recent studies, while the number of sparsely
activated experts $k$ and expert capacity $C$ in top-$k$ routing can
significantly make a difference in this context. Furthermore, we take a step
forward to propose a simple method called expert prototyping that splits
experts into different prototypes and applies $k$ top-$1$ routing. This
strategy improves the model quality but maintains constant computational costs,
and our further exploration on extremely large-scale models reflects that it is
more effective in training larger models. We push the model scale to over $1$
trillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in
comparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model
achieves substantial speedup in convergence over the same-size baseline.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ TellMeWhy: A Dataset for Answering Why-Questions in Narratives.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1">Yash Kumar Lal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1">Nathanael Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1">Raymond Mooney</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06132">
                                        <div class="article-summary-box-inner">
                                            <span><p>Answering questions about why characters perform certain actions is central
to understanding and reasoning about narratives. Despite recent progress in QA,
it is not clear if existing models have the ability to answer "why" questions
that may require commonsense knowledge external to the input narrative. In this
work, we introduce TellMeWhy, a new crowd-sourced dataset that consists of more
than 30k questions and free-form answers concerning why characters in short
narratives perform the actions described. For a third of this dataset, the
answers are not present within the narrative. Given the limitations of
automated evaluation for this task, we also present a systematized human
evaluation interface for this dataset. Our evaluation of state-of-the-art
models show that they are far below human performance on answering such
questions. They are especially worse on questions whose answers are external to
the narrative, thus providing a challenge for future QA and narrative
understanding research.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Ashwin Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1">Adriel Saporta</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Steven QH Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1">Du Nguyen Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tan Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambon_P/0/1/0/all/0/1">Pierre Chambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1">Curtis P. Langlotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
                                        <div class="article-summary-box-inner">
                                            <span><p>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Don't Take It Literally: An Edit-Invariant Sequence Loss for Text Generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zichao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_T/0/1/0/all/0/1">Tianhua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1"><span class="highlight_author">Zhiting Hu</span></a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15078">
                                        <div class="article-summary-box-inner">
                                            <span><p>Neural text generation models are typically trained by maximizing
log-likelihood with the sequence cross entropy loss, which encourages an exact
token-by-token match between a target sequence with a generated sequence. Such
training objective is sub-optimal when the target sequence not perfect, e.g.,
when the target sequence is corrupted with noises, or when only weak sequence
supervision is available. To address this challenge, we propose a novel
Edit-Invariant Sequence Loss (EISL), which computes the matching loss of a
target n-gram with all n-grams in the generated sequence. EISL draws
inspirations from convolutional networks (ConvNets) which are shift-invariant
to images, hence is robust to the shift of n-grams to tolerate edits in the
target sequences. Moreover, the computation of EISL is essentially a
convolution operation with target n-grams as kernels, which is easy to
implement with existing libraries. To demonstrate the effectiveness of EISL, we
conduct experiments on three tasks: machine translation with noisy target
sequences, unsupervised text style transfer, and non-autoregressive machine
translation. Experimental results show our method significantly outperforms
cross entropy loss on these three tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Causal<span class="highlight_title">BERT</span>: Injecting Causal Knowledge Into <span class="highlight_title">Pre-train</span>ed Models with Minimal Supervision.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xiao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_K/0/1/0/all/0/1">Kuo Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09852">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent work has shown success in incorporating pre-trained models like BERT
to improve NLP systems. However, existing pre-trained models lack of causal
knowledge which prevents today's NLP systems from thinking like humans. In this
paper, we investigate the problem of injecting causal knowledge into
pre-trained models. There are two fundamental problems: 1) how to collect
various granularities of causal pairs from unstructured texts; 2) how to
effectively inject causal knowledge into pre-trained models. To address these
issues, we extend the idea of CausalBERT from previous studies, and conduct
experiments on various datasets to evaluate its effectiveness. In addition, we
adopt a regularization-based method to preserve the already learned knowledge
with an extra regularization term while injecting causal knowledge. Extensive
experiments on 7 datasets, including four causal pair classification tasks, two
causal QA tasks and a causal inference task, demonstrate that CausalBERT
captures rich causal knowledge and outperforms all pre-trained models-based
state-of-the-art methods, achieving a new causal inference benchmark.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Greedy Gradient Ensemble for Robust Visual Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xinzhe Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12651">
                                        <div class="article-summary-box-inner">
                                            <span><p>Language bias is a critical issue in Visual Question Answering (VQA), where
models often exploit dataset biases for the final decision without considering
the image information. As a result, they suffer from performance drop on
out-of-distribution data and inadequate visual explanation. Based on
experimental analysis for existing robust VQA methods, we stress the language
bias in VQA that comes from two aspects, i.e., distribution bias and shortcut
bias. We further propose a new de-bias framework, Greedy Gradient Ensemble
(GGE), which combines multiple biased models for unbiased base model learning.
With the greedy strategy, GGE forces the biased models to over-fit the biased
data distribution in priority, thus makes the base model pay more attention to
examples that are hard to solve by biased models. The experiments demonstrate
that our method makes better use of visual information and achieves
state-of-the-art performance on diagnosing dataset VQA-CP without using extra
annotations.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Underreporting of errors in NLG output, and what to do about it.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Miltenburg_E/0/1/0/all/0/1">Emiel van Miltenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Clinciu_M/0/1/0/all/0/1">Miruna-Adriana Clinciu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1">Ond&#x159;ej Du&#x161;ek</a>, <a href="http://arxiv.org/find/cs/1/au:+Gkatzia_D/0/1/0/all/0/1">Dimitra Gkatzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Inglis_S/0/1/0/all/0/1">Stephanie Inglis</a>, <a href="http://arxiv.org/find/cs/1/au:+Leppanen_L/0/1/0/all/0/1">Leo Lepp&#xe4;nen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahamood_S/0/1/0/all/0/1">Saad Mahamood</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_E/0/1/0/all/0/1">Emma Manning</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoch_S/0/1/0/all/0/1">Stephanie Schoch</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomson_C/0/1/0/all/0/1">Craig Thomson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1">Luou Wen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01182">
                                        <div class="article-summary-box-inner">
                                            <span><p>We observe a severe under-reporting of the different kinds of errors that
Natural Language Generation systems make. This is a problem, because mistakes
are an important indicator of where systems should still be improved. If
authors only report overall performance metrics, the research community is left
in the dark about the specific weaknesses that are exhibited by
`state-of-the-art' research. Next to quantifying the extent of error
under-reporting, this position paper provides recommendations for error
identification, analysis and reporting.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Is it Fake? News Disinformation Detection on South African News Websites.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wet_H/0/1/0/all/0/1">Harm de Wet</a>, <a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02941">
                                        <div class="article-summary-box-inner">
                                            <span><p>Disinformation through fake news is an ongoing problem in our society and has
become easily spread through social media. The most cost and time effective way
to filter these large amounts of data is to use a combination of human and
technical interventions to identify it. From a technical perspective, Natural
Language Processing (NLP) is widely used in detecting fake news. Social media
companies use NLP techniques to identify the fake news and warn their users,
but fake news may still slip through undetected. It is especially a problem in
more localised contexts (outside the United States of America). How do we
adjust fake news detection systems to work better for local contexts such as in
South Africa. In this work we investigate fake news detection on South African
websites. We curate a dataset of South African fake news and then train
detection models. We contrast this with using widely available fake news
datasets (from mostly USA website). We also explore making the datasets more
diverse by combining them and observe the differences in behaviour in writing
between nations' fake news using interpretable machine learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.IR updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Profiling Web Archival Voids for Memento Routing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1">Sawood Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Weigle_M/0/1/0/all/0/1">Michele C. Weigle</a>, <a href="http://arxiv.org/find/cs/1/au:+Nelson_M/0/1/0/all/0/1">Michael L. Nelson</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03311">
                                        <div class="article-summary-box-inner">
                                            <span><p>Prior work on web archive profiling were focused on Archival Holdings to
describe what is present in an archive. This work defines and explores Archival
Voids to establish a means to represent portions of URI spaces that are not
present in a web archive. Archival Holdings and Archival Voids profiles can
work independently or as complements to each other to maximize the Accuracy of
Memento Aggregators. We discuss various sources of truth that can be used to
create Archival Voids profiles. We use access logs from Arquivo.pt to create
various Archival Voids profiles and analyze them against our MemGator access
logs for evaluation. We find that we could have avoided more than 8% of
additional False Positives on top of the 60% Accuracy we got from profiling
Archival Holdings in our prior work, if Arquivo.pt were to provide an Archival
Voids profile based on URIs that were requested hundreds of times and never
returned any success responses.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Distilling <span class="highlight_title">Transformer</span>s for Neural Cross-Domain Search.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1">Colin B. Clement</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1">Dawn Drain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1">Neel Sundaresan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03322">
                                        <div class="article-summary-box-inner">
                                            <span><p>Pre-trained transformers have recently clinched top spots in the gamut of
natural language tasks and pioneered solutions to software engineering tasks.
Even information retrieval has not been immune to the charm of the transformer,
though their large size and cost is generally a barrier to deployment. While
there has been much work in streamlining, caching, and modifying transformer
architectures for production, here we explore a new direction: distilling a
large pre-trained translation model into a lightweight bi-encoder which can be
efficiently cached and queried. We argue from a probabilistic perspective that
sequence-to-sequence models are a conceptually ideal---albeit highly
impractical---retriever. We derive a new distillation objective, implementing
it as a data augmentation scheme. Using natural language source code search as
a case study for cross-domain search, we demonstrate the validity of this idea
by significantly improving upon the current leader of the CodeSearchNet
challenge, a recent natural language code search benchmark.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning to Represent Human Motives for Goal-directed Web Browsing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jyun-Yu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chia-Jung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Longqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarrafzadeh_B/0/1/0/all/0/1">Bahareh Sarrafzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hecht_B/0/1/0/all/0/1">Brent Hecht</a>, <a href="http://arxiv.org/find/cs/1/au:+Teevan_J/0/1/0/all/0/1">Jaime Teevan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03350">
                                        <div class="article-summary-box-inner">
                                            <span><p>Motives or goals are recognized in psychology literature as the most
fundamental drive that explains and predicts why people do what they do,
including when they browse the web. Although providing enormous value, these
higher-ordered goals are often unobserved, and little is known about how to
leverage such goals to assist people's browsing activities. This paper proposes
to take a new approach to address this problem, which is fulfilled through a
novel neural framework, Goal-directed Web Browsing (GoWeB). We adopt a
psychologically-sound taxonomy of higher-ordered goals and learn to build their
representations in a structure-preserving manner. Then we incorporate the
resulting representations for enhancing the experiences of common activities
people perform on the web. Experiments on large-scale data from Microsoft Edge
web browser show that GoWeB significantly outperforms competitive baselines for
in-session web page recommendation, re-visitation classification, and
goal-based web page grouping. A follow-up analysis further characterizes how
the variety of human motives can affect the difference observed in human
behavioral patterns.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zang_T/0/1/0/all/0/1">Tianzi Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanmin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haobing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiadi Yu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03357">
                                        <div class="article-summary-box-inner">
                                            <span><p>Traditional recommendation systems are faced with two long-standing
obstacles, namely, data sparsity and cold-start problems, which promote the
emergence and development of Cross-Domain Recommendation (CDR). The core idea
of CDR is to leverage information collected from other domains to alleviate the
two problems in one domain. Over the last decade, many efforts have been
engaged for cross-domain recommendation. Recently, with the development of deep
learning and neural networks, a large number of methods have emerged. However,
there is a limited number of systematic surveys on CDR, especially regarding
the latest proposed methods as well as the recommendation scenarios and
recommendation tasks they address. In this survey paper, we first proposed a
two-level taxonomy of cross-domain recommendation which classifies different
recommendation scenarios and recommendation tasks. We then introduce and
summarize existing cross-domain recommendation approaches under different
recommendation scenarios in a structured manner. We also organize datasets
commonly used. We conclude this survey by providing several potential research
directions about this field.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ What a million Indian farmers say?: A crowdsourcing-based method for pest surveillance.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Adhikari_P/0/1/0/all/0/1">Poonam Adhikari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Ritesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyengar_S/0/1/0/all/0/1">S.R.S Iyengar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaur_R/0/1/0/all/0/1">Rishemjit Kaur</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03374">
                                        <div class="article-summary-box-inner">
                                            <span><p>Many different technologies are used to detect pests in the crops, such as
manual sampling, sensors, and radar. However, these methods have scalability
issues as they fail to cover large areas, are uneconomical and complex. This
paper proposes a crowdsourced based method utilising the real-time farmer
queries gathered over telephones for pest surveillance. We developed
data-driven strategies by aggregating and analyzing historical data to find
patterns and get future insights into pest occurrence. We showed that it can be
an accurate and economical method for pest surveillance capable of enveloping a
large area with high spatio-temporal granularity. Forecasting the pest
population will help farmers in making informed decisions at the right time.
This will also help the government and policymakers to make the necessary
preparations as and when required and may also ensure food security.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unbiased Cascade Bandits: Mitigating Exposure Bias in Online Learning to Rank Recommendation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mansoury_M/0/1/0/all/0/1">Masoud Mansoury</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdollahpouri_H/0/1/0/all/0/1">Himan Abdollahpouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mobasher_B/0/1/0/all/0/1">Bamshad Mobasher</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Burke_R/0/1/0/all/0/1">Robin Burke</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabouri_M/0/1/0/all/0/1">Milad Sabouri</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03440">
                                        <div class="article-summary-box-inner">
                                            <span><p>Exposure bias is a well-known issue in recommender systems where items and
suppliers are not equally represented in the recommendation results. This is
especially problematic when bias is amplified over time as a few popular items
are repeatedly over-represented in recommendation lists. This phenomenon can be
viewed as a recommendation feedback loop: the system repeatedly recommends
certain items at different time points and interactions of users with those
items will amplify bias towards those items over time. This issue has been
extensively studied in the literature on model-based or neighborhood-based
recommendation algorithms, but less work has been done on online recommendation
models such as those based on multi-armed Bandit algorithms. In this paper, we
study exposure bias in a class of well-known bandit algorithms known as Linear
Cascade Bandits. We analyze these algorithms on their ability to handle
exposure bias and provide a fair representation for items and suppliers in the
recommendation results. Our analysis reveals that these algorithms fail to
treat items and suppliers fairly and do not sufficiently explore the item space
for each user. To mitigate this bias, we propose a discounting factor and
incorporate it into these algorithms that controls the exposure of items at
each time step. To show the effectiveness of the proposed discounting factor on
mitigating exposure bias, we perform experiments on two datasets using three
cascading bandit algorithms and our experimental results show that the proposed
method improves the exposure fairness for items and suppliers.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ BeatNet: CRNN and Particle Filtering for Online Joint Beat Downbeat and Meter Tracking.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Heydari_M/0/1/0/all/0/1">Mojtaba Heydari</a>, <a href="http://arxiv.org/find/eess/1/au:+Cwitkowitz_F/0/1/0/all/0/1">Frank Cwitkowitz</a>, <a href="http://arxiv.org/find/eess/1/au:+Duan_Z/0/1/0/all/0/1">Zhiyao Duan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03576">
                                        <div class="article-summary-box-inner">
                                            <span><p>The online estimation of rhythmic information, such as beat positions,
downbeat positions, and meter, is critical for many real-time music
applications. Musical rhythm comprises complex hierarchical relationships
across time, rendering its analysis intrinsically challenging and at times
subjective. Furthermore, systems which attempt to estimate rhythmic information
in real-time must be causal and must produce estimates quickly and efficiently.
In this work, we introduce an online system for joint beat, downbeat, and meter
tracking, which utilizes causal convolutional and recurrent layers, followed by
a pair of sequential Monte Carlo particle filters applied during inference. The
proposed system does not need to be primed with a time signature in order to
perform downbeat tracking, and is instead able to estimate meter and adjust the
predictions over time. Additionally, we propose an information gate strategy to
significantly decrease the computational cost of particle filtering during the
inference step, making the system much faster than previous sampling-based
methods. Experiments on the GTZAN dataset, which is unseen during training,
show that the system outperforms various online beat and downbeat tracking
systems and achieves comparable performance to a baseline offline joint method.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ PoolRank: Max/Min Pooling-based Ranking Loss for Listwise Learning & Ranking Balance.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhizhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03586">
                                        <div class="article-summary-box-inner">
                                            <span><p>Numerous neural retrieval models have been proposed in recent years. These
models learn to compute a ranking score between the given query and document.
The majority of existing models are trained in pairwise fashion using
human-judged labels directly without further calibration. The traditional
pairwise schemes can be time-consuming and require pre-defined
positive-negative document pairs for training, potentially leading to learning
bias due to document distribution mismatch between training and test
conditions. Some popular existing listwise schemes rely on the strong
pre-defined probabilistic assumptions and stark difference between relevant and
non-relevant documents for the given query, which may limit the model potential
due to the low-quality or ambiguous relevance labels. To address these
concerns, we turn to a physics-inspired ranking balance scheme and propose
PoolRank, a pooling-based listwise learning framework. The proposed scheme has
four major advantages: (1) PoolRank extracts training information from the best
candidates at the local level based on model performance and relative ranking
among abundant document candidates. (2) By combining four pooling-based loss
components in a multi-task learning fashion, PoolRank calibrates the ranking
balance for the partially relevant and the highly non-relevant documents
automatically without costly human inspection. (3) PoolRank can be easily
generalized to any neural retrieval model without requiring additional
learnable parameters or model structure modifications. (4) Compared to pairwise
learning and existing listwise learning schemes, PoolRank yields better ranking
performance for all studied retrieval models while retaining efficient
convergence rates.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning Joint Embedding with Modality Alignments for <span class="highlight_title">Cross-Modal</span> Retrieval of Recipes and Food Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03788">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper presents a three-tier modality alignment approach to learning
text-image joint embedding, coined as JEMA, for cross-modal retrieval of
cooking recipes and food images. The first tier improves recipe text embedding
by optimizing the LSTM networks with term extraction and ranking enhanced
sequence patterns, and optimizes the image embedding by combining the
ResNeXt-101 image encoder with the category embedding using wideResNet-50 with
word2vec. The second tier modality alignment optimizes the textual-visual joint
embedding loss function using a double batch-hard triplet loss with soft-margin
optimization. The third modality alignment incorporates two types of
cross-modality alignments as the auxiliary loss regularizations to further
reduce the alignment errors in the joint learning of the two modality-specific
embedding functions. The category-based cross-modal alignment aims to align the
image category with the recipe category as a loss regularization to the joint
embedding. The cross-modal discriminator-based alignment aims to add the
visual-textual embedding distribution alignment to further regularize the joint
embedding loss. Extensive experiments with the one-million recipes benchmark
dataset Recipe1M demonstrate that the proposed JEMA approach outperforms the
state-of-the-art cross-modal embedding methods for both image-to-recipe and
recipe-to-image retrievals.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DoSSIER@COLIEE 2021: Leveraging dense retrieval and summarization-based re-ranking for case law retrieval.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1">Sophia Althammer</a>, <a href="http://arxiv.org/find/cs/1/au:+Askari_A/0/1/0/all/0/1">Arian Askari</a>, <a href="http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1">Suzan Verberne</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1">Allan Hanbury</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03937">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we present our approaches for the case law retrieval and the
legal case entailment task in the Competition on Legal Information
Extraction/Entailment (COLIEE) 2021. As first stage retrieval methods combined
with neural re-ranking methods using contextualized language models like BERT
achieved great performance improvements for information retrieval in the web
and news domain, we evaluate these methods for the legal domain. A distinct
characteristic of legal case retrieval is that the query case and case
description in the corpus tend to be long documents and therefore exceed the
input length of BERT. We address this challenge by combining lexical and dense
retrieval methods on the paragraph-level of the cases for the first stage
retrieval. Here we demonstrate that the retrieval on the paragraph-level
outperforms the retrieval on the document-level. Furthermore the experiments
suggest that dense retrieval methods outperform lexical retrieval. For
re-ranking we address the problem of long documents by summarizing the cases
and fine-tuning a BERT-based re-ranker with the summaries. Overall, our best
results were obtained with a combination of BM25 and dense passage retrieval
using domain-specific embeddings.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Image Retrieval on Real-life Images with <span class="highlight_title">Pre-train</span>ed <span class="highlight_title">Vision-and-Language</span> Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Opazo_C/0/1/0/all/0/1">Cristian Rodriguez-Opazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1">Damien Teney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04024">
                                        <div class="article-summary-box-inner">
                                            <span><p>We extend the task of composed image retrieval, where an input query consists
of an image and short textual description of how to modify the image. Existing
methods have only been applied to non-complex images within narrow domains,
such as fashion products, thereby limiting the scope of study on in-depth
visual reasoning in rich image and language contexts. To address this issue, we
collect the Compose Image Retrieval on Real-life images (CIRR) dataset, which
consists of over 36,000 pairs of crowd-sourced, open-domain images with
human-generated modifying text. To extend current methods to the open-domain,
we propose CIRPLANT, a transformer based model that leverages rich pre-trained
vision-and-language (V&amp;L) knowledge for modifying visual features conditioned
on natural language. Retrieval is then done by nearest neighbor lookup on the
modified features. We demonstrate that with a relatively simple architecture,
CIRPLANT outperforms existing methods on open-domain images, while matching
state-of-the-art accuracy on the existing narrow datasets, such as fashion.
Together with the release of CIRR, we believe this work will inspire further
research on composed image retrieval.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ IntenT5: Search Result Diversification using Causal Language Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+MacAvaney_S/0/1/0/all/0/1">Sean MacAvaney</a>, <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Murray_Smith_R/0/1/0/all/0/1">Roderick Murray-Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04026">
                                        <div class="article-summary-box-inner">
                                            <span><p>Search result diversification is a beneficial approach to overcome
under-specified queries, such as those that are ambiguous or multi-faceted.
Existing approaches often rely on massive query logs and interaction data to
generate a variety of possible query intents, which then can be used to re-rank
documents. However, relying on user interaction data is problematic because one
first needs a massive user base to build a sufficient log; public query logs
are insufficient on their own. Given the recent success of causal language
models (such as the Text-To-Text Transformer (T5) model) at text generation
tasks, we explore the capacity of these models to generate potential query
intents. We find that to encourage diversity in the generated queries, it is
beneficial to adapt the model by including a new Distributional Causal Language
Modeling (DCLM) objective during fine-tuning and a representation replacement
during inference. Across six standard evaluation benchmarks, we find that our
method (which we call IntenT5) improves search result diversity and attains
(and sometimes exceeds) the diversity obtained when using query suggestions
based on a proprietary query log. Our analysis shows that our approach is most
effective for multi-faceted queries and is able to generalize effectively to
queries that were unseen in training data.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DGEM: A New Dual-modal Graph Embedding Method in Recommendation System.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huimin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rongwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhuyun Qi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04031">
                                        <div class="article-summary-box-inner">
                                            <span><p>In the current deep learning based recommendation system, the embedding
method is generally employed to complete the conversion from the
high-dimensional sparse feature vector to the low-dimensional dense feature
vector. However, as the dimension of the input vector of the embedding layer is
too large, the addition of the embedding layer significantly slows down the
convergence speed of the entire neural network, which is not acceptable in
real-world scenarios. In addition, as the interaction between users and items
increases and the relationship between items becomes more complicated, the
embedding method proposed for sequence data is no longer suitable for graphic
data in the current real environment. Therefore, in this paper, we propose the
Dual-modal Graph Embedding Method (DGEM) to solve these problems. DGEM includes
two modes, static and dynamic. We first construct the item graph to extract the
graph structure and use random walk of unequal probability to capture the
high-order proximity between the items. Then we generate the graph embedding
vector through the Skip-Gram model, and finally feed the downstream deep neural
network for the recommendation task. The experimental results show that DGEM
can mine the high-order proximity between items and enhance the expression
ability of the recommendation model. Meanwhile it also improves the
recommendation performance by utilizing the time dependent relationship between
items.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Multi-modal Retrieval of Tables and Texts Using Tri-encoder Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kostic_B/0/1/0/all/0/1">Bogdan Kosti&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04049">
                                        <div class="article-summary-box-inner">
                                            <span><p>Open-domain extractive question answering works well on textual data by first
retrieving candidate texts and then extracting the answer from those
candidates. However, some questions cannot be answered by text alone but
require information stored in tables. In this paper, we present an approach for
retrieving both texts and tables relevant to a question by jointly encoding
texts, tables and questions into a single vector space. To this end, we create
a new multi-modal dataset based on text and table datasets from related work
and compare the retrieval performance of different encoding schemata. We find
that dense vector embeddings of transformer models outperform sparse embeddings
on four out of six evaluation datasets. Comparing different dense embedding
models, tri-encoders, with one encoder for each question, text and table,
increase retrieval performance compared to bi-encoders with one encoder for the
question and one for both text and tables. We release the newly created
multi-modal dataset to the community so that it can be used for training and
evaluation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.00414">
                                        <div class="article-summary-box-inner">
                                            <span><p>A central roadblock to analyzing quantum algorithms on quantum states is the
lack of a comparable input model for classical algorithms. Inspired by recent
work of the author [E. Tang, STOC'19], we introduce such a model, where we
assume we can efficiently perform $\ell^2$-norm samples of input data, a
natural analogue to quantum algorithms that assume efficient state preparation
of classical data. Though this model produces less practical algorithms than
the (stronger) standard model of classical computation, it captures versions of
many of the features and nuances of quantum linear algebra algorithms. With
this model, we describe classical analogues to Lloyd, Mohseni, and Rebentrost's
quantum algorithms for principal component analysis [Nat. Phys. 10, 631 (2014)]
and nearest-centroid clustering [<a href="/abs/1307.0411">arXiv:1307.0411</a>]. Since they are only
polynomially slower, these algorithms suggest that the exponential speedups of
their quantum counterparts are simply an artifact of state preparation
assumptions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Tag Embedding Based Personalized Point Of Interest Recommendation System.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1">Suraj Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1">Dwaipayan Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_M/0/1/0/all/0/1">Mandar Mitra</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.06389">
                                        <div class="article-summary-box-inner">
                                            <span><p>Personalized Point of Interest recommendation is very helpful for satisfying
users' needs at new places. In this article, we propose a tag embedding based
method for Personalized Recommendation of Point Of Interest. We model the
relationship between tags corresponding to Point Of Interest. The model
provides representative embedding corresponds to a tag in a way that related
tags will be closer. We model Point of Interest-based on tag embedding and also
model the users (user profile) based on the Point Of Interest rated by them.
finally, we rank the user's candidate Point Of Interest based on cosine
similarity between user's embedding and Point of Interest's embedding. Further,
we find the parameters required to model user by discrete optimizing over
different measures (like ndcg@5, MRR, ...). We also analyze the result while
considering the same parameters for all users and individual parameters for
each user. Along with it we also analyze the effect on the result while
changing the dataset to model the relationship between tags. Our method also
minimizes the privacy leak issue. We used TREC Contextual Suggestion 2016 Phase
2 dataset and have significant improvement over all the measures on the state
of the art method. It improves ndcg@5 by 12.8%, p@5 by 4.3%, and MRR by 7.8%,
which shows the effectiveness of the method.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Generation-Augmented Retrieval for Open-domain Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1"><span class="highlight_author">Jianfeng Gao</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"><span class="highlight_author">Jiawei Han</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08553">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose Generation-Augmented Retrieval (GAR) for answering open-domain
questions, which augments a query through text generation of heuristically
discovered relevant contexts without external resources as supervision. We
demonstrate that the generated contexts substantially enrich the semantics of
the queries and GAR with sparse representations (BM25) achieves comparable or
better performance than state-of-the-art dense retrieval methods such as DPR.
We show that generating diverse contexts for a query is beneficial as fusing
their results consistently yields better retrieval accuracy. Moreover, as
sparse and dense representations are often complementary, GAR can be easily
combined with DPR to achieve even better performance. GAR achieves
state-of-the-art performance on Natural Questions and TriviaQA datasets under
the extractive QA setup when equipped with an extractive reader, and
consistently outperforms other retrieval methods when the same generative
reader is used.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Rider: Reader-Guided Passage Reranking for Open-Domain Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1"><span class="highlight_author">Jianfeng Gao</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"><span class="highlight_author">Jiawei Han</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00294">
                                        <div class="article-summary-box-inner">
                                            <span><p>Current open-domain question answering systems often follow a
Retriever-Reader architecture, where the retriever first retrieves relevant
passages and the reader then reads the retrieved passages to form an answer. In
this paper, we propose a simple and effective passage reranking method, named
Reader-guIDEd Reranker (RIDER), which does not involve training and reranks the
retrieved passages solely based on the top predictions of the reader before
reranking. We show that RIDER, despite its simplicity, achieves 10 to 20
absolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) gains
without refining the retriever or reader. In addition, RIDER, without any
training, outperforms state-of-the-art transformer-based supervised rerankers.
Remarkably, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 EM
on the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are
used as the reader input after passage reranking.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Semantic Models for the First-stage Retrieval: A Comprehensive Review.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yinqiong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yixing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiafeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04831">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multi-stage ranking pipelines have been a practical solution in modern search
systems, where the first-stage retrieval is to return a subset of candidate
documents, and latter stages attempt to re-rank those candidates. Unlike
re-ranking stages going through quick technique shifts during past decades, the
first-stage retrieval has long been dominated by classical term-based models.
Unfortunately, these models suffer from the vocabulary mismatch problem, which
may block re-ranking stages from relevant documents at the very beginning.
Therefore, it has been a long-term desire to build semantic models for the
first-stage retrieval that can achieve high recall efficiently. Recently, we
have witnessed an explosive growth of research interests on the first-stage
semantic retrieval models. We believe it is the right time to survey current
status, learn from existing methods, and gain some insights for future
development. In this paper, we describe the current landscape of the
first-stage retrieval models under a unified framework to clarify the
connection between classical term-based retrieval methods, early semantic
retrieval methods and neural semantic retrieval methods. Moreover, we identify
some open challenges and envision some future directions, with the hope of
inspiring more researches on these important yet less investigated topics.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Practical Relative Order Attack in Deep Ranking.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05248">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent studies unveil the vulnerabilities of deep ranking models, where an
imperceptible perturbation can trigger dramatic changes in the ranking result.
While previous attempts focus on manipulating absolute ranks of certain
candidates, the possibility of adjusting their relative order remains
under-explored. In this paper, we formulate a new adversarial attack against
deep ranking systems, i.e., the Order Attack, which covertly alters the
relative order among a selected set of candidates according to an
attacker-specified permutation, with limited interference to other unrelated
candidates. Specifically, it is formulated as a triplet-style loss imposing an
inequality chain reflecting the specified permutation. However, direct
optimization of such white-box objective is infeasible in a real-world attack
scenario due to various black-box limitations. To cope with them, we propose a
Short-range Ranking Correlation metric as a surrogate objective for black-box
Order Attack to approximate the white-box method. The Order Attack is evaluated
on the Fashion-MNIST and Stanford-Online-Products datasets under both white-box
and black-box threat models. The black-box attack is also successfully
implemented on a major e-commerce platform. Comprehensive experimental
evaluations demonstrate the effectiveness of the proposed methods, revealing a
new type of ranking model vulnerability.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DCAP: Deep Cross Attentional Product Network for User Response Prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zekai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fangtian Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pless_R/0/1/0/all/0/1">Robert Pless</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuzhen Cheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08649">
                                        <div class="article-summary-box-inner">
                                            <span><p>User response prediction, which aims to predict the probability that a user
will provide a predefined positive response in a given context such as clicking
on an ad or purchasing an item, is crucial to many industrial applications such
as online advertising, recommender systems, and search ranking. However, due to
the high dimensionality and super sparsity of the data collected in these
tasks, handcrafting cross features is inevitably time expensive. Prior studies
in predicting user response leveraged the feature interactions by enhancing
feature vectors with products of features to model second-order or high-order
cross features, either explicitly or implicitly. Nevertheless, these existing
methods can be hindered by not learning sufficient cross features due to model
architecture limitations or modeling all high-order feature interactions with
equal weights. This work aims to fill this gap by proposing a novel
architecture Deep Cross Attentional Product Network (DCAP), which keeps cross
network's benefits in modeling high-order feature interactions explicitly at
the vector-wise level. Beyond that, it can differentiate the importance of
different cross features in each network layer inspired by the multi-head
attention mechanism and Product Neural Network (PNN), allowing practitioners to
perform a more in-depth analysis of user behaviors. Additionally, our proposed
model can be easily implemented and train in parallel. We conduct comprehensive
experiments on three real-world datasets. The results have robustly
demonstrated that our proposed model DCAP achieves superior prediction
performance compared with the state-of-the-art models.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Ashwin Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1">Adriel Saporta</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Steven QH Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1">Du Nguyen Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tan Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambon_P/0/1/0/all/0/1">Pierre Chambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1">Curtis P. Langlotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
                                        <div class="article-summary-box-inner">
                                            <span><p>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Towards Accurate Localization by Instance Search.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yi-Geng Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Hui-Chu Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wan-Lei Zhao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05005">
                                        <div class="article-summary-box-inner">
                                            <span><p>Visual object localization is the key step in a series of object detection
tasks. In the literature, high localization accuracy is achieved with the
mainstream strongly supervised frameworks. However, such methods require
object-level annotations and are unable to detect objects of unknown
categories. Weakly supervised methods face similar difficulties. In this paper,
a self-paced learning framework is proposed to achieve accurate object
localization on the rank list returned by instance search. The proposed
framework mines the target instance gradually from the queries and their
corresponding top-ranked search results. Since a common instance is shared
between the query and the images in the rank list, the target visual instance
can be accurately localized even without knowing what the object category is.
In addition to performing localization on instance search, the issue of
few-shot object detection is also addressed under the same framework. Superior
performance over state-of-the-art methods is observed on both tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.MM updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ HetEmotionNet: Two-Stream Heterogeneous Graph Recurrent Neural Network for Multi-modal Emotion Recognition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Ziyu Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Youfang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhiyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiangheng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Caijie Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03354">
                                        <div class="article-summary-box-inner">
                                            <span><p>The research on human emotion under multimedia stimulation based on
physiological signals is an emerging field, and important progress has been
achieved for emotion recognition based on multi-modal signals. However, it is
challenging to make full use of the complementarity among
spatial-spectral-temporal domain features for emotion recognition, as well as
model the heterogeneity and correlation among multi-modal signals. In this
paper, we propose a novel two-stream heterogeneous graph recurrent neural
network, named HetEmotionNet, fusing multi-modal physiological signals for
emotion recognition. Specifically, HetEmotionNet consists of the
spatial-temporal stream and the spatial-spectral stream, which can fuse
spatial-spectral-temporal domain features in a unified framework. Each stream
is composed of the graph transformer network for modeling the heterogeneity,
the graph convolutional network for modeling the correlation, and the gated
recurrent unit for capturing the temporal domain or spectral domain dependency.
Extensive experiments on two real-world datasets demonstrate that our proposed
model achieves better performance than state-of-the-art baselines.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Temporal Action Localization Using Gated Recurrent Units.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khojasteh_H/0/1/0/all/0/1">Hassan Keshvari Khojasteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadzade_H/0/1/0/all/0/1">Hoda Mohammadzade</a>, <a href="http://arxiv.org/find/cs/1/au:+Behroozi_H/0/1/0/all/0/1">Hamid Behroozi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03375">
                                        <div class="article-summary-box-inner">
                                            <span><p>Temporal Action Localization (TAL) task in which the aim is to predict the
start and end of each action and its class label has many applications in the
real world. But due to its complexity, researchers have not reached great
results compared to the action recognition task. The complexity is related to
predicting precise start and end times for different actions in any video. In
this paper, we propose a new network based on Gated Recurrent Unit (GRU) and
two novel post-processing ideas for TAL task. Specifically, we propose a new
design for the output layer of the GRU resulting in the so-called GRU-Splitted
model. Moreover, linear interpolation is used to generate the action proposals
with precise start and end times. Finally, to rank the generated proposals
appropriately, we use a Learn to Rank (LTR) approach. We evaluated the
performance of the proposed method on Thumos14 dataset. Results show the
superiority of the performance of the proposed method compared to
state-of-the-art. Especially in the mean Average Precision (mAP) metric at
Intersection over Union (IoU) 0.7, we get 27.52% which is 5.12% better than
that of state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Cough Detection Using Selected Informative Features from Audio Signals.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinru Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Menghan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03538">
                                        <div class="article-summary-box-inner">
                                            <span><p>Cough is a common symptom of respiratory and lung diseases. Cough detection
is important to prevent, assess and control epidemic, such as COVID-19. This
paper proposes a model to detect cough events from cough audio signals. The
models are trained by the dataset combined ESC-50 dataset with self-recorded
cough recordings. The test dataset contains inpatient cough recordings
collected from inpatients of the respiratory disease department in Ruijin
Hospital. We totally build 15 cough detection models based on different feature
numbers selected by Random Frog, Uninformative Variable Elimination (UVE), and
Variable influence on projection (VIP) algorithms respectively. The optimal
model is based on 20 features selected from Mel Frequency Cepstral Coefficients
(MFCC) features by UVE algorithm and classified with Support Vector Machine
(SVM) linear two-class classifier. The best cough detection model realizes the
accuracy, recall, precision and F1-score with 94.9%, 97.1%, 93.1% and 0.95
respectively. Its excellent performance with fewer dimensionality of the
feature vector shows the potential of being applied to mobile devices, such as
smartphones, thus making cough detection remote and non-contact.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Two-pronged Strategy: Lightweight Augmented Graph Network Hashing for Scalable Image Retrieval.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1">Hui Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhiyong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03914">
                                        <div class="article-summary-box-inner">
                                            <span><p>Hashing learns compact binary codes to store and retrieve massive data
efficiently. Particularly, unsupervised deep hashing is supported by powerful
deep neural networks and has the desirable advantage of label independence. It
is a promising technique for scalable image retrieval. However, deep models
introduce a large number of parameters, which is hard to optimize due to the
lack of explicit semantic labels and brings considerable training cost. As a
result, the retrieval accuracy and training efficiency of existing unsupervised
deep hashing are still limited. To tackle the problems, in this paper, we
propose a simple and efficient \emph{Lightweight Augmented Graph Network
Hashing} (LAGNH) method with a two-pronged strategy. For one thing, we extract
the inner structure of the image as the auxiliary semantics to enhance the
semantic supervision of the unsupervised hash learning process. For another, we
design a lightweight network structure with the assistance of the auxiliary
semantics, which greatly reduces the number of network parameters that needs to
be optimized and thus greatly accelerates the training process. Specifically,
we design a cross-modal attention module based on the auxiliary semantic
information to adaptively mitigate the adverse effects in the deep image
features. Besides, the hash codes are learned by multi-layer message passing
within an adversarial regularized graph convolutional network. Simultaneously,
the semantic representation capability of hash codes is further enhanced by
reconstructing the similarity graph.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DCAP: Deep Cross Attentional Product Network for User Response Prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zekai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fangtian Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pless_R/0/1/0/all/0/1">Robert Pless</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuzhen Cheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08649">
                                        <div class="article-summary-box-inner">
                                            <span><p>User response prediction, which aims to predict the probability that a user
will provide a predefined positive response in a given context such as clicking
on an ad or purchasing an item, is crucial to many industrial applications such
as online advertising, recommender systems, and search ranking. However, due to
the high dimensionality and super sparsity of the data collected in these
tasks, handcrafting cross features is inevitably time expensive. Prior studies
in predicting user response leveraged the feature interactions by enhancing
feature vectors with products of features to model second-order or high-order
cross features, either explicitly or implicitly. Nevertheless, these existing
methods can be hindered by not learning sufficient cross features due to model
architecture limitations or modeling all high-order feature interactions with
equal weights. This work aims to fill this gap by proposing a novel
architecture Deep Cross Attentional Product Network (DCAP), which keeps cross
network's benefits in modeling high-order feature interactions explicitly at
the vector-wise level. Beyond that, it can differentiate the importance of
different cross features in each network layer inspired by the multi-head
attention mechanism and Product Neural Network (PNN), allowing practitioners to
perform a more in-depth analysis of user behaviors. Additionally, our proposed
model can be easily implemented and train in parallel. We conduct comprehensive
experiments on three real-world datasets. The results have robustly
demonstrated that our proposed model DCAP achieves superior prediction
performance compared with the state-of-the-art models.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Efficient Deep Feature Calibration for <span class="highlight_title">Cross-Modal</span> Joint Embedding Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00705">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper introduces a two-phase deep feature calibration framework for
efficient learning of semantics enhanced text-image cross-modal joint
embedding, which clearly separates the deep feature calibration in data
preprocessing from training the joint embedding model. We use the Recipe1M
dataset for the technical description and empirical validation. In
preprocessing, we perform deep feature calibration by combining deep feature
engineering with semantic context features derived from raw text-image input
data. We leverage LSTM to identify key terms, NLP methods to produce ranking
scores for key terms before generating the key term feature. We leverage
wideResNet50 to extract and encode the image category semantics to help
semantic alignment of the learned recipe and image embeddings in the joint
latent space. In joint embedding learning, we perform deep feature calibration
by optimizing the batch-hard triplet loss function with soft-margin and double
negative sampling, also utilizing the category-based alignment loss and
discriminator-based alignment loss. Extensive experiments demonstrate that our
SEJE approach with the deep feature calibration significantly outperforms the
state-of-the-art approaches.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.CV updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Operational Learning-based Boundary Estimation in Electromagnetic Medical Imaging.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Al_Saffar_A/0/1/0/all/0/1">A. Al-Saffar</a>, <a href="http://arxiv.org/find/cs/1/au:+Stancombe_A/0/1/0/all/0/1">A. Stancombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_A/0/1/0/all/0/1">A. Zamani</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbosh_A/0/1/0/all/0/1">A. Abbosh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03233">
                                        <div class="article-summary-box-inner">
                                            <span><p>Incorporating boundaries of the imaging object as a priori information to
imaging algorithms can significantly improve the performance of electromagnetic
medical imaging systems. To avoid overly complicating the system by using
different sensors and the adverse effect of the subject's movement, a
learning-based method is proposed to estimate the boundary (external contour)
of the imaged object using the same electromagnetic imaging data. While imaging
techniques may discard the reflection coefficients for being dominant and
uninformative for imaging, these parameters are made use of for boundary
detection. The learned model is verified through independent clinical human
trials by using a head imaging system with a 16-element antenna array that
works across the band 0.7-1.6 GHz. The evaluation demonstrated that the model
achieves average dissimilarity of 0.012 in Hu-moment while detecting head
boundary. The model enables fast scan and image creation while eliminating the
need for additional devices for accurate boundary estimation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ The Right to Talk: An Audio-Visual <span class="highlight_title">Transformer</span> Approach.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Thanh-Dat Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1">Chi Nhan Duong</a>, The <a href="http://arxiv.org/find/cs/1/au:+Vu_D/0/1/0/all/0/1">De Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hoang Anh Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1">Bhiksha Raj</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngan Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1">Khoa Luu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03256">
                                        <div class="article-summary-box-inner">
                                            <span><p>Turn-taking has played an essential role in structuring the regulation of a
conversation. The task of identifying the main speaker (who is properly taking
his/her turn of speaking) and the interrupters (who are interrupting or
reacting to the main speaker's utterances) remains a challenging task. Although
some prior methods have partially addressed this task, there still remain some
limitations. Firstly, a direct association of Audio and Visual features may
limit the correlations to be extracted due to different modalities. Secondly,
the relationship across temporal segments helping to maintain the consistency
of localization, separation, and conversation contexts is not effectively
exploited. Finally, the interactions between speakers that usually contain the
tracking and anticipatory decisions about the transition to a new speaker are
usually ignored. Therefore, this work introduces a new Audio-Visual Transformer
approach to the problem of localization and highlighting the main speaker in
both audio and visual channels of a multi-speaker conversation video in the
wild. The proposed method exploits different types of correlations presented in
both visual and audio signals. The temporal audio-visual relationships across
spatial-temporal space are anticipated and optimized via the self-attention
mechanism in a Transformerstructure. Moreover, a newly collected dataset is
introduced for the main speaker detection. To the best of our knowledge, it is
one of the first studies that is able to automatically localize and highlight
the main speaker in both visual and audio channels in multi-speaker
conversation videos.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ (Just) A Spoonful of Refinements Helps the Registration Error Go Down.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Agostinho_S/0/1/0/all/0/1">S&#xe9;rgio Agostinho</a>, <a href="http://arxiv.org/find/cs/1/au:+Osep_A/0/1/0/all/0/1">Aljo&#x161;a O&#x161;ep</a>, <a href="http://arxiv.org/find/cs/1/au:+Bue_A/0/1/0/all/0/1">Alessio Del Bue</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1">Laura Leal-Taix&#xe9;</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03257">
                                        <div class="article-summary-box-inner">
                                            <span><p>We tackle data-driven 3D point cloud registration. Given point
correspondences, the standard Kabsch algorithm provides an optimal rotation
estimate. This allows to train registration models in an end-to-end manner by
differentiating the SVD operation. However, given the initial rotation estimate
supplied by Kabsch, we show we can improve point correspondence learning during
model training by extending the original optimization problem. In particular,
we linearize the governing constraints of the rotation matrix and solve the
resulting linear system of equations. We then iteratively produce new solutions
by updating the initial estimate. Our experiments show that, by plugging our
differentiable layer to existing learning-based registration methods, we
improve the correspondence matching quality. This yields up to a 7% decrease in
rotation error for correspondence-based data-driven registration methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ BiMaL: Bijective Maximum Likelihood Approach to Domain Adaptation in Semantic Scene Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Thanh-Dat Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1">Chi Nhan Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngan Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_S/0/1/0/all/0/1">Son Lam Phung</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainwater_C/0/1/0/all/0/1">Chase Rainwater</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1">Khoa Luu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03267">
                                        <div class="article-summary-box-inner">
                                            <span><p>Semantic segmentation aims to predict pixel-level labels. It has become a
popular task in various computer vision applications. While fully supervised
segmentation methods have achieved high accuracy on large-scale vision
datasets, they are unable to generalize on a new test environment or a new
domain well. In this work, we first introduce a new Un-aligned Domain Score to
measure the efficiency of a learned model on a new target domain in
unsupervised manner. Then, we present the new Bijective Maximum
Likelihood(BiMaL) loss that is a generalized form of the Adversarial Entropy
Minimization without any assumption about pixel independence. We have evaluated
the proposed BiMaL on two domains. The proposed BiMaL approach consistently
outperforms the SOTA methods on empirical experiments on "SYNTHIA to
Cityscapes", "GTA5 to Cityscapes", and "SYNTHIA to Vistas".
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ IGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Lingelbach_M/0/1/0/all/0/1">Michael Lingelbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1">Bokui Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokmen_C/0/1/0/all/0/1">Cem Gokmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dharan_G/0/1/0/all/0/1">Gokul Dharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_T/0/1/0/all/0/1">Tanish Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurenkov_A/0/1/0/all/0/1">Andrey Kurenkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gweon_H/0/1/0/all/0/1">Hyowon Gweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"><span class="highlight_author">Jiajun Wu</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1"><span class="highlight_author">Li Fei-Fei</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03272">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset will be publicly available at
<a href="http://svl.stanford.edu/igibson/.">this http URL</a>
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Semantic Segmentation and Object Detection Towards Instance Segmentation: Breast Tumor Identification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mejri_M/0/1/0/all/0/1">Mohamed Mejri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mejri_A/0/1/0/all/0/1">Aymen Mejri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mejri_O/0/1/0/all/0/1">Oumayma Mejri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fekih_C/0/1/0/all/0/1">Chiraz Fekih</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03287">
                                        <div class="article-summary-box-inner">
                                            <span><p>Breast cancer is one of the factors that cause the increase of mortality of
women. The most widely used method for diagnosing this geological disease i.e.
breast cancer is the ultrasound scan. Several key features such as the
smoothness and the texture of the tumor captured through ultrasound scans
encode the abnormality of the breast tumors (malignant from benign). However,
ultrasound scans are often noisy and include irrelevant parts of the breast
that may bias the segmentation of eventual tumors. In this paper, we are going
to extract the region of interest ( i.e, bounding boxes of the tumors) and
feed-forward them to one semantic segmentation encoder-decoder structure based
on its classification (i.e, malignant or benign). the whole process aims to
build an instance-based segmenter from a semantic segmenter and an object
detector.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Medical image segmentation with imperfect 3D bounding boxes.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Redekop_E/0/1/0/all/0/1">Ekaterina Redekop</a>, <a href="http://arxiv.org/find/cs/1/au:+Chernyavskiy_A/0/1/0/all/0/1">Alexey Chernyavskiy</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03300">
                                        <div class="article-summary-box-inner">
                                            <span><p>The development of high quality medical image segmentation algorithms depends
on the availability of large datasets with pixel-level labels. The challenges
of collecting such datasets, especially in case of 3D volumes, motivate to
develop approaches that can learn from other types of labels that are cheap to
obtain, e.g. bounding boxes. We focus on 3D medical images with their
corresponding 3D bounding boxes which are considered as series of per-slice
non-tight 2D bounding boxes. While current weakly-supervised approaches that
use 2D bounding boxes as weak labels can be applied to medical image
segmentation, we show that their success is limited in cases when the
assumption about the tightness of the bounding boxes breaks. We propose a new
bounding box correction framework which is trained on a small set of
pixel-level annotations to improve the tightness of a larger set of non-tight
bounding box annotations. The effectiveness of our solution is demonstrated by
evaluating a known weakly-supervised segmentation approach with and without the
proposed bounding box correction algorithm. When the tightness is improved by
our solution, the results of the weakly-supervised segmentation become much
closer to those of the fully-supervised one.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Feature-Supervised Action Modality Transfer.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Thoker_F/0/1/0/all/0/1">Fida Mohammad Thoker</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G. M. Snoek</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03329">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper strives for action recognition and detection in video modalities
like RGB, depth maps or 3D-skeleton sequences when only limited
modality-specific labeled examples are available. For the RGB, and derived
optical-flow, modality many large-scale labeled datasets have been made
available. They have become the de facto pre-training choice when recognizing
or detecting new actions from RGB datasets that have limited amounts of labeled
examples available. Unfortunately, large-scale labeled action datasets for
other modalities are unavailable for pre-training. In this paper, our goal is
to recognize actions from limited examples in non-RGB video modalities, by
learning from large-scale labeled RGB data. To this end, we propose a two-step
training process: (i) we extract action representation knowledge from an
RGB-trained teacher network and adapt it to a non-RGB student network. (ii) we
then fine-tune the transfer model with available labeled examples of the target
modality. For the knowledge transfer we introduce feature-supervision
strategies, which rely on unlabeled pairs of two modalities (the RGB and the
target modality) to transfer feature level representations from the teacher to
the student network. Ablations and generalizations with two RGB source datasets
and two non-RGB target datasets demonstrate that an optical-flow teacher
provides better action transfer features than RGB for both depth maps and
3D-skeletons, even when evaluated on a different target domain, or for a
different task. Compared to alternative cross-modal action transfer methods we
show a good improvement in performance especially when labeled non-RGB examples
to learn from are scarce
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lingelbach_M/0/1/0/all/0/1">Michael Lingelbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_Z/0/1/0/all/0/1">Zheng Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokmen_C/0/1/0/all/0/1">Cem Gokmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Buch_S/0/1/0/all/0/1">Shyamal Buch</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">C. Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Gweon_H/0/1/0/all/0/1">Hyowon Gweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"><span class="highlight_author">Jiajun Wu</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1"><span class="highlight_author">Li Fei-Fei</span></a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03332">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce BEHAVIOR, a benchmark for embodied AI with 100 activities in
simulation, spanning a range of everyday household chores such as cleaning,
maintenance, and food preparation. These activities are designed to be
realistic, diverse, and complex, aiming to reproduce the challenges that agents
must face in the real world. Building such a benchmark poses three fundamental
difficulties for each activity: definition (it can differ by time, place, or
person), instantiation in a simulator, and evaluation. BEHAVIOR addresses these
with three innovations. First, we propose an object-centric, predicate
logic-based description language for expressing an activity's initial and goal
conditions, enabling generation of diverse instances for any activity. Second,
we identify the simulator-agnostic features required by an underlying
environment to support BEHAVIOR, and demonstrate its realization in one such
simulator. Third, we introduce a set of metrics to measure task progress and
efficiency, absolute and relative to human demonstrators. We include 500 human
demonstrations in virtual reality (VR) to serve as the human ground truth. Our
experiments demonstrate that even state of the art embodied AI solutions
struggle with the level of realism, diversity, and complexity imposed by the
activities in our benchmark. We make BEHAVIOR publicly available at
behavior.stanford.edu to facilitate and calibrate the development of new
embodied AI solutions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Real-time Geo-localization Using Satellite Imagery and Topography for Unmanned Aerial Vehicles.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiangyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_M/0/1/0/all/0/1">Mark W. Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sreenath_K/0/1/0/all/0/1">Koushil Sreenath</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03344">
                                        <div class="article-summary-box-inner">
                                            <span><p>The capabilities of autonomous flight with unmanned aerial vehicles (UAVs)
have significantly increased in recent times. However, basic problems such as
fast and robust geo-localization in GPS-denied environments still remain
unsolved. Existing research has primarily concentrated on improving the
accuracy of localization at the cost of long and varying computation time in
various situations, which often necessitates the use of powerful ground station
machines. In order to make image-based geo-localization online and pragmatic
for lightweight embedded systems on UAVs, we propose a framework that is
reliable in changing scenes, flexible about computing resource allocation and
adaptable to common camera placements. The framework is comprised of two
stages: offline database preparation and online inference. At the first stage,
color images and depth maps are rendered as seen from potential vehicle poses
quantized over the satellite and topography maps of anticipated flying areas. A
database is then populated with the global and local descriptors of the
rendered images. At the second stage, for each captured real-world query image,
top global matches are retrieved from the database and the vehicle pose is
further refined via local descriptor matching. We present field experiments of
image-based localization on two different UAV platforms to validate our
results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Neighborhood Consensus <span class="highlight_title">Contrastive Learning</span> for Backward-Compatible Representation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shengsen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yihang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+YanBai/0/1/0/all/0/1">YanBai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_T/0/1/0/all/0/1">Tao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1">Minghua Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_L/0/1/0/all/0/1">Lingyu Duan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03372">
                                        <div class="article-summary-box-inner">
                                            <span><p>In object re-identification (ReID), the development of deep learning
techniques often involves model update and deployment. It is unbearable to
re-extract image features of the large-scale gallery when deploying new models.
Therefore, backward-compatible representation is proposed to enable the "new"
features compatible with "old"' features, free from the re-extracting process.
The existing backward-compatible methods simply conduct constraints in the
embedding space or discriminative space and ignore the intra-class variance of
the old embeddings, resulting in a risk of damaging the discriminability of new
embeddings.
</p>
<p>In this work, we propose a Neighborhood Consensus Contrastive Learning (NCCL)
method, which learns backward-compatible representation from a neighborhood
consensus perspective with both embedding structures and discriminative
knowledge. With NCCL, the new embeddings are aligned and improved with old
embeddings in a multi-cluster view. Besides, we also propose a scheme to filter
the old embeddings with low credibility, which can further improve the
compatibility robustness. Our method ensures backward compatibility without
impairing the accuracy of the new model. And it can even improve the new
model's accuracy in most scenarios.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Temporal Action Localization Using Gated Recurrent Units.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khojasteh_H/0/1/0/all/0/1">Hassan Keshvari Khojasteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadzade_H/0/1/0/all/0/1">Hoda Mohammadzade</a>, <a href="http://arxiv.org/find/cs/1/au:+Behroozi_H/0/1/0/all/0/1">Hamid Behroozi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03375">
                                        <div class="article-summary-box-inner">
                                            <span><p>Temporal Action Localization (TAL) task in which the aim is to predict the
start and end of each action and its class label has many applications in the
real world. But due to its complexity, researchers have not reached great
results compared to the action recognition task. The complexity is related to
predicting precise start and end times for different actions in any video. In
this paper, we propose a new network based on Gated Recurrent Unit (GRU) and
two novel post-processing ideas for TAL task. Specifically, we propose a new
design for the output layer of the GRU resulting in the so-called GRU-Splitted
model. Moreover, linear interpolation is used to generate the action proposals
with precise start and end times. Finally, to rank the generated proposals
appropriately, we use a Learn to Rank (LTR) approach. We evaluated the
performance of the proposed method on Thumos14 dataset. Results show the
superiority of the performance of the proposed method compared to
state-of-the-art. Especially in the mean Average Precision (mAP) metric at
Intersection over Union (IoU) 0.7, we get 27.52% which is 5.12% better than
that of state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning Indoor Layouts from Simple Point-Clouds.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mahmood_M/0/1/0/all/0/1">Md. Tareq Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohammed Eunus Ali</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03378">
                                        <div class="article-summary-box-inner">
                                            <span><p>Reconstructing a layout of indoor spaces has been a crucial part of growing
indoor location based services. One of the key challenges in the proliferation
of indoor location based services is the unavailability of indoor spatial maps
due to the complex nature of capturing an indoor space model (e.g., floor plan)
of an existing building. In this paper, we propose a system to automatically
generate floor plans that can recognize rooms from the point-clouds obtained
through smartphones like Google's Tango. In particular, we propose two
approaches - a Recurrent Neural Network based approach using Pointer Network
and a Convolutional Neural Network based approach using Mask-RCNN to identify
rooms (and thereby floor plans) from point-clouds. Experimental results on
different datasets demonstrate approximately 0.80-0.90 Intersection-over-Union
scores, which show that our models can effectively identify the rooms and
regenerate the shapes of the rooms in heterogeneous environment.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Categorized Reflection Removal Dataset with Diverse Real-world Scenes.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lei_C/0/1/0/all/0/1">Chenyang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuhua Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_C/0/1/0/all/0/1">Chenyang Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yankun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wenxiu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Q/0/1/0/all/0/1">Qiong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03380">
                                        <div class="article-summary-box-inner">
                                            <span><p>Due to the lack of a large-scale reflection removal dataset with diverse
real-world scenes, many existing reflection removal methods are trained on
synthetic data plus a small amount of real-world data, which makes it difficult
to evaluate the strengths or weaknesses of different reflection removal methods
thoroughly. Furthermore, existing real-world benchmarks and datasets do not
categorize image data based on the types and appearances of reflection (e.g.,
smoothness, intensity), making it hard to analyze reflection removal methods.
Hence, we construct a new reflection removal dataset that is categorized,
diverse, and real-world (CDR). A pipeline based on RAW data is used to capture
perfectly aligned input images and transmission images. The dataset is
constructed using diverse glass types under various environments to ensure
diversity. By analyzing several reflection removal methods and conducting
extensive experiments on our dataset, we show that state-of-the-art reflection
removal methods generally perform well on blurry reflection but fail in
obtaining satisfying performance on other types of real-world reflection. We
believe our dataset can help develop novel methods to remove real-world
reflection better. Our dataset is available at
https://alexzhao-hugga.github.io/Real-World-Reflection-Removal/.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Information Bottleneck Approach to Spatial Attention Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lai_Q/0/1/0/all/0/1">Qiuxia Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Ailing Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minhao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hanqiu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiang Xu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03418">
                                        <div class="article-summary-box-inner">
                                            <span><p>The selective visual attention mechanism in the human visual system (HVS)
restricts the amount of information to reach visual awareness for perceiving
natural scenes, allowing near real-time information processing with limited
computational capacity [Koch and Ullman, 1987]. This kind of selectivity acts
as an 'Information Bottleneck (IB)', which seeks a trade-off between
information compression and predictive accuracy. However, such information
constraints are rarely explored in the attention mechanism for deep neural
networks (DNNs). In this paper, we propose an IB-inspired spatial attention
module for DNN structures built for visual recognition. The module takes as
input an intermediate representation of the input image, and outputs a
variational 2D attention map that minimizes the mutual information (MI) between
the attention-modulated representation and the input, while maximizing the MI
between the attention-modulated representation and the task label. To further
restrict the information bypassed by the attention map, we quantize the
continuous attention scores to a set of learnable anchor values during
training. Extensive experiments show that the proposed IB-inspired spatial
attention mechanism can yield attention maps that neatly highlight the regions
of interest while suppressing backgrounds, and bootstrap standard DNN
structures for visual recognition tasks (e.g., image classification,
fine-grained recognition, cross-domain classification). The attention maps are
interpretable for the decision making of the DNNs as verified in the
experiments. Our code is available at https://github.com/ashleylqx/AIB.git.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning Facial Representations from the Cycle-consistency of Face.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Jia-Ren Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yong-Sheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1">Wei-Chen Chiu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03427">
                                        <div class="article-summary-box-inner">
                                            <span><p>Faces manifest large variations in many aspects, such as identity,
expression, pose, and face styling. Therefore, it is a great challenge to
disentangle and extract these characteristics from facial images, especially in
an unsupervised manner. In this work, we introduce cycle-consistency in facial
characteristics as free supervisory signal to learn facial representations from
unlabeled facial images. The learning is realized by superimposing the facial
motion cycle-consistency and identity cycle-consistency constraints. The main
idea of the facial motion cycle-consistency is that, given a face with
expression, we can perform de-expression to a neutral face via the removal of
facial motion and further perform re-expression to reconstruct back to the
original face. The main idea of the identity cycle-consistency is to exploit
both de-identity into mean face by depriving the given neutral face of its
identity via feature re-normalization and re-identity into neutral face by
adding the personal attributes to the mean face. At training time, our model
learns to disentangle two distinct facial representations to be useful for
performing cycle-consistent face reconstruction. At test time, we use the
linear protocol scheme for evaluating facial representations on various tasks,
including facial expression recognition and head pose regression. We also can
directly apply the learnt facial representations to person recognition,
frontalization and image-to-image translation. Our experiments show that the
results of our approach is competitive with those of existing methods,
demonstrating the rich and unique information embedded in the disentangled
representations. Code is available at https://github.com/JiaRenChang/FaceCycle .
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ PSViT: Better Vision <span class="highlight_title">Transformer</span> via Token Pooling and Attention Sharing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junjie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03428">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we observe two levels of redundancies when applying vision
transformers (ViT) for image recognition. First, fixing the number of tokens
through the whole network produces redundant features at the spatial level.
Second, the attention maps among different transformer layers are redundant.
Based on the observations above, we propose a PSViT: a ViT with token Pooling
and attention Sharing to reduce the redundancy, effectively enhancing the
feature representation ability, and achieving a better speed-accuracy
trade-off. Specifically, in our PSViT, token pooling can be defined as the
operation that decreases the number of tokens at the spatial level. Besides,
attention sharing will be built between the neighboring transformer layers for
reusing the attention maps having a strong correlation among adjacent layers.
Then, a compact set of the possible combinations for different token pooling
and attention sharing mechanisms are constructed. Based on the proposed compact
set, the number of tokens in each layer and the choices of layers sharing
attention can be treated as hyper-parameters that are learned from data
automatically. Experimental results show that the proposed scheme can achieve
up to 6.6% accuracy improvement in ImageNet classification compared with the
DeiT.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Enhancing MR Image Segmentation with Realistic Adversarial Data Augmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Cheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1">Huaqi Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarroni_G/0/1/0/all/0/1">Giacomo Tarroni</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1">Wenjia Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03429">
                                        <div class="article-summary-box-inner">
                                            <span><p>The success of neural networks on medical image segmentation tasks typically
relies on large labeled datasets for model training. However, acquiring and
manually labeling a large medical image set is resource-intensive, expensive,
and sometimes impractical due to data sharing and privacy issues. To address
this challenge, we propose an adversarial data augmentation approach to improve
the efficiency in utilizing training data and to enlarge the dataset via
simulated but realistic transformations. Specifically, we present a generic
task-driven learning framework, which jointly optimizes a data augmentation
model and a segmentation network during training, generating informative
examples to enhance network generalizability for the downstream task. The data
augmentation model utilizes a set of photometric and geometric image
transformations and chains them to simulate realistic complex imaging
variations that could exist in magnetic resonance (MR) imaging. The proposed
adversarial data augmentation does not rely on generative networks and can be
used as a plug-in module in general segmentation networks. It is
computationally efficient and applicable for both supervised and
semi-supervised learning. We analyze and evaluate the method on two MR image
segmentation tasks: cardiac segmentation and prostate segmentation. Results
show that the proposed approach can alleviate the need for labeled data while
improving model generalization ability, indicating its practical value in
medical imaging applications.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ NASOA: Towards Faster <span class="highlight_title">Task-oriented</span> Online Fine-tuning with a Zoo of Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_N/0/1/0/all/0/1">Ning Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gengwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chuanlong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03434">
                                        <div class="article-summary-box-inner">
                                            <span><p>Fine-tuning from pre-trained ImageNet models has been a simple, effective,
and popular approach for various computer vision tasks. The common practice of
fine-tuning is to adopt a default hyperparameter setting with a fixed
pre-trained model, while both of them are not optimized for specific tasks and
time constraints. Moreover, in cloud computing or GPU clusters where the tasks
arrive sequentially in a stream, faster online fine-tuning is a more desired
and realistic strategy for saving money, energy consumption, and CO2 emission.
In this paper, we propose a joint Neural Architecture Search and Online
Adaption framework named NASOA towards a faster task-oriented fine-tuning upon
the request of users. Specifically, NASOA first adopts an offline NAS to
identify a group of training-efficient networks to form a pretrained model zoo.
We propose a novel joint block and macro-level search space to enable a
flexible and efficient search. Then, by estimating fine-tuning performance via
an adaptive model by accumulating experience from the past tasks, an online
schedule generator is proposed to pick up the most suitable model and generate
a personalized training regime with respect to each desired task in a one-shot
fashion. The resulting model zoo is more training efficient than SOTA models,
e.g. 6x faster than RegNetY-16GF, and 1.7x faster than EfficientNetB3.
Experiments on multiple datasets also show that NASOA achieves much better
fine-tuning results, i.e. improving around 2.1% accuracy than the best
performance in RegNet series under various constraints and tasks; 40x faster
compared to the BOHB.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Towards Discriminative Representation Learning for Unsupervised Person Re-identification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Isobe_T/0/1/0/all/0/1">Takashi Isobe</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Lu Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weihua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1">Yi Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shengjin Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03439">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this work, we address the problem of unsupervised domain adaptation for
person re-ID where annotations are available for the source domain but not for
target. Previous methods typically follow a two-stage optimization pipeline,
where the network is first pre-trained on source and then fine-tuned on target
with pseudo labels created by feature clustering. Such methods sustain two main
limitations. (1) The label noise may hinder the learning of discriminative
features for recognizing target classes. (2) The domain gap may hinder
knowledge transferring from source to target. We propose three types of
technical schemes to alleviate these issues. First, we propose a cluster-wise
contrastive learning algorithm (CCL) by iterative optimization of feature
learning and cluster refinery to learn noise-tolerant representations in the
unsupervised manner. Second, we adopt a progressive domain adaptation (PDA)
strategy to gradually mitigate the domain gap between source and target data.
Third, we propose Fourier augmentation (FA) for further maximizing the class
separability of re-ID models by imposing extra constraints in the Fourier
space. We observe that these proposed schemes are capable of facilitating the
learning of discriminative feature representations. Experiments demonstrate
that our method consistently achieves notable improvements over the
state-of-the-art unsupervised re-ID methods on multiple benchmarks, e.g.,
surpassing MMT largely by 8.1\%, 9.9\%, 11.4\% and 11.1\% mAP on the
Market-to-Duke, Duke-to-Market, Market-to-MSMT and Duke-to-MSMT tasks,
respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Deformable Image Registration using Neural ODEs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yifan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiahao_T/0/1/0/all/0/1">Tom Z.Jiahao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiancong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yushkevich_P/0/1/0/all/0/1">Paul A.Yushkevich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gee_J/0/1/0/all/0/1">James C.Gee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_M/0/1/0/all/0/1">M.Ani Hsieh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03443">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deformable image registration, aiming to find spatial correspondence between
a given image pair, is one of the most critical problems in the domain of
medical image analysis. In this paper, we present a generic, fast, and accurate
diffeomorphic image registration framework that leverages neural ordinary
differential equations (NODEs). We model each voxel as a moving particle and
consider the set of all voxels in a 3D image as a high-dimensional dynamical
system whose trajectory determines the targeted deformation field. Compared
with traditional optimization-based methods, our framework reduces the running
time from tens of minutes to tens of seconds. Compared with recent data-driven
deep learning methods, our framework is more accessible since it does not
require large amounts of training data. Our experiments show that the
registration results of our method outperform state-of-the-arts under various
metrics, indicating that our modeling approach is well fitted for the task of
deformable image registration.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Stereo Waterdrop Removal with Row-wise Dilated Attention.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zifan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1">Dit-Yan Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03457">
                                        <div class="article-summary-box-inner">
                                            <span><p>Existing vision systems for autonomous driving or robots are sensitive to
waterdrops adhered to windows or camera lenses. Most recent waterdrop removal
approaches take a single image as input and often fail to recover the missing
content behind waterdrops faithfully. Thus, we propose a learning-based model
for waterdrop removal with stereo images. To better detect and remove
waterdrops from stereo images, we propose a novel row-wise dilated attention
module to enlarge attention's receptive field for effective information
propagation between the two stereo images. In addition, we propose an attention
consistency loss between the ground-truth disparity map and attention scores to
enhance the left-right consistency in stereo images. Because of related
datasets' unavailability, we collect a real-world dataset that contains stereo
images with and without waterdrops. Extensive experiments on our dataset
suggest that our model outperforms state-of-the-art methods both quantitatively
and qualitatively. Our source code and the stereo waterdrop dataset are
available at
\href{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unsupervised Portrait Shadow Removal via Generative Priors.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yingqing He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Y/0/1/0/all/0/1">Yazhou Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianjia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03466">
                                        <div class="article-summary-box-inner">
                                            <span><p>Portrait images often suffer from undesirable shadows cast by casual objects
or even the face itself. While existing methods for portrait shadow removal
require training on a large-scale synthetic dataset, we propose the first
unsupervised method for portrait shadow removal without any training data. Our
key idea is to leverage the generative facial priors embedded in the
off-the-shelf pretrained StyleGAN2. To achieve this, we formulate the shadow
removal task as a layer decomposition problem: a shadowed portrait image is
constructed by the blending of a shadow image and a shadow-free image. We
propose an effective progressive optimization algorithm to learn the
decomposition process. Our approach can also be extended to portrait tattoo
removal and watermark removal. Qualitative and quantitative experiments on a
real-world portrait shadow dataset demonstrate that our approach achieves
comparable performance with supervised shadow removal methods. Our source code
is available at
https://github.com/YingqingHe/Shadow-Removal-via-Generative-Priors.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A distillation based approach for the diagnosis of diseases.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bandyopadhyay_H/0/1/0/all/0/1">Hmrishav Bandyopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Dastidar_S/0/1/0/all/0/1">Shuvayan Ghosh Dastidar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_B/0/1/0/all/0/1">Bisakh Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1">Biplab Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_N/0/1/0/all/0/1">Nibaran Das</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03470">
                                        <div class="article-summary-box-inner">
                                            <span><p>Presently, Covid-19 is a serious threat to the world at large. Efforts are
being made to reduce disease screening times and in the development of a
vaccine to resist this disease, even as thousands succumb to it everyday. We
propose a novel method of automated screening of diseases like Covid-19 and
pneumonia from Chest X-Ray images with the help of Computer Vision. Unlike
computer vision classification algorithms which come with heavy computational
costs, we propose a knowledge distillation based approach which allows us to
bring down the model depth, while preserving the accuracy. We make use of an
augmentation of the standard distillation module with an auxiliary intermediate
assistant network that aids in the continuity of the flow of information.
Following this approach, we are able to build an extremely light student
network, consisting of just 3 convolutional blocks without any compromise on
accuracy. We thus propose a method of classification of diseases which can not
only lead to faster screening, but can also operate seamlessly on low-end
devices.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Impact of Aliasing on Generalization in Deep Convolutional Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1">Cristina Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Romijnders_R/0/1/0/all/0/1">Rob Romijnders</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>, <a href="http://arxiv.org/find/cs/1/au:+Goroshin_R/0/1/0/all/0/1">Ross Goroshin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03489">
                                        <div class="article-summary-box-inner">
                                            <span><p>We investigate the impact of aliasing on generalization in Deep Convolutional
Networks and show that data augmentation schemes alone are unable to prevent it
due to structural limitations in widely used architectures. Drawing insights
from frequency analysis theory, we take a closer look at ResNet and
EfficientNet architectures and review the trade-off between aliasing and
information loss in each of their major components. We show how to mitigate
aliasing by inserting non-trainable low-pass filters at key locations,
particularly where networks lack the capacity to learn them. These simple
architectural changes lead to substantial improvements in generalization on
i.i.d. and even more on out-of-distribution conditions, such as image
classification under natural corruptions on ImageNet-C [11] and few-shot
learning on Meta-Dataset [26]. State-of-the art results are achieved on both
datasets without introducing additional trainable parameters and using the
default hyper-parameters of open source codebases.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning Foveated Reconstruction to Preserve Perceived Image Statistics.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Surace_L/0/1/0/all/0/1">Luca Surace</a> (Universit&#xe0; della Svizzera italiana), <a href="http://arxiv.org/find/cs/1/au:+Wernikowski_M/0/1/0/all/0/1">Marek Wernikowski</a> (West Pomeranian University of Technology), <a href="http://arxiv.org/find/cs/1/au:+Tursun_O/0/1/0/all/0/1">Okan Tursun</a> (Universit&#xe0; della Svizzera italiana), <a href="http://arxiv.org/find/cs/1/au:+Myszkowski_K/0/1/0/all/0/1">Karol Myszkowski</a> (Max Planck Institute for Informatics), <a href="http://arxiv.org/find/cs/1/au:+Mantiuk_R/0/1/0/all/0/1">Rados&#x142;aw Mantiuk</a> (West Pomeranian University of Technology), <a href="http://arxiv.org/find/cs/1/au:+Didyk_P/0/1/0/all/0/1">Piotr Didyk</a> (Universit&#xe0; della Svizzera italiana), ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03499">
                                        <div class="article-summary-box-inner">
                                            <span><p>Foveated image reconstruction recovers full image from a sparse set of
samples distributed according to the human visual system's retinal sensitivity
that rapidly drops with eccentricity. Recently, the use of Generative
Adversarial Networks was shown to be a promising solution for such a task as
they can successfully hallucinate missing image information. Like for other
supervised learning approaches, also for this one, the definition of the loss
function and training strategy heavily influences the output quality. In this
work, we pose the question of how to efficiently guide the training of foveated
reconstruction techniques such that they are fully aware of the human visual
system's capabilities and limitations, and therefore, reconstruct visually
important image features. Due to the nature of GAN-based solutions, we
concentrate on the human's sensitivity to hallucination for different input
sample densities. We present new psychophysical experiments, a dataset, and a
procedure for training foveated image reconstruction. The strategy provides
flexibility to the generator network by penalizing only perceptually important
deviations in the output. As a result, the method aims to preserve perceived
image statistics rather than natural image statistics. We evaluate our strategy
and compare it to alternative solutions using a newly trained objective metric
and user experiments.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DeepFH Segmentations for Superpixel-based Object Proposal Refinement.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wilms_C/0/1/0/all/0/1">Christian Wilms</a>, <a href="http://arxiv.org/find/cs/1/au:+Frintrop_S/0/1/0/all/0/1">Simone Frintrop</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03503">
                                        <div class="article-summary-box-inner">
                                            <span><p>Class-agnostic object proposal generation is an important first step in many
object detection pipelines. However, object proposals of modern systems are
rather inaccurate in terms of segmentation and only roughly adhere to object
boundaries. Since typical refinement steps are usually not applicable to
thousands of proposals, we propose a superpixel-based refinement system for
object proposal generation systems. Utilizing precise superpixels and
superpixel pooling on deep features, we refine initial coarse proposals in an
end-to-end learned system. Furthermore, we propose a novel DeepFH segmentation,
which enriches the classic Felzenszwalb and Huttenlocher (FH) segmentation with
deep features leading to improved segmentation results and better object
proposal refinements. On the COCO dataset with LVIS annotations, we show that
our refinement based on DeepFH superpixels outperforms state-of-the-art methods
and leads to more precise object proposals.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Membership Inference Attacks on Lottery Ticket Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bagmar_A/0/1/0/all/0/1">Aadesh Bagmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Maiya_S/0/1/0/all/0/1">Shishira R Maiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidwalka_S/0/1/0/all/0/1">Shruti Bidwalka</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Amol Deshpande</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03506">
                                        <div class="article-summary-box-inner">
                                            <span><p>The vulnerability of the Lottery Ticket Hypothesis has not been studied from
the purview of Membership Inference Attacks. Through this work, we are the
first to empirically show that the lottery ticket networks are equally
vulnerable to membership inference attacks. A Membership Inference Attack (MIA)
is the process of determining whether a data sample belongs to a training set
of a trained model or not. Membership Inference Attacks could leak critical
information about the training data that can be used for targeted attacks.
Recent deep learning models often have very large memory footprints and a high
computational cost associated with training and drawing inferences. Lottery
Ticket Hypothesis is used to prune the networks to find smaller sub-networks
that at least match the performance of the original model in terms of test
accuracy in a similar number of iterations. We used CIFAR-10, CIFAR-100, and
ImageNet datasets to perform image classification tasks and observe that the
attack accuracies are similar. We also see that the attack accuracy varies
directly according to the number of classes in the dataset and the sparsity of
the network. We demonstrate that these attacks are transferable across models
with high accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ContinuityLearner: Geometric Continuity Feature Learning for Lane Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1">Haoyu Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yi Fang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03507">
                                        <div class="article-summary-box-inner">
                                            <span><p>Lane segmentation is a challenging issue in autonomous driving system
designing because lane marks show weak textural consistency due to occlusion or
extreme illumination but strong geometric continuity in traffic images, from
which general convolution neural networks (CNNs) are not capable of learning
semantic objects. To empower conventional CNNs in learning geometric clues of
lanes, we propose a deep network named ContinuityLearner to better learn
geometric prior within lane. Specifically, our proposed CNN-based paradigm
involves a novel Context-encoding image feature learning network to generate
class-dependent image feature maps and a new encoding layer to exploit the
geometric continuity feature representation by fusing both spatial and visual
information of lane together. The ContinuityLearner, performing on the
geometric continuity feature of lanes, is trained to directly predict the lane
in traffic scenarios with integrated and continuous instance semantic. The
experimental results on the CULane dataset and the Tusimple benchmark
demonstrate that our ContinuityLearner has superior performance over other
state-of-the-art techniques in lane segmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Reducing Annotating Load: Active Learning with Synthetic Images in Surgical Instrument Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Haonan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+King_D/0/1/0/all/0/1">Daniel King</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yun-Hsuan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Bly_R/0/1/0/all/0/1">Randall A. Bly</a>, <a href="http://arxiv.org/find/cs/1/au:+Moe_K/0/1/0/all/0/1">Kris S. Moe</a>, <a href="http://arxiv.org/find/cs/1/au:+Hannaford_B/0/1/0/all/0/1">Blake Hannaford</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03534">
                                        <div class="article-summary-box-inner">
                                            <span><p>Accurate instrument segmentation in endoscopic vision of robot-assisted
surgery is challenging due to reflection on the instruments and frequent
contacts with tissue. Deep neural networks (DNN) show competitive performance
and are in favor in recent years. However, the hunger of DNN for labeled data
poses a huge workload of annotation. Motivated by alleviating this workload, we
propose a general embeddable method to decrease the usage of labeled real
images, using active generated synthetic images. In each active learning
iteration, the most informative unlabeled images are first queried by active
learning and then labeled. Next, synthetic images are generated based on these
selected images. The instruments and backgrounds are cropped out and randomly
combined with each other with blending and fusion near the boundary. The
effectiveness of the proposed method is validated on 2 sinus surgery datasets
and 1 intraabdominal surgery dataset. The results indicate a considerable
improvement in performance, especially when the budget for annotation is small.
The effectiveness of different types of synthetic images, blending methods, and
external background are also studied. All the code is open-sourced at:
https://github.com/HaonanPeng/active_syn_generator.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nguyen_E/0/1/0/all/0/1">Eric Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tu Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaminathan_V/0/1/0/all/0/1">Vishy Swaminathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Collomosse_J/0/1/0/all/0/1">John Collomosse</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03541">
                                        <div class="article-summary-box-inner">
                                            <span><p>Images tell powerful stories but cannot always be trusted. Matching images
back to trusted sources (attribution) enables users to make a more informed
judgment of the images they encounter online. We propose a robust image hashing
algorithm to perform such matching. Our hash is sensitive to manipulation of
subtle, salient visual details that can substantially change the story told by
an image. Yet the hash is invariant to benign transformations (changes in
quality, codecs, sizes, shapes, etc.) experienced by images during online
redistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph
Attention for Image Attribution Network); a robust image hashing model inspired
by recent successes of Transformers in the visual domain. OSCAR-Net constructs
a scene graph representation that attends to fine-grained changes of every
object's visual appearance and their spatial relationships. The network is
trained via contrastive learning on a dataset of original and manipulated
images yielding a state of the art image hash for content fingerprinting that
scales to millions of images.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Spatio-Temporal Attention Mechanism and Knowledge <span class="highlight_title">Distillation</span> for Lip Reading.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Elashmawy_S/0/1/0/all/0/1">Shahd Elashmawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramsis_M/0/1/0/all/0/1">Marian Ramsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Eraqi_H/0/1/0/all/0/1">Hesham M. Eraqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Eldeshnawy_F/0/1/0/all/0/1">Farah Eldeshnawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mabrouk_H/0/1/0/all/0/1">Hadeel Mabrouk</a>, <a href="http://arxiv.org/find/cs/1/au:+Abugabal_O/0/1/0/all/0/1">Omar Abugabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakr_N/0/1/0/all/0/1">Nourhan Sakr</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03543">
                                        <div class="article-summary-box-inner">
                                            <span><p>Despite the advancement in the domain of audio and audio-visual speech
recognition, visual speech recognition systems are still quite under-explored
due to the visual ambiguity of some phonemes. In this work, we propose a new
lip-reading model that combines three contributions. First, the model front-end
adopts a spatio-temporal attention mechanism to help extract the informative
data from the input visual frames. Second, the model back-end utilizes a
sequence-level and frame-level Knowledge Distillation (KD) techniques that
allow leveraging audio data during the visual model training. Third, a data
preprocessing pipeline is adopted that includes facial landmarks
detection-based lip-alignment. On LRW lip-reading dataset benchmark, a
noticeable accuracy improvement is demonstrated; the spatio-temporal attention,
Knowledge Distillation, and lip-alignment contributions achieved 88.43%,
88.64%, and 88.37% respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Disentangled High Quality Salient Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Lv Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Shouhong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mofei Song</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03551">
                                        <div class="article-summary-box-inner">
                                            <span><p>Aiming at discovering and locating most distinctive objects from visual
scenes, salient object detection (SOD) plays an essential role in various
computer vision systems. Coming to the era of high resolution, SOD methods are
facing new challenges. The major limitation of previous methods is that they
try to identify the salient regions and estimate the accurate objects
boundaries simultaneously with a single regression task at low-resolution. This
practice ignores the inherent difference between the two difficult problems,
resulting in poor detection quality. In this paper, we propose a novel deep
learning framework for high-resolution SOD task, which disentangles the task
into a low-resolution saliency classification network (LRSCN) and a
high-resolution refinement network (HRRN). As a pixel-wise classification task,
LRSCN is designed to capture sufficient semantics at low-resolution to identify
the definite salient, background and uncertain image regions. HRRN is a
regression task, which aims at accurately refining the saliency value of pixels
in the uncertain region to preserve a clear object boundary at high-resolution
with limited GPU memory. It is worth noting that by introducing uncertainty
into the training process, our HRRN can well address the high-resolution
refinement task without using any high-resolution training data. Extensive
experiments on high-resolution saliency datasets as well as some widely used
saliency benchmarks show that the proposed method achieves superior performance
compared to the state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Self-Adversarial Disentangling for Specific Domain Adaptation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qianyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Qiqi Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhengyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xuequan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jianping Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03553">
                                        <div class="article-summary-box-inner">
                                            <span><p>Domain adaptation aims to bridge the domain shifts between the source and
target domains. These shifts may span different dimensions such as fog,
rainfall, etc. However, recent methods typically do not consider explicit prior
knowledge on a specific dimension, thus leading to less desired adaptation
performance. In this paper, we study a practical setting called Specific Domain
Adaptation (SDA) that aligns the source and target domains in a
demanded-specific dimension. Within this setting, we observe the intra-domain
gap induced by different domainness (i.e., numerical magnitudes of this
dimension) is crucial when adapting to a specific domain. To address the
problem, we propose a novel Self-Adversarial Disentangling (SAD) framework. In
particular, given a specific dimension, we first enrich the source domain by
introducing a domainness creator with providing additional supervisory signals.
Guided by the created domainness, we design a self-adversarial regularizer and
two loss functions to jointly disentangle the latent representations into
domainness-specific and domainness-invariant features, thus mitigating the
intra-domain gap. Our method can be easily taken as a plug-and-play framework
and does not introduce any extra costs in the inference time. We achieve
consistent improvements over state-of-the-art methods in both object detection
and semantic segmentation tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ <span class="highlight_title">Contrastive</span> Representation Learning for Rapid Intraoperative Diagnosis of Skull Base Tumors Imaged Using Stimulated Raman Histology.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Cheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1">Abhishek Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Linzey_J/0/1/0/all/0/1">Joseph Linzey</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1">Rushikesh Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sung Jik Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Sudharsan Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alber_D/0/1/0/all/0/1">Daniel Alber</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondepudi_A/0/1/0/all/0/1">Akhil Kondepudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Urias_E/0/1/0/all/0/1">Esteban Urias</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandian_B/0/1/0/all/0/1">Balaji Pandian</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Holou_W/0/1/0/all/0/1">Wajd Al-Holou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_S/0/1/0/all/0/1">Steve Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_B/0/1/0/all/0/1">B. Gregory Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Heth_J/0/1/0/all/0/1">Jason Heth</a>, <a href="http://arxiv.org/find/cs/1/au:+Freudiger_C/0/1/0/all/0/1">Chris Freudiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalsa_S/0/1/0/all/0/1">Siri Khalsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacione_D/0/1/0/all/0/1">Donato Pacione</a>, <a href="http://arxiv.org/find/cs/1/au:+Golfinos_J/0/1/0/all/0/1">John G. Golfinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Camelo_Piragua_S/0/1/0/all/0/1">Sandra Camelo-Piragua</a>, <a href="http://arxiv.org/find/cs/1/au:+Orringer_D/0/1/0/all/0/1">Daniel A. Orringer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hollon_T/0/1/0/all/0/1">Todd Hollon</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03555">
                                        <div class="article-summary-box-inner">
                                            <span><p>Background: Accurate diagnosis of skull base tumors is essential for
providing personalized surgical treatment strategies. Intraoperative diagnosis
can be challenging due to tumor diversity and lack of intraoperative pathology
resources.
</p>
<p>Objective: To develop an independent and parallel intraoperative pathology
workflow that can provide rapid and accurate skull base tumor diagnoses using
label-free optical imaging and artificial intelligence (AI).
</p>
<p>Method: We used a fiber laser-based, label-free, non-consumptive,
high-resolution microscopy method ($&lt;$ 60 sec per 1 $\times$ 1 mm$^\text{2}$),
called stimulated Raman histology (SRH), to image a consecutive, multicenter
cohort of skull base tumor patients. SRH images were then used to train a
convolutional neural network (CNN) model using three representation learning
strategies: cross-entropy, self-supervised contrastive learning, and supervised
contrastive learning. Our trained CNN models were tested on a held-out,
multicenter SRH dataset.
</p>
<p>Results: SRH was able to image the diagnostic features of both benign and
malignant skull base tumors. Of the three representation learning strategies,
supervised contrastive learning most effectively learned the distinctive and
diagnostic SRH image features for each of the skull base tumor types. In our
multicenter testing set, cross-entropy achieved an overall diagnostic accuracy
of 91.5%, self-supervised contrastive learning 83.9%, and supervised
contrastive learning 96.6%. Our trained model was able to identify tumor-normal
margins and detect regions of microscopic tumor infiltration in whole-slide SRH
images.
</p>
<p>Conclusion: SRH with AI models trained using contrastive representation
learning can provide rapid and accurate intraoperative diagnosis of skull base
tumors.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Context-Aware Mixup for Domain Adaptive Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qianyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhengyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Qiqi Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xuequan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jianping Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03557">
                                        <div class="article-summary-box-inner">
                                            <span><p>Unsupervised domain adaptation (UDA) aims to adapt a model of the labeled
source domain to an unlabeled target domain. Although the domain shifts may
exist in various dimensions such as appearance, textures, etc, the contextual
dependency, which is generally shared across different domains, is neglected by
recent methods. In this paper, we utilize this important clue as explicit prior
knowledge and propose end-to-end Context-Aware Mixup (CAMix) for domain
adaptive semantic segmentation. Firstly, we design a contextual mask generation
strategy by leveraging accumulated spatial distributions and contextual
relationships. The generated contextual mask is critical in this work and will
guide the domain mixup. In addition, we define the significance mask to
indicate where the pixels are credible. To alleviate the over-alignment (e.g.,
early performance degradation), the source and target significance masks are
mixed based on the contextual mask into the mixed significance mask, and we
introduce a significance-reweighted consistency loss on it. Experimental
results show that the proposed method outperforms the state-of-the-art methods
by a large margin on two widely-used domain adaptation benchmarks, i.e., GTAV
$\rightarrow $ Cityscapes and SYNTHIA $\rightarrow $ Cityscapes.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ LeafMask: Towards Greater Accuracy on Leaf Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1">Ruohao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liao Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1">Dantong Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_J/0/1/0/all/0/1">Jun Yue</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03568">
                                        <div class="article-summary-box-inner">
                                            <span><p>Leaf segmentation is the most direct and effective way for high-throughput
plant phenotype data analysis and quantitative researches of complex traits.
Currently, the primary goal of plant phenotyping is to raise the accuracy of
the autonomous phenotypic measurement. In this work, we present the LeafMask
neural network, a new end-to-end model to delineate each leaf region and count
the number of leaves, with two main components: 1) the mask assembly module
merging position-sensitive bases of each predicted box after non-maximum
suppression (NMS) and corresponding coefficients to generate original masks; 2)
the mask refining module elaborating leaf boundaries from the mask assembly
module by the point selection strategy and predictor. In addition, we also
design a novel and flexible multi-scale attention module for the dual
attention-guided mask (DAG-Mask) branch to effectively enhance information
expression and produce more accurate bases. Our main contribution is to
generate the final improved masks by combining the mask assembly module with
the mask refining module under the anchor-free instance segmentation paradigm.
We validate our LeafMask through extensive experiments on Leaf Segmentation
Challenge (LSC) dataset. Our proposed model achieves the 90.09% BestDice score
outperforming other state-of-the-art approaches.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Expressive Power and Loss Surfaces of Deep Learning Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dube_S/0/1/0/all/0/1">Simant Dube</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03579">
                                        <div class="article-summary-box-inner">
                                            <span><p>The goals of this paper are two-fold. The first goal is to serve as an
expository tutorial on the working of deep learning models which emphasizes
geometrical intuition about the reasons for success of deep learning. The
second goal is to complement the current results on the expressive power of
deep learning models and their loss surfaces with novel insights and results.
In particular, we describe how deep neural networks carve out manifolds
especially when the multiplication neurons are introduced. Multiplication is
used in dot products and the attention mechanism and it is employed in capsule
networks and self-attention based transformers. We also describe how random
polynomial, random matrix, spin glass and computational complexity perspectives
on the loss surfaces are interconnected.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Visible Watermark Removal via Self-calibrated Localization and Background Refinement.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jing Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1">Li Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1">Fengjun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_T/0/1/0/all/0/1">Teng Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liqing Zhang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03581">
                                        <div class="article-summary-box-inner">
                                            <span><p>Superimposing visible watermarks on images provides a powerful weapon to cope
with the copyright issue. Watermark removal techniques, which can strengthen
the robustness of visible watermarks in an adversarial way, have attracted
increasing research interest. Modern watermark removal methods perform
watermark localization and background restoration simultaneously, which could
be viewed as a multi-task learning problem. However, existing approaches suffer
from incomplete detected watermark and degraded texture quality of restored
background. Therefore, we design a two-stage multi-task network to address the
above issues. The coarse stage consists of a watermark branch and a background
branch, in which the watermark branch self-calibrates the roughly estimated
mask and passes the calibrated mask to background branch to reconstruct the
watermarked area. In the refinement stage, we integrate multi-level features to
improve the texture quality of watermarked area. Extensive experiments on two
datasets demonstrate the effectiveness of our proposed method.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ZiGAN: Fine-grained Chinese Calligraphy Font Generation via a Few-shot Style Transfer Approach.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1">Qi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bingfeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yi Yuan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03596">
                                        <div class="article-summary-box-inner">
                                            <span><p>Chinese character style transfer is a very challenging problem because of the
complexity of the glyph shapes or underlying structures and large numbers of
existed characters, when comparing with English letters. Moreover, the
handwriting of calligraphy masters has a more irregular stroke and is difficult
to obtain in real-world scenarios. Recently, several GAN-based methods have
been proposed for font synthesis, but some of them require numerous reference
data and the other part of them have cumbersome preprocessing steps to divide
the character into different parts to be learned and transferred separately. In
this paper, we propose a simple but powerful end-to-end Chinese calligraphy
font generation framework ZiGAN, which does not require any manual operation or
redundant preprocessing to generate fine-grained target-style characters with
few-shot references. To be specific, a few paired samples from different
character styles are leveraged to attain a fine-grained correlation between
structures underlying different glyphs. To capture valuable style knowledge in
target and strengthen the coarse-grained understanding of character content, we
utilize multiple unpaired samples to align the feature distributions belonging
to different character styles. By doing so, only a few target Chinese
calligraphy characters are needed to generated expected style transferred
characters. Experiments demonstrate that our method has a state-of-the-art
generalization ability in few-shot Chinese character style transfer.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Understanding the computational demands underlying visual reasoning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Vaishnav_M/0/1/0/all/0/1">Mohit Vaishnav</a>, <a href="http://arxiv.org/find/cs/1/au:+Cadene_R/0/1/0/all/0/1">Remi Cadene</a>, <a href="http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1">Andrea Alamia</a>, <a href="http://arxiv.org/find/cs/1/au:+Linsley_D/0/1/0/all/0/1">Drew Linsley</a>, <a href="http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1">Rufin VanRullen</a>, <a href="http://arxiv.org/find/cs/1/au:+Serre_T/0/1/0/all/0/1">Thomas Serre</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03603">
                                        <div class="article-summary-box-inner">
                                            <span><p>Visual understanding requires comprehending complex visual relations between
objects within a scene. Here, we seek to characterize the computational demands
for abstract visual reasoning. We do this by systematically assessing the
ability of modern deep convolutional neural networks (CNNs) to learn to solve
the Synthetic Visual Reasoning Test (SVRT) challenge, a collection of
twenty-three visual reasoning problems. Our analysis leads to a novel taxonomy
of visual reasoning tasks, which can be primarily explained by both the type of
relations (same-different vs. spatial-relation judgments) and the number of
relations used to compose the underlying rules. Prior cognitive neuroscience
work suggests that attention plays a key role in human's visual reasoning
ability. To test this, we extended the CNNs with spatial and feature-based
attention mechanisms. In a second series of experiments, we evaluated the
ability of these attention networks to learn to solve the SVRT challenge and
found the resulting architectures to be much more efficient at solving the
hardest of these visual reasoning tasks. Most importantly, the corresponding
improvements on individual tasks partially explained the taxonomy. Overall,
this work advances our understanding of visual reasoning and yields testable
Neuroscience predictions regarding the need for feature-based vs. spatial
attention in visual reasoning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Triplet <span class="highlight_title">Contrastive Learning</span> for Brain Tumor Classification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tian Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03611">
                                        <div class="article-summary-box-inner">
                                            <span><p>Brain tumor is a common and fatal form of cancer which affects both adults
and children. The classification of brain tumors into different types is hence
a crucial task, as it greatly influences the treatment that physicians will
prescribe. In light of this, medical imaging techniques, especially those
applying deep convolutional networks followed by a classification layer, have
been developed to make possible computer-aided classification of brain tumor
types. In this paper, we present a novel approach of directly learning deep
embeddings for brain tumor types, which can be used for downstream tasks such
as classification. Along with using triplet loss variants, our approach applies
contrastive learning to performing unsupervised pre-training, combined with a
rare-case data augmentation module to effectively ameliorate the lack of data
problem in the brain tumor imaging analysis domain. We evaluate our method on
an extensive brain tumor dataset which consists of 27 different tumor classes,
out of which 13 are defined as rare. With a common encoder during all the
experiments, we compare our approach with a baseline classification-layer based
model, and the results well prove the effectiveness of our approach across all
measured metrics.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ An EM Framework for Online Incremental Learning of Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shipeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiale Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiangwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Songyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03613">
                                        <div class="article-summary-box-inner">
                                            <span><p>Incremental learning of semantic segmentation has emerged as a promising
strategy for visual scene interpretation in the open- world setting. However,
it remains challenging to acquire novel classes in an online fashion for the
segmentation task, mainly due to its continuously-evolving semantic label
space, partial pixelwise ground-truth annotations, and constrained data
availability. To ad- dress this, we propose an incremental learning strategy
that can fast adapt deep segmentation models without catastrophic forgetting,
using a streaming input data with pixel annotations on the novel classes only.
To this end, we develop a uni ed learning strategy based on the
Expectation-Maximization (EM) framework, which integrates an iterative
relabeling strategy that lls in the missing labels and a rehearsal-based
incremental learning step that balances the stability-plasticity of the model.
Moreover, our EM algorithm adopts an adaptive sampling method to select
informative train- ing data and a class-balancing training strategy in the
incremental model updates, both improving the e cacy of model learning. We
validate our approach on the PASCAL VOC 2012 and ADE20K datasets, and the
results demonstrate its superior performance over the existing incremental
methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Monte Carlo DropBlock for Modelling Uncertainty in Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Deepshikha_K/0/1/0/all/0/1">Kumari Deepshikha</a>, <a href="http://arxiv.org/find/cs/1/au:+Yelleni_S/0/1/0/all/0/1">Sai Harsha Yelleni</a>, <a href="http://arxiv.org/find/cs/1/au:+Srijith_P/0/1/0/all/0/1">P.K. Srijith</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_C/0/1/0/all/0/1">C Krishna Mohan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03614">
                                        <div class="article-summary-box-inner">
                                            <span><p>With the advancements made in deep learning, computer vision problems like
object detection and segmentation have seen a great improvement in performance.
However, in many real-world applications such as autonomous driving vehicles,
the risk associated with incorrect predictions of objects is very high.
Standard deep learning models for object detection such as YOLO models are
often overconfident in their predictions and do not take into account the
uncertainty in predictions on out-of-distribution data. In this work, we
propose an efficient and effective approach to model uncertainty in object
detection and segmentation tasks using Monte-Carlo DropBlock (MC-DropBlock)
based inference. The proposed approach applies drop-block during training time
and test time on the convolutional layer of the deep learning models such as
YOLO. We show that this leads to a Bayesian convolutional neural network
capable of capturing the epistemic uncertainty in the model. Additionally, we
capture the aleatoric uncertainty using a Gaussian likelihood. We demonstrate
the effectiveness of the proposed approach on modeling uncertainty in object
detection and segmentation tasks using out-of-distribution experiments.
Experimental results show that MC-DropBlock improves the generalization,
calibration, and uncertainty modeling capabilities of YOLO models in object
detection and segmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ MPI: Multi-receptive and Parallel Integration for Salient Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Han Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cen_J/0/1/0/all/0/1">Jun Cen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ningzhong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Dong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03618">
                                        <div class="article-summary-box-inner">
                                            <span><p>The semantic representation of deep features is essential for image context
understanding, and effective fusion of features with different semantic
representations can significantly improve the model's performance on salient
object detection. In this paper, a novel method called MPI is proposed for
salient object detection. Firstly, a multi-receptive enhancement module (MRE)
is designed to effectively expand the receptive fields of features from
different layers and generate features with different receptive fields. MRE can
enhance the semantic representation and improve the model's perception of the
image context, which enables the model to locate the salient object accurately.
Secondly, in order to reduce the reuse of redundant information in the complex
top-down fusion method and weaken the differences between semantic features, a
relatively simple but effective parallel fusion strategy (PFS) is proposed. It
allows multi-scale features to better interact with each other, thus improving
the overall performance of the model. Experimental results on multiple datasets
demonstrate that the proposed method outperforms state-of-the-art methods under
different evaluation metrics.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning an Augmented RGB Representation with <span class="highlight_title">Cross-Modal</span> Knowledge <span class="highlight_title">Distillation</span> for Action Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1">Rui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Srijan Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Bremond_F/0/1/0/all/0/1">Francois Bremond</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03619">
                                        <div class="article-summary-box-inner">
                                            <span><p>In video understanding, most cross-modal knowledge distillation (KD) methods
are tailored for classification tasks, focusing on the discriminative
representation of the trimmed videos. However, action detection requires not
only categorizing actions, but also localizing them in untrimmed videos.
Therefore, transferring knowledge pertaining to temporal relations is critical
for this task which is missing in the previous cross-modal KD frameworks. To
this end, we aim at learning an augmented RGB representation for action
detection, taking advantage of additional modalities at training time through
KD. We propose a KD framework consisting of two levels of distillation. On one
hand, atomic-level distillation encourages the RGB student to learn the
sub-representation of the actions from the teacher in a contrastive manner. On
the other hand, sequence-level distillation encourages the student to learn the
temporal knowledge from the teacher, which consists of transferring the Global
Contextual Relations and the Action Boundary Saliency. The result is an
Augmented-RGB stream that can achieve competitive performance as the two-stream
network while using only RGB at inference time. Extensive experimental analysis
shows that our proposed distillation framework is generic and outperforms other
popular cross-modal distillation methods in action detection task.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ WideCaps: A Wide Attention based Capsule Network for Image Classification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+J_P/0/1/0/all/0/1">Pawan S J</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rishi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_H/0/1/0/all/0/1">Hemanth Sai Ram Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Vani_M/0/1/0/all/0/1">M Vani</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_J/0/1/0/all/0/1">Jeny Rajan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03627">
                                        <div class="article-summary-box-inner">
                                            <span><p>The capsule network is a distinct and promising segment of the neural network
family that drew attention due to its unique ability to maintain the
equivariance property by preserving the spatial relationship amongst the
features. The capsule network has attained unprecedented success over image
classification tasks with datasets such as MNIST and affNIST by encoding the
characteristic features into the capsules and building the parse-tree
structure. However, on the datasets involving complex foreground and background
regions such as CIFAR-10, the performance of the capsule network is sub-optimal
due to its naive data routing policy and incompetence towards extracting
complex features. This paper proposes a new design strategy for capsule network
architecture for efficiently dealing with complex images. The proposed method
incorporates wide bottleneck residual modules and the Squeeze and Excitation
attention blocks upheld by the modified FM routing algorithm to address the
defined problem. A wide bottleneck residual module facilitates extracting
complex features followed by the squeeze and excitation attention block to
enable channel-wise attention by suppressing the trivial features. This setup
allows channel inter-dependencies at almost no computational cost, thereby
enhancing the representation ability of capsules on complex images. We
extensively evaluate the performance of the proposed model on three publicly
available datasets, namely CIFAR-10, Fashion MNIST, and SVHN, to outperform the
top-5 performance on CIFAR-10 and Fashion MNIST with highly competitive
performance on the SVHN dataset.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Anchor-free 3D Single Stage Detector with Mask-Guided Attention for Point Cloud.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiale Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yong Ding</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03634">
                                        <div class="article-summary-box-inner">
                                            <span><p>Most of the existing single-stage and two-stage 3D object detectors are
anchor-based methods, while the efficient but challenging anchor-free
single-stage 3D object detection is not well investigated. Recent studies on 2D
object detection show that the anchor-free methods also are of great potential.
However, the unordered and sparse properties of point clouds prevent us from
directly leveraging the advanced 2D methods on 3D point clouds. We overcome
this by converting the voxel-based sparse 3D feature volumes into the sparse 2D
feature maps. We propose an attentive module to fit the sparse feature maps to
dense mostly on the object regions through the deformable convolution tower and
the supervised mask-guided attention. By directly regressing the 3D bounding
box from the enhanced and dense feature maps, we construct a novel single-stage
3D detector for point clouds in an anchor-free manner. We propose an IoU-based
detection confidence re-calibration scheme to improve the correlation between
the detection confidence score and the accuracy of the bounding box regression.
Our code is publicly available at \url{https://github.com/jialeli1/MGAF-3DSSD}.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Efficient Light Field Reconstruction via Spatio-Angular Dense Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zexi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_H/0/1/0/all/0/1">Henry Wing Fung Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yuk Ying Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haisheng Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03635">
                                        <div class="article-summary-box-inner">
                                            <span><p>As an image sensing instrument, light field images can supply extra angular
information compared with monocular images and have facilitated a wide range of
measurement applications. Light field image capturing devices usually suffer
from the inherent trade-off between the angular and spatial resolutions. To
tackle this problem, several methods, such as light field reconstruction and
light field super-resolution, have been proposed but leaving two problems
unaddressed, namely domain asymmetry and efficient information flow. In this
paper, we propose an end-to-end Spatio-Angular Dense Network (SADenseNet) for
light field reconstruction with two novel components, namely correlation blocks
and spatio-angular dense skip connections to address them. The former performs
effective modeling of the correlation information in a way that conforms with
the domain asymmetry. And the latter consists of three kinds of connections
enhancing the information flow within two domains. Extensive experiments on
both real-world and synthetic datasets have been conducted to demonstrate that
the proposed SADenseNet's state-of-the-art performance at significantly reduced
costs in memory and computation. The qualitative results show that the
reconstructed light field images are sharp with correct details and can serve
as pre-processing to improve the accuracy of related measurement applications.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Saliency-Associated Object Tracking.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zikun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_W/0/1/0/all/0/1">Wenjie Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongpeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhenyu He</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03637">
                                        <div class="article-summary-box-inner">
                                            <span><p>Most existing trackers based on deep learning perform tracking in a holistic
strategy, which aims to learn deep representations of the whole target for
localizing the target. It is arduous for such methods to track targets with
various appearance variations. To address this limitation, another type of
methods adopts a part-based tracking strategy which divides the target into
equal patches and tracks all these patches in parallel. The target state is
inferred by summarizing the tracking results of these patches. A potential
limitation of such trackers is that not all patches are equally informative for
tracking. Some patches that are not discriminative may have adverse effects. In
this paper, we propose to track the salient local parts of the target that are
discriminative for tracking. In particular, we propose a fine-grained saliency
mining module to capture the local saliencies. Further, we design a
saliency-association modeling module to associate the captured saliencies
together to learn effective correlation representations between the exemplar
and the search image for state estimation. Extensive experiments on five
diverse datasets demonstrate that the proposed method performs favorably
against state-of-the-art trackers.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Image reconstruction in light-sheet microscopy: spatially varying deconvolution and mixed noise.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Toader_B/0/1/0/all/0/1">Bogdan Toader</a>, <a href="http://arxiv.org/find/math/1/au:+Boulanger_J/0/1/0/all/0/1">Jerome Boulanger</a>, <a href="http://arxiv.org/find/math/1/au:+Korolev_Y/0/1/0/all/0/1">Yury Korolev</a>, <a href="http://arxiv.org/find/math/1/au:+Lenz_M/0/1/0/all/0/1">Martin O. Lenz</a>, <a href="http://arxiv.org/find/math/1/au:+Manton_J/0/1/0/all/0/1">James Manton</a>, <a href="http://arxiv.org/find/math/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Schonlieb</a>, <a href="http://arxiv.org/find/math/1/au:+Muresan_L/0/1/0/all/0/1">Leila Muresan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03642">
                                        <div class="article-summary-box-inner">
                                            <span><p>We study the problem of deconvolution for light-sheet microscopy, where the
data is corrupted by spatially varying blur and a combination of Poisson and
Gaussian noise. The spatial variation of the point spread function (PSF) of a
light-sheet microscope is determined by the interaction between the excitation
sheet and the detection objective PSF. First, we introduce a model of the image
formation process that incorporates this interaction, therefore capturing the
main characteristics of this imaging modality. Then, we formulate a variational
model that accounts for the combination of Poisson and Gaussian noise through a
data fidelity term consisting of the infimal convolution of the single noise
fidelities, first introduced in L. Calatroni et al. "Infimal convolution of
data discrepancies for mixed noise removal", SIAM Journal on Imaging Sciences
10.3 (2017), 1196-1233. We establish convergence rates in a Bregman distance
under a source condition for the infimal convolution fidelity and a discrepancy
principle for choosing the value of the regularisation parameter. The inverse
problem is solved by applying the primal-dual hybrid gradient (PDHG) algorithm
in a novel way. Finally, numerical experiments performed on both simulated and
real data show superior reconstruction results in comparison with other
methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ AdaAttN: Revisit Attention Mechanism in Arbitrary Neural Style Transfer.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Songhua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tianwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meiling Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhengxing Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03647">
                                        <div class="article-summary-box-inner">
                                            <span><p>Fast arbitrary neural style transfer has attracted widespread attention from
academic, industrial and art communities due to its flexibility in enabling
various applications. Existing solutions either attentively fuse deep style
feature into deep content feature without considering feature distributions, or
adaptively normalize deep content feature according to the style such that
their global statistics are matched. Although effective, leaving shallow
feature unexplored and without locally considering feature statistics, they are
prone to unnatural output with unpleasing local distortions. To alleviate this
problem, in this paper, we propose a novel attention and normalization module,
named Adaptive Attention Normalization (AdaAttN), to adaptively perform
attentive normalization on per-point basis. Specifically, spatial attention
score is learnt from both shallow and deep features of content and style
images. Then per-point weighted statistics are calculated by regarding a style
feature point as a distribution of attention-weighted output of all style
feature points. Finally, the content feature is normalized so that they
demonstrate the same local feature statistics as the calculated per-point
weighted style feature statistics. Besides, a novel local feature loss is
derived based on AdaAttN to enhance local visual quality. We also extend
AdaAttN to be ready for video style transfer with slight modifications.
Experiments demonstrate that our method achieves state-of-the-art arbitrary
image/video style transfer. Codes and models are available.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ From Voxel to Point: IoU-guided 3D Object Detection for Point Cloud with Voxel-to-Point Decoder.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiale Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yong Ding</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03648">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we present an Intersection-over-Union (IoU) guided two-stage
3D object detector with a voxel-to-point decoder. To preserve the necessary
information from all raw points and maintain the high box recall in voxel based
Region Proposal Network (RPN), we propose a residual voxel-to-point decoder to
extract the point features in addition to the map-view features from the voxel
based RPN. We use a 3D Region of Interest (RoI) alignment to crop and align the
features with the proposal boxes for accurately perceiving the object position.
The RoI-Aligned features are finally aggregated with the corner geometry
embeddings that can provide the potentially missing corner information in the
box refinement stage. We propose a simple and efficient method to align the
estimated IoUs to the refined proposal boxes as a more relevant localization
confidence. The comprehensive experiments on KITTI and Waymo Open Dataset
demonstrate that our method achieves significant improvements with novel
architectures against the existing methods. The code is available on Github
URL\footnote{\url{https://github.com/jialeli1/From-Voxel-to-Point}}.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Joint Depth and Normal Estimation from Real-world Time-of-flight Raw Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Rongrong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Changlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03649">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a novel approach to joint depth and normal estimation for
time-of-flight (ToF) sensors. Our model learns to predict the high-quality
depth and normal maps jointly from ToF raw sensor data. To achieve this, we
meticulously constructed the first large-scale dataset (named ToF-100) with
paired raw ToF data and ground-truth high-resolution depth maps provided by an
industrial depth camera. In addition, we also design a simple but effective
framework for joint depth and normal estimation, applying a robust Chamfer loss
via jittering to improve the performance of our model. Our experiments
demonstrate that our proposed method can efficiently reconstruct
high-resolution depth and normal maps and significantly outperforms
state-of-the-art approaches. Our code and data will be available at
\url{https://github.com/hkustVisionRr/JointlyDepthNormalEstimation}
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Skeleton-<span class="highlight_title">Contrastive</span> 3D Action Representation Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Thoker_F/0/1/0/all/0/1">Fida Mohammad Thoker</a>, <a href="http://arxiv.org/find/cs/1/au:+Doughty_H/0/1/0/all/0/1">Hazel Doughty</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G.M. Snoek</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03656">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper strives for self-supervised learning of a feature space suitable
for skeleton-based action recognition. Our proposal is built upon learning
invariances to input skeleton representations and various skeleton
augmentations via a noise contrastive estimation. In particular, we propose
inter-skeleton contrastive learning, which learns from multiple different input
skeleton representations in a cross-contrastive manner. In addition, we
contribute several skeleton-specific spatial and temporal augmentations which
further encourage the model to learn the spatio-temporal dynamics of skeleton
data. By learning similarities between different skeleton representations as
well as augmented views of the same sequence, the network is encouraged to
learn higher-level semantics of the skeleton data than when only using the
augmented views. Our approach achieves state-of-the-art performance for
self-supervised learning from skeleton data on the challenging PKU and NTU
datasets with multiple downstream tasks, including action recognition, action
retrieval and semi-supervised learning. Code is available at
https://github.com/fmthoker/skeleton-contrast.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ One-Shot Object Affordance Detection in the Wild.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1">Wei Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Hongchen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03658">
                                        <div class="article-summary-box-inner">
                                            <span><p>Affordance detection refers to identifying the potential action possibilities
of objects in an image, which is a crucial ability for robot perception and
manipulation. To empower robots with this ability in unseen scenarios, we first
study the challenging one-shot affordance detection problem in this paper,
i.e., given a support image that depicts the action purpose, all objects in a
scene with the common affordance should be detected. To this end, we devise a
One-Shot Affordance Detection Network (OSAD-Net) that firstly estimates the
human action purpose and then transfers it to help detect the common affordance
from all candidate images. Through collaboration learning, OSAD-Net can capture
the common characteristics between objects having the same underlying
affordance and learn a good adaptation capability for perceiving unseen
affordances. Besides, we build a large-scale Purpose-driven Affordance Dataset
v2 (PADv2) by collecting and labeling 30k images from 39 affordance and 103
object categories. With complex scenes and rich annotations, our PADv2 dataset
can be used as a test bed to benchmark affordance detection methods and may
also facilitate downstream vision tasks, such as scene understanding, action
recognition, and robot manipulation. Specifically, we conducted comprehensive
experiments on PADv2 dataset by including 11 advanced models from several
related research fields. Experimental results demonstrate the superiority of
our model over previous representative ones in terms of both objective metrics
and visual quality. The benchmark suite is available at
https://github.com/lhc1224/OSAD Net.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Discriminative Latent Semantic Graph for Video Captioning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junyan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1">Bingzhang Hul Yang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagnucco_M/0/1/0/all/0/1">Maurice Pagnucco</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1">Yu Guan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03662">
                                        <div class="article-summary-box-inner">
                                            <span><p>Video captioning aims to automatically generate natural language sentences
that can describe the visual contents of a given video. Existing generative
models like encoder-decoder frameworks cannot explicitly explore the
object-level interactions and frame-level information from complex
spatio-temporal data to generate semantic-rich captions. Our main contribution
is to identify three key problems in a joint framework for future video
summarization tasks. 1) Enhanced Object Proposal: we propose a novel
Conditional Graph that can fuse spatio-temporal information into latent object
proposal. 2) Visual Knowledge: Latent Proposal Aggregation is proposed to
dynamically extract visual words with higher semantic levels. 3) Sentence
Validation: A novel Discriminative Language Validator is proposed to verify
generated captions so that key semantic concepts can be effectively preserved.
Our experiments on two public datasets (MVSD and MSR-VTT) manifest significant
improvements over state-of-the-art approaches on all metrics, especially for
BLEU-4 and CIDEr. Our code is available at
https://github.com/baiyang4/D-LSG-Video-Caption.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ RECALL: Replay-based Continual Learning in Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Maracani_A/0/1/0/all/0/1">Andrea Maracani</a>, <a href="http://arxiv.org/find/cs/1/au:+Michieli_U/0/1/0/all/0/1">Umberto Michieli</a>, <a href="http://arxiv.org/find/cs/1/au:+Toldo_M/0/1/0/all/0/1">Marco Toldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanuttigh_P/0/1/0/all/0/1">Pietro Zanuttigh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03673">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep networks allow to obtain outstanding results in semantic segmentation,
however they need to be trained in a single shot with a large amount of data.
Continual learning settings where new classes are learned in incremental steps
and previous training data is no longer available are challenging due to the
catastrophic forgetting phenomenon. Existing approaches typically fail when
several incremental steps are performed or in presence of a distribution shift
of the background class. We tackle these issues by recreating no longer
available data for the old classes and outlining a content inpainting scheme on
the background class. We propose two sources for replay data. The first resorts
to a generative adversarial network to sample from the class space of past
learning steps. The second relies on web-crawled data to retrieve images
containing examples of old classes from online databases. In both scenarios no
samples of past steps are stored, thus avoiding privacy concerns. Replay data
are then blended with new samples during the incremental steps. Our approach,
RECALL, outperforms state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ AMDet: A Tool for Mitotic Cell Detection in Histopathology Slides.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Williams_W/0/1/0/all/0/1">Walt Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Hall_J/0/1/0/all/0/1">Jimmy Hall</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03676">
                                        <div class="article-summary-box-inner">
                                            <span><p>Breast Cancer is the most prevalent cancer in the world. The World Health
Organization reports that the disease still affects a significant portion of
the developing world citing increased mortality rates in the majority of low to
middle income countries. The most popular protocol pathologists use for
diagnosing breast cancer is the Nottingham grading system which grades the
proliferation of tumors based on 3 major criteria, the most important of them
being mitotic cell count. The way in which pathologists evaluate mitotic cell
count is to subjectively and qualitatively analyze cells present in stained
slides of tissue and make a decision on its mitotic state i.e. is it mitotic or
not?This process is extremely inefficient and tiring for pathologists and so an
efficient, accurate, and fully automated tool to aid with the diagnosis is
extremely desirable. Fortunately, creating such a tool is made significantly
easier with the AutoML tool available from Microsoft Azure, however to the best
of our knowledge the AutoML tool has never been formally evaluated for use in
mitotic cell detection in histopathology images. This paper serves as an
evaluation of the AutoML tool for this purpose and will provide a first look on
how the tool handles this challenging problem. All code is available
athttps://github.com/WaltAFWilliams/AMDet
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Joint Inductive and Transductive Learning for Video Object Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yunyao Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Ning Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03679">
                                        <div class="article-summary-box-inner">
                                            <span><p>Semi-supervised video object segmentation is a task of segmenting the target
object in a video sequence given only a mask annotation in the first frame. The
limited information available makes it an extremely challenging task. Most
previous best-performing methods adopt matching-based transductive reasoning or
online inductive learning. Nevertheless, they are either less discriminative
for similar instances or insufficient in the utilization of spatio-temporal
information. In this work, we propose to integrate transductive and inductive
learning into a unified framework to exploit the complementarity between them
for accurate and robust video object segmentation. The proposed approach
consists of two functional branches. The transduction branch adopts a
lightweight transformer architecture to aggregate rich spatio-temporal cues
while the induction branch performs online inductive learning to obtain
discriminative target information. To bridge these two diverse branches, a
two-head label encoder is introduced to learn the suitable target prior for
each of them. The generated mask encodings are further forced to be
disentangled to better retain their complementarity. Extensive experiments on
several prevalent benchmarks show that, without the need of synthetic training
data, the proposed approach sets a series of new state-of-the-art records. Code
is available at https://github.com/maoyunyao/JOINT.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Enhanced Invertible Encoding for Learned Image Compression.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yueqi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1">Ka Leong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03690">
                                        <div class="article-summary-box-inner">
                                            <span><p>Although deep learning based image compression methods have achieved
promising progress these days, the performance of these methods still cannot
match the latest compression standard Versatile Video Coding (VVC). Most of the
recent developments focus on designing a more accurate and flexible entropy
model that can better parameterize the distributions of the latent features.
However, few efforts are devoted to structuring a better transformation between
the image space and the latent feature space. In this paper, instead of
employing previous autoencoder style networks to build this transformation, we
propose an enhanced Invertible Encoding Network with invertible neural networks
(INNs) to largely mitigate the information loss problem for better compression.
Experimental results on the Kodak, CLIC, and Tecnick datasets show that our
method outperforms the existing learned image compression methods and
compression standards, including VVC (VTM 12.1), especially for high-resolution
images. Our source code is available at https://github.com/xyq7/InvCompress.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Alignment of Tractography Streamlines using Deformation Transfer via Parallel Transport.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lizarraga_A/0/1/0/all/0/1">Andrew Lizarraga</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">David Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kubicki_A/0/1/0/all/0/1">Antoni Kubicki</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahib_A/0/1/0/all/0/1">Ashish Sahib</a>, <a href="http://arxiv.org/find/cs/1/au:+Nunez_E/0/1/0/all/0/1">Elvis Nunez</a>, <a href="http://arxiv.org/find/cs/1/au:+Narr_K/0/1/0/all/0/1">Katherine Narr</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Shantanu H. Joshi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03697">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a geometric framework for aligning white matter fiber tracts. By
registering fiber tracts between brains, one expects to see overlap of
anatomical structures that often provide meaningful comparisons across
subjects. However, the geometry of white matter tracts is highly heterogeneous,
and finding direct tract-correspondence across multiple individuals remains a
challenging problem. We present a novel deformation metric between tracts that
allows one to compare tracts while simultaneously obtaining a registration. To
accomplish this, fiber tracts are represented by an intrinsic mean along with
the deformation fields represented by tangent vectors from the mean. In this
setting, one can determine a parallel transport between tracts and then
register corresponding tangent vectors. We present the results of bundle
alignment on a population of 43 healthy adult subjects.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ BIGRoC: Boosting Image Generation via a Robust Classifier.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ganz_R/0/1/0/all/0/1">Roy Ganz</a>, <a href="http://arxiv.org/find/cs/1/au:+Elad_M/0/1/0/all/0/1">Michael Elad</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03702">
                                        <div class="article-summary-box-inner">
                                            <span><p>The interest of the machine learning community in image synthesis has grown
significantly in recent years, with the introduction of a wide range of deep
generative models and means for training them. Such machines' ultimate goal is
to match the distributions of the given training images and the synthesized
ones. In this work, we propose a general model-agnostic technique for improving
the image quality and the distribution fidelity of generated images, obtained
by any generative model. Our method, termed BIGRoC (boosting image generation
via a robust classifier), is based on a post-processing procedure via the
guidance of a given robust classifier and without a need for additional
training of the generative model. Given a synthesized image, we propose to
update it through projected gradient steps over the robust classifier, in an
attempt to refine its recognition. We demonstrate this post-processing
algorithm on various image synthesis methods and show a significant improvement
of the generated images, both quantitatively and qualitatively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ OVIS: Open-Vocabulary Visual Instance Search via Visual-Semantic Aligned Representation Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kevin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Junsong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03704">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce the task of open-vocabulary visual instance search (OVIS). Given
an arbitrary textual search query, Open-vocabulary Visual Instance Search
(OVIS) aims to return a ranked list of visual instances, i.e., image patches,
that satisfies the search intent from an image database. The term "open
vocabulary" means that there are neither restrictions to the visual instance to
be searched nor restrictions to the word that can be used to compose the
textual search query. We propose to address such a search challenge via
visual-semantic aligned representation learning (ViSA). ViSA leverages massive
image-caption pairs as weak image-level (not instance-level) supervision to
learn a rich cross-modal semantic space where the representations of visual
instances (not images) and those of textual queries are aligned, thus allowing
us to measure the similarities between any visual instance and an arbitrary
textual query. To evaluate the performance of ViSA, we build two datasets named
OVIS40 and OVIS1600 and also introduce a pipeline for error analysis. Through
extensive experiments on the two datasets, we demonstrate ViSA's ability to
search for visual instances in images not available during training given a
wide range of textual queries including those composed of uncommon words.
Experimental results show that ViSA achieves an mAP@50 of 21.9% on OVIS40 under
the most challenging setting and achieves an mAP@6 of 14.9% on OVIS1600
dataset.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Hierarchical View Predictor: Unsupervised 3D Global Feature Learning through Hierarchical Prediction among Unordered Views.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhizhong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu-Shen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zwicker_M/0/1/0/all/0/1">Matthias Zwicker</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03743">
                                        <div class="article-summary-box-inner">
                                            <span><p>Unsupervised learning of global features for 3D shape analysis is an
important research challenge because it avoids manual effort for supervised
information collection. In this paper, we propose a view-based deep learning
model called Hierarchical View Predictor (HVP) to learn 3D shape features from
unordered views in an unsupervised manner. To mine highly discriminative
information from unordered views, HVP performs a novel hierarchical view
prediction over a view pair, and aggregates the knowledge learned from the
predictions in all view pairs into a global feature. In a view pair, we pose
hierarchical view prediction as the task of hierarchically predicting a set of
image patches in a current view from its complementary set of patches, and in
addition, completing the current view and its opposite from any one of the two
sets of patches. Hierarchical prediction, in patches to patches, patches to
view and view to view, facilitates HVP to effectively learn the structure of 3D
shapes from the correlation between patches in the same view and the
correlation between a pair of complementary views. In addition, the employed
implicit aggregation over all view pairs enables HVP to learn global features
from unordered views. Our results show that HVP can outperform state-of-the-art
methods under large-scale 3D shape benchmarks in shape classification and
retrieval.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projection Matching.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chao_C/0/1/0/all/0/1">Chen Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhizhong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu-Shen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zwicker_M/0/1/0/all/0/1">Matthias Zwicker</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03746">
                                        <div class="article-summary-box-inner">
                                            <span><p>Learning to generate 3D point clouds without 3D supervision is an important
but challenging problem. Current solutions leverage various differentiable
renderers to project the generated 3D point clouds onto a 2D image plane, and
train deep neural networks using the per-pixel difference with 2D ground truth
images. However, these solutions are still struggling to fully recover fine
structures of 3D shapes, such as thin tubes or planes. To resolve this issue,
we propose an unsupervised approach for 3D point cloud generation with fine
structures. Specifically, we cast 3D point cloud learning as a 2D projection
matching problem. Rather than using entire 2D silhouette images as a regular
pixel supervision, we introduce structure adaptive sampling to randomly sample
2D points within the silhouettes as an irregular point supervision, which
alleviates the consistency issue of sampling from different view angles. Our
method pushes the neural network to generate a 3D point cloud whose 2D
projections match the irregular point supervision from different view angles.
Our 2D projection matching approach enables the neural network to learn more
accurate structure information than using the per-pixel difference, especially
for fine and thin 3D structures. Our method can recover fine 3D structures from
2D silhouette images at different resolutions, and is robust to different
sampling methods and point number in irregular point supervision. Our method
outperforms others under widely used benchmarks. Our code, data and models are
available at https://github.com/chenchao15/2D\_projection\_matching.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ PASS: Protected Attribute Suppression System for Mitigating Bias in Face Recognition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dhar_P/0/1/0/all/0/1">Prithviraj Dhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gleason_J/0/1/0/all/0/1">Joshua Gleason</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Aniket Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillo_C/0/1/0/all/0/1">Carlos D. Castillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1">Rama Chellappa</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03764">
                                        <div class="article-summary-box-inner">
                                            <span><p>Face recognition networks encode information about sensitive attributes while
being trained for identity classification. Such encoding has two major issues:
(a) it makes the face representations susceptible to privacy leakage (b) it
appears to contribute to bias in face recognition. However, existing bias
mitigation approaches generally require end-to-end training and are unable to
achieve high verification accuracy. Therefore, we present a descriptor-based
adversarial de-biasing approach called `Protected Attribute Suppression System
(PASS)'. PASS can be trained on top of descriptors obtained from any previously
trained high-performing network to classify identities and simultaneously
reduce encoding of sensitive attributes. This eliminates the need for
end-to-end training. As a component of PASS, we present a novel discriminator
training strategy that discourages a network from encoding protected attribute
information. We show the efficacy of PASS to reduce gender and skintone
information in descriptors from SOTA face recognition networks like Arcface. As
a result, PASS descriptors outperform existing baselines in reducing gender and
skintone bias on the IJB-C dataset, while maintaining a high verification
accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Multi-Slice Net: A novel light weight framework for COVID-19 Diagnosis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gammulle_H/0/1/0/all/0/1">Harshala Gammulle</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_T/0/1/0/all/0/1">Tharindu Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1">Sridha Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03786">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper presents a novel lightweight COVID-19 diagnosis framework using CT
scans. Our system utilises a novel two-stage approach to generate robust and
efficient diagnoses across heterogeneous patient level inputs. We use a
powerful backbone network as a feature extractor to capture discriminative
slice-level features. These features are aggregated by a lightweight network to
obtain a patient level diagnosis. The aggregation network is carefully designed
to have a small number of trainable parameters while also possessing sufficient
capacity to generalise to diverse variations within different CT volumes and to
adapt to noise introduced during the data acquisition. We achieve a significant
performance increase over the baselines when benchmarked on the SPGC COVID-19
Radiomics Dataset, despite having only 2.5 million trainable parameters and
requiring only 0.623 seconds on average to process a single patient's CT volume
using an Nvidia-GeForce RTX 2080 GPU.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning Joint Embedding with Modality Alignments for <span class="highlight_title">Cross-Modal</span> Retrieval of Recipes and Food Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03788">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper presents a three-tier modality alignment approach to learning
text-image joint embedding, coined as JEMA, for cross-modal retrieval of
cooking recipes and food images. The first tier improves recipe text embedding
by optimizing the LSTM networks with term extraction and ranking enhanced
sequence patterns, and optimizes the image embedding by combining the
ResNeXt-101 image encoder with the category embedding using wideResNet-50 with
word2vec. The second tier modality alignment optimizes the textual-visual joint
embedding loss function using a double batch-hard triplet loss with soft-margin
optimization. The third modality alignment incorporates two types of
cross-modality alignments as the auxiliary loss regularizations to further
reduce the alignment errors in the joint learning of the two modality-specific
embedding functions. The category-based cross-modal alignment aims to align the
image category with the recipe category as a loss regularization to the joint
embedding. The cross-modal discriminator-based alignment aims to add the
visual-textual embedding distribution alignment to further regularize the joint
embedding loss. Extensive experiments with the one-million recipes benchmark
dataset Recipe1M demonstrate that the proposed JEMA approach outperforms the
state-of-the-art cross-modal embedding methods for both image-to-recipe and
recipe-to-image retrievals.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Boundary-aware Graph Reasoning for Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haoteng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">Haozhe Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1">Liang Zhan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03791">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we propose a Boundary-aware Graph Reasoning (BGR) module to
learn long-range contextual features for semantic segmentation. Rather than
directly construct the graph based on the backbone features, our BGR module
explores a reasonable way to combine segmentation erroneous regions with the
graph construction scenario. Motivated by the fact that most hard-to-segment
pixels broadly distribute on boundary regions, our BGR module uses the boundary
score map as prior knowledge to intensify the graph node connections and
thereby guide the graph reasoning focus on boundary regions. In addition, we
employ an efficient graph convolution implementation to reduce the
computational cost, which benefits the integration of our BGR module into
current segmentation backbones. Extensive experiments on three challenging
segmentation benchmarks demonstrate the effectiveness of our proposed BGR
module for semantic segmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Paint <span class="highlight_title">Transformer</span>: Feed Forward Neural Painting with Stroke Prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Songhua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tianwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1">Ruifeng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03798">
                                        <div class="article-summary-box-inner">
                                            <span><p>Neural painting refers to the procedure of producing a series of strokes for
a given image and non-photo-realistically recreating it using neural networks.
While reinforcement learning (RL) based agents can generate a stroke sequence
step by step for this task, it is not easy to train a stable RL agent. On the
other hand, stroke optimization methods search for a set of stroke parameters
iteratively in a large search space; such low efficiency significantly limits
their prevalence and practicality. Different from previous methods, in this
paper, we formulate the task as a set prediction problem and propose a novel
Transformer-based framework, dubbed Paint Transformer, to predict the
parameters of a stroke set with a feed forward network. This way, our model can
generate a set of strokes in parallel and obtain the final painting of size 512
* 512 in near real time. More importantly, since there is no dataset available
for training the Paint Transformer, we devise a self-training pipeline such
that it can be trained without any off-the-shelf dataset while still achieving
excellent generalization capability. Experiments demonstrate that our method
achieves better painting performance than previous ones with cheaper training
and inference costs. Codes and models are available.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ COVID-view: Diagnosis of COVID-19 using Chest CT.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jadhav_S/0/1/0/all/0/1">Shreeraj Jadhav</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_G/0/1/0/all/0/1">Gaofeng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zawin_M/0/1/0/all/0/1">Marlene Zawin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaufman_A/0/1/0/all/0/1">Arie E. Kaufman</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03799">
                                        <div class="article-summary-box-inner">
                                            <span><p>Significant work has been done towards deep learning (DL) models for
automatic lung and lesion segmentation and classification of COVID-19 on chest
CT data. However, comprehensive visualization systems focused on supporting the
dual visual+DL diagnosis of COVID-19 are non-existent. We present COVID-view, a
visualization application specially tailored for radiologists to diagnose
COVID-19 from chest CT data. The system incorporates a complete pipeline of
automatic lungs segmentation, localization/ isolation of lung abnormalities,
followed by visualization, visual and DL analysis, and
measurement/quantification tools. Our system combines the traditional 2D
workflow of radiologists with newer 2D and 3D visualization techniques with DL
support for a more comprehensive diagnosis. COVID-view incorporates a novel DL
model for classifying the patients into positive/negative COVID-19 cases, which
acts as a reading aid for the radiologist using COVID-view and provides the
attention heatmap as an explainable DL for the model output. We designed and
evaluated COVID-view through suggestions, close feedback and conducting case
studies of real-world patient data by expert radiologists who have substantial
experience diagnosing chest CT scans for COVID-19, pulmonary embolism, and
other forms of lung infections. We present requirements and task analysis for
the diagnosis of COVID-19 that motivate our design choices and results in a
practical system which is capable of handling real-world patient cases.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ PSGR: Pixel-wise Sparse Graph Reasoning for COVID-19 Pneumonia Segmentation in CT Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">Haozhe Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haoteng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1">Guixiang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1">Liang Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yong Xia</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03809">
                                        <div class="article-summary-box-inner">
                                            <span><p>Automated and accurate segmentation of the infected regions in computed
tomography (CT) images is critical for the prediction of the pathological stage
and treatment response of COVID-19. Several deep convolutional neural networks
(DCNNs) have been designed for this task, whose performance, however, tends to
be suppressed by their limited local receptive fields and insufficient global
reasoning ability. In this paper, we propose a pixel-wise sparse graph
reasoning (PSGR) module and insert it into a segmentation network to enhance
the modeling of long-range dependencies for COVID-19 infected region
segmentation in CT images. In the PSGR module, a graph is first constructed by
projecting each pixel on a node based on the features produced by the
segmentation backbone, and then converted into a sparsely-connected graph by
keeping only K strongest connections to each uncertain pixel. The long-range
information reasoning is performed on the sparsely-connected graph to generate
enhanced features. The advantages of this module are two-fold: (1) the
pixel-wise mapping strategy not only avoids imprecise pixel-to-node projections
but also preserves the inherent information of each pixel for global reasoning;
and (2) the sparsely-connected graph construction results in effective
information retrieval and reduction of the noise propagation. The proposed
solution has been evaluated against four widely-used segmentation models on
three public datasets. The results show that the segmentation model equipped
with our PSGR module can effectively segment COVID-19 infected regions in CT
images, outperforming all other competing models.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ P-WAE: Generalized Patch-Wasserstein Autoencoder for Anomaly Screening.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yurong Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03815">
                                        <div class="article-summary-box-inner">
                                            <span><p>To mitigate the inspector's workload and improve the quality of the product,
computer vision-based anomaly detection (AD) techniques are gradually deployed
in real-world industrial scenarios. Recent anomaly analysis benchmarks progress
to generative models. The aim is to model the defect-free distribution so that
anomalies can be classified as out-of-distribution samples. Nevertheless, there
are two disturbing factors that need researchers and deployers to prioritize:
(i) the simplistic prior latent distribution inducing limited expressive
capability; (ii) the collapsed mutual-dependent features resulting in poor
generalization. In this paper, we propose a novel Patch-wise Wasserstein
AutoEncoder (P-WAE) architecture to alleviate those challenges. In particular,
a patch-wise variational inference model coupled with solving the jigsaw puzzle
is designed, which is a simple yet effective way to increase the expressiveness
and complexity of the latent manifold. This alleviates the blurry
reconstruction problem. In addition, the Hilbert-Schmidt Independence Criterion
(HSIC) bottleneck is introduced to constrain the over-regularization
representation. Comprehensive experiments, conducted on the MVTec AD dataset,
demonstrate the superior performance of our propo
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DistillPose: Lightweight Camera Localization Using Auxiliary Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Abouelnaga_Y/0/1/0/all/0/1">Yehya Abouelnaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_M/0/1/0/all/0/1">Mai Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilic_S/0/1/0/all/0/1">Slobodan Ilic</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03819">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose a lightweight retrieval-based pipeline to predict 6DOF camera
poses from RGB images. Our pipeline uses a convolutional neural network (CNN)
to encode a query image as a feature vector. A nearest neighbor lookup finds
the pose-wise nearest database image. A siamese convolutional neural network
regresses the relative pose from the nearest neighboring database image to the
query image. The relative pose is then applied to the nearest neighboring
absolute pose to obtain the query image's final absolute pose prediction. Our
model is a distilled version of NN-Net that reduces its parameters by 98.87%,
information retrieval feature vector size by 87.5%, and inference time by
89.18% without a significant decrease in localization accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Video Annotation for Visual Tracking via Selection and Refinement.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dai_K/0/1/0/all/0/1">Kenan Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jie Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianhua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Huchuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xuesheng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoyun Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03821">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep learning based visual trackers entail offline pre-training on large
volumes of video datasets with accurate bounding box annotations that are
labor-expensive to achieve. We present a new framework to facilitate bounding
box annotations for video sequences, which investigates a
selection-and-refinement strategy to automatically improve the preliminary
annotations generated by tracking algorithms. A temporal assessment network
(T-Assess Net) is proposed which is able to capture the temporal coherence of
target locations and select reliable tracking results by measuring their
quality. Meanwhile, a visual-geometry refinement network (VG-Refine Net) is
also designed to further enhance the selected tracking results by considering
both target appearance and temporal geometry constraints, allowing inaccurate
tracking results to be corrected. The combination of the above two networks
provides a principled approach to ensure the quality of automatic video
annotation. Experiments on large scale tracking benchmarks demonstrate that our
method can deliver highly accurate bounding box annotations and significantly
reduce human labor by 94.0%, yielding an effective means to further boost
tracking performance with augmented training data.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Towards to Robust and Generalized Medical Image Segmentation Framework.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yurong Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03823">
                                        <div class="article-summary-box-inner">
                                            <span><p>To mitigate the radiologist's workload, computer-aided diagnosis with the
capability to review and analyze medical images is gradually deployed. Deep
learning-based region of interest segmentation is among the most exciting use
cases. However, this paradigm is restricted in real-world clinical applications
due to poor robustness and generalization. The issue is more sinister with a
lack of training data. In this paper, we address the challenge from the
representation learning point of view. We investigate that the collapsed
representations, as one of the main reasons which caused poor robustness and
generalization, could be avoided through transfer learning. Therefore, we
propose a novel two-stage framework for robust generalized segmentation. In
particular, an unsupervised Tile-wise AutoEncoder (T-AE) pretraining
architecture is coined to learn meaningful representation for improving the
generalization and robustness of the downstream tasks. Furthermore, the learned
knowledge is transferred to the segmentation benchmark. Coupled with an image
reconstruction network, the representation keeps to be decoded, encouraging the
model to capture more semantic features. Experiments of lung segmentation on
multi chest X-ray datasets are conducted. Empirically, the related experimental
results demonstrate the superior generalization capability of the proposed
framework on unseen domains in terms of high performance and robustness to
corruption, especially under the scenario of the limited training data.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ AA-RMVSNet: Adaptive Aggregation Recurrent Multi-view Stereo Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zizhuang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qingtian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_C/0/1/0/all/0/1">Chen Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yisong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoping Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03824">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we present a novel recurrent multi-view stereo network based
on long short-term memory (LSTM) with adaptive aggregation, namely AA-RMVSNet.
We firstly introduce an intra-view aggregation module to adaptively extract
image features by using context-aware convolution and multi-scale aggregation,
which efficiently improves the performance on challenging regions, such as thin
objects and large low-textured surfaces. To overcome the difficulty of varying
occlusion in complex scenes, we propose an inter-view cost volume aggregation
module for adaptive pixel-wise view aggregation, which is able to preserve
better-matched pairs among all views. The two proposed adaptive aggregation
modules are lightweight, effective and complementary regarding improving the
accuracy and completeness of 3D reconstruction. Instead of conventional 3D
CNNs, we utilize a hybrid network with recurrent structure for cost volume
regularization, which allows high-resolution reconstruction and finer
hypothetical plane sweep. The proposed network is trained end-to-end and
achieves excellent performance on various datasets. It ranks $1^{st}$ among all
submissions on Tanks and Temples benchmark and achieves competitive results on
DTU dataset, which exhibits strong generalizability and robustness.
Implementation of our method is available at
https://github.com/QT-Zhu/AA-RMVSNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Weakly-Supervised Spatio-Temporal Anomaly Detection in Surveillance Video.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03825">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we introduce a novel task, referred to as Weakly-Supervised
Spatio-Temporal Anomaly Detection (WSSTAD) in surveillance video. Specifically,
given an untrimmed video, WSSTAD aims to localize a spatio-temporal tube (i.e.,
a sequence of bounding boxes at consecutive times) that encloses the abnormal
event, with only coarse video-level annotations as supervision during training.
To address this challenging task, we propose a dual-branch network which takes
as input the proposals with multi-granularities in both spatial-temporal
domains. Each branch employs a relationship reasoning module to capture the
correlation between tubes/videolets, which can provide rich contextual
information and complex entity relationships for the concept learning of
abnormal behaviors. Mutually-guided Progressive Refinement framework is set up
to employ dual-path mutual guidance in a recurrent manner, iteratively sharing
auxiliary supervision information across branches. It impels the learned
concepts of each branch to serve as a guide for its counterpart, which
progressively refines the corresponding branch and the whole framework.
Furthermore, we contribute two datasets, i.e., ST-UCF-Crime and STRA,
consisting of videos containing spatio-temporal abnormal annotations to serve
as the benchmarks for WSSTAD. We conduct extensive qualitative and quantitative
evaluations to demonstrate the effectiveness of the proposed approach and
analyze the key factors that contribute more to handle this task.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Regularizing Nighttime Weirdness: Efficient Self-supervised Monocular Depth Estimation in the Dark.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhiqiang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Baobei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03830">
                                        <div class="article-summary-box-inner">
                                            <span><p>Monocular depth estimation aims at predicting depth from a single image or
video. Recently, self-supervised methods draw much attention, due to their free
of depth annotations and impressive performance on several daytime benchmarks,
such as KITTI and Cityscapes. However, they produce weird outputs in more
challenging nighttime scenarios because of low visibility and varying
illuminations, which bring weak textures and break brightness-consistency
assumption, respectively. To address these problems, in this paper we propose a
novel framework with several improvements: (1) we introduce Priors-Based
Regularization to learn distribution knowledge from unpaired depth maps and
prevent model from being incorrectly trained; (2) we leverage
Mapping-Consistent Image Enhancement module to enhance image visibility and
contrast while maintaining brightness consistency; and (3) we present
Statistics-Based Mask strategy to tune the number of removed pixels within
textureless regions, using dynamic statistics. Experimental results demonstrate
the effectiveness of each component. Meanwhile, our framework achieves
remarkable improvements and state-of-the-art results on two nighttime datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Complementary Patch for Weakly Supervised Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1">Chaochen Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chenyue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yuchao Dai</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03852">
                                        <div class="article-summary-box-inner">
                                            <span><p>Weakly Supervised Semantic Segmentation (WSSS) based on image-level labels
has been greatly advanced by exploiting the outputs of Class Activation Map
(CAM) to generate the pseudo labels for semantic segmentation. However, CAM
merely discovers seeds from a small number of regions, which may be
insufficient to serve as pseudo masks for semantic segmentation. In this paper,
we formulate the expansion of object regions in CAM as an increase in
information. From the perspective of information theory, we propose a novel
Complementary Patch (CP) Representation and prove that the information of the
sum of the CAMs by a pair of input images with complementary hidden (patched)
parts, namely CP Pair, is greater than or equal to the information of the
baseline CAM. Therefore, a CAM with more information related to object seeds
can be obtained by narrowing down the gap between the sum of CAMs generated by
the CP Pair and the original CAM. We propose a CP Network (CPN) implemented by
a triplet network and three regularization functions. To further improve the
quality of the CAMs, we propose a Pixel-Region Correlation Module (PRCM) to
augment the contextual information by using object-region relations between the
feature maps and the CAMs. Experimental results on the PASCAL VOC 2012 datasets
show that our proposed method achieves a new state-of-the-art in WSSS,
validating the effectiveness of our CP Representation and CPN.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                        <div class="article-summary-box-inner">
                                            <span><p>"Art is the lie that enables us to realize the truth." - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Safe Vessel Navigation Visually Aided by Autonomous Unmanned Aerial Vehicles in Congested Harbors and Waterways.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sejersen_J/0/1/0/all/0/1">Jonas le Fevre Sejersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Figueiredo_R/0/1/0/all/0/1">Rui Pimentel de Figueiredo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kayacan_E/0/1/0/all/0/1">Erdal Kayacan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03862">
                                        <div class="article-summary-box-inner">
                                            <span><p>In the maritime sector, safe vessel navigation is of great importance,
particularly in congested harbors and waterways. The focus of this work is to
estimate the distance between an object of interest and potential obstacles
using a companion UAV. The proposed approach fuses GPS data with long-range
aerial images. First, we employ semantic segmentation DNN for discriminating
the vessel of interest, water, and potential solid objects using raw image
data. The network is trained with both real and images generated and
automatically labeled from a realistic AirSim simulation environment. Then, the
distances between the extracted vessel and non-water obstacle blobs are
computed using a novel GSD estimation algorithm. To the best of our knowledge,
this work is the first attempt to detect and estimate distances to unknown
objects from long-range visual data captured with conventional RGB cameras and
auxiliary absolute positioning systems (e.g. GPS). The simulation results
illustrate the accuracy and efficacy of the proposed method for visually aided
navigation of vessels assisted by UAV.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ TransForensics: Image Forgery Localization with Dense Self-Attention.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jing Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhixin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shicai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_D/0/1/0/all/0/1">Di Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1">Shiliang Pu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03871">
                                        <div class="article-summary-box-inner">
                                            <span><p>Nowadays advanced image editing tools and technical skills produce tampered
images more realistically, which can easily evade image forensic systems and
make authenticity verification of images more difficult. To tackle this
challenging problem, we introduce TransForensics, a novel image forgery
localization method inspired by Transformers. The two major components in our
framework are dense self-attention encoders and dense correction modules. The
former is to model global context and all pairwise interactions between local
patches at different scales, while the latter is used for improving the
transparency of the hidden layers and correcting the outputs from different
branches. Compared to previous traditional and deep learning methods,
TransForensics not only can capture discriminative representations and obtain
high-quality mask predictions but is also not limited by tampering types and
patch sequence orders. By conducting experiments on main benchmarks, we show
that TransForensics outperforms the stateof-the-art methods by a large margin.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Rain Removal and Illumination Enhancement Done in One Go.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1">Yecong Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yuanshuo Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_M/0/1/0/all/0/1">Mingwen Shao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03873">
                                        <div class="article-summary-box-inner">
                                            <span><p>Rain removal plays an important role in the restoration of degraded images.
Recently, data-driven methods have achieved remarkable success. However, these
approaches neglect that the appearance of rain is often accompanied by low
light conditions, which will further degrade the image quality. Therefore, it
is very indispensable to jointly remove the rain and enhance the light for
real-world rain image restoration. In this paper, we aim to address this
problem from two aspects. First, we proposed a novel entangled network, namely
EMNet, which can remove the rain and enhance illumination in one go.
Specifically, two encoder-decoder networks interact complementary information
through entanglement structure, and parallel rain removal and illumination
enhancement. Considering that the encoder-decoder structure is unreliable in
preserving spatial details, we employ a detail recovery network to restore the
desired fine texture. Second, we present a new synthetic dataset, namely
DarkRain, to boost the development of rain image restoration algorithms in
practical scenarios. DarkRain not only contains different degrees of rain, but
also considers different lighting conditions, and more realistically simulates
the rainfall in the real world. EMNet is extensively evaluated on the proposed
benchmark and achieves state-of-the-art results. In addition, after a simple
transformation, our method outshines existing methods in both rain removal and
low-light image enhancement. The source code and dataset will be made publicly
available later.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ NeuralMVS: Bridging Multi-View Stereo and Novel View Synthesis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rosu_R/0/1/0/all/0/1">Radu Alexandru Rosu</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03880">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multi-View Stereo (MVS) is a core task in 3D computer vision. With the surge
of novel deep learning methods, learned MVS has surpassed the accuracy of
classical approaches, but still relies on building a memory intensive dense
cost volume. Novel View Synthesis (NVS) is a parallel line of research and has
recently seen an increase in popularity with Neural Radiance Field (NeRF)
models, which optimize a per scene radiance field. However, NeRF methods do not
generalize to novel scenes and are slow to train and test. We propose to bridge
the gap between these two methodologies with a novel network that can recover
3D scene geometry as a distance function, together with high-resolution color
images. Our method uses only a sparse set of images as input and can generalize
well to novel scenes. Additionally, we propose a coarse-to-fine sphere tracing
approach in order to significantly increase speed. We show on various datasets
that our method reaches comparable accuracy to per-scene optimized methods
while being able to generalize and running significantly faster.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Self-supervised Learning of Occlusion Aware Flow Guided 3D Geometry Perception with Adaptive Cross Weighted Loss from Monocular Videos.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jiaojiao Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guizhong Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03893">
                                        <div class="article-summary-box-inner">
                                            <span><p>Self-supervised deep learning-based 3D scene understanding methods can
overcome the difficulty of acquiring the densely labeled ground-truth and have
made a lot of advances. However, occlusions and moving objects are still some
of the major limitations. In this paper, we explore the learnable occlusion
aware optical flow guided self-supervised depth and camera pose estimation by
an adaptive cross weighted loss to address the above limitations. Firstly, we
explore to train the learnable occlusion mask fused optical flow network by an
occlusion-aware photometric loss with the temporally supplemental information
and backward-forward consistency of adjacent views. And then, we design an
adaptive cross-weighted loss between the depth-pose and optical flow loss of
the geometric and photometric error to distinguish the moving objects which
violate the static scene assumption. Our method shows promising results on
KITTI, Make3D, and Cityscapes datasets under multiple tasks. We also show good
generalization ability under a variety of challenging scenarios.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ FIFA: Fast Inference Approximation for Action Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1">Yaser Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Farha_Y/0/1/0/all/0/1">Yazan Abu Farha</a>, <a href="http://arxiv.org/find/cs/1/au:+Despinoy_F/0/1/0/all/0/1">Fabien Despinoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1">Gianpiero Francesca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03894">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce FIFA, a fast approximate inference method for action
segmentation and alignment. Unlike previous approaches, FIFA does not rely on
expensive dynamic programming for inference. Instead, it uses an approximate
differentiable energy function that can be minimized using gradient-descent.
FIFA is a general approach that can replace exact inference improving its speed
by more than 5 times while maintaining its performance. FIFA is an anytime
inference algorithm that provides a better speed vs. accuracy trade-off
compared to exact inference. We apply FIFA on top of state-of-the-art
approaches for weakly supervised action segmentation and alignment as well as
fully supervised action segmentation. FIFA achieves state-of-the-art results on
most metrics on two action segmentation datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unified Regularity Measures for Sample-wise Learning and Generalization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaoning Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yuanqi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuehu Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03913">
                                        <div class="article-summary-box-inner">
                                            <span><p>Fundamental machine learning theory shows that different samples contribute
unequally both in learning and testing processes. Contemporary studies on DNN
imply that such sample di?erence is rooted on the distribution of intrinsic
pattern information, namely sample regularity. Motivated by the recent
discovery on network memorization and generalization, we proposed a pair of
sample regularity measures for both processes with a formulation-consistent
representation. Specifically, cumulative binary training/generalizing loss
(CBTL/CBGL), the cumulative number of correct classi?cations of the
training/testing sample within training stage, is proposed to quantize the
stability in memorization-generalization process; while
forgetting/mal-generalizing events, i.e., the mis-classification of previously
learned or generalized sample, are utilized to represent the uncertainty of
sample regularity with respect to optimization dynamics. Experiments validated
the effectiveness and robustness of the proposed approaches for mini-batch SGD
optimization. Further applications on training/testing sample selection show
the proposed measures sharing the uni?ed computing procedure could benefit for
both tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ LatticeNet: Fast Spatio-Temporal Point Cloud Segmentation Using Permutohedral Lattices.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rosu_R/0/1/0/all/0/1">Radu Alexandru Rosu</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutt_P/0/1/0/all/0/1">Peer Sch&#xfc;tt</a>, <a href="http://arxiv.org/find/cs/1/au:+Quenzel_J/0/1/0/all/0/1">Jan Quenzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03917">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep convolutional neural networks (CNNs) have shown outstanding performance
in the task of semantically segmenting images. Applying the same methods on 3D
data still poses challenges due to the heavy memory requirements and the lack
of structured data. Here, we propose LatticeNet, a novel approach for 3D
semantic segmentation, which takes raw point clouds as input. A PointNet
describes the local geometry which we embed into a sparse permutohedral
lattice. The lattice allows for fast convolutions while keeping a low memory
footprint. Further, we introduce DeformSlice, a novel learned data-dependent
interpolation for projecting lattice features back onto the point cloud. We
present results of 3D segmentation on multiple datasets where our method
achieves state-of-the-art performance. We also extend and evaluate our network
for instance and dynamic object segmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Selective Light Field Refocusing for Camera Arrays Using Bokeh Rendering and Superresolution.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jungang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yulan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+An_W/0/1/0/all/0/1">Wei An</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03918">
                                        <div class="article-summary-box-inner">
                                            <span><p>Camera arrays provide spatial and angular information within a single
snapshot. With refocusing methods, focal planes can be altered after exposure.
In this letter, we propose a light field refocusing method to improve the
imaging quality of camera arrays. In our method, the disparity is first
estimated. Then, the unfocused region (bokeh) is rendered by using a
depth-based anisotropic filter. Finally, the refocused image is produced by a
reconstruction-based superresolution approach where the bokeh image is used as
a regularization term. Our method can selectively refocus images with focused
region being superresolved and bokeh being aesthetically rendered. Our method
also enables postadjustment of depth of field. We conduct experiments on both
public and self-developed datasets. Our method achieves superior visual
performance with acceptable computational cost as compared to other
state-of-the-art methods. Code is available at
https://github.com/YingqianWang/Selective-LF-Refocusing.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ FA-GAN: Fused Attentive Generative Adversarial Networks for MRI Image Super-Resolution.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Mingfeng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhi_M/0/1/0/all/0/1">Minghao Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Liying Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaocheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jucheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yongming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiahao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guang Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03920">
                                        <div class="article-summary-box-inner">
                                            <span><p>High-resolution magnetic resonance images can provide fine-grained anatomical
information, but acquiring such data requires a long scanning time. In this
paper, a framework called the Fused Attentive Generative Adversarial
Networks(FA-GAN) is proposed to generate the super-resolution MR image from
low-resolution magnetic resonance images, which can reduce the scanning time
effectively but with high resolution MR images. In the framework of the FA-GAN,
the local fusion feature block, consisting of different three-pass networks by
using different convolution kernels, is proposed to extract image features at
different scales. And the global feature fusion module, including the channel
attention module, the self-attention module, and the fusion operation, is
designed to enhance the important features of the MR image. Moreover, the
spectral normalization process is introduced to make the discriminator network
stable. 40 sets of 3D magnetic resonance images (each set of images contains
256 slices) are used to train the network, and 10 sets of images are used to
test the proposed method. The experimental results show that the PSNR and SSIM
values of the super-resolution magnetic resonance image generated by the
proposed FA-GAN method are higher than the state-of-the-art reconstruction
methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ 3D Human Reconstruction in the Wild with Collaborative Aerial Cameras.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ho_C/0/1/0/all/0/1">Cherie Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_A/0/1/0/all/0/1">Andrew Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Freeman_H/0/1/0/all/0/1">Harry Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_R/0/1/0/all/0/1">Rohan Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonatti_R/0/1/0/all/0/1">Rogerio Bonatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03936">
                                        <div class="article-summary-box-inner">
                                            <span><p>Aerial vehicles are revolutionizing applications that require capturing the
3D structure of dynamic targets in the wild, such as sports, medicine, and
entertainment. The core challenges in developing a motion-capture system that
operates in outdoors environments are: (1) 3D inference requires multiple
simultaneous viewpoints of the target, (2) occlusion caused by obstacles is
frequent when tracking moving targets, and (3) the camera and vehicle state
estimation is noisy. We present a real-time aerial system for multi-camera
control that can reconstruct human motions in natural environments without the
use of special-purpose markers. We develop a multi-robot coordination scheme
that maintains the optimal flight formation for target reconstruction quality
amongst obstacles. We provide studies evaluating system performance in
simulation, and validate real-world performance using two drones while a target
performs activities such as jogging and playing soccer. Supplementary video:
https://youtu.be/jxt91vx0cns
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ TriTransNet: RGB-D Salient Object Detection with a Triplet <span class="highlight_title">Transformer</span> Embedding Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhengzheng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1">Bin Tang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03990">
                                        <div class="article-summary-box-inner">
                                            <span><p>Salient object detection is the pixel-level dense prediction task which can
highlight the prominent object in the scene. Recently U-Net framework is widely
used, and continuous convolution and pooling operations generate multi-level
features which are complementary with each other. In view of the more
contribution of high-level features for the performance, we propose a triplet
transformer embedding module to enhance them by learning long-range
dependencies across layers. It is the first to use three transformer encoders
with shared weights to enhance multi-level features. By further designing scale
adjustment module to process the input, devising three-stream decoder to
process the output and attaching depth features to color features for the
multi-modal fusion, the proposed triplet transformer embedding network
(TriTransNet) achieves the state-of-the-art performance in RGB-D salient object
detection, and pushes the performance to a new level. Experimental results
demonstrate the effectiveness of the proposed modules and the competition of
TriTransNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Transductive Few-Shot Classification on the Oblique Manifold.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1">Guodong Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Huimin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhaohui Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuzhao Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04009">
                                        <div class="article-summary-box-inner">
                                            <span><p>Few-shot learning (FSL) attempts to learn with limited data. In this work, we
perform the feature extraction in the Euclidean space and the geodesic distance
metric on the Oblique Manifold (OM). Specially, for better feature extraction,
we propose a non-parametric Region Self-attention with Spatial Pyramid Pooling
(RSSPP), which realizes a trade-off between the generalization and the
discriminative ability of the single image feature. Then, we embed the feature
to OM as a point. Furthermore, we design an Oblique Distance-based Classifier
(ODC) that achieves classification in the tangent spaces which better
approximate OM locally by learnable tangency points. Finally, we introduce a
new method for parameters initialization and a novel loss function in the
transductive settings. Extensive experiments demonstrate the effectiveness of
our algorithm and it outperforms state-of-the-art methods on the popular
benchmarks: mini-ImageNet, tiered-ImageNet, and Caltech-UCSD Birds-200-2011
(CUB).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Dynamic Multi-Scale Loss Optimization for Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yihao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Juntao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Peng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianjiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1">Qi Feng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04014">
                                        <div class="article-summary-box-inner">
                                            <span><p>With the continuous improvement of the performance of object detectors via
advanced model architectures, imbalance problems in the training process have
received more attention. It is a common paradigm in object detection frameworks
to perform multi-scale detection. However, each scale is treated equally during
training. In this paper, we carefully study the objective imbalance of
multi-scale detector training. We argue that the loss in each scale level is
neither equally important nor independent. Different from the existing
solutions of setting multi-task weights, we dynamically optimize the loss
weight of each scale level in the training process. Specifically, we propose an
Adaptive Variance Weighting (AVW) to balance multi-scale loss according to the
statistical variance. Then we develop a novel Reinforcement Learning
Optimization (RLO) to decide the weighting scheme probabilistically during
training. The proposed dynamic methods make better utilization of multi-scale
training loss without extra computational complexity and learnable parameters
for backpropagation. Experiments show that our approaches can consistently
boost the performance over various baseline detectors on Pascal VOC and MS COCO
benchmark.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Deep Learning methods for automatic evaluation of delayed enhancement-MRI. The results of the EMIDEC challenge.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lalande_A/0/1/0/all/0/1">Alain Lalande</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhihao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pommier_T/0/1/0/all/0/1">Thibaut Pommier</a>, <a href="http://arxiv.org/find/cs/1/au:+Decourselle_T/0/1/0/all/0/1">Thomas Decourselle</a>, <a href="http://arxiv.org/find/cs/1/au:+Qayyum_A/0/1/0/all/0/1">Abdul Qayyum</a>, <a href="http://arxiv.org/find/cs/1/au:+Salomon_M/0/1/0/all/0/1">Michel Salomon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ginhac_D/0/1/0/all/0/1">Dominique Ginhac</a>, <a href="http://arxiv.org/find/cs/1/au:+Skandarani_Y/0/1/0/all/0/1">Youssef Skandarani</a>, <a href="http://arxiv.org/find/cs/1/au:+Boucher_A/0/1/0/all/0/1">Arnaud Boucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahim_K/0/1/0/all/0/1">Khawla Brahim</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruijne_M/0/1/0/all/0/1">Marleen de Bruijne</a>, <a href="http://arxiv.org/find/cs/1/au:+Camarasa_R/0/1/0/all/0/1">Robin Camarasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Correia_T/0/1/0/all/0/1">Teresa M. Correia</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xue Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Girum_K/0/1/0/all/0/1">Kibrom B. Girum</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennemuth_A/0/1/0/all/0/1">Anja Hennemuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Huellebrand_M/0/1/0/all/0/1">Markus Huellebrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_R/0/1/0/all/0/1">Raabid Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ivantsits_M/0/1/0/all/0/1">Matthias Ivantsits</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyer_C/0/1/0/all/0/1">Craig Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rishabh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jixi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsekos_N/0/1/0/all/0/1">Nikolaos V. Tsekos</a>, <a href="http://arxiv.org/find/cs/1/au:+Varela_M/0/1/0/all/0/1">Marta Varela</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiyue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hannu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuncheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1">Xiahai Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Couturier_R/0/1/0/all/0/1">Raphael Couturier</a>, <a href="http://arxiv.org/find/cs/1/au:+Meriaudeau_F/0/1/0/all/0/1">Fabrice Meriaudeau</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04016">
                                        <div class="article-summary-box-inner">
                                            <span><p>A key factor for assessing the state of the heart after myocardial infarction
(MI) is to measure whether the myocardium segment is viable after reperfusion
or revascularization therapy. Delayed enhancement-MRI or DE-MRI, which is
performed several minutes after injection of the contrast agent, provides high
contrast between viable and nonviable myocardium and is therefore a method of
choice to evaluate the extent of MI. To automatically assess myocardial status,
the results of the EMIDEC challenge that focused on this task are presented in
this paper. The challenge's main objectives were twofold. First, to evaluate if
deep learning methods can distinguish between normal and pathological cases.
Second, to automatically calculate the extent of myocardial infarction. The
publicly available database consists of 150 exams divided into 50 cases with
normal MRI after injection of a contrast agent and 100 cases with myocardial
infarction (and then with a hyperenhanced area on DE-MRI), whatever their
inclusion in the cardiac emergency department. Along with MRI, clinical
characteristics are also provided. The obtained results issued from several
works show that the automatic classification of an exam is a reachable task
(the best method providing an accuracy of 0.92), and the automatic segmentation
of the myocardium is possible. However, the segmentation of the diseased area
needs to be improved, mainly due to the small size of these areas and the lack
of contrast with the surrounding structures.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DRINet: A Dual-Representation Iterative Learning Network for Point Cloud Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Maosheng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuangjie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1">Tongyi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04023">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a novel and flexible architecture for point cloud segmentation
with dual-representation iterative learning. In point cloud processing,
different representations have their own pros and cons. Thus, finding suitable
ways to represent point cloud data structure while keeping its own internal
physical property such as permutation and scale-invariant is a fundamental
problem. Therefore, we propose our work, DRINet, which serves as the basic
network structure for dual-representation learning with great flexibility at
feature transferring and less computation cost, especially for large-scale
point clouds. DRINet mainly consists of two modules called Sparse Point-Voxel
Feature Extraction and Sparse Voxel-Point Feature Extraction. By utilizing
these two modules iteratively, features can be propagated between two different
representations. We further propose a novel multi-scale pooling layer for
pointwise locality learning to improve context information propagation. Our
network achieves state-of-the-art results for point cloud classification and
segmentation tasks on several datasets while maintaining high runtime
efficiency. For large-scale outdoor scenarios, our method outperforms
state-of-the-art methods with a real-time inference speed of 62ms per frame.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Image Retrieval on Real-life Images with <span class="highlight_title">Pre-train</span>ed <span class="highlight_title">Vision-and-Language</span> Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Opazo_C/0/1/0/all/0/1">Cristian Rodriguez-Opazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1">Damien Teney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04024">
                                        <div class="article-summary-box-inner">
                                            <span><p>We extend the task of composed image retrieval, where an input query consists
of an image and short textual description of how to modify the image. Existing
methods have only been applied to non-complex images within narrow domains,
such as fashion products, thereby limiting the scope of study on in-depth
visual reasoning in rich image and language contexts. To address this issue, we
collect the Compose Image Retrieval on Real-life images (CIRR) dataset, which
consists of over 36,000 pairs of crowd-sourced, open-domain images with
human-generated modifying text. To extend current methods to the open-domain,
we propose CIRPLANT, a transformer based model that leverages rich pre-trained
vision-and-language (V&amp;L) knowledge for modifying visual features conditioned
on natural language. Retrieval is then done by nearest neighbor lookup on the
modified features. We demonstrate that with a relatively simple architecture,
CIRPLANT outperforms existing methods on open-domain images, while matching
state-of-the-art accuracy on the existing narrow datasets, such as fashion.
Together with the release of CIRR, we believe this work will inspire further
research on composed image retrieval.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Tensor Yard: One-Shot Algorithm of Hardware-Friendly Tensor-Train Decomposition for Convolutional Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Taskynov_A/0/1/0/all/0/1">Anuar Taskynov</a>, <a href="http://arxiv.org/find/cs/1/au:+Korviakov_V/0/1/0/all/0/1">Vladimir Korviakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazurenko_I/0/1/0/all/0/1">Ivan Mazurenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yepan Xiong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04029">
                                        <div class="article-summary-box-inner">
                                            <span><p>Nowadays Deep Learning became widely used in many economic, technical and
scientific areas of human interest. It is clear that efficiency of solutions
based on Deep Neural Networks should consider not only quality metric for the
target task, but also latency and constraints of target platform design should
be taken into account. In this paper we present novel hardware-friendly
Tensor-Train decomposition implementation for Convolutional Neural Networks
together with Tensor Yard - one-shot training algorithm which optimizes an
order of decomposition of network layers. These ideas allow to accelerate
ResNet models on Ascend 310 NPU devices without significant loss of accuracy.
For example we accelerate ResNet-101 by 14.6% with drop by 0.5 of top-1
ImageNet accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Two-stream Convolutional Networks for Multi-frame Face Anti-spoofing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuoyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Cheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1">Xiya Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifeng Zhang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04032">
                                        <div class="article-summary-box-inner">
                                            <span><p>Face anti-spoofing is an important task to protect the security of face
recognition. Most of previous work either struggle to capture discriminative
and generalizable feature or rely on auxiliary information which is unavailable
for most of industrial product. Inspired by the video classification work, we
propose an efficient two-stream model to capture the key differences between
live and spoof faces, which takes multi-frames and RGB difference as input
respectively. Feature pyramid modules with two opposite fusion directions and
pyramid pooling modules are applied to enhance feature representation. We
evaluate the proposed method on the datasets of Siw, Oulu-NPU, CASIA-MFSD and
Replay-Attack. The results show that our model achieves the state-of-the-art
results on most of datasets' protocol with much less parameter size.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Detecting Visual Design Principles in Art and Architecture through Deep Convolutional Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Demir_G/0/1/0/all/0/1">Gozdenur Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Cekmis_A/0/1/0/all/0/1">Asli Cekmis</a>, <a href="http://arxiv.org/find/cs/1/au:+Yesilkaynak_V/0/1/0/all/0/1">Vahit Bugra Yesilkaynak</a>, <a href="http://arxiv.org/find/cs/1/au:+Unal_G/0/1/0/all/0/1">Gozde Unal</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04048">
                                        <div class="article-summary-box-inner">
                                            <span><p>Visual design is associated with the use of some basic design elements and
principles. Those are applied by the designers in the various disciplines for
aesthetic purposes, relying on an intuitive and subjective process. Thus,
numerical analysis of design visuals and disclosure of the aesthetic value
embedded in them are considered as hard. However, it has become possible with
emerging artificial intelligence technologies. This research aims at a neural
network model, which recognizes and classifies the design principles over
different domains. The domains include artwork produced since the late 20th
century; professional photos; and facade pictures of contemporary buildings.
The data collection and curation processes, including the production of
computationally-based synthetic dataset, is genuine. The proposed model learns
from the knowledge of myriads of original designs, by capturing the underlying
shared patterns. It is expected to consolidate design processes by providing an
aesthetic evaluation of the visual compositions with objectivity.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Automatic Image Transformation for Inducing Affect.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Afsheen Rafaqat Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohsen Ali</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1707.08148">
                                        <div class="article-summary-box-inner">
                                            <span><p>Current image transformation and recoloring algorithms try to introduce
artistic effects in the photographed images, based on user input of target
image(s) or selection of pre-designed filters. These manipulations, although
intended to enhance the impact of an image on the viewer, do not include the
option of image transformation by specifying the affect information. In this
paper we present an automatic image-transformation method that transforms the
source image such that it can induce an emotional affect on the viewer, as
desired by the user. Our proposed novel image emotion transfer algorithm does
not require a user-specified target image. The proposed algorithm uses features
extracted from top layers of deep convolutional neural network and the
user-specified emotion distribution to select multiple target images from an
image database for color transformation, such that the resultant image has
desired emotional impact. Our method can handle more diverse set of photographs
than the previous methods. We conducted a detailed user study showing the
effectiveness of our proposed method. A discussion and reasoning of failure
cases has also been provided, indicating inherent limitation of color-transfer
based methods in the use of emotion assignment.
</p>
<p>Project Page: <a href="http://im.itu.edu.pk/affective-image-transfer/">this http URL</a>
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ BAOD: Budget-Aware Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Pardo_A/0/1/0/all/0/1">Alejandro Pardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengmeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1">Ali Thabet</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbelaez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.05443">
                                        <div class="article-summary-box-inner">
                                            <span><p>We study the problem of object detection from a novel perspective in which
annotation budget constraints are taken into consideration, appropriately
coined Budget Aware Object Detection (BAOD). When provided with a fixed budget,
we propose a strategy for building a diverse and informative dataset that can
be used to optimally train a robust detector. We investigate both optimization
and learning-based methods to sample which images to annotate and what type of
annotation (strongly or weakly supervised) to annotate them with. We adopt a
hybrid supervised learning framework to train the object detector from both
these types of annotation. We conduct a comprehensive empirical study showing
that a handcrafted optimization method outperforms other selection techniques
including random sampling, uncertainty sampling and active learning. By
combining an optimal image/annotation selection scheme with hybrid supervised
learning to solve the BAOD problem, we show that one can achieve the
performance of a strongly supervised detector on PASCAL-VOC 2007 while saving
12.8% of its original annotation budget. Furthermore, when $100\%$ of the
budget is used, it surpasses this performance by 2.0 mAP percentage points.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Persistence Curves: A canonical framework for summarizing persistence diagrams.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yu-Min Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawson_A/0/1/0/all/0/1">Austin Lawson</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.07768">
                                        <div class="article-summary-box-inner">
                                            <span><p>Persistence diagrams are one of the main tools in the field of Topological
Data Analysis (TDA). They contain fruitful information about the shape of data.
The use of machine learning algorithms on the space of persistence diagrams
proves to be challenging as the space lacks an inner product. For that reason,
transforming these diagrams in a way that is compatible with machine learning
is an important topic currently researched in TDA. In this paper, our main
contribution consists of three components. First, we develop a general and
unifying framework of vectorizing diagrams that we call the \textit{Persistence
Curves} (PCs), and show that several well-known summaries, such as Persistence
Landscapes, fall under the PC framework. Second, we propose several new
summaries based on PC framework and provide a theoretical foundation for their
stability analysis. Finally, we apply proposed PCs to two
applications---texture classification and determining the parameters of a
discrete dynamical system; their performances are competitive with other TDA
methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Constrained Nonnegative Matrix Factorization for Blind Hyperspectral Unmixing incorporating Endmember Independence.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Ekanayake_E/0/1/0/all/0/1">E.M.M.B. Ekanayake</a>, <a href="http://arxiv.org/find/eess/1/au:+Weerasooriya_H/0/1/0/all/0/1">H.M.H.K. Weerasooriya</a>, <a href="http://arxiv.org/find/eess/1/au:+Ranasinghe_D/0/1/0/all/0/1">D.Y.L. Ranasinghe</a>, <a href="http://arxiv.org/find/eess/1/au:+Herath_S/0/1/0/all/0/1">S. Herath</a>, <a href="http://arxiv.org/find/eess/1/au:+Rathnayake_B/0/1/0/all/0/1">B. Rathnayake</a>, <a href="http://arxiv.org/find/eess/1/au:+Godaliyadda_G/0/1/0/all/0/1">G.M.R.I. Godaliyadda</a>, <a href="http://arxiv.org/find/eess/1/au:+Ekanayake_M/0/1/0/all/0/1">M.P.B. Ekanayake</a>, <a href="http://arxiv.org/find/eess/1/au:+Herath_H/0/1/0/all/0/1">H.M.V.R. Herath</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.01041">
                                        <div class="article-summary-box-inner">
                                            <span><p>Hyperspectral unmixing (HU) has become an important technique in exploiting
hyperspectral data since it decomposes a mixed pixel into a collection of
endmembers weighted by fractional abundances. The endmembers of a hyperspectral
image (HSI) are more likely to be generated by independent sources and be mixed
in a macroscopic degree before arriving at the sensor element of the imaging
spectrometer as mixed spectra. Over the past few decades, many attempts have
focused on imposing auxiliary constraints on the conventional nonnegative
matrix factorization (NMF) framework in order to effectively unmix these mixed
spectra. As a promising step toward finding an optimum constraint to extract
endmembers, this paper presents a novel blind HU algorithm, referred to as
Kurtosis-based Smooth Nonnegative Matrix Factorization (KbSNMF) which
incorporates a novel constraint based on the statistical independence of the
probability density functions of endmember spectra. Imposing this constraint on
the conventional NMF framework promotes the extraction of independent
endmembers while further enhancing the parts-based representation of data.
Experiments conducted on diverse synthetic HSI datasets (with numerous numbers
of endmembers, spectral bands, pixels, and noise levels) and three standard
real HSI datasets demonstrate the validity of the proposed KbSNMF algorithm
compared to several state-of-the-art NMF-based HU baselines. The proposed
algorithm exhibits superior performance especially in terms of extracting
endmember spectra from hyperspectral data; therefore, it could uplift the
performance of recent deep learning HU methods which utilize the endmember
spectra as supervisory input data for abundance extraction.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On the Convergence Rate of Projected Gradient Descent for a Back-Projection based Objective.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Tirer_T/0/1/0/all/0/1">Tom Tirer</a>, <a href="http://arxiv.org/find/math/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00959">
                                        <div class="article-summary-box-inner">
                                            <span><p>Ill-posed linear inverse problems appear in many scientific setups, and are
typically addressed by solving optimization problems, which are composed of
data fidelity and prior terms. Recently, several works have considered a
back-projection (BP) based fidelity term as an alternative to the common least
squares (LS), and demonstrated excellent results for popular inverse problems.
These works have also empirically shown that using the BP term, rather than the
LS term, requires fewer iterations of optimization algorithms. In this paper,
we examine the convergence rate of the projected gradient descent (PGD)
algorithm for the BP objective. Our analysis allows to identify an inherent
source for its faster convergence compared to using the LS objective, while
making only mild assumptions. We also analyze the more general proximal
gradient method under a relaxed contraction condition on the proximal mapping
of the prior. This analysis further highlights the advantage of BP when the
linear measurement operator is badly conditioned. Numerical experiments with
both $\ell_1$-norm and GAN-based priors corroborate our theoretical results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ AlphaGAN: Fully Differentiable Architecture Search for Generative Adversarial Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuesong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1">Guinan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09134">
                                        <div class="article-summary-box-inner">
                                            <span><p>Generative Adversarial Networks (GANs) are formulated as minimax game
problems, whereby generators attempt to approach real data distributions by
virtue of adversarial learning against discriminators. The intrinsic problem
complexity poses the challenge to enhance the performance of generative
networks. In this work, we aim to boost model learning from the perspective of
network architectures, by incorporating recent progress on automated
architecture search into GANs. To this end, we propose a fully differentiable
search framework for generative adversarial networks, dubbed alphaGAN. The
searching process is formalized as solving a bi-level minimax optimization
problem, in which the outer-level objective aims for seeking a suitable network
architecture towards pure Nash Equilibrium conditioned on the generator and the
discriminator network parameters optimized with a traditional GAN loss in the
inner level. The entire optimization performs a first-order method by
alternately minimizing the two-level objective in a fully differentiable
manner, enabling architecture search to be completed in an enormous search
space. Extensive experiments on CIFAR-10 and STL-10 datasets show that our
algorithm can obtain high-performing architectures only with 3-GPU hours on a
single GPU in the search space comprised of approximate 2 ? 1011 possible
configurations. We also provide a comprehensive analysis on the behavior of the
searching process and the properties of searched architectures, which would
benefit further research on architectures for generative models. Pretrained
models and codes are available at https://github.com/yuesongtian/AlphaGAN.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ A Survey on Negative Transfer.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lingfei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00909">
                                        <div class="article-summary-box-inner">
                                            <span><p>Transfer learning (TL) utilizes data or knowledge from one or more source
domains to facilitate the learning in a target domain. It is particularly
useful when the target domain has very few or no labeled data, due to
annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of
TL is not always guaranteed. Negative transfer (NT), i.e., leveraging source
domain data/knowledge undesirably reduces the learning performance in the
target domain, has been a long-standing and challenging problem in TL. Various
approaches have been proposed in the literature to handle it. However, there
does not exist a systematic survey on the formulation of NT, the factors
leading to NT, and the algorithms that mitigate NT. This paper fills this gap,
by first introducing the definition of NT and its factors, then reviewing about
fifty representative approaches for overcoming NT, according to four
categories: secure transfer, domain similarity estimation, distant transfer,
and NT mitigation. NT in related fields, e.g., multi-task learning, lifelong
learning, and adversarial attacks, are also discussed.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DanceIt: Music-inspired Dancing Video Synthesis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yifan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08027">
                                        <div class="article-summary-box-inner">
                                            <span><p>Close your eyes and listen to music, one can easily imagine an actor dancing
rhythmically along with the music. These dance movements are usually made up of
dance movements you have seen before. In this paper, we propose to reproduce
such an inherent capability of the human-being within a computer vision system.
The proposed system consists of three modules. To explore the relationship
between music and dance movements, we propose a cross-modal alignment module
that focuses on dancing video clips, accompanied on pre-designed music, to
learn a system that can judge the consistency between the visual features of
pose sequences and the acoustic features of music. The learned model is then
used in the imagination module to select a pose sequence for the given music.
Such pose sequence selected from the music, however, is usually discontinuous.
To solve this problem, in the spatial-temporal alignment module we develop a
spatial alignment algorithm based on the tendency and periodicity of dance
movements to predict dance movements between discontinuous fragments. In
addition, the selected pose sequence is often misaligned with the music beat.
To solve this problem, we further develop a temporal alignment algorithm to
align the rhythm of music and dance. Finally, the processed pose sequence is
used to synthesize realistic dancing videos in the imagination module. The
generated dancing videos match the content and rhythm of the music.
Experimental results and subjective evaluations show that the proposed approach
can perform the function of generating promising dancing videos by inputting
music.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Densely Guided Knowledge <span class="highlight_title">Distillation</span> using Multiple Teacher Assistants.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Son_W/0/1/0/all/0/1">Wonchul Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_J/0/1/0/all/0/1">Jaemin Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Junyong Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonjun Hwang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08825">
                                        <div class="article-summary-box-inner">
                                            <span><p>With the success of deep neural networks, knowledge distillation which guides
the learning of a small student network from a large teacher network is being
actively studied for model compression and transfer learning. However, few
studies have been performed to resolve the poor learning issue of the student
network when the student and teacher model sizes significantly differ. In this
paper, we propose a densely guided knowledge distillation using multiple
teacher assistants that gradually decreases the model size to efficiently
bridge the large gap between the teacher and student networks. To stimulate
more efficient learning of the student network, we guide each teacher assistant
to every other smaller teacher assistants iteratively. Specifically, when
teaching a smaller teacher assistant at the next step, the existing larger
teacher assistants from the previous step are used as well as the teacher
network. Moreover, we design stochastic teaching where, for each mini-batch, a
teacher or teacher assistants are randomly dropped. This acts as a regularizer
to improve the efficiency of teaching of the student network. Thus, the student
can always learn salient distilled knowledge from the multiple sources. We
verified the effectiveness of the proposed method for a classification task
using CIFAR-10, CIFAR-100, and ImageNet. We also achieved significant
performance improvements with various backbone architectures such as ResNet,
WideResNet, and VGG.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1">Lalith Bharadwaj B</a>, <a href="http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1">Rohit Boddeda</a>, <a href="http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1">Sai Vardhan K</a>, <a href="http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1">Madhu G</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05690">
                                        <div class="article-summary-box-inner">
                                            <span><p>The issue of COVID-19, increasing with a massive mortality rate. This led to
the WHO declaring it as a pandemic. In this situation, it is crucial to perform
efficient and fast diagnosis. The reverse transcript polymerase chain reaction
(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is
time-consuming and instead chest CT (or Chest X-ray) can be used for a fast and
accurate diagnosis. Automated diagnosis is considered to be important as it
reduces human effort and provides accurate and low-cost tests. The
contributions of our research are three-fold. First, it is aimed to analyse the
behaviour and performance of variant vision models ranging from Inception to
NAS networks with the appropriate fine-tuning procedure. Second, the behaviour
of these models is visually analysed by plotting CAMs for individual networks
and determining classification performance with AUCROC curves. Thirdly, stacked
ensembles techniques are imparted to provide higher generalisation on combining
the fine-tuned models, in which six ensemble neural networks are designed by
combining the existing fine-tuned networks. Implying these stacked ensembles
provides a great generalization to the models. The ensemble model designed by
combining all the fine-tuned networks obtained a state-of-the-art accuracy
score of 99.17%. The precision and recall for the COVID-19 class are 99.99% and
89.79% respectively, which resembles the robustness of the stacked ensembles.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Minimizing Labeling Effort for Tree Skeleton Segmentation using an Automated Iterative Training Methodology.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Granland_K/0/1/0/all/0/1">Keenan Granland</a>, <a href="http://arxiv.org/find/cs/1/au:+Newbury_R/0/1/0/all/0/1">Rhys Newbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Ting_D/0/1/0/all/0/1">David Ting</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chao Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08296">
                                        <div class="article-summary-box-inner">
                                            <span><p>Training of convolutional neural networks for semantic segmentation requires
accurate pixel-wise labeling which requires large amounts of human effort. The
human-in-the-loop method reduces labeling effort; however, it requires human
intervention for each image. This paper describes a general iterative training
methodology for semantic segmentation, Automating-the-Loop. This aims to
replicate the manual adjustments of the human-in-the-loop method with an
automated process, hence, drastically reducing labeling effort. Using the
application of detecting partially occluded apple tree segmentation, we compare
manually labeled annotations, self-training, human-in-the-loop, and
Automating-the-Loop methods in both the quality of the trained convolutional
neural networks, and the effort needed to create them. The convolutional neural
network (U-Net) performance is analyzed using traditional metrics and a new
metric, Complete Grid Scan, which promotes connectivity and low noise. It is
shown that in our application, the new Automating-the-Loop method greatly
reduces the labeling effort while producing comparable performance to both
human-in-the-loop and complete manual labeling methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Cascaded Refinement Network for Point Cloud Completion with Self-supervision.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1">Marcelo H Ang Jr</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gim Hee Lee</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08719">
                                        <div class="article-summary-box-inner">
                                            <span><p>Point clouds are often sparse and incomplete, which imposes difficulties for
real-world applications. Existing shape completion methods tend to generate
rough shapes without fine-grained details. Considering this, we introduce a
two-branch network for shape completion. The first branch is a cascaded shape
completion sub-network to synthesize complete objects, where we propose to use
the partial input together with the coarse output to preserve the object
details during the dense point reconstruction. The second branch is an
auto-encoder to reconstruct the original partial input. The two branches share
a same feature extractor to learn an accurate global feature for shape
completion. Furthermore, we propose two strategies to enable the training of
our network when ground truth data are not available. This is to mitigate the
dependence of existing approaches on large amounts of ground truth training
data that are often difficult to obtain in real-world applications.
Additionally, our proposed strategies are also able to improve the
reconstruction quality for fully supervised learning. We verify our approach in
self-supervised, semi-supervised and fully supervised settings with superior
performances. Quantitative and qualitative results on different datasets
demonstrate that our method achieves more realistic outputs than
state-of-the-art approaches on the point cloud completion task.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ MGIC: Multigrid-in-Channels Neural Network Architectures.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Eliasof_M/0/1/0/all/0/1">Moshe Eliasof</a>, <a href="http://arxiv.org/find/cs/1/au:+Ephrath_J/0/1/0/all/0/1">Jonathan Ephrath</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruthotto_L/0/1/0/all/0/1">Lars Ruthotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Treister_E/0/1/0/all/0/1">Eran Treister</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09128">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a multigrid-in-channels (MGIC) approach that tackles the quadratic
growth of the number of parameters with respect to the number of channels in
standard convolutional neural networks (CNNs). Thereby our approach addresses
the redundancy in CNNs that is also exposed by the recent success of
lightweight CNNs. Lightweight CNNs can achieve comparable accuracy to standard
CNNs with fewer parameters; however, the number of weights still scales
quadratically with the CNN's width. Our MGIC architectures replace each CNN
block with an MGIC counterpart that utilizes a hierarchy of nested grouped
convolutions of small group size to address this.
</p>
<p>Hence, our proposed architectures scale linearly with respect to the
network's width while retaining full coupling of the channels as in standard
CNNs.
</p>
<p>Our extensive experiments on image classification, segmentation, and point
cloud classification show that applying this strategy to different
architectures like ResNet and MobileNetV3 reduces the number of parameters
while obtaining similar or better accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Pedestrian Trajectory Prediction using Context-Augmented <span class="highlight_title">Transformer</span> Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Saleh_K/0/1/0/all/0/1">Khaled Saleh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01757">
                                        <div class="article-summary-box-inner">
                                            <span><p>Forecasting the trajectory of pedestrians in shared urban traffic
environments is still considered one of the challenging problems facing the
development of autonomous vehicles (AVs). In the literature, this problem is
often tackled using recurrent neural networks (RNNs). Despite the powerful
capabilities of RNNs in capturing the temporal dependency in the pedestrians'
motion trajectories, they were argued to be challenged when dealing with longer
sequential data. Thus, in this work, we are introducing a framework based on
the transformer networks that were shown recently to be more efficient and
outperformed RNNs in many sequential-based tasks. We relied on a fusion of the
past positional information, agent interactions information and scene physical
semantics information as an input to our framework in order to provide a robust
trajectory prediction of pedestrians. We have evaluated our framework on two
real-life datasets of pedestrians in shared urban traffic environments and it
has outperformed the compared baseline approaches in both short-term and
long-term prediction horizons.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ChartPointFlow for Topology-Aware 3D Point Cloud Generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kimura_T/0/1/0/all/0/1">Takumi Kimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsubara_T/0/1/0/all/0/1">Takashi Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_K/0/1/0/all/0/1">Kuniaki Uehara</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02346">
                                        <div class="article-summary-box-inner">
                                            <span><p>A point cloud serves as a representation of the surface of a
three-dimensional (3D) shape. Deep generative models have been adapted to model
their variations typically using a map from a ball-like set of latent
variables. However, previous approaches did not pay much attention to the
topological structure of a point cloud, despite that a continuous map cannot
express the varying numbers of holes and intersections. Moreover, a point cloud
is often composed of multiple subparts, and it is also difficult to express. In
this study, we propose ChartPointFlow, a flow-based generative model with
multiple latent labels for 3D point clouds. Each label is assigned to points in
an unsupervised manner. Then, a map conditioned on a label is assigned to a
continuous subset of a point cloud, similar to a chart of a manifold. This
enables our proposed model to preserve the topological structure with clear
boundaries, whereas previous approaches tend to generate blurry point clouds
and fail to generate holes. The experimental results demonstrate that
ChartPointFlow achieves state-of-the-art performance in terms of generation and
reconstruction compared with other point cloud generators. Moreover,
ChartPointFlow divides an object into semantic subparts using charts, and it
demonstrates superior performance in case of unsupervised segmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Bifold and Semantic Reasoning for Pedestrian Behavior Prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rasouli_A/0/1/0/all/0/1">Amir Rasouli</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohani_M/0/1/0/all/0/1">Mohsen Rohani</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jun Luo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03298">
                                        <div class="article-summary-box-inner">
                                            <span><p>Pedestrian behavior prediction is one of the major challenges for intelligent
driving systems. Pedestrians often exhibit complex behaviors influenced by
various contextual elements. To address this problem, we propose BiPed, a
multitask learning framework that simultaneously predicts trajectories and
actions of pedestrians by relying on multimodal data. Our method benefits from
1) a bifold encoding approach where different data modalities are processed
independently allowing them to develop their own representations, and jointly
to produce a representation for all modalities using shared parameters; 2) a
novel interaction modeling technique that relies on categorical semantic
parsing of the scenes to capture interactions between target pedestrians and
their surroundings; and 3) a bifold prediction mechanism that uses both
independent and shared decoding of multimodal representations. Using public
pedestrian behavior benchmark datasets for driving, PIE and JAAD, we highlight
the benefits of the proposed method for behavior prediction and show that our
model achieves state-of-the-art performance and improves trajectory and action
prediction by up to 22% and 9% respectively. We further investigate the
contributions of the proposed reasoning techniques via extensive ablation
studies.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ViNet: Pushing the limits of Visual Modality for Audio-Visual Saliency Prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Samyak Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Yarlagadda_P/0/1/0/all/0/1">Pradeep Yarlagadda</a>, <a href="http://arxiv.org/find/cs/1/au:+Jyoti_S/0/1/0/all/0/1">Shreyank Jyoti</a>, <a href="http://arxiv.org/find/cs/1/au:+Karthik_S/0/1/0/all/0/1">Shyamgopal Karthik</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_R/0/1/0/all/0/1">Ramanathan Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhi_V/0/1/0/all/0/1">Vineet Gandhi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06170">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose the ViNet architecture for audio-visual saliency prediction. ViNet
is a fully convolutional encoder-decoder architecture. The encoder uses visual
features from a network trained for action recognition, and the decoder infers
a saliency map via trilinear interpolation and 3D convolutions, combining
features from multiple hierarchies. The overall architecture of ViNet is
conceptually simple; it is causal and runs in real-time (60 fps). ViNet does
not use audio as input and still outperforms the state-of-the-art audio-visual
saliency prediction models on nine different datasets (three visual-only and
six audio-visual datasets). ViNet also surpasses human performance on the CC,
SIM and AUC metrics for the AVE dataset, and to our knowledge, it is the first
network to do so. We also explore a variation of ViNet architecture by
augmenting audio features into the decoder. To our surprise, upon sufficient
training, the network becomes agnostic to the input audio and provides the same
output irrespective of the input. Interestingly, we also observe similar
behaviour in the previous state-of-the-art models \cite{tsiami2020stavis} for
audio-visual saliency prediction. Our findings contrast with previous works on
deep learning-based audio-visual saliency prediction, suggesting a clear avenue
for future explorations incorporating audio in a more effective manner. The
code and pre-trained models are available at
https://github.com/samyak0210/ViNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Fast Monocular Hand Pose Estimation on Embedded Systems.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1">Shan An</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiajie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1">Dong Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Haogang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsintotas_K/0/1/0/all/0/1">Konstantinos A. Tsintotas</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07067">
                                        <div class="article-summary-box-inner">
                                            <span><p>Hand pose estimation is a fundamental task in many human-robot
interaction-related applications. However, previous approaches suffer from
unsatisfying hand landmark predictions in real-world scenes and high
computation burden. In this paper, we propose a fast and accurate framework for
hand pose estimation, dubbed as "FastHand". Using a lightweight encoder-decoder
network architecture, FastHand fulfills the requirements of practical
applications running on embedded devices. The encoder consists of deep layers
with a small number of parameters, while the decoder makes use of spatial
location information to obtain more accurate results. The evaluation took place
on two publicly available datasets demonstrating the improved performance of
the proposed pipeline compared to other state-of-the-art approaches. FastHand
offers high accuracy scores while reaching a speed of 25 frames per second on
an NVIDIA Jetson TX2 graphics processing unit.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ BiconNet: An Edge-preserved Connectivity-based Approach for Salient Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziyun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltanian_Zadeh_S/0/1/0/all/0/1">Somayyeh Soltanian-Zadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Farsiu_S/0/1/0/all/0/1">Sina Farsiu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00334">
                                        <div class="article-summary-box-inner">
                                            <span><p>Salient object detection (SOD) is viewed as a pixel-wise saliency modeling
task by traditional deep learning-based methods. A limitation of current SOD
models is insufficient utilization of inter-pixel information, which usually
results in imperfect segmentation near edge regions and low spatial coherence.
As we demonstrate, using a saliency mask as the only label is suboptimal. To
address this limitation, we propose a connectivity-based approach called
bilateral connectivity network (BiconNet), which uses connectivity masks
together with saliency masks as labels for effective modeling of inter-pixel
relationships and object saliency. Moreover, we propose a bilateral voting
module to enhance the output connectivity map, and a novel edge feature
enhancement method that efficiently utilizes edge-specific features. Through
comprehensive experiments on five benchmark datasets, we demonstrate that our
proposed method can be plugged into any existing state-of-the-art
saliency-based SOD framework to improve its performance with negligible
parameter increase.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Adaptive Consistency Regularization for Semi-Supervised Transfer Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xingjian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Cheng-Zhong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02193">
                                        <div class="article-summary-box-inner">
                                            <span><p>While recent studies on semi-supervised learning have shown remarkable
progress in leveraging both labeled and unlabeled data, most of them presume a
basic setting of the model is randomly initialized. In this work, we consider
semi-supervised learning and transfer learning jointly, leading to a more
practical and competitive paradigm that can utilize both powerful pre-trained
models from source domain as well as labeled/unlabeled data in the target
domain. To better exploit the value of both pre-trained weights and unlabeled
target examples, we introduce adaptive consistency regularization that consists
of two complementary components: Adaptive Knowledge Consistency (AKC) on the
examples between the source and target model, and Adaptive Representation
Consistency (ARC) on the target model between labeled and unlabeled examples.
Examples involved in the consistency regularization are adaptively selected
according to their potential contributions to the target task. We conduct
extensive experiments on popular benchmarks including CIFAR-10, CUB-200, and
MURA, by fine-tuning the ImageNet pre-trained ResNet-50 model. Results show
that our proposed adaptive consistency regularization outperforms
state-of-the-art semi-supervised learning techniques such as Pseudo Label, Mean
Teacher, and FixMatch. Moreover, our algorithm is orthogonal to existing
methods and thus able to gain additional improvements on top of MixMatch and
FixMatch. Our code is available at
https://github.com/SHI-Labs/Semi-Supervised-Transfer-Learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Convolution Neural Network Hyperparameter Optimization Using Simplified Swarm Optimization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yeh_W/0/1/0/all/0/1">Wei-Chang Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yi-Ping Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yun-Chia Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chyh-Ming Lai</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03995">
                                        <div class="article-summary-box-inner">
                                            <span><p>Convolutional neural networks (CNNs) are widely used in image recognition.
Numerous CNN models, such as LeNet, AlexNet, VGG, ResNet, and GoogLeNet, have
been proposed by increasing the number of layers, to improve the performance of
CNNs. However, performance deteriorates beyond a certain number of layers.
Hence, hyperparameter optimisation is a more efficient way to improve CNNs. To
validate this concept, a new algorithm based on simplified swarm optimisation
is proposed to optimise the hyperparameters of the simplest CNN model, which is
LeNet. The results of experiments conducted on the MNIST, Fashion MNIST, and
Cifar10 datasets showed that the accuracy of the proposed algorithm is higher
than the original LeNet model and PSO-LeNet and that it has a high potential to
be extended to more complicated models, such as AlexNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Practical Relative Order Attack in Deep Ranking.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05248">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent studies unveil the vulnerabilities of deep ranking models, where an
imperceptible perturbation can trigger dramatic changes in the ranking result.
While previous attempts focus on manipulating absolute ranks of certain
candidates, the possibility of adjusting their relative order remains
under-explored. In this paper, we formulate a new adversarial attack against
deep ranking systems, i.e., the Order Attack, which covertly alters the
relative order among a selected set of candidates according to an
attacker-specified permutation, with limited interference to other unrelated
candidates. Specifically, it is formulated as a triplet-style loss imposing an
inequality chain reflecting the specified permutation. However, direct
optimization of such white-box objective is infeasible in a real-world attack
scenario due to various black-box limitations. To cope with them, we propose a
Short-range Ranking Correlation metric as a surrogate objective for black-box
Order Attack to approximate the white-box method. The Order Attack is evaluated
on the Fashion-MNIST and Stanford-Online-Products datasets under both white-box
and black-box threat models. The black-box attack is also successfully
implemented on a major e-commerce platform. Comprehensive experimental
evaluations demonstrate the effectiveness of the proposed methods, revealing a
new type of ranking model vulnerability.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Re-energizing Domain Discriminator with Sample Relabeling for Adversarial Domain Adaptation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Cuiling Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11661">
                                        <div class="article-summary-box-inner">
                                            <span><p>Many unsupervised domain adaptation (UDA) methods exploit domain adversarial
training to align the features to reduce domain gap, where a feature extractor
is trained to fool a domain discriminator in order to have aligned feature
distributions. The discrimination capability of the domain classifier w.r.t the
increasingly aligned feature distributions deteriorates as training goes on,
thus cannot effectively further drive the training of feature extractor. In
this work, we propose an efficient optimization strategy named Re-enforceable
Adversarial Domain Adaptation (RADA) which aims to re-energize the domain
discriminator during the training by using dynamic domain labels. Particularly,
we relabel the well aligned target domain samples as source domain samples on
the fly. Such relabeling makes the less separable distributions more separable,
and thus leads to a more powerful domain classifier w.r.t. the new data
distributions, which in turn further drives feature alignment. Extensive
experiments on multiple UDA benchmarks demonstrate the effectiveness and
superiority of our RADA.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On Exposing the Challenging Long Tail in Future Prediction of Traffic Actors.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Makansi_O/0/1/0/all/0/1">Osama Makansi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicek_O/0/1/0/all/0/1">&#xd6;zg&#xfc;n Cicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Marrakchi_Y/0/1/0/all/0/1">Yassine Marrakchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1">Thomas Brox</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12474">
                                        <div class="article-summary-box-inner">
                                            <span><p>Predicting the states of dynamic traffic actors into the future is important
for autonomous systems to operate safelyand efficiently. Remarkably, the most
critical scenarios aremuch less frequent and more complex than the
uncriticalones. Therefore, uncritical cases dominate the prediction. In this
paper, we address specifically the challenging scenarios at the long tail of
the dataset distribution. Our analysis shows that the common losses tend to
place challenging cases suboptimally in the embedding space. As a consequence,
we propose to supplement the usual loss with aloss that places challenging
cases closer to each other. This triggers sharing information among challenging
cases andlearning specific predictive features. We show on four public datasets
that this leads to improved performance on the challenging scenarios while the
overall performance stays stable. The approach is agnostic w.r.t. the used
network architecture, input modality or viewpoint, and can be integrated into
existing solutions easily. Code is available at
https://github.com/lmb-freiburg/Contrastive-Future-Trajectory-Prediction
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Mining Latent Classes for Few-shot Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lihe Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_W/0/1/0/all/0/1">Wei Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lei Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yinghuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15402">
                                        <div class="article-summary-box-inner">
                                            <span><p>Few-shot segmentation (FSS) aims to segment unseen classes given only a few
annotated samples. Existing methods suffer the problem of feature undermining,
i.e. potential novel classes are treated as background during training phase.
Our method aims to alleviate this problem and enhance the feature embedding on
latent novel classes. In our work, we propose a novel joint-training framework.
Based on conventional episodic training on support-query pairs, we add an
additional mining branch that exploits latent novel classes via transferable
sub-clusters, and a new rectification technique on both background and
foreground categories to enforce more stable prototypes. Over and above that,
our transferable sub-cluster has the ability to leverage extra unlabeled data
for further feature enhancement. Extensive experiments on two FSS benchmarks
demonstrate that our method outperforms previous state-of-the-art by a large
margin of 3.7% mIOU on PASCAL-5i and 7.0% mIOU on COCO-20i at the cost of 74%
fewer parameters and 2.5x faster inference speed. The source code is available
at https://github.com/LiheYoung/MiningFSS.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Physics-based Differentiable Depth Sensor Simulation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Planche_B/0/1/0/all/0/1">Benjamin Planche</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rajat Vikram Singh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16563">
                                        <div class="article-summary-box-inner">
                                            <span><p>Gradient-based algorithms are crucial to modern computer-vision and graphics
applications, enabling learning-based optimization and inverse problems. For
example, photorealistic differentiable rendering pipelines for color images
have been proven highly valuable to applications aiming to map 2D and 3D
domains. However, to the best of our knowledge, no effort has been made so far
towards extending these gradient-based methods to the generation of depth
(2.5D) images, as simulating structured-light depth sensors implies solving
complex light transport and stereo-matching problems. In this paper, we
introduce a novel end-to-end differentiable simulation pipeline for the
generation of realistic 2.5D scans, built on physics-based 3D rendering and
custom block-matching algorithms. Each module can be differentiated w.r.t
sensor and scene parameters; e.g., to automatically tune the simulation for new
devices over some provided scans or to leverage the pipeline as a 3D-to-2.5D
transformer within larger computer-vision applications. Applied to the training
of deep-learning methods for various depth-based recognition tasks
(classification, pose estimation, semantic segmentation), our simulation
greatly improves the performance of the resulting models on real scans, thereby
demonstrating the fidelity and value of its synthetic depth data compared to
previous static simulations and learning-based domain adaptation schemes.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Neural Camera Simulators.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ouyang_H/0/1/0/all/0/1">Hao Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zifan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_C/0/1/0/all/0/1">Chenyang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_K/0/1/0/all/0/1">Ka Lung Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05237">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a controllable camera simulator based on deep neural networks to
synthesize raw image data under different camera settings, including exposure
time, ISO, and aperture. The proposed simulator includes an exposure module
that utilizes the principle of modern lens designs for correcting the luminance
level. It also contains a noise module using the noise level function and an
aperture module with adaptive attention to simulate the side effects on noise
and defocus blur. To facilitate the learning of a simulator model, we collect a
dataset of the 10,000 raw images of 450 scenes with different exposure
settings. Quantitative experiments and qualitative comparisons show that our
approach outperforms relevant baselines in raw data synthesize on multiple
cameras. Furthermore, the camera simulator enables various applications,
including large-aperture enhancement, HDR, auto exposure, and data augmentation
for training local feature detectors. Our work represents the first attempt to
simulate a camera sensor's behavior leveraging both the advantage of
traditional raw sensor features and the power of data-driven deep learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Simultaneous Face Hallucination and Translation for Thermal to Visible Face Verification using Axial-GAN.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Immidisetti_R/0/1/0/all/0/1">Rakhil Immidisetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shuowen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06534">
                                        <div class="article-summary-box-inner">
                                            <span><p>Existing thermal-to-visible face verification approaches expect the thermal
and visible face images to be of similar resolution. This is unlikely in
real-world long-range surveillance systems, since humans are distant from the
cameras. To address this issue, we introduce the task of thermal-to-visible
face verification from low-resolution thermal images. Furthermore, we propose
Axial-Generative Adversarial Network (Axial-GAN) to synthesize high-resolution
visible images for matching. In the proposed approach we augment the GAN
framework with axial-attention layers which leverage the recent advances in
transformers for modelling long-range dependencies. We demonstrate the
effectiveness of the proposed method by evaluating on two different
thermal-visible face datasets. When compared to related state-of-the-art works,
our results show significant improvements in both image quality and face
verification performance, and are also much more efficient.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Intelligent Monitoring of Stress Induced by Water Deficiency in Plants using Deep Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Azimi_S/0/1/0/all/0/1">Shiva Azimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadhawan_R/0/1/0/all/0/1">Rohan Wadhawan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhi_T/0/1/0/all/0/1">Tapan K. Gandhi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07911">
                                        <div class="article-summary-box-inner">
                                            <span><p>In the recent decade, high-throughput plant phenotyping techniques, which
combine non-invasive image analysis and machine learning, have been
successfully applied to identify and quantify plant health and diseases.
However, these techniques usually do not consider the progressive nature of
plant stress and often require images showing severe signs of stress to ensure
high confidence detection, thereby reducing the feasibility for early detection
and recovery of plants under stress. To overcome the problem mentioned above,
we propose a deep learning pipeline for the temporal analysis of the visual
changes induced in the plant due to stress and apply it for the specific case
of water stress identification in Chickpea plant shoot images. For this, we
have considered an image dataset of two chickpea varieties JG-62 and Pusa-372,
under three water stress conditions; control, young seedling, and before
flowering, captured over five months. We have employed a variant of the
Long-term Recurrent Convolutional Network (LRCN) to learn spatio-temporal
patterns from the chickpea plant dataset and use them for water stress
classification. Our model has achieved ceiling level classification performance
of 98.52% on JG-62 and 97.78% on Pusa-372 chickpea plant data and has
outperformed the state-of-the-art time-invariant technique by at least 14% for
both JG-62 and Pusa-372 species, to the best of our knowledge. Furthermore, our
LRCN model has demonstrated robustness to noisy input, with a less than 2.5%
dip in average model accuracy and a small standard deviation about the mean for
both species. Lastly, we have performed an ablation study to analyze the
performance of the LRCN model by decreasing the number of temporal session data
used for training.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Combining a Convolutional Neural Network with Autoencoders to Predict the Survival Chance of COVID-19 Patients.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khozeimeh_F/0/1/0/all/0/1">Fahime Khozeimeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifrazi_D/0/1/0/all/0/1">Danial Sharifrazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Izadi_N/0/1/0/all/0/1">Navid Hoseini Izadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joloudari_J/0/1/0/all/0/1">Javad Hassannataj Joloudari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1">Juan M. Gorriz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1">Sadiq Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sani_Z/0/1/0/all/0/1">Zahra Alizadeh Sani</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosaei_H/0/1/0/all/0/1">Hossein Moosaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Sheikh Mohammed Shariful Islam</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08954">
                                        <div class="article-summary-box-inner">
                                            <span><p>COVID-19 has caused many deaths worldwide. The automation of the diagnosis of
this virus is highly desired. Convolutional neural networks (CNNs) have shown
outstanding classification performance on image datasets. To date, it appears
that COVID computer-aided diagnosis systems based on CNNs and clinical
information have not yet been analysed or explored. We propose a novel method,
named the CNN-AE, to predict the survival chance of COVID-19 patients using a
CNN trained with clinical information. Notably, the required resources to
prepare CT images are expensive and limited compared to those required to
collect clinical data, such as blood pressure, liver disease, etc. We evaluated
our method using a publicly available clinical dataset that we collected. The
dataset properties were carefully analysed to extract important features and
compute the correlations of features. A data augmentation procedure based on
autoencoders (AEs) was proposed to balance the dataset. The experimental
results revealed that the average accuracy of the CNN-AE (96.05%) was higher
than that of the CNN (92.49%). To demonstrate the generality of our
augmentation method, we trained some existing mortality risk prediction methods
on our dataset (with and without data augmentation) and compared their
performances. We also evaluated our method using another dataset for further
generality verification. To show that clinical data can be used for COVID-19
survival chance prediction, the CNN-AE was compared with multiple pre-trained
deep models that were tuned based on CT images.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DisCo: Remedy Self-supervised Learning on Lightweight Models with Distilled <span class="highlight_title">Contrastive Learning</span>.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yuting Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1">Jia-Xin Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaowei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xing Sun</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09124">
                                        <div class="article-summary-box-inner">
                                            <span><p>While self-supervised representation learning (SSL) has received widespread
attention from the community, recent research argue that its performance will
suffer a cliff fall when the model size decreases. The current method mainly
relies on contrastive learning to train the network and in this work, we
propose a simple yet effective Distilled Contrastive Learning (DisCo) to ease
the issue by a large margin. Specifically, we find the final embedding obtained
by the mainstream SSL methods contains the most fruitful information, and
propose to distill the final embedding to maximally transmit a teacher's
knowledge to a lightweight model by constraining the last embedding of the
student to be consistent with that of the teacher. In addition, in the
experiment, we find that there exists a phenomenon termed Distilling BottleNeck
and present to enlarge the embedding dimension to alleviate this problem. Our
method does not introduce any extra parameter to lightweight models during
deployment. Experimental results demonstrate that our method achieves the
state-of-the-art on all lightweight models. Particularly, when
ResNet-101/ResNet-50 is used as teacher to teach EfficientNet-B0, the linear
result of EfficientNet-B0 on ImageNet is very close to ResNet-101/ResNet-50,
but the number of parameters of EfficientNet-B0 is only 9.4\%/16.3\% of
ResNet-101/ResNet-50. Code is available at https://github.
com/Yuting-Gao/DisCo-pytorch.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ EigenGAN: Layer-Wise Eigen-Learning for GANs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhenliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1">Meina Kan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Shiguang Shan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12476">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent studies on Generative Adversarial Network (GAN) reveal that different
layers of a generative CNN hold different semantics of the synthesized images.
However, few GAN models have explicit dimensions to control the semantic
attributes represented in a specific layer. This paper proposes EigenGAN which
is able to unsupervisedly mine interpretable and controllable dimensions from
different generator layers. Specifically, EigenGAN embeds one linear subspace
with orthogonal basis into each generator layer. Via generative adversarial
training to learn a target distribution, these layer-wise subspaces
automatically discover a set of "eigen-dimensions" at each layer corresponding
to a set of semantic attributes or interpretable variations. By traversing the
coefficient of a specific eigen-dimension, the generator can produce samples
with continuous changes corresponding to a specific semantic attribute. Taking
the human face for example, EigenGAN can discover controllable dimensions for
high-level concepts such as pose and gender in the subspace of deep layers, as
well as low-level concepts such as hue and color in the subspace of shallow
layers. Moreover, in the linear case, we theoretically prove that our algorithm
derives the principal components as PCA does. Codes can be found in
https://github.com/LynnHo/EigenGAN-Tensorflow.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Time Series Forecasting of New Cases and New Deaths Rate for COVID-19 using Deep Learning Methods.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ayoobi_N/0/1/0/all/0/1">Nooshin Ayoobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifrazi_D/0/1/0/all/0/1">Danial Sharifrazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1">Juan M. Gorriz</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosaei_H/0/1/0/all/0/1">Hossein Moosaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chofreh_A/0/1/0/all/0/1">Abdoulmohammad Gholamzadeh Chofreh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goni_F/0/1/0/all/0/1">Feybi Ariani Goni</a>, <a href="http://arxiv.org/find/cs/1/au:+Klemes_J/0/1/0/all/0/1">Jiri Jaromir Klemes</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosavi_A/0/1/0/all/0/1">Amir Mosavi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15007">
                                        <div class="article-summary-box-inner">
                                            <span><p>The first known case of Coronavirus disease 2019 (COVID-19) was identified in
December 2019. It has spread worldwide, leading to an ongoing pandemic, imposed
restrictions and costs to many countries. Predicting the number of new cases
and deaths during this period can be a useful step in predicting the costs and
facilities required in the future. The purpose of this study is to predict new
cases and deaths rate one, three and seven-day ahead during the next 100 days.
The motivation for predicting every n days (instead of just every day) is the
investigation of the possibility of computational cost reduction and still
achieving reasonable performance. Such a scenario may be encountered real-time
forecasting of time series. Six different deep learning methods are examined on
the data adopted from the WHO website. Three methods are LSTM, Convolutional
LSTM, and GRU. The bidirectional extension is then considered for each method
to forecast the rate of new cases and new deaths in Australia and Iran
countries.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Single-Training Collaborative Object Detectors Adaptive to Bandwidth and Computation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Assine_J/0/1/0/all/0/1">Juliano S. Assine</a>, <a href="http://arxiv.org/find/cs/1/au:+Filho_J/0/1/0/all/0/1">J. C. S. Santos Filho</a>, <a href="http://arxiv.org/find/cs/1/au:+Valle_E/0/1/0/all/0/1">Eduardo Valle</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00591">
                                        <div class="article-summary-box-inner">
                                            <span><p>In the past few years, mobile deep-learning deployment progressed by leaps
and bounds, but solutions still struggle to accommodate its severe and
fluctuating operational restrictions, which include bandwidth, latency,
computation, and energy. In this work, we help to bridge that gap, introducing
the first configurable solution for object detection that manages the triple
communication-computation-accuracy trade-off with a single set of weights. Our
solution shows state-of-the-art results on COCO-2017, adding only a minor
penalty on the base EfficientDet-D2 architecture. Our design is robust to the
choice of base architecture and compressor and should adapt well for future
architectures.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Towards Novel Target Discovery Through Open-Set Domain Adaptation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jing_T/0/1/0/all/0/1">Taotao Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongfu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhengming Ding</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02432">
                                        <div class="article-summary-box-inner">
                                            <span><p>Open-set domain adaptation (OSDA) considers that the target domain contains
samples from novel categories unobserved in external source domain.
Unfortunately, existing OSDA methods always ignore the demand for the
information of unseen categories and simply recognize them as "unknown" set
without further explanation. This motivates us to understand the unknown
categories more specifically by exploring the underlying structures and
recovering their interpretable semantic attributes. In this paper, we propose a
novel framework to accurately identify the seen categories in target domain,
and effectively recover the semantic attributes for unseen categories.
Specifically, structure preserving partial alignment is developed to recognize
the seen categories through domain-invariant feature learning. Attribute
propagation over visual graph is designed to smoothly transit attributes from
seen to unseen categories via visual-semantic mapping. Moreover, two new
cross-main benchmarks are constructed to evaluate the proposed framework in the
novel and practical challenge. Experimental results on open-set recognition and
semantic recovery demonstrate the superiority of the proposed method over other
compared baselines.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Self-Adaptive Transfer Learning for Multicenter Glaucoma Classification in Fundus Retina Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Bao_Y/0/1/0/all/0/1">Yiming Bao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Tong Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_L/0/1/0/all/0/1">Linyan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jianwei Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1">Juan Ye</a>, <a href="http://arxiv.org/find/eess/1/au:+Qian_D/0/1/0/all/0/1">Dahong Qian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03068">
                                        <div class="article-summary-box-inner">
                                            <span><p>The early diagnosis and screening of glaucoma are important for patients to
receive treatment in time and maintain eyesight. Nowadays, deep learning (DL)
based models have been successfully used for computer-aided diagnosis (CAD) of
glaucoma from retina fundus images. However, a DL model pre-trained using a
dataset from one hospital center may have poor performance on a dataset from
another new hospital center and therefore its applications in the real scene
are limited. In this paper, we propose a self-adaptive transfer learning (SATL)
strategy to fill the domain gap between multicenter datasets. Specifically, the
encoder of a DL model that is pre-trained on the source domain is used to
initialize the encoder of a reconstruction model. Then, the reconstruction
model is trained using only unlabeled image data from the target domain, which
makes the encoder in the model adapt itself to extract useful high-level
features both for target domain images encoding and glaucoma classification,
simultaneously. Experimental results demonstrate that the proposed SATL
strategy is effective in the domain adaptation task between one private and two
public glaucoma diagnosis datasets, i.e. pri-RFG, REFUGE, and LAG. Moreover,
the proposed strategy is completely independent of the source domain data,
which meets the real scene application and the privacy protection policy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Applications of Deep Learning Techniques for Automated Multiple Sclerosis Detection Using Magnetic Resonance Imaging: A Review.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/eess/1/au:+Khodatars_M/0/1/0/all/0/1">Marjane Khodatars</a>, <a href="http://arxiv.org/find/eess/1/au:+Jafari_M/0/1/0/all/0/1">Mahboobeh Jafari</a>, <a href="http://arxiv.org/find/eess/1/au:+Moridian_P/0/1/0/all/0/1">Parisa Moridian</a>, <a href="http://arxiv.org/find/eess/1/au:+Rezaei_M/0/1/0/all/0/1">Mitra Rezaei</a>, <a href="http://arxiv.org/find/eess/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/eess/1/au:+Khozeimeh_F/0/1/0/all/0/1">Fahime Khozeimeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Gorriz_J/0/1/0/all/0/1">Juan Manuel Gorriz</a>, <a href="http://arxiv.org/find/eess/1/au:+Heras_J/0/1/0/all/0/1">J&#xf3;nathan Heras</a>, <a href="http://arxiv.org/find/eess/1/au:+Panahiazar_M/0/1/0/all/0/1">Maryam Panahiazar</a>, <a href="http://arxiv.org/find/eess/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/eess/1/au:+Acharya_U/0/1/0/all/0/1">U. Rajendra Acharya</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04881">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multiple Sclerosis (MS) is a type of brain disease which causes visual,
sensory, and motor problems for people with a detrimental effect on the
functioning of the nervous system. In order to diagnose MS, multiple screening
methods have been proposed so far; among them, magnetic resonance imaging (MRI)
has received considerable attention among physicians. MRI modalities provide
physicians with fundamental information about the structure and function of the
brain, which is crucial for the rapid diagnosis of MS lesions. Diagnosing MS
using MRI is time-consuming, tedious, and prone to manual errors. Hence,
computer aided diagnosis systems (CADS) based on artificial intelligence (AI)
methods have been proposed in recent years for accurate diagnosis of MS using
MRI neuroimaging modalities. In the AI field, automated MS diagnosis is being
conducted using (i) conventional machine learning and (ii) deep learning (DL)
techniques. The conventional machine learning approach is based on feature
extraction and selection by trial and error. In DL, these steps are performed
by the DL model itself. In this paper, a complete review of automated MS
diagnosis methods performed using DL techniques with MRI neuroimaging
modalities are discussed. Also, each work is thoroughly reviewed and discussed.
Finally, the most important challenges and future directions in the automated
MS diagnosis using DL techniques coupled with MRI modalities are presented in
detail.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Multi-Perspective Anomaly Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1">Peter Jakob</a>, <a href="http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1">Manav Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1">Tobias Schmid-Schirling</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09903">
                                        <div class="article-summary-box-inner">
                                            <span><p>Anomaly detection is a critical problem in the manufacturing industry. In
many applications, images of objects to be analyzed are captured from multiple
perspectives which can be exploited to improve the robustness of anomaly
detection. In this work, we build upon the deep support vector data description
algorithm and address multi-perspective anomaly detection using three different
fusion techniques, i.e., early fusion, late fusion, and late fusion with
multiple decoders. We employ different augmentation techniques with a denoising
process to deal with scarce one-class data, which further improves the
performance (ROC AUC $= 80\%$). Furthermore, we introduce the dices dataset,
which consists of over 2000 grayscale images of falling dices from multiple
perspectives, with 5\% of the images containing rare anomalies (e.g., drill
holes, sawing, or scratches). We evaluate our approach on the new dices dataset
using images from two different perspectives and also benchmark on the standard
MNIST dataset. Extensive experiments demonstrate that our proposed
{multi-perspective} approach exceeds the state-of-the-art {single-perspective
anomaly detection on both the MNIST and dices datasets}. To the best of our
knowledge, this is the first work that focuses on addressing multi-perspective
anomaly detection in images by jointly using different perspectives together
with one single objective function for anomaly detection.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ SVMAC: Unsupervised 3D Human Pose Estimation from a Single Image with Single-view-multi-angle Consistenty.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yicheng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Cheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiahui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yongqi Sun</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05616">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recovering 3D human pose from 2D joints is still a challenging problem,
especially without any 3D annotation, video information, or multi-view
information. In this paper, we present an unsupervised GAN-based model
consisting of multiple weight-sharing generators to estimate a 3D human pose
from a single image without 3D annotations. In our model, we introduce
single-view-multi-angle consistency (SVMAC) to significantly improve the
estimation performance. With 2D joint locations as input, our model estimates a
3D pose and a camera simultaneously. During training, the estimated 3D pose is
rotated by random angles and the estimated camera projects the rotated 3D poses
back to 2D. The 2D reprojections will be fed into weight-sharing generators to
estimate the corresponding 3D poses and cameras, which are then mixed to impose
SVMAC constraints to self-supervise the training process. The experimental
results show that our method outperforms the state-of-the-art unsupervised
methods by 2.6% on Human 3.6M and 15.0% on MPI-INF-3DHP. Moreover, qualitative
results on MPII and LSP show that our method can generalize well to unknown
data.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Automated Deepfake Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Ping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yuewei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhen_L/0/1/0/all/0/1">Liangli Zhen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goh_R/0/1/0/all/0/1">Rick Siow Mong Goh</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingen Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10705">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we propose to utilize Automated Machine Learning to adaptively
search a neural architecture for deepfake detection. This is the first time to
employ automated machine learning for deepfake detection. Based on our explored
search space, our proposed method achieves competitive prediction accuracy
compared to previous methods. To improve the generalizability of our method,
especially when training data and testing data are manipulated by different
methods, we propose a simple yet effective strategy in our network learning
process: making it to estimate potential manipulation regions besides
predicting the real/fake labels. Unlike previous works manually design neural
networks, our method can relieve us from the high labor cost in network
construction. More than that, compared to previous works, our method depends
much less on prior knowledge, e.g., which manipulation method is utilized or
where exactly the fake image is manipulated. Extensive experimental results on
two benchmark datasets demonstrate the effectiveness of our proposed method for
deepfake detection.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Team PyKale (xy9) Submission to the EPIC-Kitchens 2021 Unsupervised Domain Adaptation Challenge for Action Recognition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1">Tao Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12023">
                                        <div class="article-summary-box-inner">
                                            <span><p>This report describes the technical details of our submission to the
EPIC-Kitchens 2021 Unsupervised Domain Adaptation Challenge for Action
Recognition. The EPIC-Kitchens dataset is more difficult than other video
domain adaptation datasets due to multi-tasks with more modalities. Firstly, to
participate in the challenge, we employ a transformer to capture the spatial
information from each modality. Secondly, we employ a temporal attention module
to model temporal-wise inter-dependency. Thirdly, we employ the adversarial
domain adaptation network to learn the general features between labeled source
and unlabeled target domain. Finally, we incorporate multiple modalities to
improve the performance by a three-stream network with late fusion. Our network
achieves the comparable performance with the state-of-the-art baseline T$A^3$N
and outperforms the baseline on top-1 accuracy for verb class and top-5
accuracies for all three tasks which are verb, noun and action. Under the team
name xy9, our submission achieved 5th place in terms of top-1 accuracy for verb
class and all top-5 accuracies.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Aerial Map-Based Navigation Using Semantic Segmentation and Pattern Matching.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Youngjoo Kim</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00689">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper proposes a novel approach to map-based navigation system for
unmanned aircraft. The proposed system attempts label-to-label matching, not
image-to-image matching, between aerial images and a map database. By using
semantic segmentation, the ground objects are labelled and the configuration of
the objects is used to find the corresponding location in the map database. The
use of the deep learning technique as a tool for extracting high-level features
reduces the image-based localization problem to a pattern matching problem.
This paper proposes a pattern matching algorithm which does not require
altitude information or a camera model to estimate the absolute horizontal
position. The feasibility analysis with simulated images shows the proposed
map-based navigation can be realized with the proposed pattern matching
algorithm and it is able to provide positions given the labelled objects.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Anomaly Detection using Edge Computing in Video Surveillance System: Review.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Patrikar_D/0/1/0/all/0/1">Devashree R. Patrikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Parate_M/0/1/0/all/0/1">Mayur Rajram Parate</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02778">
                                        <div class="article-summary-box-inner">
                                            <span><p>The current concept of Smart Cities influences urban planners and researchers
to provide modern, secured and sustainable infrastructure and give a decent
quality of life to its residents. To fulfill this need video surveillance
cameras have been deployed to enhance the safety and well-being of the
citizens. Despite technical developments in modern science, abnormal event
detection in surveillance video systems is challenging and requires exhaustive
human efforts. In this paper, we surveyed various methodologies developed to
detect anomalies in intelligent video surveillance. Firstly, we revisit the
surveys on anomaly detection in the last decade. We then present a systematic
categorization of methodologies developed for ease of understanding.
Considering the notion of anomaly depends on context, we identify different
objects-of-interest and publicly available datasets in anomaly detection. Since
anomaly detection is considered a time-critical application of computer vision,
our emphasis is on anomaly detection using edge devices and approaches
explicitly designed for them. Further, we discuss the challenges and
opportunities involved in anomaly detection at the edge.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ GLiT: Neural Architecture Search for Global and Local Image <span class="highlight_title">Transformer</span>.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+yan_J/0/1/0/all/0/1">Junjie yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02960">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce the first Neural Architecture Search (NAS) method to find a
better transformer architecture for image recognition. Recently, transformers
without CNN-based backbones are found to achieve impressive performance for
image recognition. However, the transformer is designed for NLP tasks and thus
could be sub-optimal when directly used for image recognition. In order to
improve the visual representation ability for transformers, we propose a new
search space and searching algorithm. Specifically, we introduce a locality
module that models the local correlations in images explicitly with fewer
computational cost. With the locality module, our search space is defined to
let the search algorithm freely trade off between global and local information
as well as optimizing the low-level design choice in each module. To tackle the
problem caused by huge search space, a hierarchical neural architecture search
method is proposed to search the optimal vision transformer from two levels
separately with the evolutionary algorithm. Extensive experiments on the
ImageNet dataset demonstrate that our method can find more discriminative and
efficient transformer variants than the ResNet family (e.g., ResNet101) and the
baseline ViT for image classification.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Anomaly Detection in Residential Video Surveillance on Edge Devices in IoT Framework.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Parate_M/0/1/0/all/0/1">Mayur R. Parate</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhurchandi_K/0/1/0/all/0/1">Kishor M. Bhurchandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1">Ashwin G. Kothari</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04767">
                                        <div class="article-summary-box-inner">
                                            <span><p>Intelligent resident surveillance is one of the most essential smart
community services. The increasing demand for security needs surveillance
systems to be able to detect anomalies in surveillance scenes. Employing
high-capacity computational devices for intelligent surveillance in residential
societies is costly and not feasible. Therefore, we propose anomaly detection
for intelligent surveillance using CPU-only edge devices. A modular framework
to capture object-level inferences and tracking is developed. To cope with
partial occlusions, posture deformations, and complex scenes, we employed
feature encoding and trajectory association governed by two metrices
complementing to each other. The elements of an anomaly detection framework are
optimized to run on CPU-only edge devices with sufficient frames per second
(FPS). The experimental results indicate the proposed method is feasible and
achieves satisfactory results in real-life scenarios.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Towards Accurate Localization by Instance Search.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yi-Geng Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Hui-Chu Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wan-Lei Zhao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05005">
                                        <div class="article-summary-box-inner">
                                            <span><p>Visual object localization is the key step in a series of object detection
tasks. In the literature, high localization accuracy is achieved with the
mainstream strongly supervised frameworks. However, such methods require
object-level annotations and are unable to detect objects of unknown
categories. Weakly supervised methods face similar difficulties. In this paper,
a self-paced learning framework is proposed to achieve accurate object
localization on the rank list returned by instance search. The proposed
framework mines the target instance gradually from the queries and their
corresponding top-ranked search results. Since a common instance is shared
between the query and the images in the rank list, the target visual instance
can be accurately localized even without knowing what the object category is.
In addition to performing localization on instance search, the issue of
few-shot object detection is also addressed under the same framework. Superior
performance over state-of-the-art methods is observed on both tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Autonomy 2.0: Why is self-driving always 5 years away?.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ashesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Pero_L/0/1/0/all/0/1">Luca Del Pero</a>, <a href="http://arxiv.org/find/cs/1/au:+Grimmett_H/0/1/0/all/0/1">Hugo Grimmett</a>, <a href="http://arxiv.org/find/cs/1/au:+Ondruska_P/0/1/0/all/0/1">Peter Ondruska</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08142">
                                        <div class="article-summary-box-inner">
                                            <span><p>Despite the numerous successes of machine learning over the past decade
(image recognition, decision-making, NLP, image synthesis), self-driving
technology has not yet followed the same trend. In this paper, we study the
history, composition, and development bottlenecks of the modern self-driving
stack. We argue that the slow progress is caused by approaches that require too
much hand-engineering, an over-reliance on road testing, and high fleet
deployment costs. We observe that the classical stack has several bottlenecks
that preclude the necessary scale needed to capture the long tail of rare
events. To resolve these problems, we outline the principles of Autonomy 2.0,
an ML-first approach to self-driving, as a viable alternative to the currently
adopted state-of-the-art. This approach is based on (i) a fully differentiable
AV stack trainable from human demonstrations, (ii) closed-loop data-driven
reactive simulation, and (iii) large-scale, low-cost data collections as
critical solutions towards scalability issues. We outline the general
architecture, survey promising works in this direction and propose key
challenges to be addressed by the community in the future.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tsung-Han Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hsin-Ying Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Ping-Chia Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11769">
                                        <div class="article-summary-box-inner">
                                            <span><p>Despite the success of deep learning on supervised point cloud semantic
segmentation, obtaining large-scale point-by-point manual annotations is still
a significant challenge. To reduce the huge annotation burden, we propose a
Region-based and Diversity-aware Active Learning (ReDAL), a general framework
for many deep learning approaches, aiming to automatically select only
informative and diverse sub-scene regions for label acquisition. Observing that
only a small portion of annotated regions are sufficient for 3D scene
understanding with deep learning, we use softmax entropy, color discontinuity,
and structural complexity to measure the information of sub-scene regions. A
diversity-aware selection algorithm is also developed to avoid redundant
annotations resulting from selecting informative but similar regions in a
querying batch. Extensive experiments show that our method highly outperforms
previous active learning strategies, and we achieve the performance of 90%
fully supervised learning, while less than 15% and 5% annotations are required
on S3DIS and SemanticKITTI datasets, respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Adaptive Hierarchical Graph Reasoning with Semantic Coherence for Video-and-Language Inference.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juncheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Linchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haochen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanwen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yueting Zhuang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12270">
                                        <div class="article-summary-box-inner">
                                            <span><p>Video-and-Language Inference is a recently proposed task for joint
video-and-language understanding. This new task requires a model to draw
inference on whether a natural language statement entails or contradicts a
given video clip. In this paper, we study how to address three critical
challenges for this task: judging the global correctness of the statement
involved multiple semantic meanings, joint reasoning over video and subtitles,
and modeling long-range relationships and complex social interactions. First,
we propose an adaptive hierarchical graph network that achieves in-depth
understanding of the video over complex interactions. Specifically, it performs
joint reasoning over video and subtitles in three hierarchies, where the graph
structure is adaptively adjusted according to the semantic structures of the
statement. Secondly, we introduce semantic coherence learning to explicitly
encourage the semantic coherence of the adaptive hierarchical graph network
from three hierarchies. The semantic coherence learning can further improve the
alignment between vision and linguistics, and the coherence across a sequence
of video segments. Experimental results show that our method significantly
outperforms the baseline by a large margin.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Spatial-Temporal <span class="highlight_title">Transformer</span> for Dynamic Scene Graph Generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Cong_Y/0/1/0/all/0/1">Yuren Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wentong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ackermann_H/0/1/0/all/0/1">Hanno Ackermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Michael Ying Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12309">
                                        <div class="article-summary-box-inner">
                                            <span><p>Dynamic scene graph generation aims at generating a scene graph of the given
video. Compared to the task of scene graph generation from images, it is more
challenging because of the dynamic relationships between objects and the
temporal dependencies between frames allowing for a richer semantic
interpretation. In this paper, we propose Spatial-temporal Transformer
(STTran), a neural network that consists of two core modules: (1) a spatial
encoder that takes an input frame to extract spatial context and reason about
the visual relationships within a frame, and (2) a temporal decoder which takes
the output of the spatial encoder as input in order to capture the temporal
dependencies between frames and infer the dynamic relationships. Furthermore,
STTran is flexible to take varying lengths of videos as input without clipping,
which is especially important for long videos. Our method is validated on the
benchmark dataset Action Genome (AG). The experimental results demonstrate the
superior performance of our method in terms of dynamic scene graphs. Moreover,
a set of ablative studies is conducted and the effect of each proposed module
is justified. Code available at: https://github.com/yrcong/STTran.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Boshen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12619">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, the problem of inaccurate learning targets in crowd counting draws
increasing attention. Inspired by a few pioneering work, we solve this problem
by trying to predict the indices of pre-defined interval bins of counts instead
of the count values themselves. However, an inappropriate interval setting
might make the count error contributions from different intervals extremely
imbalanced, leading to inferior counting performance. Therefore, we propose a
novel count interval partition criterion called Uniform Error Partition (UEP),
which always keeps the expected counting error contributions equal for all
intervals to minimize the prediction risk. Then to mitigate the inevitably
introduced discretization errors in the count quantization process, we propose
another criterion called Mean Count Proxies (MCP). The MCP criterion selects
the best count proxy for each interval to represent its count value during
inference, making the overall expected discretization error of an image nearly
negligible. As far as we are aware, this work is the first to delve into such a
classification task and ends up with a promising solution for count interval
partition. Following the above two theoretically demonstrated criterions, we
propose a simple yet effective model termed Uniform Error Partition Network
(UEPNet), which achieves state-of-the-art performance on several challenging
datasets. The codes will be available at:
https://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Greedy Gradient Ensemble for Robust Visual Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xinzhe Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12651">
                                        <div class="article-summary-box-inner">
                                            <span><p>Language bias is a critical issue in Visual Question Answering (VQA), where
models often exploit dataset biases for the final decision without considering
the image information. As a result, they suffer from performance drop on
out-of-distribution data and inadequate visual explanation. Based on
experimental analysis for existing robust VQA methods, we stress the language
bias in VQA that comes from two aspects, i.e., distribution bias and shortcut
bias. We further propose a new de-bias framework, Greedy Gradient Ensemble
(GGE), which combines multiple biased models for unbiased base model learning.
With the greedy strategy, GGE forces the biased models to over-fit the biased
data distribution in priority, thus makes the base model pay more attention to
examples that are hard to solve by biased models. The experiments demonstrate
that our method makes better use of visual information and achieves
state-of-the-art performance on diagnosing dataset VQA-CP without using extra
annotations.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zefeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Changxing Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhiyin Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12666">
                                        <div class="article-summary-box-inner">
                                            <span><p>Text-to-image person re-identification (ReID) aims to search for images
containing a person of interest using textual descriptions. However, due to the
significant modality gap and the large intra-class variance in textual
descriptions, text-to-image ReID remains a challenging problem. Accordingly, in
this paper, we propose a Semantically Self-Aligned Network (SSAN) to handle the
above problems. First, we propose a novel method that automatically extracts
semantically aligned part-level features from the two modalities. Second, we
design a multi-view non-local network that captures the relationships between
body parts, thereby establishing better correspondences between body parts and
noun phrases. Third, we introduce a Compound Ranking (CR) loss that makes use
of textual descriptions for other images of the same identity to provide extra
supervision, thereby effectively reducing the intra-class variance in textual
features. Finally, to expedite future research in text-to-image ReID, we build
a new database named ICFG-PEDES. Extensive experiments demonstrate that SSAN
outperforms state-of-the-art approaches by significant margins. Both the new
ICFG-PEDES database and the SSAN code are available at
https://github.com/zifyloo/SSAN.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Rethinking Counting and Localization in Crowds:A Purely Point-Based Framework.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhengkai Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12746">
                                        <div class="article-summary-box-inner">
                                            <span><p>Localizing individuals in crowds is more in accordance with the practical
demands of subsequent high-level crowd analysis tasks than simply counting.
However, existing localization based methods relying on intermediate
representations (\textit{i.e.}, density maps or pseudo boxes) serving as
learning targets are counter-intuitive and error-prone. In this paper, we
propose a purely point-based framework for joint crowd counting and individual
localization. For this framework, instead of merely reporting the absolute
counting error at image level, we propose a new metric, called density
Normalized Average Precision (nAP), to provide more comprehensive and more
precise performance evaluation. Moreover, we design an intuitive solution under
this framework, which is called Point to Point Network (P2PNet). P2PNet
discards superfluous steps and directly predicts a set of point proposals to
represent heads in an image, being consistent with the human annotation
results. By thorough analysis, we reveal the key step towards implementing such
a novel idea is to assign optimal learning targets for these proposals.
Therefore, we propose to conduct this crucial association in an one-to-one
matching manner using the Hungarian algorithm. The P2PNet not only
significantly surpasses state-of-the-art methods on popular counting
benchmarks, but also achieves promising localization accuracy. The codes will
be available at: https://github.com/TencentYoutuResearch/CrowdCounting-P2PNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Enriching Local and Global Contexts for Temporal Action Localization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zixin Zhu</a> (Xi&#x27;an jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1">Wei Tang</a> (University of Illinois at Chicago), <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a> (Xi&#x27;an Jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a> (Xi&#x27;an Jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a> (Wormpex AI Research), ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12960">
                                        <div class="article-summary-box-inner">
                                            <span><p>Effectively tackling the problem of temporal action localization (TAL)
necessitates a visual representation that jointly pursues two confounding
goals, i.e., fine-grained discrimination for temporal localization and
sufficient visual invariance for action classification. We address this
challenge by enriching both the local and global contexts in the popular
two-stage temporal localization framework, where action proposals are first
generated followed by action classification and temporal boundary regression.
Our proposed model, dubbed ContextLoc, can be divided into three sub-networks:
L-Net, G-Net and P-Net. L-Net enriches the local context via fine-grained
modeling of snippet-level features, which is formulated as a
query-and-retrieval process. G-Net enriches the global context via higher-level
modeling of the video-level representation. In addition, we introduce a novel
context adaptation module to adapt the global context to different proposals.
P-Net further models the context-aware inter-proposal relations. We explore two
existing models to be the P-Net in our experiments. The efficacy of our
proposed method is validated by experimental results on the THUMOS14 (54.3\% at
tIoU@0.5) and ActivityNet v1.3 (56.01\% at tIoU@0.5) datasets, which
outperforms recent states of the art. Code is available at
https://github.com/buxiangzhiren/ContextLoc.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ManiSkill: Learning-from-Demonstrations Benchmark for Generalizable Manipulation Skills.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tongzhou Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zhan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_F/0/1/0/all/0/1">Fanbo Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Derek Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuanlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1">Stone Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhiwei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14483">
                                        <div class="article-summary-box-inner">
                                            <span><p>Learning generalizable manipulation skills is central for robots to achieve
task automation in environments with endless scene and object variations.
However, existing robot learning environments are limited in both scale and
diversity of 3D assets (especially of articulated objects), making it difficult
to train and evaluate the generalization ability of agents over novel objects.
In this work, we focus on object-level generalization and propose SAPIEN
Manipulation Skill Benchmark (abbreviated as ManiSkill), a large-scale
learning-from-demonstrations benchmark for articulated object manipulation with
3D visual input (point cloud and RGB-D image). ManiSkill supports object-level
variations by utilizing a rich and diverse set of articulated objects, and each
task is carefully designed for learning manipulations on a single category of
objects. We equip ManiSkill with a large number of high-quality demonstrations
to facilitate learning-from-demonstrations approaches and perform evaluations
on baseline algorithms. We believe that ManiSkill can encourage the robot
learning community to explore more on learning generalizable object
manipulation skills.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Product1M: Towards Weakly Supervised Instance-Level Product Retrieval via Cross-modal <span class="highlight_title">Pretrain</span>ing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1">Xunlin Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yangxin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Minlong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14572">
                                        <div class="article-summary-box-inner">
                                            <span><p>Nowadays, customer's demands for E-commerce are more diversified, which
introduces more complications to the product retrieval industry. Previous
methods are either subject to single-modal input or perform supervised
image-level product retrieval, thus fail to accommodate real-life scenarios
where enormous weakly annotated multi-modal data are present. In this paper, we
investigate a more realistic setting that aims to perform weakly-supervised
multi-modal instance-level product retrieval among fine-grained product
categories. To promote the study of this challenging task, we contribute
Product1M, one of the largest multi-modal cosmetic datasets for real-world
instance-level retrieval. Notably, Product1M contains over 1 million
image-caption pairs and consists of two sample types, i.e., single-product and
multi-product samples, which encompass a wide variety of cosmetics brands. In
addition to the great diversity, Product1M enjoys several appealing
characteristics including fine-grained categories, complex combinations, and
fuzzy correspondence that well mimic the real-world scenes. Moreover, we
propose a novel model named Cross-modal contrAstive Product Transformer for
instance-level prodUct REtrieval (CAPTURE), that excels in capturing the
potential synergy between multi-modal inputs via a hybrid-stream transformer in
a self-supervised manner.CAPTURE generates discriminative instance features via
masked multi-modal learning as well as cross-modal contrastive pretraining and
it outperforms several SOTA cross-modal baselines. Extensive ablation studies
well demonstrate the effectiveness and the generalization capacity of our
model. Dataset and codes are available at https:
//github.com/zhanxlin/Product1M.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Sparse-to-dense Feature Matching: Intra and Inter domain Cross-modal Learning in Domain Adaptation for 3D Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Duo Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1">Yinjie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pingping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yulan Guo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14724">
                                        <div class="article-summary-box-inner">
                                            <span><p>Domain adaptation is critical for success when confronting with the lack of
annotations in a new domain. As the huge time consumption of labeling process
on 3D point cloud, domain adaptation for 3D semantic segmentation is of great
expectation. With the rise of multi-modal datasets, large amount of 2D images
are accessible besides 3D point clouds. In light of this, we propose to further
leverage 2D data for 3D domain adaptation by intra and inter domain cross modal
learning. As for intra-domain cross modal learning, most existing works sample
the dense 2D pixel-wise features into the same size with sparse 3D point-wise
features, resulting in the abandon of numerous useful 2D features. To address
this problem, we propose Dynamic sparse-to-dense Cross Modal Learning (DsCML)
to increase the sufficiency of multi-modality information interaction for
domain adaptation. For inter-domain cross modal learning, we further advance
Cross Modal Adversarial Learning (CMAL) on 2D and 3D data which contains
different semantic content aiming to promote high-level modal complementarity.
We evaluate our model under various multi-modality domain adaptation settings
including day-to-night, country-to-country and dataset-to-dataset, brings large
improvements over both uni-modal and multi-modal domain adaptation methods on
all settings.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Pro-UIGAN: Progressive Face Hallucination from Occluded Thumbnails.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaobo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Ping Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00602">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we study the task of hallucinating an authentic
high-resolution (HR) face from an occluded thumbnail. We propose a multi-stage
Progressive Upsampling and Inpainting Generative Adversarial Network, dubbed
Pro-UIGAN, which exploits facial geometry priors to replenish and upsample (8*)
the occluded and tiny faces (16*16 pixels). Pro-UIGAN iteratively (1) estimates
facial geometry priors for low-resolution (LR) faces and (2) acquires
non-occluded HR face images under the guidance of the estimated priors. Our
multi-stage hallucination network super-resolves and inpaints occluded LR faces
in a coarse-to-fine manner, thus reducing unwanted blurriness and artifacts
significantly. Specifically, we design a novel cross-modal transformer module
for facial priors estimation, in which an input face and its landmark features
are formulated as queries and keys, respectively. Such a design encourages
joint feature learning across the input facial and landmark features, and deep
feature correspondences will be discovered by attention. Thus, facial
appearance features and facial geometry priors are learned in a mutual
promotion manner. Extensive experiments demonstrate that our Pro-UIGAN achieves
visually pleasing HR faces, reaching superior performance in downstream tasks,
i.e., face alignment, face parsing, face recognition and expression
classification, compared with other state-of-the-art (SotA) methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Efficient Deep Feature Calibration for <span class="highlight_title">Cross-Modal</span> Joint Embedding Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00705">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper introduces a two-phase deep feature calibration framework for
efficient learning of semantics enhanced text-image cross-modal joint
embedding, which clearly separates the deep feature calibration in data
preprocessing from training the joint embedding model. We use the Recipe1M
dataset for the technical description and empirical validation. In
preprocessing, we perform deep feature calibration by combining deep feature
engineering with semantic context features derived from raw text-image input
data. We leverage LSTM to identify key terms, NLP methods to produce ranking
scores for key terms before generating the key term feature. We leverage
wideResNet50 to extract and encode the image category semantics to help
semantic alignment of the learned recipe and image embeddings in the joint
latent space. In joint embedding learning, we perform deep feature calibration
by optimizing the batch-hard triplet loss function with soft-margin and double
negative sampling, also utilizing the category-based alignment loss and
discriminator-based alignment loss. Extensive experiments demonstrate that our
SEJE approach with the deep feature calibration significantly outperforms the
state-of-the-art approaches.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Skeleton Cloud Colorization for Unsupervised 3D Action Representation Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Siyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Er_M/0/1/0/all/0/1">Meng Hwa Er</a>, <a href="http://arxiv.org/find/cs/1/au:+Kot_A/0/1/0/all/0/1">Alex C. Kot</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01959">
                                        <div class="article-summary-box-inner">
                                            <span><p>Skeleton-based human action recognition has attracted increasing attention in
recent years. However, most of the existing works focus on supervised learning
which requiring a large number of annotated action sequences that are often
expensive to collect. We investigate unsupervised representation learning for
skeleton action recognition, and design a novel skeleton cloud colorization
technique that is capable of learning skeleton representations from unlabeled
skeleton sequence data. Specifically, we represent a skeleton action sequence
as a 3D skeleton cloud and colorize each point in the cloud according to its
temporal and spatial orders in the original (unannotated) skeleton sequence.
Leveraging the colorized skeleton point cloud, we design an auto-encoder
framework that can learn spatial-temporal features from the artificial color
labels of skeleton joints effectively. We evaluate our skeleton cloud
colorization approach with action classifiers trained under different
configurations, including unsupervised, semi-supervised and fully-supervised
settings. Extensive experiments on NTU RGB+D and NW-UCLA datasets show that the
proposed method outperforms existing unsupervised and semi-supervised 3D action
recognition methods by large margins, and it achieves competitive performance
in supervised 3D action recognition as well.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Optimal Transport for Unsupervised Restoration Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wen_F/0/1/0/all/0/1">Fei Wen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Z/0/1/0/all/0/1">Zeyu Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Ying_R/0/1/0/all/0/1">Rendong Ying</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1">Peilin Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02574">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, much progress has been made in unsupervised restoration learning.
However, existing methods more or less rely on some assumptions on the signal
and/or degradation model, which limits their practical performance. How to
construct an optimal criterion for unsupervised restoration learning without
any prior knowledge on the degradation model is still an open question. Toward
answering this question, this work proposes a criterion for unsupervised
restoration learning based on the optimal transport theory. This criterion has
favorable properties, e.g., approximately maximal preservation of the
information of the signal, whilst achieving perceptual reconstruction.
Furthermore, though a relaxed unconstrained formulation is used in practical
implementation, we show that the relaxed formulation in theory has the same
solution as the original constrained formulation. Experiments on synthetic and
real-world data, including realistic photographic, microscopy, depth, and raw
depth images, demonstrate that the proposed method even compares favorably with
supervised methods, e.g., approaching the PSNR of supervised methods while
having better perceptual quality. Particularly, for spatially correlated noise
and realistic microscopy images, the proposed method not only achieves better
perceptual quality but also has higher PSNR than supervised methods. Besides,
it shows remarkable superiority in harsh practical conditions with complex
noise, e.g., raw depth images.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Simpler is Better: Few-shot Semantic Segmentation with Classifier Weight <span class="highlight_title">Transformer</span>.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+lu_Z/0/1/0/all/0/1">Zhihe lu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Sen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tao Xiang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03032">
                                        <div class="article-summary-box-inner">
                                            <span><p>A few-shot semantic segmentation model is typically composed of a CNN
encoder, a CNN decoder and a simple classifier (separating foreground and
background pixels). Most existing methods meta-learn all three model components
for fast adaptation to a new class. However, given that as few as a single
support set image is available, effective model adaption of all three
components to the new class is extremely challenging. In this work we propose
to simplify the meta-learning task by focusing solely on the simplest
component, the classifier, whilst leaving the encoder and decoder to
pre-training. We hypothesize that if we pre-train an off-the-shelf segmentation
model over a set of diverse training classes with sufficient annotations, the
encoder and decoder can capture rich discriminative features applicable for any
unseen classes, rendering the subsequent meta-learning stage unnecessary. For
the classifier meta-learning, we introduce a Classifier Weight Transformer
(CWT) designed to dynamically adapt the supportset trained classifier's weights
to each query image in an inductive way. Extensive experiments on two standard
benchmarks show that despite its simplicity, our method outperforms the
state-of-the-art alternatives, often by a large margin.Code is available on
https://github.com/zhiheLu/CWT-for-FSS.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ GLASS: Geometric Latent Augmentation for Shape Spaces.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Muralikrishnan_S/0/1/0/all/0/1">Sanjeev Muralikrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Siddhartha Chaudhuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Aigerman_N/0/1/0/all/0/1">Noam Aigerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_V/0/1/0/all/0/1">Vladimir Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisher_M/0/1/0/all/0/1">Matthew Fisher</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1">Niloy Mitra</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03225">
                                        <div class="article-summary-box-inner">
                                            <span><p>We investigate the problem of training generative models on a very sparse
collection of 3D models. We use geometrically motivated energies to augment and
thus boost a sparse collection of example (training) models. We analyze the
Hessian of the as-rigid-as-possible (ARAP) energy to sample from and project to
the underlying (local) shape space, and use the augmented dataset to train a
variational autoencoder (VAE). We iterate the process of building latent spaces
of VAE and augmenting the associated dataset, to progressively reveal a richer
and more expressive generative space for creating geometrically and
semantically valid samples. Our framework allows us to train generative 3D
models even with a small set of good quality 3D models, which are typically
hard to curate. We extensively evaluate our method against a set of strong
baselines, provide ablation studies and demonstrate application towards
establishing shape correspondences. We present multiple examples of interesting
and meaningful shape variations even when starting from as few as 3-10 training
shapes.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.LG updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Operational Learning-based Boundary Estimation in Electromagnetic Medical Imaging.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Al_Saffar_A/0/1/0/all/0/1">A. Al-Saffar</a>, <a href="http://arxiv.org/find/cs/1/au:+Stancombe_A/0/1/0/all/0/1">A. Stancombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_A/0/1/0/all/0/1">A. Zamani</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbosh_A/0/1/0/all/0/1">A. Abbosh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03233">
                                        <div class="article-summary-box-inner">
                                            <span><p>Incorporating boundaries of the imaging object as a priori information to
imaging algorithms can significantly improve the performance of electromagnetic
medical imaging systems. To avoid overly complicating the system by using
different sensors and the adverse effect of the subject's movement, a
learning-based method is proposed to estimate the boundary (external contour)
of the imaged object using the same electromagnetic imaging data. While imaging
techniques may discard the reflection coefficients for being dominant and
uninformative for imaging, these parameters are made use of for boundary
detection. The learned model is verified through independent clinical human
trials by using a head imaging system with a 16-element antenna array that
works across the band 0.7-1.6 GHz. The evaluation demonstrated that the model
achieves average dissimilarity of 0.012 in Hu-moment while detecting head
boundary. The model enables fast scan and image creation while eliminating the
need for additional devices for accurate boundary estimation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ SMOTified-GAN for class imbalanced pattern classification problems.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Anuraganand Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhat Kumar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1">Rohitash Chandra</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03235">
                                        <div class="article-summary-box-inner">
                                            <span><p>Class imbalance in a dataset is a major problem for classifiers that results
in poor prediction with a high true positive rate (TPR) but a low true negative
rate (TNR) for a majority positive training dataset. Generally, the
pre-processing technique of oversampling of minority class(es) are used to
overcome this deficiency. Our focus is on using the hybridization of Generative
Adversarial Network (GAN) and Synthetic Minority Over-Sampling Technique
(SMOTE) to address class imbalanced problems. We propose a novel two-phase
oversampling approach that has the synergy of SMOTE and GAN. The initial data
of minority class(es) generated by SMOTE is further enhanced by GAN that
produces better quality samples. We named it SMOTified-GAN as GAN works on
pre-sampled minority data produced by SMOTE rather than randomly generating the
samples itself. The experimental results prove the sample quality of minority
class(es) has been improved in a variety of tested benchmark datasets. Its
performance is improved by up to 9\% from the next best algorithm tested on
F1-score measurements. Its time complexity is also reasonable which is around
$O(N^2d^2T)$ for a sequential algorithm.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Efficient Representation for Electric Vehicle Charging Station Operations using Reinforcement Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kwon_K/0/1/0/all/0/1">Kyung-bin Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03236">
                                        <div class="article-summary-box-inner">
                                            <span><p>Effectively operating electrical vehicle charging station (EVCS) is crucial
for enabling the rapid transition of electrified transportation. To solve this
problem using reinforcement learning (RL), the dimension of state/action spaces
scales with the number of EVs and is thus very large and time-varying. This
dimensionality issue affects the efficiency and convergence properties of
generic RL algorithms. We develop aggregation schemes that are based on the
emergency of EV charging, namely the laxity value. A least-laxity first (LLF)
rule is adopted to consider only the total charging power of the EVCS which
ensures the feasibility of individual EV schedules. In addition, we propose an
equivalent state aggregation that can guarantee to attain the same optimal
policy. Based on the proposed representation, policy gradient method is used to
find the best parameters for the linear Gaussian policy . Numerical results
have validated the performance improvement of the proposed representation
approaches in attaining higher rewards and more effective policies as compared
to existing approximation based approach.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ IGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Lingelbach_M/0/1/0/all/0/1">Michael Lingelbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1">Bokui Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokmen_C/0/1/0/all/0/1">Cem Gokmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dharan_G/0/1/0/all/0/1">Gokul Dharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_T/0/1/0/all/0/1">Tanish Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurenkov_A/0/1/0/all/0/1">Andrey Kurenkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gweon_H/0/1/0/all/0/1">Hyowon Gweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"><span class="highlight_author">Jiajun Wu</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1"><span class="highlight_author">Li Fei-Fei</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03272">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset will be publicly available at
<a href="http://svl.stanford.edu/igibson/.">this http URL</a>
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Concept Drift Detection with Variable Interaction Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zenisek_J/0/1/0/all/0/1">Jan Zenisek</a>, <a href="http://arxiv.org/find/cs/1/au:+Kronberger_G/0/1/0/all/0/1">Gabriel Kronberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfartsberger_J/0/1/0/all/0/1">Josef Wolfartsberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wild_N/0/1/0/all/0/1">Norbert Wild</a>, <a href="http://arxiv.org/find/cs/1/au:+Affenzeller_M/0/1/0/all/0/1">Michael Affenzeller</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03273">
                                        <div class="article-summary-box-inner">
                                            <span><p>The current development of today's production industry towards seamless
sensor-based monitoring is paving the way for concepts such as Predictive
Maintenance. By this means, the condition of plants and products in future
production lines will be continuously analyzed with the objective to predict
any kind of breakdown and trigger preventing actions proactively. Such
ambitious predictions are commonly performed with support of machine learning
algorithms. In this work, we utilize these algorithms to model complex systems,
such as production plants, by focusing on their variable interactions. The core
of this contribution is a sliding window based algorithm, designed to detect
changes of the identified interactions, which might indicate beginning
malfunctions in the context of a monitored production plant. Besides a detailed
description of the algorithm, we present results from experiments with a
synthetic dynamical system, simulating stable and drifting system behavior.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Smooth Symbolic Regression: Transformation of Symbolic Regression into a Real-valued Optimization Problem.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Pitzer_E/0/1/0/all/0/1">Erik Pitzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kronberger_G/0/1/0/all/0/1">Gabriel Kronberger</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03274">
                                        <div class="article-summary-box-inner">
                                            <span><p>The typical methods for symbolic regression produce rather abrupt changes in
solution candidates. In this work, we have tried to transform symbolic
regression from an optimization problem, with a landscape that is so rugged
that typical analysis methods do not produce meaningful results, to one that
can be compared to typical and very smooth real-valued problems. While the
ruggedness might not interfere with the performance of optimization, it
restricts the possibilities of analysis. Here, we have explored different
aspects of a transformation and propose a simple procedure to create
real-valued optimization problems from symbolic regression problems.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Ensemble Augmentation for Deep Neural Networks Using 1-D Time Series Vibration Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Faysal_A/0/1/0/all/0/1">Atik Faysal</a>, <a href="http://arxiv.org/find/cs/1/au:+Keng_N/0/1/0/all/0/1">Ngui Wai Keng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1">M. H. Lim</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03288">
                                        <div class="article-summary-box-inner">
                                            <span><p>Time-series data are one of the fundamental types of raw data representation
used in data-driven techniques. In machine condition monitoring, time-series
vibration data are overly used in data mining for deep neural networks.
Typically, vibration data is converted into images for classification using
Deep Neural Networks (DNNs), and scalograms are the most effective form of
image representation. However, the DNN classifiers require huge labeled
training samples to reach their optimum performance. So, many forms of data
augmentation techniques are applied to the classifiers to compensate for the
lack of training samples. However, the scalograms are graphical representations
where the existing augmentation techniques suffer because they either change
the graphical meaning or have too much noise in the samples that change the
physical meaning. In this study, a data augmentation technique named ensemble
augmentation is proposed to overcome this limitation. This augmentation method
uses the power of white noise added in ensembles to the original samples to
generate real-like samples. After averaging the signal with ensembles, a new
signal is obtained that contains the characteristics of the original signal.
The parameters for the ensemble augmentation are validated using a simulated
signal. The proposed method is evaluated using 10 class bearing vibration data
using three state-of-the-art Transfer Learning (TL) models, namely,
Inception-V3, MobileNet-V2, and ResNet50. Augmented samples are generated in
two increments: the first increment generates the same number of fake samples
as the training samples, and in the second increment, the number of samples is
increased gradually. The outputs from the proposed method are compared with no
augmentation, augmentations using deep convolution generative adversarial
network (DCGAN), and several geometric transformation-based augmentations...
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Joint AP Probing and Scheduling: A Contextual Bandit Approach.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tianyi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Ding Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_P/0/1/0/all/0/1">Parth H. Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zizhan Zheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03297">
                                        <div class="article-summary-box-inner">
                                            <span><p>We consider a set of APs with unknown data rates that cooperatively serve a
mobile client. The data rate of each link is i.i.d. sampled from a distribution
that is unknown a priori. In contrast to traditional link scheduling problems
under uncertainty, we assume that in each time step, the device can probe a
subset of links before deciding which one to use. We model this problem as a
contextual bandit problem with probing (CBwP) and present an efficient
algorithm. We further establish the regret of our algorithm for links with
Bernoulli data rates. Our CBwP model is a novel extension of the classic
contextual bandit model and can potentially be applied to a large class of
sequential decision-making problems that involve joint probing and play under
uncertainty.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ What Matters in Learning from Offline Human Demonstrations for Robot Manipulation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mandlekar_A/0/1/0/all/0/1">Ajay Mandlekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Danfei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1">Josiah Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasiriany_S/0/1/0/all/0/1">Soroush Nasiriany</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_R/0/1/0/all/0/1">Rohun Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1"><span class="highlight_author">Li Fei-Fei</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03298">
                                        <div class="article-summary-box-inner">
                                            <span><p>Imitating human demonstrations is a promising approach to endow robots with
various manipulation capabilities. While recent advances have been made in
imitation learning and batch (offline) reinforcement learning, a lack of
open-source human datasets and reproducible learning methods make assessing the
state of the field difficult. In this paper, we conduct an extensive study of
six offline learning algorithms for robot manipulation on five simulated and
three real-world multi-stage manipulation tasks of varying complexity, and with
datasets of varying quality. Our study analyzes the most critical challenges
when learning from offline human data for manipulation. Based on the study, we
derive a series of lessons including the sensitivity to different algorithmic
design choices, the dependence on the quality of the demonstrations, and the
variability based on the stopping criteria due to the different objectives in
training and evaluation. We also highlight opportunities for learning from
human datasets, such as the ability to learn proficient policies on
challenging, multi-stage tasks beyond the scope of current reinforcement
learning methods, and the ability to easily scale to natural, real-world
manipulation scenarios where only raw sensory signals are available. We have
open-sourced our datasets and all algorithm implementations to facilitate
future research and fair comparisons in learning from human demonstration data.
Codebase, datasets, trained models, and more available at
https://arise-initiative.github.io/robomimic-web/
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Deep Neural Network Approach for Crop Selection and Yield Prediction in Bangladesh.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chisty_T/0/1/0/all/0/1">Tanjir Alam Chisty</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_A/0/1/0/all/0/1">Amitabha Chakrabarty</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03320">
                                        <div class="article-summary-box-inner">
                                            <span><p>Agriculture is the essential ingredients to mankind which is a major source
of livelihood. Agriculture work in Bangladesh is mostly done in old ways which
directly affects our economy. In addition, institutions of agriculture are
working with manual data which cannot provide a proper solution for crop
selection and yield prediction. This paper shows the best way of crop selection
and yield prediction in minimum cost and effort. Artificial Neural Network is
considered robust tools for modeling and prediction. This algorithm aims to get
better output and prediction, as well as, support vector machine, Logistic
Regression, and random forest algorithm is also considered in this study for
comparing the accuracy and error rate. Moreover, all of these algorithms used
here are just to see how well they performed for a dataset which is over 0.3
million. We have collected 46 parameters such as maximum and minimum
temperature, average rainfall, humidity, climate, weather, and types of land,
types of chemical fertilizer, types of soil, soil structure, soil composition,
soil moisture, soil consistency, soil reaction and soil texture for applying
into this prediction process. In this paper, we have suggested using the deep
neural network for agricultural crop selection and yield prediction.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Distilling <span class="highlight_title">Transformer</span>s for Neural Cross-Domain Search.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1">Colin B. Clement</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1">Dawn Drain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1">Neel Sundaresan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03322">
                                        <div class="article-summary-box-inner">
                                            <span><p>Pre-trained transformers have recently clinched top spots in the gamut of
natural language tasks and pioneered solutions to software engineering tasks.
Even information retrieval has not been immune to the charm of the transformer,
though their large size and cost is generally a barrier to deployment. While
there has been much work in streamlining, caching, and modifying transformer
architectures for production, here we explore a new direction: distilling a
large pre-trained translation model into a lightweight bi-encoder which can be
efficiently cached and queried. We argue from a probabilistic perspective that
sequence-to-sequence models are a conceptually ideal---albeit highly
impractical---retriever. We derive a new distillation objective, implementing
it as a data augmentation scheme. Using natural language source code search as
a case study for cross-domain search, we demonstrate the validity of this idea
by significantly improving upon the current leader of the CodeSearchNet
challenge, a recent natural language code search benchmark.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Estimating Graph Dimension with Cross-validated Eigenvalues.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Chen_F/0/1/0/all/0/1">Fan Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Roch_S/0/1/0/all/0/1">Sebastien Roch</a>, <a href="http://arxiv.org/find/stat/1/au:+Rohe_K/0/1/0/all/0/1">Karl Rohe</a>, <a href="http://arxiv.org/find/stat/1/au:+Yu_S/0/1/0/all/0/1">Shuqi Yu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03336">
                                        <div class="article-summary-box-inner">
                                            <span><p>In applied multivariate statistics, estimating the number of latent
dimensions or the number of clusters is a fundamental and recurring problem.
One common diagnostic is the scree plot, which shows the largest eigenvalues of
the data matrix; the user searches for a "gap" or "elbow" in the decreasing
eigenvalues; unfortunately, these patterns can hide beneath the bias of the
sample eigenvalues. This methodological problem is conceptually difficult
because, in many situations, there is only enough signal to detect a subset of
the $k$ population dimensions/eigenvectors. In this situation, one could argue
that the correct choice of $k$ is the number of detectable dimensions. We
alleviate these problems with cross-validated eigenvalues. Under a large class
of random graph models, without any parametric assumptions, we provide a
p-value for each sample eigenvector. It tests the null hypothesis that this
sample eigenvector is orthogonal to (i.e., uncorrelated with) the true latent
dimensions. This approach naturally adapts to problems where some dimensions
are not statistically detectable. In scenarios where all $k$ dimensions can be
estimated, we prove that our procedure consistently estimates $k$. In
simulations and a data example, the proposed estimator compares favorably to
alternative approaches in both computational and statistical performance.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Edge-augmented Graph <span class="highlight_title">Transformer</span>s: Global Self-attention is Enough for Graphs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hussain_M/0/1/0/all/0/1">Md Shamim Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaki_M/0/1/0/all/0/1">Mohammed J. Zaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_D/0/1/0/all/0/1">Dharmashankar Subramanian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03348">
                                        <div class="article-summary-box-inner">
                                            <span><p>Transformer neural networks have achieved state-of-the-art results for
unstructured data such as text and images but their adoption for
graph-structured data has been limited. This is partly due to the difficulty in
incorporating complex structural information in the basic transformer
framework. We propose a simple yet powerful extension to the transformer -
residual edge channels. The resultant framework, which we call Edge-augmented
Graph Transformer (EGT), can directly accept, process and output structural
information as well as node information. This simple addition allows us to use
global self-attention, the key element of transformers, directly for graphs and
comes with the benefit of long-range interaction among nodes. Moreover, the
edge channels allow the structural information to evolve from layer to layer,
and prediction tasks on edges can be derived directly from these channels. In
addition to that, we introduce positional encodings based on Singular Value
Decomposition which can improve the performance of EGT. Our framework, which
relies on global node feature aggregation, achieves better performance compared
to Graph Convolutional Networks (GCN), which rely on local feature aggregation
within a neighborhood. We verify the performance of EGT in a supervised
learning setting on a wide range of experiments on benchmark datasets. Our
findings indicate that convolutional aggregation is not an essential inductive
bias for graphs and global self-attention can serve as a flexible and adaptive
alternative to graph convolution.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bryan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhourong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Grossman_T/0/1/0/all/0/1">Tovi Grossman</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03353">
                                        <div class="article-summary-box-inner">
                                            <span><p>Mobile User Interface Summarization generates succinct language descriptions
of mobile screens for conveying important contents and functionalities of the
screen, which can be useful for many language-based application scenarios. We
present Screen2Words, a novel screen summarization approach that automatically
encapsulates essential information of a UI screen into a coherent language
phrase. Summarizing mobile screens requires a holistic understanding of the
multi-modal data of mobile UIs, including text, image, structures as well as UI
semantics, motivating our multi-modal learning approach. We collected and
analyzed a large-scale screen summarization dataset annotated by human workers.
Our dataset contains more than 112k language summarization across $\sim$22k
unique UI screens. We then experimented with a set of deep models with
different configurations. Our evaluation of these models with both automatic
accuracy metrics and human rating shows that our approach can generate
high-quality summaries for mobile screens. We demonstrate potential use cases
of Screen2Words and open-source our dataset and model to lay the foundations
for further bridging language and user interfaces.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ HetEmotionNet: Two-Stream Heterogeneous Graph Recurrent Neural Network for Multi-modal Emotion Recognition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Ziyu Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Youfang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhiyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiangheng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Caijie Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03354">
                                        <div class="article-summary-box-inner">
                                            <span><p>The research on human emotion under multimedia stimulation based on
physiological signals is an emerging field, and important progress has been
achieved for emotion recognition based on multi-modal signals. However, it is
challenging to make full use of the complementarity among
spatial-spectral-temporal domain features for emotion recognition, as well as
model the heterogeneity and correlation among multi-modal signals. In this
paper, we propose a novel two-stream heterogeneous graph recurrent neural
network, named HetEmotionNet, fusing multi-modal physiological signals for
emotion recognition. Specifically, HetEmotionNet consists of the
spatial-temporal stream and the spatial-spectral stream, which can fuse
spatial-spectral-temporal domain features in a unified framework. Each stream
is composed of the graph transformer network for modeling the heterogeneity,
the graph convolutional network for modeling the correlation, and the gated
recurrent unit for capturing the temporal domain or spectral domain dependency.
Extensive experiments on two real-world datasets demonstrate that our proposed
model achieves better performance than state-of-the-art baselines.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zang_T/0/1/0/all/0/1">Tianzi Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanmin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haobing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiadi Yu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03357">
                                        <div class="article-summary-box-inner">
                                            <span><p>Traditional recommendation systems are faced with two long-standing
obstacles, namely, data sparsity and cold-start problems, which promote the
emergence and development of Cross-Domain Recommendation (CDR). The core idea
of CDR is to leverage information collected from other domains to alleviate the
two problems in one domain. Over the last decade, many efforts have been
engaged for cross-domain recommendation. Recently, with the development of deep
learning and neural networks, a large number of methods have emerged. However,
there is a limited number of systematic surveys on CDR, especially regarding
the latest proposed methods as well as the recommendation scenarios and
recommendation tasks they address. In this survey paper, we first proposed a
two-level taxonomy of cross-domain recommendation which classifies different
recommendation scenarios and recommendation tasks. We then introduce and
summarize existing cross-domain recommendation approaches under different
recommendation scenarios in a structured manner. We also organize datasets
commonly used. We conclude this survey by providing several potential research
directions about this field.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning Indoor Layouts from Simple Point-Clouds.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mahmood_M/0/1/0/all/0/1">Md. Tareq Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohammed Eunus Ali</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03378">
                                        <div class="article-summary-box-inner">
                                            <span><p>Reconstructing a layout of indoor spaces has been a crucial part of growing
indoor location based services. One of the key challenges in the proliferation
of indoor location based services is the unavailability of indoor spatial maps
due to the complex nature of capturing an indoor space model (e.g., floor plan)
of an existing building. In this paper, we propose a system to automatically
generate floor plans that can recognize rooms from the point-clouds obtained
through smartphones like Google's Tango. In particular, we propose two
approaches - a Recurrent Neural Network based approach using Pointer Network
and a Convolutional Neural Network based approach using Mask-RCNN to identify
rooms (and thereby floor plans) from point-clouds. Experimental results on
different datasets demonstrate approximately 0.80-0.90 Intersection-over-Union
scores, which show that our models can effectively identify the rooms and
regenerate the shapes of the rooms in heterogeneous environment.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Jointly Attacking Graph Neural Network and its Explanations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wenqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Han Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xianfeng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Suhang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1">Charu Aggarwal</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03388">
                                        <div class="article-summary-box-inner">
                                            <span><p>Graph Neural Networks (GNNs) have boosted the performance for many
graph-related tasks. Despite the great success, recent studies have shown that
GNNs are highly vulnerable to adversarial attacks, where adversaries can
mislead the GNNs' prediction by modifying graphs. On the other hand, the
explanation of GNNs (GNNExplainer) provides a better understanding of a trained
GNN model by generating a small subgraph and features that are most influential
for its prediction. In this paper, we first perform empirical studies to
validate that GNNExplainer can act as an inspection tool and have the potential
to detect the adversarial perturbations for graphs. This finding motivates us
to further initiate a new problem investigation: Whether a graph neural network
and its explanations can be jointly attacked by modifying graphs with malicious
desires? It is challenging to answer this question since the goals of
adversarial attacks and bypassing the GNNExplainer essentially contradict each
other. In this work, we give a confirmative answer to this question by
proposing a novel attack framework (GEAttack), which can attack both a GNN
model and its explanations by simultaneously exploiting their vulnerabilities.
Extensive experiments on two explainers (GNNExplainer and PGExplainer) under
various real-world datasets demonstrate the effectiveness of the proposed
method.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Missing Data Estimation in Temporal Multilayer Position-aware Graph Neural Network (TMP-GNN).
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Najafi_B/0/1/0/all/0/1">Bahareh Najafi</a>, <a href="http://arxiv.org/find/cs/1/au:+Parsaeefard_S/0/1/0/all/0/1">Saeedeh Parsaeefard</a>, <a href="http://arxiv.org/find/cs/1/au:+Leon_Garcia_A/0/1/0/all/0/1">Alberto Leon-Garcia</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03400">
                                        <div class="article-summary-box-inner">
                                            <span><p>GNNs have been proven to perform highly effective in various node-level,
edge-level, and graph-level prediction tasks in several domains. Existing
approaches mainly focus on static graphs. However, many graphs change over time
with their edge may disappear, or node or edge attribute may alter from one
time to the other. It is essential to consider such evolution in representation
learning of nodes in time varying graphs. In this paper, we propose a Temporal
Multilayered Position-aware Graph Neural Network (TMP-GNN), a node embedding
approach for dynamic graph that incorporates the interdependence of temporal
relations into embedding computation. We evaluate the performance of TMP-GNN on
two different representations of temporal multilayered graphs. The performance
is assessed against the most popular GNNs on node-level prediction tasks. Then,
we incorporate TMP-GNN into a deep learning framework to estimate missing data
and compare the performance with their corresponding competent GNNs from our
former experiment, and a baseline method. Experimental results on four
real-world datasets yield up to 58% of lower ROC AUC for pairwise node
classification task, and 96% of lower MAE in missing feature estimation,
particularly for graphs with a relatively high number of nodes and lower mean
degree of connectivity.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unsupervised learning of anomalous diffusion data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cond-mat/1/au:+Munoz_Gil_G/0/1/0/all/0/1">Gorka Mu&#xf1;oz-Gil</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Corominas_G/0/1/0/all/0/1">Guillem Guig&#xf3; i Corominas</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Lewenstein_M/0/1/0/all/0/1">Maciej Lewenstein</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03411">
                                        <div class="article-summary-box-inner">
                                            <span><p>The characterization of diffusion processes is a keystone in our
understanding of a variety of physical phenomena. Many of these deviate from
Brownian motion, giving rise to anomalous diffusion. Various theoretical models
exists nowadays to describe such processes, but their application to
experimental setups is often challenging, due to the stochastic nature of the
phenomena and the difficulty to harness reliable data. The latter often
consists on short and noisy trajectories, which are hard to characterize with
usual statistical approaches. In recent years, we have witnessed an impressive
effort to bridge theory and experiments by means of supervised machine learning
techniques, with astonishing results. In this work, we explore the use of
unsupervised methods in anomalous diffusion data. We show that the main
diffusion characteristics can be learnt without the need of any labelling of
the data. We use such method to discriminate between anomalous diffusion models
and extract their physical parameters. Moreover, we explore the feasibility of
finding novel types of diffusion, in this case represented by compositions of
existing diffusion models. At last, we showcase the use of the method in
experimental data and demonstrate its advantages for cases where supervised
learning is not applicable.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Secure Neuroimaging Analysis using Federated Learning with Homomorphic Encryption.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Stripelis_D/0/1/0/all/0/1">Dimitris Stripelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleem_H/0/1/0/all/0/1">Hamza Saleem</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghai_T/0/1/0/all/0/1">Tanmay Ghai</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhinagar_N/0/1/0/all/0/1">Nikhil Dhinagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1">Umang Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasiou_C/0/1/0/all/0/1">Chrysovalantis Anastasiou</a>, <a href="http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1">Greg Ver Steeg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1">Srivatsan Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Naveed_M/0/1/0/all/0/1">Muhammad Naveed</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_P/0/1/0/all/0/1">Paul M. Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambite_J/0/1/0/all/0/1">Jose Luis Ambite</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03437">
                                        <div class="article-summary-box-inner">
                                            <span><p>Federated learning (FL) enables distributed computation of machine learning
models over various disparate, remote data sources, without requiring to
transfer any individual data to a centralized location. This results in an
improved generalizability of models and efficient scaling of computation as
more sources and larger datasets are added to the federation. Nevertheless,
recent membership attacks show that private or sensitive personal data can
sometimes be leaked or inferred when model parameters or summary statistics are
shared with a central site, requiring improved security solutions. In this
work, we propose a framework for secure FL using fully-homomorphic encryption
(FHE). Specifically, we use the CKKS construction, an approximate, floating
point compatible scheme that benefits from ciphertext packing and rescaling. In
our evaluation on large-scale brain MRI datasets, we use our proposed secure FL
framework to train a deep learning model to predict a person's age from
distributed MRI scans, a common benchmarking task, and demonstrate that there
is no degradation in the learning performance between the encrypted and
non-encrypted federated models.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Clustering Large Data Sets with Incremental Estimation of Low-density Separating Hyperplanes.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Hofmeyr_D/0/1/0/all/0/1">David P. Hofmeyr</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03442">
                                        <div class="article-summary-box-inner">
                                            <span><p>An efficient method for obtaining low-density hyperplane separators in the
unsupervised context is proposed. Low density separators can be used to obtain
a partition of a set of data based on their allocations to the different sides
of the separators. The proposed method is based on applying stochastic gradient
descent to the integrated density on the hyperplane with respect to a
convolution of the underlying distribution and a smoothing kernel. In the case
where the bandwidth of the smoothing kernel is decreased towards zero, the bias
of these updates with respect to the true underlying density tends to zero, and
convergence to a minimiser of the density on the hyperplane can be obtained. A
post-processing of the partition induced by a collection of low-density
hyperplanes yields an efficient and accurate clustering method which is capable
of automatically selecting an appropriate number of clusters. Experiments with
the proposed approach show that it is highly competitive in terms of both speed
and accuracy when compared with relevant benchmarks. Code to implement the
proposed approach is available in the form of an R package from
https://github.com/DavidHofmeyr/iMDH.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Machine Learning Tool to Determine State of Mind and Emotion.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jamisola_R/0/1/0/all/0/1">Rodrigo S. Jamisola Jr</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03444">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper investigates the possibility of creating a machine learning tool
that automatically determines the state of mind and emotion of an individual
through a questionnaire, without the aid of a human expert. The state of mind
and emotion is defined in this work as pertaining to preference, feelings, or
opinion that is not based on logic or reason. It is the case when a person
gives out an answer to start by saying, "I feel...". The tool is designed to
mimic the expertise of a psychologist and is built without any formal knowledge
of psychology. The idea is to build the expertise by purely computational
methods through thousands of questions collected from users. It is aimed
towards possibly diagnosing substance addiction, alcoholism, sexual attraction,
HIV status, degree of commitment, activity inclination, etc. First, the paper
presents the related literature and classifies them according to data gathering
methods. Another classification is created according to preference, emotion,
grouping, and rules to achieve a deeper interpretation and better understanding
of the state of mind and emotion. Second, the proposed tool is developed using
an online addiction questionnaire with 10 questions and 292 respondents. In
addition, an initial investigation on the dimension of addiction is presented
through the built machine learning model. Machine learning methods, namely,
artificial neural network (ANN) and support vector machine (SVM), are used to
determine a true or false or degree of state of a respondent.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Self-learning sparse PCA for multimode process monitoring.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingxin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Donghua Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Maoyin Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03449">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper proposes a novel sparse principal component analysis algorithm
with self-learning ability for successive modes, where synaptic intelligence is
employed to measure the importance of variables and a regularization term is
added to preserve the learned knowledge of previous modes. Different from
traditional multimode monitoring methods, the monitoring model is updated based
on the current model and new data when a new mode arrives, thus delivering
prominent performance for sequential modes. Besides, the computation and
storage resources are saved in the long run, because it is not necessary to
retrain the model from scratch frequently and store data from previous modes.
More importantly, the model furnishes excellent interpretability owing to the
sparsity of parameters. Finally, a numerical case and a practical pulverizing
system are adopted to illustrate the effectiveness of the proposed algorithm.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Stereo Waterdrop Removal with Row-wise Dilated Attention.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zifan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1">Dit-Yan Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03457">
                                        <div class="article-summary-box-inner">
                                            <span><p>Existing vision systems for autonomous driving or robots are sensitive to
waterdrops adhered to windows or camera lenses. Most recent waterdrop removal
approaches take a single image as input and often fail to recover the missing
content behind waterdrops faithfully. Thus, we propose a learning-based model
for waterdrop removal with stereo images. To better detect and remove
waterdrops from stereo images, we propose a novel row-wise dilated attention
module to enlarge attention's receptive field for effective information
propagation between the two stereo images. In addition, we propose an attention
consistency loss between the ground-truth disparity map and attention scores to
enhance the left-right consistency in stereo images. Because of related
datasets' unavailability, we collect a real-world dataset that contains stereo
images with and without waterdrops. Extensive experiments on our dataset
suggest that our model outperforms state-of-the-art methods both quantitatively
and qualitatively. Our source code and the stereo waterdrop dataset are
available at
\href{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A k-mer Based Approach for SARS-CoV-2 Variant Identification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/q-bio/1/au:+Ali_S/0/1/0/all/0/1">Sarwan Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sahoo_B/0/1/0/all/0/1">Bikram Sahoo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ullah_N/0/1/0/all/0/1">Naimat Ullah</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zelikovskiy_A/0/1/0/all/0/1">Alexander Zelikovskiy</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Patterson_M/0/1/0/all/0/1">Murray Patterson</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khan_I/0/1/0/all/0/1">Imdadullah Khan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03465">
                                        <div class="article-summary-box-inner">
                                            <span><p>With the rapid spread of the novel coronavirus (COVID-19) across the globe
and its continuous mutation, it is of pivotal importance to design a system to
identify different known (and unknown) variants of SARS-CoV-2. Identifying
particular variants helps to understand and model their spread patterns, design
effective mitigation strategies, and prevent future outbreaks. It also plays a
crucial role in studying the efficacy of known vaccines against each variant
and modeling the likelihood of breakthrough infections. It is well known that
the spike protein contains most of the information/variation pertaining to
coronavirus variants.
</p>
<p>In this paper, we use spike sequences to classify different variants of the
coronavirus in humans. We show that preserving the order of the amino acids
helps the underlying classifiers to achieve better performance. We also show
that we can train our model to outperform the baseline algorithms using only a
small number of training samples ($1\%$ of the data). Finally, we show the
importance of the different amino acids which play a key role in identifying
variants and how they coincide with those reported by the USA's Centers for
Disease Control and Prevention (CDC).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ An empirical assessment of deep learning approaches to task-oriented dialog management.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Matej%5Cr%7Bu%7D_L/0/1/0/all/0/1">Luk&#xe1;&#x161; Mat&#x11b;j&#x16f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Griol_D/0/1/0/all/0/1">David Griol</a>, <a href="http://arxiv.org/find/cs/1/au:+Callejas_Z/0/1/0/all/0/1">Zoraida Callejas</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_J/0/1/0/all/0/1">Jos&#xe9; Manuel Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchis_A/0/1/0/all/0/1">Araceli Sanchis</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03478">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep learning is providing very positive results in areas related to
conversational interfaces, such as speech recognition, but its potential
benefit for dialog management has still not been fully studied. In this paper,
we perform an assessment of different configurations for deep-learned dialog
management with three dialog corpora from different application domains and
varying in size, dimensionality and possible system responses. Our results have
allowed us to identify several aspects that can have an impact on accuracy,
including the approaches used for feature extraction, input representation,
context consideration and the hyper-parameters of the deep neural networks
employed.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Impact of Aliasing on Generalization in Deep Convolutional Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1">Cristina Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Romijnders_R/0/1/0/all/0/1">Rob Romijnders</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>, <a href="http://arxiv.org/find/cs/1/au:+Goroshin_R/0/1/0/all/0/1">Ross Goroshin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03489">
                                        <div class="article-summary-box-inner">
                                            <span><p>We investigate the impact of aliasing on generalization in Deep Convolutional
Networks and show that data augmentation schemes alone are unable to prevent it
due to structural limitations in widely used architectures. Drawing insights
from frequency analysis theory, we take a closer look at ResNet and
EfficientNet architectures and review the trade-off between aliasing and
information loss in each of their major components. We show how to mitigate
aliasing by inserting non-trainable low-pass filters at key locations,
particularly where networks lack the capacity to learn them. These simple
architectural changes lead to substantial improvements in generalization on
i.i.d. and even more on out-of-distribution conditions, such as image
classification under natural corruptions on ImageNet-C [11] and few-shot
learning on Meta-Dataset [26]. State-of-the art results are achieved on both
datasets without introducing additional trainable parameters and using the
default hyper-parameters of open source codebases.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Clustering Algorithms to Analyze the Road Traffic Crashes.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Mahnaz Rafia Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenny_I/0/1/0/all/0/1">Israt Jahan Jenny</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayon_M/0/1/0/all/0/1">Moniruzzaman Nayon</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Md. Rajibul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Amiruzzaman_M/0/1/0/all/0/1">Md Amiruzzaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdullah_Al_Wadud_M/0/1/0/all/0/1">M. Abdullah-Al-Wadud</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03490">
                                        <div class="article-summary-box-inner">
                                            <span><p>Selecting an appropriate clustering method as well as an optimal number of
clusters in road accident data is at times confusing and difficult. This paper
analyzes shortcomings of different existing techniques applied to cluster
accident-prone areas and recommends using Density-Based Spatial Clustering of
Applications with Noise (DBSCAN) and Ordering Points To Identify the Clustering
Structure (OPTICS) to overcome them. Comparative performance analysis based on
real-life data on the recorded cases of road accidents in North Carolina also
show more effectiveness and efficiency achieved by these algorithms.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Approximate Last Iterate Convergence in Overparameterized GANs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Du_E/0/1/0/all/0/1">Elbert Du</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03491">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this work, we showed that the Implicit Update and Predictive Methods
dynamics introduced in prior work satisfy last iterate convergence to a
neighborhood around the optimum in overparameterized GANs, where the size of
the neighborhood shrinks with the width of the neural network. This is in
contrast to prior results, which only guaranteed average iterate convergence.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Kinematics clustering enables head impact subtyping for better traumatic brain injury prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Zhan_X/0/1/0/all/0/1">Xianghao Zhan</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1">Yiheng Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1">Yuzhe Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Cecchi_N/0/1/0/all/0/1">Nicholas J. Cecchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Gevaert_O/0/1/0/all/0/1">Olivier Gevaert</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeineh_M/0/1/0/all/0/1">Michael M. Zeineh</a>, <a href="http://arxiv.org/find/stat/1/au:+Grant_G/0/1/0/all/0/1">Gerald A. Grant</a>, <a href="http://arxiv.org/find/stat/1/au:+Camarillo_D/0/1/0/all/0/1">David B. Camarillo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03498">
                                        <div class="article-summary-box-inner">
                                            <span><p>Traumatic brain injury can be caused by various types of head impacts.
However, due to different kinematic characteristics, many brain injury risk
estimation models are not generalizable across the variety of impacts that
humans may sustain. The current definitions of head impact subtypes are based
on impact sources (e.g., football, traffic accident), which may not reflect the
intrinsic kinematic similarities of impacts across the impact sources. To
investigate the potential new definitions of impact subtypes based on
kinematics, 3,161 head impacts from various sources including simulation,
college football, mixed martial arts, and car racing were collected. We applied
the K-means clustering to cluster the impacts on 16 standardized temporal
features from head rotation kinematics. Then, we developed subtype-specific
ridge regression models for cumulative strain damage (using the threshold of
15%), which significantly improved the estimation accuracy compared with the
baseline method which mixed impacts from different sources and developed one
model (R^2 from 0.7 to 0.9). To investigate the effect of kinematic features,
we presented the top three critical features (maximum resultant angular
acceleration, maximum angular acceleration along the z-axis, maximum linear
acceleration along the y-axis) based on regression accuracy and used logistic
regression to find the critical points for each feature that partitioned the
subtypes. This study enables researchers to define head impact subtypes in a
data-driven manner, which leads to more generalizable brain injury risk
estimation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Membership Inference Attacks on Lottery Ticket Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bagmar_A/0/1/0/all/0/1">Aadesh Bagmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Maiya_S/0/1/0/all/0/1">Shishira R Maiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidwalka_S/0/1/0/all/0/1">Shruti Bidwalka</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Amol Deshpande</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03506">
                                        <div class="article-summary-box-inner">
                                            <span><p>The vulnerability of the Lottery Ticket Hypothesis has not been studied from
the purview of Membership Inference Attacks. Through this work, we are the
first to empirically show that the lottery ticket networks are equally
vulnerable to membership inference attacks. A Membership Inference Attack (MIA)
is the process of determining whether a data sample belongs to a training set
of a trained model or not. Membership Inference Attacks could leak critical
information about the training data that can be used for targeted attacks.
Recent deep learning models often have very large memory footprints and a high
computational cost associated with training and drawing inferences. Lottery
Ticket Hypothesis is used to prune the networks to find smaller sub-networks
that at least match the performance of the original model in terms of test
accuracy in a similar number of iterations. We used CIFAR-10, CIFAR-100, and
ImageNet datasets to perform image classification tasks and observe that the
attack accuracies are similar. We also see that the attack accuracy varies
directly according to the number of classes in the dataset and the sparsity of
the network. We demonstrate that these attacks are transferable across models
with high accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ The Effect of Training Parameters and Mechanisms on Decentralized Federated Learning based on MNIST Dataset.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuofan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_K/0/1/0/all/0/1">Kaicheng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdallah_C/0/1/0/all/0/1">Chaouki Abdallah</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03508">
                                        <div class="article-summary-box-inner">
                                            <span><p>Federated Learning is an algorithm suited for training models on
decentralized data, but the requirement of a central "server" node is a
bottleneck. In this document, we first introduce the notion of Decentralized
Federated Learning (DFL). We then perform various experiments on different
setups, such as changing model aggregation frequency, switching from
independent and identically distributed (IID) dataset partitioning to non-IID
partitioning with partial global sharing, using different optimization methods
across clients, and breaking models into segments with partial sharing. All
experiments are run on the MNIST handwritten digits dataset. We observe that
those altered training procedures are generally robust, albeit non-optimal. We
also observe failures in training when the variance between model weights is
too large. The open-source experiment code is accessible through
GitHub\footnote{Code was uploaded at
\url{https://github.com/zhzhang2018/DecentralizedFL}}.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Machine Learning Assisted Security Analysis of 5G-Network-Connected Systems.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Saha_T/0/1/0/all/0/1">Tanujay Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Aaraj_N/0/1/0/all/0/1">Najwa Aaraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1">Niraj K. Jha</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03514">
                                        <div class="article-summary-box-inner">
                                            <span><p>The core network architecture of telecommunication systems has undergone a
paradigm shift in the fifth-generation (5G)networks. 5G networks have
transitioned to software-defined infrastructures, thereby reducing their
dependence on hardware-based network functions. New technologies, like network
function virtualization and software-defined networking, have been incorporated
in the 5G core network (5GCN) architecture to enable this transition. This has
resulted in significant improvements in efficiency, performance, and robustness
of the networks. However, this has also made the core network more vulnerable,
as software systems are generally easier to compromise than hardware systems.
In this article, we present a comprehensive security analysis framework for the
5GCN. The novelty of this approach lies in the creation and analysis of attack
graphs of the software-defined and virtualized 5GCN through machine learning.
This analysis points to 119 novel possible exploits in the 5GCN. We demonstrate
that these possible exploits of 5GCN vulnerabilities generate five novel
attacks on the 5G Authentication and Key Agreement protocol. We combine the
attacks at the network, protocol, and the application layers to generate
complex attack vectors. In a case study, we use these attack vectors to find
four novel security loopholes in WhatsApp running on a 5G network.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning to Transfer with von Neumann Conditional Divergence.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shaker_A/0/1/0/all/0/1">Ammar Shaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shujian Yu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03531">
                                        <div class="article-summary-box-inner">
                                            <span><p>The similarity of feature representations plays a pivotal role in the success
of domain adaptation and generalization. Feature similarity includes both the
invariance of marginal distributions and the closeness of conditional
distributions given the desired response $y$ (e.g., class labels).
Unfortunately, traditional methods always learn such features without fully
taking into consideration the information in $y$, which in turn may lead to a
mismatch of the conditional distributions or the mix-up of discriminative
structures underlying data distributions. In this work, we introduce the
recently proposed von Neumann conditional divergence to improve the
transferability across multiple domains. We show that this new divergence is
differentiable and eligible to easily quantify the functional dependence
between features and $y$. Given multiple source tasks, we integrate this
divergence to capture discriminative information in $y$ and design novel
learning objectives assuming those source tasks are observed either
simultaneously or sequentially. In both scenarios, we obtain favorable
performance against state-of-the-art methods in terms of smaller generalization
error on new tasks and less catastrophic forgetting on source tasks (in the
sequential setup).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nguyen_E/0/1/0/all/0/1">Eric Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tu Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaminathan_V/0/1/0/all/0/1">Vishy Swaminathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Collomosse_J/0/1/0/all/0/1">John Collomosse</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03541">
                                        <div class="article-summary-box-inner">
                                            <span><p>Images tell powerful stories but cannot always be trusted. Matching images
back to trusted sources (attribution) enables users to make a more informed
judgment of the images they encounter online. We propose a robust image hashing
algorithm to perform such matching. Our hash is sensitive to manipulation of
subtle, salient visual details that can substantially change the story told by
an image. Yet the hash is invariant to benign transformations (changes in
quality, codecs, sizes, shapes, etc.) experienced by images during online
redistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph
Attention for Image Attribution Network); a robust image hashing model inspired
by recent successes of Transformers in the visual domain. OSCAR-Net constructs
a scene graph representation that attends to fine-grained changes of every
object's visual appearance and their spatial relationships. The network is
trained via contrastive learning on a dataset of original and manipulated
images yielding a state of the art image hash for content fingerprinting that
scales to millions of images.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Recurrent Graph Neural Networks for Rumor Detection in Online Forums.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Di Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartel_J/0/1/0/all/0/1">Jacob Bartel</a>, <a href="http://arxiv.org/find/cs/1/au:+Palowitch_J/0/1/0/all/0/1">John Palowitch</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03548">
                                        <div class="article-summary-box-inner">
                                            <span><p>The widespread adoption of online social networks in daily life has created a
pressing need for effectively classifying user-generated content. This work
presents techniques for classifying linked content spread on forum websites --
specifically, links to news articles or blogs -- using user interaction signals
alone. Importantly, online forums such as Reddit do not have a user-generated
social graph, which is assumed in social network behavioral-based
classification settings. Using Reddit as a case-study, we show how to obtain a
derived social graph, and use this graph, Reddit post sequences, and comment
trees as inputs to a Recurrent Graph Neural Network (R-GNN) encoder. We train
the R-GNN on news link categorization and rumor detection, showing superior
results to recent baselines. Our code is made publicly available at
https://github.com/google-research/social_cascades.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ <span class="highlight_title">Contrastive</span> Representation Learning for Rapid Intraoperative Diagnosis of Skull Base Tumors Imaged Using Stimulated Raman Histology.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Cheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1">Abhishek Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Linzey_J/0/1/0/all/0/1">Joseph Linzey</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1">Rushikesh Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sung Jik Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Sudharsan Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alber_D/0/1/0/all/0/1">Daniel Alber</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondepudi_A/0/1/0/all/0/1">Akhil Kondepudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Urias_E/0/1/0/all/0/1">Esteban Urias</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandian_B/0/1/0/all/0/1">Balaji Pandian</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Holou_W/0/1/0/all/0/1">Wajd Al-Holou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_S/0/1/0/all/0/1">Steve Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_B/0/1/0/all/0/1">B. Gregory Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Heth_J/0/1/0/all/0/1">Jason Heth</a>, <a href="http://arxiv.org/find/cs/1/au:+Freudiger_C/0/1/0/all/0/1">Chris Freudiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalsa_S/0/1/0/all/0/1">Siri Khalsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacione_D/0/1/0/all/0/1">Donato Pacione</a>, <a href="http://arxiv.org/find/cs/1/au:+Golfinos_J/0/1/0/all/0/1">John G. Golfinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Camelo_Piragua_S/0/1/0/all/0/1">Sandra Camelo-Piragua</a>, <a href="http://arxiv.org/find/cs/1/au:+Orringer_D/0/1/0/all/0/1">Daniel A. Orringer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hollon_T/0/1/0/all/0/1">Todd Hollon</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03555">
                                        <div class="article-summary-box-inner">
                                            <span><p>Background: Accurate diagnosis of skull base tumors is essential for
providing personalized surgical treatment strategies. Intraoperative diagnosis
can be challenging due to tumor diversity and lack of intraoperative pathology
resources.
</p>
<p>Objective: To develop an independent and parallel intraoperative pathology
workflow that can provide rapid and accurate skull base tumor diagnoses using
label-free optical imaging and artificial intelligence (AI).
</p>
<p>Method: We used a fiber laser-based, label-free, non-consumptive,
high-resolution microscopy method ($&lt;$ 60 sec per 1 $\times$ 1 mm$^\text{2}$),
called stimulated Raman histology (SRH), to image a consecutive, multicenter
cohort of skull base tumor patients. SRH images were then used to train a
convolutional neural network (CNN) model using three representation learning
strategies: cross-entropy, self-supervised contrastive learning, and supervised
contrastive learning. Our trained CNN models were tested on a held-out,
multicenter SRH dataset.
</p>
<p>Results: SRH was able to image the diagnostic features of both benign and
malignant skull base tumors. Of the three representation learning strategies,
supervised contrastive learning most effectively learned the distinctive and
diagnostic SRH image features for each of the skull base tumor types. In our
multicenter testing set, cross-entropy achieved an overall diagnostic accuracy
of 91.5%, self-supervised contrastive learning 83.9%, and supervised
contrastive learning 96.6%. Our trained model was able to identify tumor-normal
margins and detect regions of microscopic tumor infiltration in whole-slide SRH
images.
</p>
<p>Conclusion: SRH with AI models trained using contrastive representation
learning can provide rapid and accurate intraoperative diagnosis of skull base
tumors.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Combining machine learning and data assimilation to forecast dynamical systems from noisy partial observations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gottwald_G/0/1/0/all/0/1">Georg A. Gottwald</a>, <a href="http://arxiv.org/find/cs/1/au:+Reich_S/0/1/0/all/0/1">Sebastian Reich</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03561">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a supervised learning method to learn the propagator map of a
dynamical system from partial and noisy observations. In our computationally
cheap and easy-to-implement framework a neural network consisting of random
feature maps is trained sequentially by incoming observations within a data
assimilation procedure. By employing Takens' embedding theorem, the network is
trained on delay coordinates. We show that the combination of random feature
maps and data assimilation, called RAFDA, outperforms standard random feature
maps for which the dynamics is learned using batch data.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Robust 1-bit Compressive Sensing with Partial Gaussian Circulant Matrices and Generative Priors.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhaoqiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Subhroshekhar Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Scarlett_J/0/1/0/all/0/1">Jonathan Scarlett</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03570">
                                        <div class="article-summary-box-inner">
                                            <span><p>In 1-bit compressive sensing, each measurement is quantized to a single bit,
namely the sign of a linear function of an unknown vector, and the goal is to
accurately recover the vector. While it is most popular to assume a standard
Gaussian sensing matrix for 1-bit compressive sensing, using structured sensing
matrices such as partial Gaussian circulant matrices is of significant
practical importance due to their faster matrix operations. In this paper, we
provide recovery guarantees for a correlation-based optimization algorithm for
robust 1-bit compressive sensing with randomly signed partial Gaussian
circulant matrices and generative models. Under suitable assumptions, we match
guarantees that were previously only known to hold for i.i.d.~Gaussian matrices
that require significantly more computation. We make use of a practical
iterative algorithm, and perform numerical experiments on image datasets to
corroborate our theoretical results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ BeatNet: CRNN and Particle Filtering for Online Joint Beat Downbeat and Meter Tracking.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Heydari_M/0/1/0/all/0/1">Mojtaba Heydari</a>, <a href="http://arxiv.org/find/eess/1/au:+Cwitkowitz_F/0/1/0/all/0/1">Frank Cwitkowitz</a>, <a href="http://arxiv.org/find/eess/1/au:+Duan_Z/0/1/0/all/0/1">Zhiyao Duan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03576">
                                        <div class="article-summary-box-inner">
                                            <span><p>The online estimation of rhythmic information, such as beat positions,
downbeat positions, and meter, is critical for many real-time music
applications. Musical rhythm comprises complex hierarchical relationships
across time, rendering its analysis intrinsically challenging and at times
subjective. Furthermore, systems which attempt to estimate rhythmic information
in real-time must be causal and must produce estimates quickly and efficiently.
In this work, we introduce an online system for joint beat, downbeat, and meter
tracking, which utilizes causal convolutional and recurrent layers, followed by
a pair of sequential Monte Carlo particle filters applied during inference. The
proposed system does not need to be primed with a time signature in order to
perform downbeat tracking, and is instead able to estimate meter and adjust the
predictions over time. Additionally, we propose an information gate strategy to
significantly decrease the computational cost of particle filtering during the
inference step, making the system much faster than previous sampling-based
methods. Experiments on the GTZAN dataset, which is unseen during training,
show that the system outperforms various online beat and downbeat tracking
systems and achieves comparable performance to a baseline offline joint method.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Language Model Evaluation in Open-ended Text Generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">An Nguyen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03578">
                                        <div class="article-summary-box-inner">
                                            <span><p>Although current state-of-the-art language models have achieved impressive
results in numerous natural language processing tasks, still they could not
solve the problem of producing repetitive, dull and sometimes inconsistent text
in open-ended text generation. Studies often attribute this problem to the
maximum likelihood training objective, and propose alternative approaches by
using stochastic decoding methods or altering the training objective. However,
there is still a lack of consistent evaluation metrics to directly compare the
efficacy of these solutions. In this work, we study different evaluation
metrics that have been proposed to evaluate quality, diversity and consistency
of machine-generated text. From there, we propose a practical pipeline to
evaluate language models in open-ended generation task, and research on how to
improve the model's performance in all dimensions by leveraging different
auxiliary training objectives.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Expressive Power and Loss Surfaces of Deep Learning Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dube_S/0/1/0/all/0/1">Simant Dube</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03579">
                                        <div class="article-summary-box-inner">
                                            <span><p>The goals of this paper are two-fold. The first goal is to serve as an
expository tutorial on the working of deep learning models which emphasizes
geometrical intuition about the reasons for success of deep learning. The
second goal is to complement the current results on the expressive power of
deep learning models and their loss surfaces with novel insights and results.
In particular, we describe how deep neural networks carve out manifolds
especially when the multiplication neurons are introduced. Multiplication is
used in dot products and the attention mechanism and it is employed in capsule
networks and self-attention based transformers. We also describe how random
polynomial, random matrix, spin glass and computational complexity perspectives
on the loss surfaces are interconnected.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Ensemble neuroevolution based approach for multivariate time series anomaly detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Faber_K/0/1/0/all/0/1">Kamil Faber</a>, <a href="http://arxiv.org/find/cs/1/au:+Zurek_D/0/1/0/all/0/1">Dominik &#x17b;urek</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietron_M/0/1/0/all/0/1">Marcin Pietro&#x144;</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietak_K/0/1/0/all/0/1">Kamil Pi&#x119;tak</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03585">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multivariate time series anomaly detection is a very common problem in the
field of failure prevention. Fast prevention means lower repair costs and
losses. The amount of sensors in novel industry systems makes the anomaly
detection process quite difficult for humans. Algorithms which automates the
process of detecting anomalies are crucial in modern failure-prevention
systems. Therefore, many machine and deep learning models have been designed to
address this problem. Mostly, they are autoencoder-based architectures with
some generative adversarial elements. In this work, a framework is shown which
incorporates neuroevolution methods to boost the anomaly-detection scores of
new and already known models. The presented approach adapts evolution
strategies for evolving ensemble model, in which every single model works on a
subgroup of data sensors. The next goal of neuroevolution is to optimise
architecture and hyperparameters like window size, the number of layers, layer
depths, etc. The proposed framework shows that it is possible to boost most of
the anomaly detection deep learning models in a reasonable time and a fully
automated mode. The tests were run on SWAT and WADI datasets. To our knowledge,
this is the first approach in which an ensemble deep learning anomaly detection
model is built in a fully automatic way using a neuroevolution strategy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Look at the Evaluation Setup of the M5 Forecasting Competition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hewamalage_H/0/1/0/all/0/1">Hansika Hewamalage</a>, <a href="http://arxiv.org/find/cs/1/au:+Montero_Manso_P/0/1/0/all/0/1">Pablo Montero-Manso</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1">Christoph Bergmeir</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyndman_R/0/1/0/all/0/1">Rob J Hyndman</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03588">
                                        <div class="article-summary-box-inner">
                                            <span><p>Forecast evaluation plays a key role in how empirical evidence shapes the
development of the discipline. Domain experts are interested in error measures
relevant for their decision making needs. Such measures may produce unreliable
results. Although reliability properties of several metrics have already been
discussed, it has hardly been quantified in an objective way. We propose a
measure named Rank Stability, which evaluates how much the rankings of an
experiment differ in between similar datasets, when the models and errors are
constant. We use this to study the evaluation setup of the M5. We find that the
evaluation setup of the M5 is less reliable than other measures. The main
drivers of instability are hierarchical aggregation and scaling.
Price-weighting reduces the stability of all tested error measures. Scale
normalization of the M5 error measure results in less stability than other
scale-free errors. Hierarchical levels taken separately are less stable with
more aggregation, and their combination is even less stable than individual
levels. We also show positive tradeoffs of retaining aggregation importance
without affecting stability. Aggregation and stability can be linked to the
influence of much debated magic numbers. Many of our findings can be applied to
general hierarchical forecast benchmarking.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ FederatedNILM: A Distributed and Privacy-preserving Framework for Non-intrusive Load Monitoring based on Federated Deep Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Shuang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanlin Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xizhong Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03591">
                                        <div class="article-summary-box-inner">
                                            <span><p>Non-intrusive load monitoring (NILM), which usually utilizes machine learning
methods and is effective in disaggregating smart meter readings from the
household-level into appliance-level consumptions, can help to analyze
electricity consumption behaviours of users and enable practical smart energy
and smart grid applications. However, smart meters are privately owned and
distributed, which make real-world applications of NILM challenging. To this
end, this paper develops a distributed and privacy-preserving federated deep
learning framework for NILM (FederatedNILM), which combines federated learning
with a state-of-the-art deep learning architecture to conduct NILM for the
classification of typical states of household appliances. Through extensive
comparative experiments, the effectiveness of the proposed FederatedNILM
framework is demonstrated.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ MAF-GNN: Multi-adaptive Spatiotemporal-flow Graph Neural Network for Traffic Speed Forecasting.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yaobin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weitang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhongyi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zixuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_T/0/1/0/all/0/1">Tingyun Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lili Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingwei Zhou</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03594">
                                        <div class="article-summary-box-inner">
                                            <span><p>Traffic forecasting is a core element of intelligent traffic monitoring
system. Approaches based on graph neural networks have been widely used in this
task to effectively capture spatial and temporal dependencies of road networks.
However, these approaches can not effectively define the complicated network
topology. Besides, their cascade network structures have limitations in
transmitting distinct features in the time and space dimensions. In this paper,
we propose a Multi-adaptive Spatiotemporal-flow Graph Neural Network (MAF-GNN)
for traffic speed forecasting. MAF-GNN introduces an effective Multi-adaptive
Adjacency Matrices Mechanism to capture multiple latent spatial dependencies
between traffic nodes. Additionally, we propose Spatiotemporal-flow Modules
aiming to further enhance feature propagation in both time and space
dimensions. MAF-GNN achieves better performance than other models on two
real-world datasets of public traffic network, METR-LA and PeMS-Bay,
demonstrating the effectiveness of the proposed approach.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Using Biological Variables and Social Determinants to Predict Malaria and Anemia among Children in Senegal.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sow_B/0/1/0/all/0/1">Boubacar Sow</a>, <a href="http://arxiv.org/find/cs/1/au:+Suguri_H/0/1/0/all/0/1">Hiroki Suguri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhtar_H/0/1/0/all/0/1">Hamid Mukhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_H/0/1/0/all/0/1">Hafiz Farooq Ahmad</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03601">
                                        <div class="article-summary-box-inner">
                                            <span><p>Integrating machine learning techniques in healthcare becomes very common
nowadays, and it contributes positively to improving clinical care and health
decisions planning. Anemia and malaria are two life-threatening diseases in
Africa that affect the red blood cells and reduce hemoglobin production. This
paper focuses on analyzing child health data in Senegal using four machine
learning algorithms in Python: KNN, Random Forests, SVM, and Na\"ive Bayes. Our
task aims to investigate large-scale data from The Demographic and Health
Survey (DHS) and to find out hidden information for anemia and malaria. We
present two classification models for the two blood disorders using biological
variables and social determinants. The findings of this research will
contribute to improving child healthcare in Senegal by eradicating anemia and
malaria, and decreasing the child mortality rate.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ An EM Framework for Online Incremental Learning of Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shipeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiale Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiangwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Songyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03613">
                                        <div class="article-summary-box-inner">
                                            <span><p>Incremental learning of semantic segmentation has emerged as a promising
strategy for visual scene interpretation in the open- world setting. However,
it remains challenging to acquire novel classes in an online fashion for the
segmentation task, mainly due to its continuously-evolving semantic label
space, partial pixelwise ground-truth annotations, and constrained data
availability. To ad- dress this, we propose an incremental learning strategy
that can fast adapt deep segmentation models without catastrophic forgetting,
using a streaming input data with pixel annotations on the novel classes only.
To this end, we develop a uni ed learning strategy based on the
Expectation-Maximization (EM) framework, which integrates an iterative
relabeling strategy that lls in the missing labels and a rehearsal-based
incremental learning step that balances the stability-plasticity of the model.
Moreover, our EM algorithm adopts an adaptive sampling method to select
informative train- ing data and a class-balancing training strategy in the
incremental model updates, both improving the e cacy of model learning. We
validate our approach on the PASCAL VOC 2012 and ADE20K datasets, and the
results demonstrate its superior performance over the existing incremental
methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unifying Heterogenous Electronic Health Records Systems via Text-Based Code Embedding.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hur_K/0/1/0/all/0/1">Kyunghoon Hur</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jiyoung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jungwoo Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_W/0/1/0/all/0/1">Wesley Price</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young-Hak Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Edward Choi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03625">
                                        <div class="article-summary-box-inner">
                                            <span><p>Substantial increase in the use of Electronic Health Records (EHRs) has
opened new frontiers for predictive healthcare. However, while EHR systems are
nearly ubiquitous, they lack a unified code system for representing medical
concepts. Heterogeneous formats of EHR present a substantial barrier for the
training and deployment of state-of-the-art deep learning models at scale. To
overcome this problem, we introduce Description-based Embedding, DescEmb, a
code-agnostic description-based representation learning framework for
predictive modeling on EHR. DescEmb takes advantage of the flexibility of
neural language understanding models while maintaining a neutral approach that
can be combined with prior frameworks for task-specific representation learning
or predictive modeling. We tested our model's capacity on various experiments
including prediction tasks, transfer learning and pooled learning. DescEmb
shows higher performance in overall experiments compared to code-based
approach, opening the door to a text-based approach in predictive healthcare
research that is not constrained by EHR structure nor special domain knowledge.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Deep Neural Network for DrawiNg Networks, (DNN)^2.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Giovannangeli_L/0/1/0/all/0/1">Loann Giovannangeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Lalanne_F/0/1/0/all/0/1">Frederic Lalanne</a>, <a href="http://arxiv.org/find/cs/1/au:+Auber_D/0/1/0/all/0/1">David Auber</a>, <a href="http://arxiv.org/find/cs/1/au:+Giot_R/0/1/0/all/0/1">Romain Giot</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourqui_R/0/1/0/all/0/1">Romain Bourqui</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03632">
                                        <div class="article-summary-box-inner">
                                            <span><p>By leveraging recent progress of stochastic gradient descent methods, several
works have shown that graphs could be efficiently laid out through the
optimization of a tailored objective function. In the meantime, Deep Learning
(DL) techniques achieved great performances in many applications. We
demonstrate that it is possible to use DL techniques to learn a graph-to-layout
sequence of operations thanks to a graph-related objective function. In this
paper, we present a novel graph drawing framework called (DNN)^2: Deep Neural
Network for DrawiNg Networks. Our method uses Graph Convolution Networks to
learn a model. Learning is achieved by optimizing a graph topology related loss
function that evaluates (DNN)^2 generated layouts during training. Once
trained, the (DNN)^ model is able to quickly lay any input graph out. We
experiment (DNN)^2 and statistically compare it to optimization-based and
regular graph layout algorithms. The results show that (DNN)^2 performs well
and are encouraging as the Deep Learning approach to Graph Drawing is novel and
many leads for future works are identified.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Online Evolutionary Batch Size Orchestration for Scheduling Deep Learning Workloads in GPU Clusters.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bian_Z/0/1/0/all/0/1">Zhengda Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shenggui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yang You</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03645">
                                        <div class="article-summary-box-inner">
                                            <span><p>Efficient GPU resource scheduling is essential to maximize resource
utilization and save training costs for the increasing amount of deep learning
workloads in shared GPU clusters. Existing GPU schedulers largely rely on
static policies to leverage the performance characteristics of deep learning
jobs. However, they can hardly reach optimal efficiency due to the lack of
elasticity. To address the problem, we propose ONES, an ONline Evolutionary
Scheduler for elastic batch size orchestration. ONES automatically manages the
elasticity of each job based on the training batch size, so as to maximize GPU
utilization and improve scheduling efficiency. It determines the batch size for
each job through an online evolutionary search that can continuously optimize
the scheduling decisions. We evaluate the effectiveness of ONES with 64 GPUs on
TACC's Longhorn supercomputers. The results show that ONES can outperform the
prior deep learning schedulers with a significantly shorter average job
completion time.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Joint Depth and Normal Estimation from Real-world Time-of-flight Raw Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Rongrong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Changlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03649">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a novel approach to joint depth and normal estimation for
time-of-flight (ToF) sensors. Our model learns to predict the high-quality
depth and normal maps jointly from ToF raw sensor data. To achieve this, we
meticulously constructed the first large-scale dataset (named ToF-100) with
paired raw ToF data and ground-truth high-resolution depth maps provided by an
industrial depth camera. In addition, we also design a simple but effective
framework for joint depth and normal estimation, applying a robust Chamfer loss
via jittering to improve the performance of our model. Our experiments
demonstrate that our proposed method can efficiently reconstruct
high-resolution depth and normal maps and significantly outperforms
state-of-the-art approaches. Our code and data will be available at
\url{https://github.com/hkustVisionRr/JointlyDepthNormalEstimation}
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Audio Spectral Enhancement: Leveraging Autoencoders for Low Latency Reconstruction of Long, Lossy Audio Sequences.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Deshpande_D/0/1/0/all/0/1">Darshan Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Abichandani_H/0/1/0/all/0/1">Harshavardhan Abichandani</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03703">
                                        <div class="article-summary-box-inner">
                                            <span><p>With active research in audio compression techniques yielding substantial
breakthroughs, spectral reconstruction of low-quality audio waves remains a
less indulged topic. In this paper, we propose a novel approach for
reconstructing higher frequencies from considerably longer sequences of
low-quality MP3 audio waves. Our technique involves inpainting audio
spectrograms with residually stacked autoencoder blocks by manipulating
individual amplitude and phase values in relation to perceptual differences.
Our architecture presents several bottlenecks while preserving the spectral
structure of the audio wave via skip-connections. We also compare several task
metrics and demonstrate our visual guide to loss selection. Moreover, we show
how to leverage differential quantization techniques to reduce the initial
model size by more than half while simultaneously reducing inference time,
which is crucial in real-world applications.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1">Pratik Ramprasad</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1">Yuantong Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1">Will Wei Sun</a>, <a href="http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1">Guang Cheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03706">
                                        <div class="article-summary-box-inner">
                                            <span><p>The recent emergence of reinforcement learning has created a demand for
robust statistical inference methods for the parameter estimates computed using
these algorithms. Existing methods for statistical inference in online learning
are restricted to settings involving independently sampled observations, while
existing statistical inference methods in reinforcement learning (RL) are
limited to the batch setting. The online bootstrap is a flexible and efficient
approach for statistical inference in linear stochastic approximation
algorithms, but its efficacy in settings involving Markov noise, such as RL,
has yet to be explored. In this paper, we study the use of the online bootstrap
method for statistical inference in RL. In particular, we focus on the temporal
difference (TD) learning and Gradient TD (GTD) learning algorithms, which are
themselves special instances of linear stochastic approximation under Markov
noise. The method is shown to be distributionally consistent for statistical
inference in policy evaluation, and numerical experiments are included to
demonstrate the effectiveness of this algorithm at statistical inference tasks
across a range of real RL environments.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Generalizing Dynamic Mode Decomposition: Balancing Accuracy and Expressiveness in Koopman Approximations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Haseli_M/0/1/0/all/0/1">Masih Haseli</a>, <a href="http://arxiv.org/find/eess/1/au:+Cortes_J/0/1/0/all/0/1">Jorge Cort&#xe9;s</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03712">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper tackles the data-driven approximation of unknown dynamical systems
using Koopman-operator methods. Given a dictionary of functions, these methods
approximate the projection of the action of the operator on the
finite-dimensional subspace spanned by the dictionary. We propose the Tunable
Symmetric Subspace Decomposition algorithm to refine the dictionary, balancing
its expressiveness and accuracy. Expressiveness corresponds to the ability of
the dictionary to describe the evolution of as many observables as possible and
accuracy corresponds to the ability to correctly predict their evolution. Based
on the observation that Koopman-invariant subspaces give rise to exact
predictions, we reason that prediction accuracy is a function of the degree of
invariance of the subspace generated by the dictionary and provide a
data-driven measure to measure invariance proximity. The proposed algorithm
iteratively prunes the initial functional space to identify a refined
dictionary of functions that satisfies the desired level of accuracy while
retaining as much of the original expressiveness as possible. We provide a full
characterization of the algorithm properties and show that it generalizes both
Extended Dynamic Mode Decomposition and Symmetric Subspace Decomposition.
Simulations on planar systems show the effectiveness of the proposed methods in
producing Koopman approximations of tunable accuracy that capture relevant
information about the dynamical system.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ On the Difficulty of Generalizing Reinforcement Learning Framework for Combinatorial Optimization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Pashazadeh_M/0/1/0/all/0/1">Mostafa Pashazadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kui Wu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03713">
                                        <div class="article-summary-box-inner">
                                            <span><p>Combinatorial optimization problems (COPs) on the graph with real-life
applications are canonical challenges in Computer Science. The difficulty of
finding quality labels for problem instances holds back leveraging supervised
learning across combinatorial problems. Reinforcement learning (RL) algorithms
have recently been adopted to solve this challenge automatically. The
underlying principle of this approach is to deploy a graph neural network (GNN)
for encoding both the local information of the nodes and the graph-structured
data in order to capture the current state of the environment. Then, it is
followed by the actor to learn the problem-specific heuristics on its own and
make an informed decision at each state for finally reaching a good solution.
Recent studies on this subject mainly focus on a family of combinatorial
problems on the graph, such as the travel salesman problem, where the proposed
model aims to find an ordering of vertices that optimizes a given objective
function. We use the security-aware phone clone allocation in the cloud as a
classical quadratic assignment problem (QAP) to investigate whether or not deep
RL-based model is generally applicable to solve other classes of such hard
problems. Extensive empirical evaluation shows that existing RL-based model may
not generalize to QAP.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Meta-Reinforcement Learning in Broad and Non-Parametric Environments.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bing_Z/0/1/0/all/0/1">Zhenshan Bing</a>, <a href="http://arxiv.org/find/cs/1/au:+Knak_L/0/1/0/all/0/1">Lukas Knak</a>, <a href="http://arxiv.org/find/cs/1/au:+Robin_F/0/1/0/all/0/1">Fabrice Oliver Robin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Knoll_A/0/1/0/all/0/1">Alois Knoll</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03718">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent state-of-the-art artificial agents lack the ability to adapt rapidly
to new tasks, as they are trained exclusively for specific objectives and
require massive amounts of interaction to learn new skills. Meta-reinforcement
learning (meta-RL) addresses this challenge by leveraging knowledge learned
from training tasks to perform well in previously unseen tasks. However,
current meta-RL approaches limit themselves to narrow parametric task
distributions, ignoring qualitative differences between tasks that occur in the
real world. In this paper, we introduce TIGR, a Task-Inference-based meta-RL
algorithm using Gaussian mixture models (GMM) and gated Recurrent units,
designed for tasks in non-parametric environments. We employ a generative model
involving a GMM to capture the multi-modality of the tasks. We decouple the
policy training from the task-inference learning and efficiently train the
inference mechanism on the basis of an unsupervised reconstruction objective.
We provide a benchmark with qualitatively distinct tasks based on the
half-cheetah environment and demonstrate the superior performance of TIGR
compared to state-of-the-art meta-RL approaches in terms of sample efficiency
(3-10 times faster), asymptotic performance, and applicability in
non-parametric environments with zero-shot adaptation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ EVGen: Adversarial Networks for Learning Electric Vehicle Charging Loads and Hidden Representations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Buechler_R/0/1/0/all/0/1">Robert Buechler</a>, <a href="http://arxiv.org/find/cs/1/au:+Balogun_E/0/1/0/all/0/1">Emmanuel Balogun</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1">Arun Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajagopal_R/0/1/0/all/0/1">Ram Rajagopal</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03762">
                                        <div class="article-summary-box-inner">
                                            <span><p>The nexus between transportation, the power grid, and consumer behavior is
more pronounced than ever before as the race to decarbonize the transportation
sector intensifies. Electrification in the transportation sector has led to
technology shifts and rapid deployment of electric vehicles (EVs). The
potential increase in stochastic and spatially heterogeneous charging load
presents a unique challenge that is not well studied, and will have significant
impacts on grid operations, emissions, and system reliability if not managed
effectively. Realistic scenario generators can help operators prepare, and
machine learning can be leveraged to this end. In this work, we develop
generative adversarial networks (GANs) to learn distributions of electric
vehicle (EV) charging sessions and disentangled representations. We show that
this model structure successfully parameterizes unlabeled temporal and power
patterns without supervision and is able to generate synthetic data conditioned
on these parameters. We benchmark the generation capability of this model with
Gaussian Mixture Models (GMMs), and empirically show that our proposed model
framework is better at capturing charging distributions and temporal dynamics.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Pathfinder: Parallel quasi-Newton variational inference.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Carpenter_B/0/1/0/all/0/1">Bob Carpenter</a>, <a href="http://arxiv.org/find/stat/1/au:+Gelman_A/0/1/0/all/0/1">Andrew Gelman</a>, <a href="http://arxiv.org/find/stat/1/au:+Vehtari_A/0/1/0/all/0/1">Aki Vehtari</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03782">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce Pathfinder, a variational method for approximately sampling from
differentiable log densities. Starting from a random initialization, Pathfinder
locates normal approximations to the target density along a quasi-Newton
optimization path, with local covariance estimated using the inverse Hessian
estimates produced by the optimizer. Pathfinder returns draws from the
approximation with the lowest estimated Kullback-Leibler (KL) divergence to the
true posterior. We evaluate Pathfinder on a wide range of posterior
distributions, demonstrating that its approximate draws are better than those
from automatic differentiation variational inference (ADVI) and comparable to
those produced by short chains of dynamic Hamiltonian Monte Carlo (HMC), as
measured by 1-Wasserstein distance. Compared to ADVI and short dynamic HMC
runs, Pathfinder requires one to two orders of magnitude fewer log density and
gradient evaluations, with greater reductions for more challenging posteriors.
Importance resampling over multiple runs of Pathfinder improves the diversity
of approximate draws, reducing 1-Wasserstein distance further and providing a
measure of robustness to optimization failures on plateaus, saddle points, or
in minor modes. The Monte Carlo KL-divergence estimates are embarrassingly
parallelizable in the core Pathfinder algorithm, as are multiple runs in the
resampling version, further increasing Pathfinder's speed advantage with
multiple cores.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Multi-Slice Net: A novel light weight framework for COVID-19 Diagnosis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gammulle_H/0/1/0/all/0/1">Harshala Gammulle</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_T/0/1/0/all/0/1">Tharindu Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1">Sridha Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03786">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper presents a novel lightweight COVID-19 diagnosis framework using CT
scans. Our system utilises a novel two-stage approach to generate robust and
efficient diagnoses across heterogeneous patient level inputs. We use a
powerful backbone network as a feature extractor to capture discriminative
slice-level features. These features are aggregated by a lightweight network to
obtain a patient level diagnosis. The aggregation network is carefully designed
to have a small number of trainable parameters while also possessing sufficient
capacity to generalise to diverse variations within different CT volumes and to
adapt to noise introduced during the data acquisition. We achieve a significant
performance increase over the baselines when benchmarked on the SPGC COVID-19
Radiomics Dataset, despite having only 2.5 million trainable parameters and
requiring only 0.623 seconds on average to process a single patient's CT volume
using an Nvidia-GeForce RTX 2080 GPU.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Mis-spoke or mis-lead: Achieving Robustness in Multi-Agent Communicative Reinforcement Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wanqi Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Wei Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bo An</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabinovich_Z/0/1/0/all/0/1">Zinovi Rabinovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Obraztsova_S/0/1/0/all/0/1">Svetlana Obraztsova</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_C/0/1/0/all/0/1">Chai Kiat Yeo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03803">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent studies in multi-agent communicative reinforcement learning (MACRL)
demonstrate that multi-agent coordination can be significantly improved when
communication between agents is allowed. Meanwhile, advances in adversarial
machine learning (ML) have shown that ML and reinforcement learning (RL) models
are vulnerable to a variety of attacks that significantly degrade the
performance of learned behaviours. However, despite the obvious and growing
importance, the combination of adversarial ML and MACRL remains largely
uninvestigated. In this paper, we make the first step towards conducting
message attacks on MACRL methods. In our formulation, one agent in the
cooperating group is taken over by an adversary and can send malicious messages
to disrupt a deployed MACRL-based coordinated strategy during the deployment
phase. We further our study by developing a defence method via message
reconstruction. Finally, we address the resulting arms race, i.e., we consider
the ability of the malicious agent to adapt to the changing and improving
defensive communicative policies of the benign agents. Specifically, we model
the adversarial MACRL problem as a two-player zero-sum game and then utilize
Policy-Space Response Oracle to achieve communication robustness. Empirically,
we demonstrate that MACRL methods are vulnerable to message attacks while our
defence method the game-theoretic framework can effectively improve the
robustness of MACRL.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Whittle Index for A Class of Restless Bandits with Imperfect Observations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Keqin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Ting Wu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03812">
                                        <div class="article-summary-box-inner">
                                            <span><p>We consider a class of restless bandit problems that finds a broad
application area in stochastic optimization, reinforcement learning and
operations research. In our model, there are $N$ independent $2$-state Markov
processes that may be observed and accessed for accruing rewards. The
observation is error-prone, i.e., both false alarm and miss detection may
happen. Furthermore, the user can only choose a subset of $M~(M&lt;N)$ processes
to observe at each discrete time. If a process in state~$1$ is correctly
observed, then it will offer some reward. Due to the partial and imperfect
observation model, the system is formulated as a restless multi-armed bandit
problem with an information state space of uncountable cardinality. Restless
bandit problems with finite state spaces are PSPACE-HARD in general. In this
paper, we establish a low-complexity algorithm that achieves a strong
performance for this class of restless bandits. Under certain conditions, we
theoretically prove the existence (indexability) of Whittle index and its
equivalence to our algorithm. When those conditions do not hold, we show by
numerical experiments the near-optimal performance of our algorithm in general.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Bob and Alice Go to a Bar: Reasoning About Future With Probabilistic Programs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tolpin_D/0/1/0/all/0/1">David Tolpin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobkin_T/0/1/0/all/0/1">Tomer Dobkin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03834">
                                        <div class="article-summary-box-inner">
                                            <span><p>Agent preferences should be specified stochastically rather than
deterministically. Planning as inference with stochastic preferences naturally
describes agent behaviors, does not require introducing rewards and exponential
weighing of behaviors, and allows to reason about agents using the solid
foundation of Bayesian statistics. Stochastic conditioning is the formalism
behind agents with stochastic preferences.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Online Multiobjective Minimax Optimization and Applications.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Noarov_G/0/1/0/all/0/1">Georgy Noarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_M/0/1/0/all/0/1">Mallesh Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03837">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce a simple but general online learning framework, in which at
every round, an adaptive adversary introduces a new game, consisting of an
action space for the learner, an action space for the adversary, and a vector
valued objective function that is convex-concave in every coordinate. The
learner and the adversary then play in this game. The learner's goal is to play
so as to minimize the maximum coordinate of the cumulative vector-valued loss.
The resulting one-shot game is not convex-concave, and so the minimax theorem
does not apply. Nevertheless, we give a simple algorithm that can compete with
the setting in which the adversary must announce their action first, with
optimally diminishing regret.
</p>
<p>We demonstrate the power of our simple framework by using it to derive
optimal bounds and algorithms across a variety of domains. This includes no
regret learning: we can recover optimal algorithms and bounds for minimizing
external regret, internal regret, adaptive regret, multigroup regret,
subsequence regret, and a notion of regret in the sleeping experts setting.
Next, we use it to derive a variant of Blackwell's Approachability Theorem,
which we term "Fast Polytope Approachability". Finally, we are able to recover
recently derived algorithms and bounds for online adversarial multicalibration
and related notions (mean-conditioned moment multicalibration, and prediction
interval multivalidity).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                        <div class="article-summary-box-inner">
                                            <span><p>"Art is the lie that enables us to realize the truth." - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Adaptive Anomaly Detection for Internet of Things in Hierarchical Edge Computing: A Contextual-Bandit Approach.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ngo_M/0/1/0/all/0/1">Mao V. Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1">Tony Q.S. Quek</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03872">
                                        <div class="article-summary-box-inner">
                                            <span><p>The advances in deep neural networks (DNN) have significantly enhanced
real-time detection of anomalous data in IoT applications. However, the
complexity-accuracy-delay dilemma persists: complex DNN models offer higher
accuracy, but typical IoT devices can barely afford the computation load, and
the remedy of offloading the load to the cloud incurs long delay. In this
paper, we address this challenge by proposing an adaptive anomaly detection
scheme with hierarchical edge computing (HEC). Specifically, we first construct
multiple anomaly detection DNN models with increasing complexity, and associate
each of them to a corresponding HEC layer. Then, we design an adaptive model
selection scheme that is formulated as a contextual-bandit problem and solved
by using a reinforcement learning policy network. We also incorporate a
parallelism policy training method to accelerate the training process by taking
advantage of distributed models. We build an HEC testbed using real IoT
devices, implement and evaluate our contextual-bandit approach with both
univariate and multivariate IoT datasets. In comparison with both baseline and
state-of-the-art schemes, our adaptive approach strikes the best accuracy-delay
tradeoff on the univariate dataset, and achieves the best accuracy and F1-score
on the multivariate dataset with only negligibly longer delay than the best
(but inflexible) scheme.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Collapsing the Decision Tree: the Concurrent Data Predictor.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Alb_C/0/1/0/all/0/1">Cristian Alb</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03887">
                                        <div class="article-summary-box-inner">
                                            <span><p>A family of concurrent data predictors is derived from the decision tree
classifier by removing the limitation of sequentially evaluating attributes. By
evaluating attributes concurrently, the decision tree collapses into a flat
structure. Experiments indicate improvements of the prediction accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Efficient Hyperparameter Optimization for Differentially Private Deep Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Priyanshu_A/0/1/0/all/0/1">Aman Priyanshu</a>, <a href="http://arxiv.org/find/cs/1/au:+Naidu_R/0/1/0/all/0/1">Rakshit Naidu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mireshghallah_F/0/1/0/all/0/1">Fatemehsadat Mireshghallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Malekzadeh_M/0/1/0/all/0/1">Mohammad Malekzadeh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03888">
                                        <div class="article-summary-box-inner">
                                            <span><p>Tuning the hyperparameters in the differentially private stochastic gradient
descent (DPSGD) is a fundamental challenge. Unlike the typical SGD, private
datasets cannot be used many times for hyperparameter search in DPSGD; e.g.,
via a grid search. Therefore, there is an essential need for algorithms that,
within a given search space, can find near-optimal hyperparameters for the best
achievable privacy-utility tradeoffs efficiently. We formulate this problem
into a general optimization framework for establishing a desirable
privacy-utility tradeoff, and systematically study three cost-effective
algorithms for being used in the proposed framework: evolutionary, Bayesian,
and reinforcement learning. Our experiments, for hyperparameter tuning in DPSGD
conducted on MNIST and CIFAR-10 datasets, show that these three algorithms
significantly outperform the widely used grid search baseline. As this paper
offers a first-of-a-kind framework for hyperparameter tuning in DPSGD, we
discuss existing challenges and open directions for future studies. As we
believe our work has implications to be utilized in the pipeline of private
deep learning, we open-source our code at
https://github.com/AmanPriyanshu/DP-HyperparamTuning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Probabilistic Active Learning for Active Class Selection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kottke_D/0/1/0/all/0/1">Daniel Kottke</a>, <a href="http://arxiv.org/find/cs/1/au:+Krempl_G/0/1/0/all/0/1">Georg Krempl</a>, <a href="http://arxiv.org/find/cs/1/au:+Stecklina_M/0/1/0/all/0/1">Marianne Stecklina</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekowski_C/0/1/0/all/0/1">Cornelius Styp von Rekowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabsch_T/0/1/0/all/0/1">Tim Sabsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Minh_T/0/1/0/all/0/1">Tuan Pham Minh</a>, <a href="http://arxiv.org/find/cs/1/au:+Deliano_M/0/1/0/all/0/1">Matthias Deliano</a>, <a href="http://arxiv.org/find/cs/1/au:+Spiliopoulou_M/0/1/0/all/0/1">Myra Spiliopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1">Bernhard Sick</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03891">
                                        <div class="article-summary-box-inner">
                                            <span><p>In machine learning, active class selection (ACS) algorithms aim to actively
select a class and ask the oracle to provide an instance for that class to
optimize a classifier's performance while minimizing the number of requests. In
this paper, we propose a new algorithm (PAL-ACS) that transforms the ACS
problem into an active learning task by introducing pseudo instances. These are
used to estimate the usefulness of an upcoming instance for each class using
the performance gain model from probabilistic active learning. Our experimental
evaluation (on synthetic and real data) shows the advantages of our algorithm
compared to state-of-the-art algorithms. It effectively prefers the sampling of
difficult classes and thereby improves the classification performance.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ FIFA: Fast Inference Approximation for Action Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1">Yaser Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Farha_Y/0/1/0/all/0/1">Yazan Abu Farha</a>, <a href="http://arxiv.org/find/cs/1/au:+Despinoy_F/0/1/0/all/0/1">Fabien Despinoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1">Gianpiero Francesca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03894">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce FIFA, a fast approximate inference method for action
segmentation and alignment. Unlike previous approaches, FIFA does not rely on
expensive dynamic programming for inference. Instead, it uses an approximate
differentiable energy function that can be minimized using gradient-descent.
FIFA is a general approach that can replace exact inference improving its speed
by more than 5 times while maintaining its performance. FIFA is an anytime
inference algorithm that provides a better speed vs. accuracy trade-off
compared to exact inference. We apply FIFA on top of state-of-the-art
approaches for weakly supervised action segmentation and alignment as well as
fully supervised action segmentation. FIFA achieves state-of-the-art results on
most metrics on two action segmentation datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unified Regularity Measures for Sample-wise Learning and Generalization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaoning Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yuanqi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuehu Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03913">
                                        <div class="article-summary-box-inner">
                                            <span><p>Fundamental machine learning theory shows that different samples contribute
unequally both in learning and testing processes. Contemporary studies on DNN
imply that such sample di?erence is rooted on the distribution of intrinsic
pattern information, namely sample regularity. Motivated by the recent
discovery on network memorization and generalization, we proposed a pair of
sample regularity measures for both processes with a formulation-consistent
representation. Specifically, cumulative binary training/generalizing loss
(CBTL/CBGL), the cumulative number of correct classi?cations of the
training/testing sample within training stage, is proposed to quantize the
stability in memorization-generalization process; while
forgetting/mal-generalizing events, i.e., the mis-classification of previously
learned or generalized sample, are utilized to represent the uncertainty of
sample regularity with respect to optimization dynamics. Experiments validated
the effectiveness and robustness of the proposed approaches for mini-batch SGD
optimization. Further applications on training/testing sample selection show
the proposed measures sharing the uni?ed computing procedure could benefit for
both tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ LatticeNet: Fast Spatio-Temporal Point Cloud Segmentation Using Permutohedral Lattices.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rosu_R/0/1/0/all/0/1">Radu Alexandru Rosu</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutt_P/0/1/0/all/0/1">Peer Sch&#xfc;tt</a>, <a href="http://arxiv.org/find/cs/1/au:+Quenzel_J/0/1/0/all/0/1">Jan Quenzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03917">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep convolutional neural networks (CNNs) have shown outstanding performance
in the task of semantically segmenting images. Applying the same methods on 3D
data still poses challenges due to the heavy memory requirements and the lack
of structured data. Here, we propose LatticeNet, a novel approach for 3D
semantic segmentation, which takes raw point clouds as input. A PointNet
describes the local geometry which we embed into a sparse permutohedral
lattice. The lattice allows for fast convolutions while keeping a low memory
footprint. Further, we introduce DeformSlice, a novel learned data-dependent
interpolation for projecting lattice features back onto the point cloud. We
present results of 3D segmentation on multiple datasets where our method
achieves state-of-the-art performance. We also extend and evaluate our network
for instance and dynamic object segmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Some thoughts on catastrophic forgetting and how to learn an algorithm.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_M/0/1/0/all/0/1">Miguel Ruiz-Garcia</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03940">
                                        <div class="article-summary-box-inner">
                                            <span><p>The work of McCloskey and Cohen popularized the concept of catastrophic
interference. They used a neural network that tried to learn addition using two
groups of examples as two different tasks. In their case, learning the second
task rapidly deteriorated the acquired knowledge about the previous one. This
could be a symptom of a fundamental problem: addition is an algorithmic task
that should not be learned through pattern recognition. We propose to use a
neural network with a different architecture that can be trained to recover the
correct algorithm for the addition of binary numbers. We test it in the setting
proposed by McCloskey and Cohen and training on random examples one by one. The
neural network not only does not suffer from catastrophic forgetting but it
improves its predictive power on unseen pairs of numbers as training
progresses. This work emphasizes the importance that neural network
architecture has for the emergence of catastrophic forgetting and introduces a
neural network that is able to learn an algorithm.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Neural Approach for Detecting Morphological Analogies.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Alsaidi_S/0/1/0/all/0/1">Safa Alsaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_A/0/1/0/all/0/1">Amandine Decker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lay_P/0/1/0/all/0/1">Puthineath Lay</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquer_E/0/1/0/all/0/1">Esteban Marquer</a>, <a href="http://arxiv.org/find/cs/1/au:+Murena_P/0/1/0/all/0/1">Pierre-Alexandre Murena</a>, <a href="http://arxiv.org/find/cs/1/au:+Couceiro_M/0/1/0/all/0/1">Miguel Couceiro</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03945">
                                        <div class="article-summary-box-inner">
                                            <span><p>Analogical proportions are statements of the form "A is to B as C is to D"
that are used for several reasoning and classification tasks in artificial
intelligence and natural language processing (NLP). For instance, there are
analogy based approaches to semantics as well as to morphology. In fact,
symbolic approaches were developed to solve or to detect analogies between
character strings, e.g., the axiomatic approach as well as that based on
Kolmogorov complexity. In this paper, we propose a deep learning approach to
detect morphological analogies, for instance, with reinflexion or conjugation.
We present empirical results that show that our framework is competitive with
the above-mentioned state of the art symbolic approaches. We also explore
empirically its transferability capacity across languages, which highlights
interesting similarities between them.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ On the Hyperparameters in Stochastic Gradient Descent with Momentum.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Bin Shi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03947">
                                        <div class="article-summary-box-inner">
                                            <span><p>Following the same routine as [SSJ20], we continue to present the theoretical
analysis for stochastic gradient descent with momentum (SGD with momentum) in
this paper. Differently, for SGD with momentum, we demonstrate it is the two
hyperparameters together, the learning rate and the momentum coefficient, that
play the significant role for the linear rate of convergence in non-convex
optimization. Our analysis is based on the use of a hyperparameters-dependent
stochastic differential equation (hp-dependent SDE) that serves as a continuous
surrogate for SGD with momentum. Similarly, we establish the linear convergence
for the continuous-time formulation of SGD with momentum and obtain an explicit
expression for the optimal linear rate by analyzing the spectrum of the
Kramers-Fokker-Planck operator. By comparison, we demonstrate how the optimal
linear rate of convergence and the final gap for SGD only about the learning
rate varies with the momentum coefficient increasing from zero to one when the
momentum is introduced. Then, we propose a mathematical interpretation why the
SGD with momentum converges faster and more robust about the learning rate than
the standard SGD in practice. Finally, we show the Nesterov momentum under the
existence of noise has no essential difference with the standard momentum.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Safe Deep Reinforcement Learning for Multi-Agent Systems with Continuous Action Spaces.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sheebaelhamd_Z/0/1/0/all/0/1">Ziyad Sheebaelhamd</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisis_K/0/1/0/all/0/1">Konstantinos Zisis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nisioti_A/0/1/0/all/0/1">Athina Nisioti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gkouletsos_D/0/1/0/all/0/1">Dimitris Gkouletsos</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavllo_D/0/1/0/all/0/1">Dario Pavllo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_J/0/1/0/all/0/1">Jonas Kohler</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03952">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multi-agent control problems constitute an interesting area of application
for deep reinforcement learning models with continuous action spaces. Such
real-world applications, however, typically come with critical safety
constraints that must not be violated. In order to ensure safety, we enhance
the well-known multi-agent deep deterministic policy gradient (MADDPG)
framework by adding a safety layer to the deep policy network. %which
automatically corrects invalid actions. In particular, we extend the idea of
linearizing the single-step transition dynamics, as was done for single-agent
systems in Safe DDPG (Dalal et al., 2018), to multi-agent settings. We
additionally propose to circumvent infeasibility problems in the action
correction step using soft constraints (Kerrigan &amp; Maciejowski, 2000). Results
from the theory of exact penalty functions can be used to guarantee constraint
satisfaction of the soft constraints under mild assumptions. We empirically
find that the soft formulation achieves a dramatic decrease in constraint
violations, making safety available even during the learning procedure.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Framework for Joint Unsupervised Learning of Cluster-Aware Embedding for Heterogeneous Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1">Rayyan Ahmad Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinsteuber_M/0/1/0/all/0/1">Martin Kleinsteuber</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03953">
                                        <div class="article-summary-box-inner">
                                            <span><p>Heterogeneous Information Network (HIN) embedding refers to the
low-dimensional projections of the HIN nodes that preserve the HIN structure
and semantics. HIN embedding has emerged as a promising research field for
network analysis as it enables downstream tasks such as clustering and node
classification. In this work, we propose \ours for joint learning of cluster
embeddings as well as cluster-aware HIN embedding. We assume that the connected
nodes are highly likely to fall in the same cluster, and adopt a variational
approach to preserve the information in the pairwise relations in a
cluster-aware manner. In addition, we deploy contrastive modules to
simultaneously utilize the information in multiple meta-paths, thereby
alleviating the meta-path selection problem - a challenge faced by many of the
famous HIN embedding approaches. The HIN embedding, thus learned, not only
improves the clustering performance but also preserves pairwise proximity as
well as the high-order HIN structure. We show the effectiveness of our approach
by comparing it with many competitive baselines on three real-world datasets on
clustering and downstream node classification.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ VeRLPy: Python Library for Verification of Digital Designs with Reinforcement Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shibu_A/0/1/0/all/0/1">Aebel Joe Shibu</a>, <a href="http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1">Sadhana S</a>, <a href="http://arxiv.org/find/cs/1/au:+N_S/0/1/0/all/0/1">Shilpa N</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Pratyush Kumar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03978">
                                        <div class="article-summary-box-inner">
                                            <span><p>Digital hardware is verified by comparing its behavior against a reference
model on a range of randomly generated input signals. The random generation of
the inputs hopes to achieve sufficient coverage of the different parts of the
design. However, such coverage is often difficult to achieve, amounting to
large verification efforts and delays. An alternative is to use Reinforcement
Learning (RL) to generate the inputs by learning to prioritize those inputs
which can more efficiently explore the design under test. In this work, we
present VeRLPy an open-source library to allow RL-driven verification with
limited additional engineering overhead. This contributes to two broad
movements within the EDA community of (a) moving to open-source toolchains and
(b) reducing barriers for development with Python support. We also demonstrate
the use of VeRLPy for a few designs and establish its value over randomly
generated input signals.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Efficient Majority Voting in Digital Hardware.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Baumgartner_S/0/1/0/all/0/1">Stefan Baumgartner</a>, <a href="http://arxiv.org/find/eess/1/au:+Huemer_M/0/1/0/all/0/1">Mario Huemer</a>, <a href="http://arxiv.org/find/eess/1/au:+Lunglmayr_M/0/1/0/all/0/1">Michael Lunglmayr</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03979">
                                        <div class="article-summary-box-inner">
                                            <span><p>In recent years, machine learning methods became increasingly important for a
manifold number of applications. However, they often suffer from high
computational requirements impairing their efficient use in real-time systems,
even when employing dedicated hardware accelerators. Ensemble learning methods
are especially suitable for hardware acceleration since they can be constructed
from individual learners of low complexity and thus offer large parallelization
potential. For classification, the outputs of these learners are typically
combined by majority voting, which often represents the bottleneck of a
hardware accelerator for ensemble inference. In this work, we present a novel
architecture that allows obtaining a majority decision in a number of clock
cycles that is logarithmic in the number of inputs. We show, that for the
example application of handwritten digit recognition a random forest processing
engine employing this majority decision architecture implemented on an FPGA
allows the classification of more than seven million images per second.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Decentralized Deep Learning for Mobile Edge Computing: A Survey on Communication Efficiency and Trustworthiness.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuwei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ochiai_H/0/1/0/all/0/1">Hideya Ochiai</a>, <a href="http://arxiv.org/find/cs/1/au:+Esaki_H/0/1/0/all/0/1">Hiroshi Esaki</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03980">
                                        <div class="article-summary-box-inner">
                                            <span><p>A wider coverage and a better solution to latency reduction in 5G
necessitates its combination with mobile edge computing (MEC) technology.
Decentralized deep learning (DDL) as a promising solution to privacy-preserving
data processing for millions of edge smart devices, it leverages federated
learning within the networking of local models, without disclosing a client's
raw data. Especially, in industries such as finance and healthcare where
sensitive data of transactions and personal medical records is cautiously
maintained, DDL facilitates the collaboration among these institutes to improve
the performance of local models, while protecting data privacy of participating
clients. In this survey paper, we demonstrate technical fundamentals of DDL for
benefiting many walks of society through decentralized learning. Furthermore,
we offer a comprehensive overview of recent challenges of DDL and the most
relevant solutions from novel perspectives of communication efficiency and
trustworthiness.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Credibility-aware Swarm-Federated Deep Learning Framework in Internet of Vehicles.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1">Zhe Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1">Xinhang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_T/0/1/0/all/0/1">Tianhao Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_C/0/1/0/all/0/1">Chen Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1">Lin Zhang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03981">
                                        <div class="article-summary-box-inner">
                                            <span><p>Federated Deep Learning (FDL) is helping to realize distributed machine
learning in the Internet of Vehicles (IoV). However, FDL's global model needs
multiple clients to upload learning model parameters, thus still existing
unavoidable communication overhead and data privacy risks. The recently
proposed Swarm Learning (SL) provides a decentralized machine-learning approach
uniting edge computing and blockchain-based coordination without the need for a
central coordinator. This paper proposes a Swarm-Federated Deep Learning
framework in the IoV system (IoV-SFDL) that integrates SL into the FDL
framework. The IoV-SFDL organizes vehicles to generate local SL models with
adjacent vehicles based on the blockchain empowered SL, then aggregates the
global FDL model among different SL groups with a proposed credibility weights
prediction algorithm. Extensive experimental results demonstrate that compared
with the baseline frameworks, the proposed IoV-SFDL framework achieves a 16.72%
reduction in edge-to-global communication overhead while improving about 5.02%
in model performance with the same training iterations.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Predicting Mechanically Driven Full-Field Quantities of Interest with Deep Learning-Based Metamodels.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mohammadzadeh_S/0/1/0/all/0/1">S. Mohammadzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lejeune_E/0/1/0/all/0/1">E. Lejeune</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03995">
                                        <div class="article-summary-box-inner">
                                            <span><p>Using simulation to predict the mechanical behavior of heterogeneous
materials has applications ranging from topology optimization to multi-scale
structural analysis. However, full-fidelity simulation techniques such as
Finite Element Analysis can be prohibitively computationally expensive when
they are used to explore the massive input parameter space of heterogeneous
materials. Therefore, there has been significant recent interest in machine
learning-based models that, once trained, can predict mechanical behavior at a
fraction of the computational cost. Over the past several years, research in
this area has been focused mainly on predicting single Quantities of Interest
(QoIs). However, there has recently been an increased interest in a more
challenging problem: predicting full-field QoI (e.g., displacement/strain
fields, damage fields) for mechanical problems. Due to the added complexity of
full-field information, network architectures that perform well on single QoI
problems may perform poorly in the full-field QoI problem setting. The work
presented in this paper is twofold. First, we made a significant extension to
the Mechanical MNIST dataset designed to enable the investigation of full field
QoI prediction. Specifically, we added Finite Element simulation results of
quasi-static brittle fracture in a heterogeneous material captured with the
phase-field method. Second, we established strong baseline performance for
predicting full-field QoI with MultiRes-WNet architecture. In addition to
presenting the results in this paper, we have released our model implementation
and the Mechanical MNIST Crack Path dataset under open-source licenses. We
anticipate that future researchers will directly use our model architecture on
related datasets and potentially design models that exceed the baseline
performance for predicting full-field QoI established in this paper.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Uncertainty quantification for industrial design using dictionaries of reduced order models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Daniel_T/0/1/0/all/0/1">Thomas Daniel</a>, <a href="http://arxiv.org/find/stat/1/au:+Casenave_F/0/1/0/all/0/1">Fabien Casenave</a>, <a href="http://arxiv.org/find/stat/1/au:+Akkari_N/0/1/0/all/0/1">Nissrine Akkari</a>, <a href="http://arxiv.org/find/stat/1/au:+Ryckelynck_D/0/1/0/all/0/1">David Ryckelynck</a>, <a href="http://arxiv.org/find/stat/1/au:+Rey_C/0/1/0/all/0/1">Christian Rey</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04012">
                                        <div class="article-summary-box-inner">
                                            <span><p>We consider the dictionary-based ROM-net (Reduced Order Model) framework [T.
Daniel, F. Casenave, N. Akkari, D. Ryckelynck, Model order reduction assisted
by deep neural networks (ROM-net), Advanced modeling and Simulation in
Engineering Sciences 7 (16), 2020] and summarize the underlying methodologies
and their recent improvements. The main contribution of this work is the
application of the complete workflow to a real-life industrial model of an
elastoviscoplastic high-pressure turbine blade subjected to thermal,
centrifugal and pressure loadings, for the quantification of the uncertainty on
dual quantities (such as the accumulated plastic strain and the stress tensor),
generated by the uncertainty on the temperature loading field. The
dictionary-based ROM-net computes predictions of dual quantities of interest
for 1008 Monte Carlo draws of the temperature loading field in 2 hours and 48
minutes, which corresponds to a speedup greater than 600 with respect to a
reference parallel solver using domain decomposition, with a relative error in
the order of 2%. Another contribution of this work consists in the derivation
of a meta-model to reconstruct the dual quantities of interest over the
complete mesh from their values on the reduced integration points.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DGEM: A New Dual-modal Graph Embedding Method in Recommendation System.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huimin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rongwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhuyun Qi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04031">
                                        <div class="article-summary-box-inner">
                                            <span><p>In the current deep learning based recommendation system, the embedding
method is generally employed to complete the conversion from the
high-dimensional sparse feature vector to the low-dimensional dense feature
vector. However, as the dimension of the input vector of the embedding layer is
too large, the addition of the embedding layer significantly slows down the
convergence speed of the entire neural network, which is not acceptable in
real-world scenarios. In addition, as the interaction between users and items
increases and the relationship between items becomes more complicated, the
embedding method proposed for sequence data is no longer suitable for graphic
data in the current real environment. Therefore, in this paper, we propose the
Dual-modal Graph Embedding Method (DGEM) to solve these problems. DGEM includes
two modes, static and dynamic. We first construct the item graph to extract the
graph structure and use random walk of unequal probability to capture the
high-order proximity between the items. Then we generate the graph embedding
vector through the Skip-Gram model, and finally feed the downstream deep neural
network for the recommendation task. The experimental results show that DGEM
can mine the high-order proximity between items and enhance the expression
ability of the recommendation model. Meanwhile it also improves the
recommendation performance by utilizing the time dependent relationship between
items.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rosendo_D/0/1/0/all/0/1">Daniel Rosendo</a> (KerData), <a href="http://arxiv.org/find/cs/1/au:+Costan_A/0/1/0/all/0/1">Alexandru Costan</a>, <a href="http://arxiv.org/find/cs/1/au:+Antoniu_G/0/1/0/all/0/1">Gabriel Antoniu</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonin_M/0/1/0/all/0/1">Matthieu Simonin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombardo_J/0/1/0/all/0/1">Jean-Christophe Lombardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Joly_A/0/1/0/all/0/1">Alexis Joly</a>, <a href="http://arxiv.org/find/cs/1/au:+Valduriez_P/0/1/0/all/0/1">Patrick Valduriez</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04033">
                                        <div class="article-summary-box-inner">
                                            <span><p>In more and more application areas, we are witnessing the emergence of
complex workflows that combine computing, analytics and learning. They often
require a hybrid execution infrastructure with IoT devices interconnected to
cloud/HPC systems (aka Computing Continuum). Such workflows are subject to
complex constraints and requirements in terms of performance, resource usage,
energy consumption and financial costs. This makes it challenging to optimize
their configuration and deployment. We propose a methodology to support the
optimization of real-life applications on the Edge-to-Cloud Continuum. We
implement it as an extension of E2Clab, a previously proposed framework
supporting the complete experimental cycle across the Edge-to-Cloud Continuum.
Our approach relies on a rigorous analysis of possible configurations in a
controlled testbed environment to understand their behaviour and related
performance trade-offs. We illustrate our methodology by optimizing Pl@ntNet, a
world-wide plant identification application. Our methodology can be generalized
to other applications in the Edge-to-Cloud Continuum.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Mixture of Linear Models Co-supervised by Deep Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Seo_B/0/1/0/all/0/1">Beomseok Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04035">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep neural network (DNN) models have achieved phenomenal success for
applications in many domains, ranging from academic research in science and
engineering to industry and business. The modeling power of DNN is believed to
have come from the complexity and over-parameterization of the model, which on
the other hand has been criticized for the lack of interpretation. Although
certainly not true for every application, in some applications, especially in
economics, social science, healthcare industry, and administrative decision
making, scientists or practitioners are resistant to use predictions made by a
black-box system for multiple reasons. One reason is that a major purpose of a
study can be to make discoveries based upon the prediction function, e.g., to
reveal the relationships between measurements. Another reason can be that the
training dataset is not large enough to make researchers feel completely sure
about a purely data-driven result. Being able to examine and interpret the
prediction function will enable researchers to connect the result with existing
knowledge or gain insights about new directions to explore. Although classic
statistical models are much more explainable, their accuracy often falls
considerably below DNN. In this paper, we propose an approach to fill the gap
between relatively simple explainable models and DNN such that we can more
flexibly tune the trade-off between interpretability and accuracy. Our main
idea is a mixture of discriminative models that is trained with the guidance
from a DNN. Although mixtures of discriminative models have been studied
before, our way of generating the mixture is quite different.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Fed-BEV: A Federated Learning Framework for Modelling Energy Consumption of Battery Electric Vehicles.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingming Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04036">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, there has been an increasing interest in the roll-out of electric
vehicles (EVs) in the global automotive market. Compared to conventional
internal combustion engine vehicles (ICEVs), EVs can not only help users reduce
monetary costs in their daily commuting, but also can effectively help mitigate
the increasing level of traffic emissions produced in cities. Among many
others, battery electric vehicles (BEVs) exclusively use chemical energy stored
in their battery packs for propulsion. Hence, it becomes important to
understand how much energy can be consumed by such vehicles in various traffic
scenarios towards effective energy management. To address this challenge, we
propose a novel framework in this paper by leveraging the federated learning
approaches for modelling energy consumption for BEVs (Fed-BEV). More
specifically, a group of BEVs involved in the Fed-BEV framework can learn from
each other to jointly enhance their energy consumption model. We present the
design of the proposed system architecture and implementation details in a
co-simulation environment. Finally, comparative studies and simulation results
are discussed to illustrate the efficacy of our proposed framework for accurate
energy modelling of BEVs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Streamwise GAN Vocoder for Wideband Speech Coding at Very Low Bit Rate.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Mustafa_A/0/1/0/all/0/1">Ahmed Mustafa</a>, <a href="http://arxiv.org/find/eess/1/au:+Buthe_J/0/1/0/all/0/1">Jan B&#xfc;the</a>, <a href="http://arxiv.org/find/eess/1/au:+Korse_S/0/1/0/all/0/1">Srikanth Korse</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_K/0/1/0/all/0/1">Kishan Gupta</a>, <a href="http://arxiv.org/find/eess/1/au:+Fuchs_G/0/1/0/all/0/1">Guillaume Fuchs</a>, <a href="http://arxiv.org/find/eess/1/au:+Pia_N/0/1/0/all/0/1">Nicola Pia</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04051">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, GAN vocoders have seen rapid progress in speech synthesis, starting
to outperform autoregressive models in perceptual quality with much higher
generation speed. However, autoregressive vocoders are still the common choice
for neural generation of speech signals coded at very low bit rates. In this
paper, we present a GAN vocoder which is able to generate wideband speech
waveforms from parameters coded at 1.6 kbit/s. The proposed model is a modified
version of the StyleMelGAN vocoder that can run in frame-by-frame manner,
making it suitable for streaming applications. The experimental results show
that the proposed model significantly outperforms prior autoregressive vocoders
like LPCNet for very low bit rate speech coding, with computational complexity
of about 5 GMACs, providing a new state of the art in this domain. Moreover,
this streamwise adversarial vocoder delivers quality competitive to advanced
speech codecs such as EVS at 5.9 kbit/s on clean speech, which motivates
further usage of feed-forward fully-convolutional models for low bit rate
speech coding.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Training of deep residual networks with stochastic MG/OPT.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Planta_C/0/1/0/all/0/1">Cyrill von Planta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopanicakova_A/0/1/0/all/0/1">Alena Kopanicakova</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_R/0/1/0/all/0/1">Rolf Krause</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04052">
                                        <div class="article-summary-box-inner">
                                            <span><p>We train deep residual networks with a stochastic variant of the nonlinear
multigrid method MG/OPT. To build the multilevel hierarchy, we use the
dynamical systems viewpoint specific to residual networks. We report
significant speed-ups and additional robustness for training MNIST on deep
residual networks. Our numerical experiments also indicate that multilevel
training can be used as a pruning technique, as many of the auxiliary networks
have accuracies comparable to the original network.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ The Role of Global Labels in Few-Shot Classification and How to Infer Them.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruohan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pontil_M/0/1/0/all/0/1">Massimiliano Pontil</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciliberto_C/0/1/0/all/0/1">Carlo Ciliberto</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04055">
                                        <div class="article-summary-box-inner">
                                            <span><p>Few-shot learning (FSL) is a central problem in meta-learning, where learners
must quickly adapt to new tasks given limited training data. Surprisingly,
recent works have outperformed meta-learning methods tailored to FSL by casting
it as standard supervised learning to jointly classify all classes shared
across tasks. However, this approach violates the standard FSL setting by
requiring global labels shared across tasks, which are often unavailable in
practice. In this paper, we show why solving FSL via standard classification is
theoretically advantageous. This motivates us to propose Meta Label Learning
(MeLa), a novel algorithm that infers global labels and obtains robust few-shot
models via standard classification. Empirically, we demonstrate that MeLa
outperforms meta-learning competitors and is comparable to the oracle setting
where ground truth labels are given. We provide extensive ablation studies to
highlight the key properties of the proposed strategy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ An Interpretable Probabilistic Model for Short-Term Solar Power Forecasting Using Natural Gradient Boosting.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Mitrentsis_G/0/1/0/all/0/1">Georgios Mitrentsis</a>, <a href="http://arxiv.org/find/stat/1/au:+Lens_H/0/1/0/all/0/1">Hendrik Lens</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04058">
                                        <div class="article-summary-box-inner">
                                            <span><p>The stochastic nature of photovoltaic (PV) power has led both academia and
industry to a large amount of research work aiming at the development of
accurate PV power forecasting models. However, most of those models are based
on machine learning algorithms and are considered as black boxes which do not
provide any insight or explanation about their predictions. Therefore, their
direct implementation in environments, where transparency is required, and the
trust associated with their predictions may be questioned. To this end, we
propose a two stage probabilistic forecasting framework able to generate highly
accurate, reliable, and sharp forecasts yet offering full transparency on both
the point forecasts and the prediction intervals (PIs). In the first stage, we
exploit natural gradient boosting (NGBoost) for yielding probabilistic
forecasts while in the second stage, we calculate the Shapley additive
explanation (SHAP) values in order to fully understand why a prediction was
made. To highlight the performance and the applicability of the proposed
framework, real data from two PV parks located in Southern Germany are
employed. Initially, the natural gradient boosting is thoroughly compared with
two state-of-the-art algorithms, namely Gaussian process and lower upper bound
estimation, in a wide range of forecasting metrics. Secondly, a detailed
analysis of the model's complex nonlinear relationships and interaction effects
between the various features is presented. The latter allows us to interpret
the model, identify some learned physical properties, explain individual
predictions, reduce the computational requirements for the training without
jeopardizing the model accuracy, detect possible bugs, and gain trust in the
model. Finally, we conclude that the model was able to develop nonlinear
relationships following human logic and intuition based on learned physical
properties.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Memory-Aware Partitioning of Machine Learning Applications for Optimal Energy Use in Batteryless Systems.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Andres Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Tretter_A/0/1/0/all/0/1">Andreas Tretter</a>, <a href="http://arxiv.org/find/cs/1/au:+Hager_P/0/1/0/all/0/1">Pascal Alexander Hager</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanmugarajah_P/0/1/0/all/0/1">Praveenth Sanmugarajah</a>, <a href="http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1">Luca Benini</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiele_L/0/1/0/all/0/1">Lothar Thiele</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04059">
                                        <div class="article-summary-box-inner">
                                            <span><p>Sensing systems powered by energy harvesting have traditionally been designed
to tolerate long periods without energy. As the Internet of Things (IoT)
evolves towards a more transient and opportunistic execution paradigm, reducing
energy storage costs will be key for its economic and ecologic viability.
However, decreasing energy storage in harvesting systems introduces reliability
issues. Transducers only produce intermittent energy at low voltage and current
levels, making guaranteed task completion a challenge. Existing ad hoc methods
overcome this by buffering enough energy either for single tasks, incurring
large data-retention overheads, or for one full application cycle, requiring a
large energy buffer. We present Julienning: an automated method for optimizing
the total energy cost of batteryless applications. Using a custom specification
model, developers can describe transient applications as a set of atomically
executed kernels with explicit data dependencies. Our optimization flow can
partition data- and energy-intensive applications into multiple execution
cycles with bounded energy consumption. By leveraging interkernel data
dependencies, these energy-bounded execution cycles minimize the number of
system activations and nonvolatile data transfers, and thus the total energy
overhead. We validate our methodology with two batteryless cameras running
energy-intensive machine learning applications. Results demonstrate that
compared to ad hoc solutions, our method can reduce the required energy storage
by over 94% while only incurring a 0.12% energy overhead.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Householder Activations for Provable Robustness against Adversarial Attacks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Sahil Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Surbhi Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1">Soheil Feizi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04062">
                                        <div class="article-summary-box-inner">
                                            <span><p>Training convolutional neural networks (CNNs) with a strict Lipschitz
constraint under the l_{2} norm is useful for provable adversarial robustness,
interpretable gradients and stable training. While 1-Lipschitz CNNs can be
designed by enforcing a 1-Lipschitz constraint on each layer, training such
networks requires each layer to have an orthogonal Jacobian matrix (for all
inputs) to prevent gradients from vanishing during backpropagation. A layer
with this property is said to be Gradient Norm Preserving (GNP). To construct
expressive GNP activation functions, we first prove that the Jacobian of any
GNP piecewise linear function is only allowed to change via Householder
transformations for the function to be continuous. Building on this result, we
introduce a class of nonlinear GNP activations with learnable Householder
transformations called Householder activations. A householder activation
parameterized by the vector $\mathbf{v}$ outputs $(\mathbf{I} -
2\mathbf{v}\mathbf{v}^{T})\mathbf{z}$ for its input $\mathbf{z}$ if
$\mathbf{v}^{T}\mathbf{z} \leq 0$; otherwise it outputs $\mathbf{z}$. Existing
GNP activations such as $\mathrm{MaxMin}$ can be viewed as special cases of
$\mathrm{HH}$ activations for certain settings of these transformations. Thus,
networks with $\mathrm{HH}$ activations have higher expressive power than those
with $\mathrm{MaxMin}$ activations. Although networks with $\mathrm{HH}$
activations have nontrivial provable robustness against adversarial attacks, we
further boost their robustness by (i) introducing a certificate regularization
and (ii) relaxing orthogonalization of the last layer of the network. Our
experiments on CIFAR-10 and CIFAR-100 show that our regularized networks with
$\mathrm{HH}$ activations lead to significant improvements in both the standard
and provable robust accuracy over the prior works (gain of 3.65\% and 4.46\% on
CIFAR-100 respectively).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Co-learning: Learning from Noisy Labels with Self-supervision.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Cheng Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1">Jun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lirong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Stan Z. Li</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04063">
                                        <div class="article-summary-box-inner">
                                            <span><p>Noisy labels, resulting from mistakes in manual labeling or webly data
collecting for supervised learning, can cause neural networks to overfit the
misleading information and degrade the generalization performance.
Self-supervised learning works in the absence of labels and thus eliminates the
negative impact of noisy labels. Motivated by co-training with both supervised
learning view and self-supervised learning view, we propose a simple yet
effective method called Co-learning for learning with noisy labels. Co-learning
performs supervised learning and self-supervised learning in a cooperative way.
The constraints of intrinsic similarity with the self-supervised module and the
structural similarity with the noisily-supervised module are imposed on a
shared common feature encoder to regularize the network to maximize the
agreement between the two constraints. Co-learning is compared with peer
methods on corrupted data from benchmark datasets fairly, and extensive results
are provided which demonstrate that Co-learning is superior to many
state-of-the-art approaches.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Model-free inference of unseen attractors: Reconstructing phase space features from a single noisy trajectory using reservoir computing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1">Andr&#xe9; R&#xf6;hm</a>, <a href="http://arxiv.org/find/cs/1/au:+Gauthier_D/0/1/0/all/0/1">Daniel J. Gauthier</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_I/0/1/0/all/0/1">Ingo Fischer</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04074">
                                        <div class="article-summary-box-inner">
                                            <span><p>Reservoir computers are powerful tools for chaotic time series prediction.
They can be trained to approximate phase space flows and can thus both predict
future values to a high accuracy, as well as reconstruct the general properties
of a chaotic attractor without requiring a model. In this work, we show that
the ability to learn the dynamics of a complex system can be extended to
systems with co-existing attractors, here a 4-dimensional extension of the
well-known Lorenz chaotic system. We demonstrate that a reservoir computer can
infer entirely unexplored parts of the phase space: a properly trained
reservoir computer can predict the existence of attractors that were never
approached during training and therefore are labelled as unseen. We provide
examples where attractor inference is achieved after training solely on a
single noisy trajectory.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Leveraging Uncertainty for Improved Static Malware Detection Under Extreme False Positive Constraints.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Andre T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1">Edward Raff</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1">Charles Nicholas</a>, <a href="http://arxiv.org/find/cs/1/au:+Holt_J/0/1/0/all/0/1">James Holt</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04081">
                                        <div class="article-summary-box-inner">
                                            <span><p>The detection of malware is a critical task for the protection of computing
environments. This task often requires extremely low false positive rates (FPR)
of 0.01% or even lower, for which modern machine learning has no readily
available tools. We introduce the first broad investigation of the use of
uncertainty for malware detection across multiple datasets, models, and feature
types. We show how ensembling and Bayesian treatments of machine learning
methods for static malware detection allow for improved identification of model
errors, uncovering of new malware families, and predictive performance under
extreme false positive constraints. In particular, we improve the true positive
rate (TPR) at an actual realized FPR of 1e-5 from an expected 0.69 for previous
methods to 0.80 on the best performing model class on the Sophos industry scale
dataset. We additionally demonstrate how previous works have used an evaluation
protocol that can lead to misleading results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Bayesian Deep Learning for Partial Differential Equation Parameter Discovery with Sparse and Noisy Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Bonneville_C/0/1/0/all/0/1">Christophe Bonneville</a>, <a href="http://arxiv.org/find/math/1/au:+Earls_C/0/1/0/all/0/1">Christopher J. Earls</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04085">
                                        <div class="article-summary-box-inner">
                                            <span><p>Scientific machine learning has been successfully applied to inverse problems
and PDE discoveries in computational physics. One caveat of current methods
however is the need for large amounts of (clean) data in order to recover full
system responses or underlying physical models. Bayesian methods may be
particularly promising to overcome these challenges as they are naturally less
sensitive to sparse and noisy data. In this paper, we propose to use Bayesian
neural networks (BNN) in order to: 1) Recover the full system states from
measurement data (e.g. temperature, velocity field, etc.). We use Hamiltonian
Monte-Carlo to sample the posterior distribution of a deep and dense BNN, and
show that it is possible to accurately capture physics of varying complexity
without overfitting. 2) Recover the parameters in the underlying partial
differential equation (PDE) governing the physical system. Using the trained
BNN as a surrogate of the system response, we generate datasets of derivatives
potentially comprising the latent PDE of the observed system and perform a
Bayesian linear regression (BLR) between the successive derivatives in space
and time to recover the original PDE parameters. We take advantage of the
confidence intervals on the BNN outputs and introduce the spatial derivative
variance into the BLR likelihood to discard the influence of highly uncertain
surrogate data points, which allows for more accurate parameter discovery. We
demonstrate our approach on a handful of example applied to physics and
non-linear dynamics.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Reinforcement Learning for Intelligent Healthcare Systems: A Comprehensive Survey.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Abdellatif_A/0/1/0/all/0/1">Alaa Awad Abdellatif</a>, <a href="http://arxiv.org/find/cs/1/au:+Mhaisen_N/0/1/0/all/0/1">Naram Mhaisen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chkirbene_Z/0/1/0/all/0/1">Zina Chkirbene</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Amr Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1">Aiman Erbad</a>, <a href="http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1">Mohsen Guizani</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04087">
                                        <div class="article-summary-box-inner">
                                            <span><p>The rapid increase in the percentage of chronic disease patients along with
the recent pandemic pose immediate threats on healthcare expenditure and
elevate causes of death. This calls for transforming healthcare systems away
from one-on-one patient treatment into intelligent health systems, to improve
services, access and scalability, while reducing costs. Reinforcement Learning
(RL) has witnessed an intrinsic breakthrough in solving a variety of complex
problems for diverse applications and services. Thus, we conduct in this paper
a comprehensive survey of the recent models and techniques of RL that have been
developed/used for supporting Intelligent-healthcare (I-health) systems. This
paper can guide the readers to deeply understand the state-of-the-art regarding
the use of RL in the context of I-health. Specifically, we first present an
overview for the I-health systems challenges, architecture, and how RL can
benefit these systems. We then review the background and mathematical modeling
of different RL, Deep RL (DRL), and multi-agent RL models. After that, we
provide a deep literature review for the applications of RL in I-health
systems. In particular, three main areas have been tackled, i.e., edge
intelligence, smart core network, and dynamic treatment regimes. Finally, we
highlight emerging challenges and outline future research directions in driving
the future success of RL in I-health systems, which opens the door for
exploring some interesting and unsolved problems.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.00414">
                                        <div class="article-summary-box-inner">
                                            <span><p>A central roadblock to analyzing quantum algorithms on quantum states is the
lack of a comparable input model for classical algorithms. Inspired by recent
work of the author [E. Tang, STOC'19], we introduce such a model, where we
assume we can efficiently perform $\ell^2$-norm samples of input data, a
natural analogue to quantum algorithms that assume efficient state preparation
of classical data. Though this model produces less practical algorithms than
the (stronger) standard model of classical computation, it captures versions of
many of the features and nuances of quantum linear algebra algorithms. With
this model, we describe classical analogues to Lloyd, Mohseni, and Rebentrost's
quantum algorithms for principal component analysis [Nat. Phys. 10, 631 (2014)]
and nearest-centroid clustering [<a href="/abs/1307.0411">arXiv:1307.0411</a>]. Since they are only
polynomially slower, these algorithms suggest that the exponential speedups of
their quantum counterparts are simply an artifact of state preparation
assumptions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Optimizing thermodynamic trajectories using evolutionary and gradient-based reinforcement learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Beeler_C/0/1/0/all/0/1">Chris Beeler</a>, <a href="http://arxiv.org/find/cs/1/au:+Yahorau_U/0/1/0/all/0/1">Uladzimir Yahorau</a>, <a href="http://arxiv.org/find/cs/1/au:+Coles_R/0/1/0/all/0/1">Rory Coles</a>, <a href="http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1">Kyle Mills</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitelam_S/0/1/0/all/0/1">Stephen Whitelam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1">Isaac Tamblyn</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.08543">
                                        <div class="article-summary-box-inner">
                                            <span><p>Using a model heat engine, we show that neural network-based reinforcement
learning can identify thermodynamic trajectories of maximal efficiency. We
consider both gradient and gradient-free reinforcement learning. We use an
evolutionary learning algorithm to evolve a population of neural networks,
subject to a directive to maximize the efficiency of a trajectory composed of a
set of elementary thermodynamic processes; the resulting networks learn to
carry out the maximally-efficient Carnot, Stirling, or Otto cycles. When given
an additional irreversible process, this evolutionary scheme learns a
previously unknown thermodynamic cycle. Gradient-based reinforcement learning
is able to learn the Stirling cycle, whereas an evolutionary approach achieves
the optimal Carnot cycle. Our results show how the reinforcement learning
strategies developed for game playing can be applied to solve physical problems
conditioned upon path-extensive order parameters.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Solving high-dimensional optimal stopping problems using deep learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1">Sebastian Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheridito_P/0/1/0/all/0/1">Patrick Cheridito</a>, <a href="http://arxiv.org/find/cs/1/au:+Jentzen_A/0/1/0/all/0/1">Arnulf Jentzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Welti_T/0/1/0/all/0/1">Timo Welti</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.01602">
                                        <div class="article-summary-box-inner">
                                            <span><p>Nowadays many financial derivatives, such as American or Bermudan options,
are of early exercise type. Often the pricing of early exercise options gives
rise to high-dimensional optimal stopping problems, since the dimension
corresponds to the number of underlying assets. High-dimensional optimal
stopping problems are, however, notoriously difficult to solve due to the
well-known curse of dimensionality. In this work, we propose an algorithm for
solving such problems, which is based on deep learning and computes, in the
context of early exercise option pricing, both approximations of an optimal
exercise strategy and the price of the considered option. The proposed
algorithm can also be applied to optimal stopping problems that arise in other
areas where the underlying stochastic process can be efficiently simulated. We
present numerical results for a large number of example problems, which include
the pricing of many high-dimensional American and Bermudan options, such as
Bermudan max-call options in up to 5000 dimensions. Most of the obtained
results are compared to reference values computed by exploiting the specific
problem design or, where available, to reference values from the literature.
These numerical results suggest that the proposed algorithm is highly effective
in the case of many underlyings, in terms of both accuracy and speed.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Manifold Oblique Random Forests: Towards Closing the Gap on Convolutional Deep Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Perry_R/0/1/0/all/0/1">Ronan Perry</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Adam Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_C/0/1/0/all/0/1">Chester Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomita_T/0/1/0/all/0/1">Tyler M. Tomita</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1">Ronak Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Arroyo_J/0/1/0/all/0/1">Jesus Arroyo</a>, <a href="http://arxiv.org/find/cs/1/au:+Patsolic_J/0/1/0/all/0/1">Jesse Patsolic</a>, <a href="http://arxiv.org/find/cs/1/au:+Falk_B/0/1/0/all/0/1">Benjamin Falk</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11799">
                                        <div class="article-summary-box-inner">
                                            <span><p>Decision forests (Forests), in particular random forests and gradient
boosting trees, have demonstrated state-of-the-art accuracy compared to other
methods in many supervised learning scenarios. In particular, Forests dominate
other methods in tabular data, that is, when the feature space is unstructured,
so that the signal is invariant to a permutation of the feature indices.
However, in structured data lying on a manifold (such as images, text, and
speech) deep networks (Networks), specifically convolutional deep networks
(ConvNets), tend to outperform Forests. We conjecture that at least part of the
reason for this is that the input to Networks is not simply the feature
magnitudes, but also their indices. In contrast, naive Forest implementations
fail to explicitly consider feature indices. A recently proposed Forest
approach demonstrates that Forests, for each node, implicitly sample a random
matrix from some specific distribution. These Forests, like some classes of
Networks, learn by partitioning the feature space into convex polytopes
corresponding to linear functions. We build on that approach and show that one
can choose distributions in a manifold-aware fashion to incorporate feature
locality. We demonstrate the empirical performance on data whose features live
on three different manifolds: a torus, images, and time-series. Moreover, we
demonstrate its strength in multivariate simulated settings and also show
superiority in predicting surgical outcome in epilepsy patients and predicting
movement direction from raw stereotactic EEG data from non-motor brain regions.
In all simulations and real data, Manifold Oblique Random Forest (MORF)
algorithm outperforms approaches that ignore feature space structure and
challenges the performance of ConvNets. Moreover, MORF runs fast and maintains
interpretability and theoretical justification.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Complex <span class="highlight_title">Transformer</span>: A Framework for Modeling Complex-Valued Sequence.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Muqiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Martin Q. Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yao-Hung Hubert Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10202">
                                        <div class="article-summary-box-inner">
                                            <span><p>While deep learning has received a surge of interest in a variety of fields
in recent years, major deep learning models barely use complex numbers.
However, speech, signal and audio data are naturally complex-valued after
Fourier Transform, and studies have shown a potentially richer representation
of complex nets. In this paper, we propose a Complex Transformer, which
incorporates the transformer model as a backbone for sequence modeling; we also
develop attention and encoder-decoder network operating for complex input. The
model achieves state-of-the-art performance on the MusicNet dataset and an
In-phase Quadrature (IQ) signal dataset.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ A Weak Supervision Approach to Detecting Visual Anomalies for Automated Testing of Graphics Units.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Szeskin_A/0/1/0/all/0/1">Adi Szeskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Faivishevsky_L/0/1/0/all/0/1">Lev Faivishevsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Muppalla_A/0/1/0/all/0/1">Ashwin K Muppalla</a>, <a href="http://arxiv.org/find/cs/1/au:+Armon_A/0/1/0/all/0/1">Amitai Armon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.04138">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a deep learning system for testing graphics units by detecting
novel visual corruptions in videos. Unlike previous work in which manual
tagging was required to collect labeled training data, our weak supervision
method is fully automatic and needs no human labelling. This is achieved by
reproducing driver bugs that increase the probability of generating
corruptions, and by making use of ideas and methods from the Multiple Instance
Learning (MIL) setting. In our experiments, we significantly outperform
unsupervised methods such as GAN-based models and discover novel corruptions
undetected by baselines, while adhering to strict requirements on accuracy and
efficiency of our real-time system.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Maxmin Q-learning: Controlling the Estimation Bias of Q-learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lan_Q/0/1/0/all/0/1">Qingfeng Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yangchen Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fyshe_A/0/1/0/all/0/1">Alona Fyshe</a>, <a href="http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1">Martha White</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.06487">
                                        <div class="article-summary-box-inner">
                                            <span><p>Q-learning suffers from overestimation bias, because it approximates the
maximum action value using the maximum estimated action value. Algorithms have
been proposed to reduce overestimation bias, but we lack an understanding of
how bias interacts with performance, and the extent to which existing
algorithms mitigate bias. In this paper, we 1) highlight that the effect of
overestimation bias on learning efficiency is environment-dependent; 2) propose
a generalization of Q-learning, called \emph{Maxmin Q-learning}, which provides
a parameter to flexibly control bias; 3) show theoretically that there exists a
parameter choice for Maxmin Q-learning that leads to unbiased estimation with a
lower approximation variance than Q-learning; and 4) prove the convergence of
our algorithm in the tabular case, as well as convergence of several previous
Q-learning variants, using a novel Generalized Q-learning framework. We
empirically verify that our algorithm better controls estimation bias in toy
environments, and that it achieves superior performance on several benchmark
problems.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ A survey of statistical learning techniques as applied to inexpensive pediatric Obstructive Sleep Apnea data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/q-bio/1/au:+Winn_E/0/1/0/all/0/1">Emily T. Winn</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Vazquez_M/0/1/0/all/0/1">Marilyn Vazquez</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Loliencar_P/0/1/0/all/0/1">Prachi Loliencar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Taipale_K/0/1/0/all/0/1">Kaisa Taipale</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1">Xu Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Heo_G/0/1/0/all/0/1">Giseon Heo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.07873">
                                        <div class="article-summary-box-inner">
                                            <span><p>Pediatric obstructive sleep apnea affects an estimated 1-5% of
elementary-school aged children and can lead to other detrimental health
problems. Swift diagnosis and treatment are critical to a child's growth and
development, but the variability of symptoms and the complexity of the
available data make this a challenge. We take a first step in streamlining the
process by focusing on inexpensive data from questionnaires and craniofacial
measurements. We apply correlation networks, the Mapper algorithm from
topological data analysis, and singular value decomposition in a process of
exploratory data analysis. We then apply a variety of supervised and
unsupervised learning techniques from statistics, machine learning, and
topology, ranging from support vector machines to Bayesian classifiers and
manifold learning. Finally, we analyze the results of each of these methods and
discuss the implications for a multi-data-sourced algorithm moving forward.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Nonconvex sparse regularization for deep neural networks and its optimality.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Ohn_I/0/1/0/all/0/1">Ilsang Ohn</a>, <a href="http://arxiv.org/find/math/1/au:+Kim_Y/0/1/0/all/0/1">Yongdai Kim</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.11769">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent theoretical studies proved that deep neural network (DNN) estimators
obtained by minimizing empirical risk with a certain sparsity constraint can
attain optimal convergence rates for regression and classification problems.
However, the sparsity constraint requires to know certain properties of the
true model, which are not available in practice. Moreover, computation is
difficult due to the discrete nature of the sparsity constraint. In this paper,
we propose a novel penalized estimation method for sparse DNNs, which resolves
the aforementioned problems existing in the sparsity constraint. We establish
an oracle inequality for the excess risk of the proposed sparse-penalized DNN
estimator and derive convergence rates for several learning tasks. In
particular, we prove that the sparse-penalized estimator can adaptively attain
minimax convergence rates for various nonparametric regression problems. For
computation, we develop an efficient gradient-based optimization algorithm that
guarantees the monotonic reduction of the objective function.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On the Convergence Rate of Projected Gradient Descent for a Back-Projection based Objective.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Tirer_T/0/1/0/all/0/1">Tom Tirer</a>, <a href="http://arxiv.org/find/math/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00959">
                                        <div class="article-summary-box-inner">
                                            <span><p>Ill-posed linear inverse problems appear in many scientific setups, and are
typically addressed by solving optimization problems, which are composed of
data fidelity and prior terms. Recently, several works have considered a
back-projection (BP) based fidelity term as an alternative to the common least
squares (LS), and demonstrated excellent results for popular inverse problems.
These works have also empirically shown that using the BP term, rather than the
LS term, requires fewer iterations of optimization algorithms. In this paper,
we examine the convergence rate of the projected gradient descent (PGD)
algorithm for the BP objective. Our analysis allows to identify an inherent
source for its faster convergence compared to using the LS objective, while
making only mild assumptions. We also analyze the more general proximal
gradient method under a relaxed contraction condition on the proximal mapping
of the prior. This analysis further highlights the advantage of BP when the
linear measurement operator is badly conditioned. Numerical experiments with
both $\ell_1$-norm and GAN-based priors corroborate our theoretical results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Sample Complexity of Asynchronous Q-Learning: Sharper Analysis and Variance Reduction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yuting Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1">Yuejie Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuantao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03041">
                                        <div class="article-summary-box-inner">
                                            <span><p>Asynchronous Q-learning aims to learn the optimal action-value function (or
Q-function) of a Markov decision process (MDP), based on a single trajectory of
Markovian samples induced by a behavior policy. Focusing on a
$\gamma$-discounted MDP with state space $\mathcal{S}$ and action space
$\mathcal{A}$, we demonstrate that the $\ell_{\infty}$-based sample complexity
of classical asynchronous Q-learning --- namely, the number of samples needed
to yield an entrywise $\varepsilon$-accurate estimate of the Q-function --- is
at most on the order of $\frac{1}{\mu_{\min}(1-\gamma)^5\varepsilon^2}+
\frac{t_{mix}}{\mu_{\min}(1-\gamma)}$ up to some logarithmic factor, provided
that a proper constant learning rate is adopted. Here, $t_{mix}$ and
$\mu_{\min}$ denote respectively the mixing time and the minimum state-action
occupancy probability of the sample trajectory. The first term of this bound
matches the sample complexity in the synchronous case with independent samples
drawn from the stationary distribution of the trajectory. The second term
reflects the cost taken for the empirical distribution of the Markovian
trajectory to reach a steady state, which is incurred at the very beginning and
becomes amortized as the algorithm runs. Encouragingly, the above bound
improves upon the state-of-the-art result \cite{qu2020finite} by a factor of at
least $|\mathcal{S}||\mathcal{A}|$ for all scenarios, and by a factor of at
least $t_{mix}|\mathcal{S}||\mathcal{A}|$ for any sufficiently small accuracy
level $\varepsilon$. Further, we demonstrate that the scaling on the effective
horizon $\frac{1}{1-\gamma}$ can be improved by means of variance reduction.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Fairness Under Feature Exemptions: Counterfactual and Observational Measures.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Sanghamitra Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_P/0/1/0/all/0/1">Praveen Venkatesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mardziel_P/0/1/0/all/0/1">Piotr Mardziel</a>, <a href="http://arxiv.org/find/cs/1/au:+Datta_A/0/1/0/all/0/1">Anupam Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_P/0/1/0/all/0/1">Pulkit Grover</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07986">
                                        <div class="article-summary-box-inner">
                                            <span><p>With the growing use of ML in highly consequential domains, quantifying
disparity with respect to protected attributes, e.g., gender, race, etc., is
important. While quantifying disparity is essential, sometimes the needs of an
occupation may require the use of certain features that are critical in a way
that any disparity that can be explained by them might need to be exempted.
E.g., in hiring a software engineer for a safety-critical application,
coding-skills may be weighed strongly, whereas name, zip code, or reference
letters may be used only to the extent that they do not add disparity. In this
work, we propose an information-theoretic decomposition of the total disparity
(a quantification inspired from counterfactual fairness) into two components: a
non-exempt component which quantifies the part that cannot be accounted for by
the critical features, and an exempt component that quantifies the remaining
disparity. This decomposition allows one to check if the disparity arose purely
due to the critical features (inspired from the business necessity defense of
disparate impact law) and also enables selective removal of the non-exempt
component if desired. We arrive at this decomposition through canonical
examples that lead to a set of desirable properties (axioms) that a measure of
non-exempt disparity should satisfy. Our proposed measure satisfies all of
them. Our quantification bridges ideas of causality, Simpson's paradox, and a
body of work from information theory called Partial Information Decomposition.
We also obtain an impossibility result showing that no observational measure
can satisfy all the desirable properties, leading us to relax our goals and
examine observational measures that satisfy only some of them. We perform case
studies to show how one can audit/train models while reducing non-exempt
disparity.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ AlphaGAN: Fully Differentiable Architecture Search for Generative Adversarial Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuesong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1">Guinan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09134">
                                        <div class="article-summary-box-inner">
                                            <span><p>Generative Adversarial Networks (GANs) are formulated as minimax game
problems, whereby generators attempt to approach real data distributions by
virtue of adversarial learning against discriminators. The intrinsic problem
complexity poses the challenge to enhance the performance of generative
networks. In this work, we aim to boost model learning from the perspective of
network architectures, by incorporating recent progress on automated
architecture search into GANs. To this end, we propose a fully differentiable
search framework for generative adversarial networks, dubbed alphaGAN. The
searching process is formalized as solving a bi-level minimax optimization
problem, in which the outer-level objective aims for seeking a suitable network
architecture towards pure Nash Equilibrium conditioned on the generator and the
discriminator network parameters optimized with a traditional GAN loss in the
inner level. The entire optimization performs a first-order method by
alternately minimizing the two-level objective in a fully differentiable
manner, enabling architecture search to be completed in an enormous search
space. Extensive experiments on CIFAR-10 and STL-10 datasets show that our
algorithm can obtain high-performing architectures only with 3-GPU hours on a
single GPU in the search space comprised of approximate 2 ? 1011 possible
configurations. We also provide a comprehensive analysis on the behavior of the
searching process and the properties of searched architectures, which would
benefit further research on architectures for generative models. Pretrained
models and codes are available at https://github.com/yuesongtian/AlphaGAN.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Multilevel Graph Matching Networks for Deep Graph Similarity Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1">Xiang Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Saizhuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengfei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Fangli Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Alex X. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chunming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shouling Ji</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04395">
                                        <div class="article-summary-box-inner">
                                            <span><p>While the celebrated graph neural networks yield effective representations
for individual nodes of a graph, there has been relatively less success in
extending to the task of graph similarity learning. Recent work on graph
similarity learning has considered either global-level graph-graph interactions
or low-level node-node interactions, however ignoring the rich cross-level
interactions (e.g., between each node of one graph and the other whole graph).
In this paper, we propose a multi-level graph matching network (MGMN) framework
for computing the graph similarity between any pair of graph-structured objects
in an end-to-end fashion. In particular, the proposed MGMN consists of a
node-graph matching network for effectively learning cross-level interactions
between each node of one graph and the other whole graph, and a siamese graph
neural network to learn global-level interactions between two input graphs.
Furthermore, to compensate for the lack of standard benchmark datasets, we have
created and collected a set of datasets for both the graph-graph classification
and graph-graph regression tasks with different sizes in order to evaluate the
effectiveness and robustness of our models. Comprehensive experiments
demonstrate that MGMN consistently outperforms state-of-the-art baseline models
on both the graph-graph classification and graph-graph regression tasks.
Compared with previous work, MGMN also exhibits stronger robustness as the
sizes of the two input graphs increase.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On the Nature and Types of Anomalies: A Review of Deviations in Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Foorthuis_R/0/1/0/all/0/1">Ralph Foorthuis</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15634">
                                        <div class="article-summary-box-inner">
                                            <span><p>Anomalies are occurrences in a dataset that are in some way unusual and do
not fit the general patterns. The concept of the anomaly is typically
ill-defined and perceived as vague and domain-dependent. Moreover, despite some
250 years of publications on the topic, no comprehensive and concrete overviews
of the different types of anomalies have hitherto been published. By means of
an extensive literature review this study therefore offers the first
theoretically principled and domain-independent typology of data anomalies and
presents a full overview of anomaly types and subtypes. To concretely define
the concept of the anomaly and its different manifestations, the typology
employs five dimensions: data type, cardinality of relationship, anomaly level,
data structure, and data distribution. These fundamental and data-centric
dimensions naturally yield 3 broad groups, 9 basic types, and 63 subtypes of
anomalies. The typology facilitates the evaluation of the functional
capabilities of anomaly detection algorithms, contributes to explainable data
science, and provides insights into relevant topics such as local versus global
anomalies.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Iterative Pre-Conditioning for Expediting the Gradient-Descent Method: The Distributed Linear Least-Squares Problem.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Chakrabarti_K/0/1/0/all/0/1">Kushal Chakrabarti</a>, <a href="http://arxiv.org/find/math/1/au:+Gupta_N/0/1/0/all/0/1">Nirupam Gupta</a>, <a href="http://arxiv.org/find/math/1/au:+Chopra_N/0/1/0/all/0/1">Nikhil Chopra</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02856">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper considers the multi-agent linear least-squares problem in a
server-agent network. In this problem, the system comprises multiple agents,
each having a set of local data points, that are connected to a server. The
goal for the agents is to compute a linear mathematical model that optimally
fits the collective data points held by all the agents, without sharing their
individual local data points. This goal can be achieved, in principle, using
the server-agent variant of the traditional iterative gradient-descent method.
The gradient-descent method converges linearly to a solution, and its rate of
convergence is lower bounded by the conditioning of the agents' collective data
points. If the data points are ill-conditioned, the gradient-descent method may
require a large number of iterations to converge.
</p>
<p>We propose an iterative pre-conditioning technique that mitigates the
deleterious effect of the conditioning of data points on the rate of
convergence of the gradient-descent method. We rigorously show that the
resulting pre-conditioned gradient-descent method, with the proposed iterative
pre-conditioning, achieves superlinear convergence when the least-squares
problem has a unique solution. In general, the convergence is linear with
improved rate of convergence in comparison to the traditional gradient-descent
method and the state-of-the-art accelerated gradient-descent methods. We
further illustrate the improved rate of convergence of our proposed algorithm
through experiments on different real-world least-squares problems in both
noise-free and noisy computation environment.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1">Aman Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+OKelly_M/0/1/0/all/0/1">Matthew O&#x27;Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1">Russ Tedrake</a>, <a href="http://arxiv.org/find/cs/1/au:+Duchi_J/0/1/0/all/0/1">John Duchi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10581">
                                        <div class="article-summary-box-inner">
                                            <span><p>Learning-based methodologies increasingly find applications in
safety-critical domains like autonomous driving and medical robotics. Due to
the rare nature of dangerous events, real-world testing is prohibitively
expensive and unscalable. In this work, we employ a probabilistic approach to
safety evaluation in simulation, where we are concerned with computing the
probability of dangerous events. We develop a novel rare-event simulation
method that combines exploration, exploitation, and optimization techniques to
find failure modes and estimate their rate of occurrence. We provide rigorous
guarantees for the performance of our method in terms of both statistical and
computational efficiency. Finally, we demonstrate the efficacy of our approach
on a variety of scenarios, illustrating its usefulness as a tool for rapid
sensitivity analysis and model comparison that are essential to developing and
testing safety-critical autonomous systems.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ How to "Improve" Prediction Using Behavior Modification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Shmueli_G/0/1/0/all/0/1">Galit Shmueli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tafti_A/0/1/0/all/0/1">Ali Tafti</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.12138">
                                        <div class="article-summary-box-inner">
                                            <span><p>Many internet platforms that collect behavioral big data use it to predict
user behavior for internal purposes and for their business customers (e.g.,
advertisers, insurers, security forces, governments, political consulting
firms) who utilize the predictions for personalization, targeting, and other
decision-making. Improving predictive accuracy is therefore extremely valuable.
Data science researchers design algorithms, models, and approaches to improve
prediction. Prediction is also improved with larger and richer data. Beyond
improving algorithms and data, platforms can stealthily achieve better
prediction accuracy by "pushing" users' behaviors towards their predicted
values, using behavior modification techniques, thereby demonstrating more
certain predictions. Such apparent "improved" prediction can unintentionally
result from employing reinforcement learning algorithms that combine prediction
and behavior modification. This strategy is absent from the machine learning
and statistics literature. Investigating its properties requires integrating
causal with predictive notation. To this end, we incorporate Pearl's causal
do(.) operator into the predictive vocabulary. We then decompose the expected
prediction error given behavior modification, and identify the components
impacting predictive power. Our derivation elucidates implications of such
behavior modification to data scientists, platforms, their customers, and the
humans whose behavior is manipulated. Behavior modification can make users'
behavior more predictable and even more homogeneous; yet this apparent
predictability might not generalize when customers use predictions in practice.
Outcomes pushed towards their predictions can be at odds with customers'
intentions, and harmful to manipulated users.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Tensor Relational Algebra for Machine Learning System Design.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Binhang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jankov_D/0/1/0/all/0/1">Dimitrije Jankov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Jia Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yuxin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourgeois_D/0/1/0/all/0/1">Daniel Bourgeois</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1">Chris Jermaine</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00524">
                                        <div class="article-summary-box-inner">
                                            <span><p>We consider the question: what is the abstraction that should be implemented
by the computational engine of a machine learning system? Current machine
learning systems typically push whole tensors through a series of compute
kernels such as matrix multiplications or activation functions, where each
kernel runs on an AI accelerator (ASIC) such as a GPU. This implementation
abstraction provides little built-in support for ML systems to scale past a
single machine, or for handling large models with matrices or tensors that do
not easily fit into the RAM of an ASIC. In this paper, we present an
alternative implementation abstraction called the tensor relational algebra
(TRA). The TRA is a set-based algebra based on the relational algebra.
Expressions in the TRA operate over binary tensor relations, where keys are
multi-dimensional arrays and values are tensors. The TRA is easily executed
with high efficiency in a parallel or distributed environment, and amenable to
automatic optimization. Our empirical study shows that the optimized TRA-based
back-end can significantly outperform alternatives for running ML workflows in
distributed clusters.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ A Survey on Negative Transfer.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lingfei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00909">
                                        <div class="article-summary-box-inner">
                                            <span><p>Transfer learning (TL) utilizes data or knowledge from one or more source
domains to facilitate the learning in a target domain. It is particularly
useful when the target domain has very few or no labeled data, due to
annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of
TL is not always guaranteed. Negative transfer (NT), i.e., leveraging source
domain data/knowledge undesirably reduces the learning performance in the
target domain, has been a long-standing and challenging problem in TL. Various
approaches have been proposed in the literature to handle it. However, there
does not exist a systematic survey on the formulation of NT, the factors
leading to NT, and the algorithms that mitigate NT. This paper fills this gap,
by first introducing the definition of NT and its factors, then reviewing about
fifty representative approaches for overcoming NT, according to four
categories: secure transfer, domain similarity estimation, distant transfer,
and NT mitigation. NT in related fields, e.g., multi-task learning, lifelong
learning, and adversarial attacks, are also discussed.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Taille_B/0/1/0/all/0/1">Bruno Taill&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1">Vincent Guigue</a>, <a href="http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1">Geoffrey Scoutheeten</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10684">
                                        <div class="article-summary-box-inner">
                                            <span><p>Despite efforts to distinguish three different evaluation setups (Bekoulis et
al., 2018), numerous end-to-end Relation Extraction (RE) articles present
unreliable performance comparison to previous work. In this paper, we first
identify several patterns of invalid comparisons in published papers and
describe them to avoid their propagation. We then propose a small empirical
study to quantify the impact of the most common mistake and evaluate it leads
to overestimating the final RE performance by around 5% on ACE05. We also seize
this opportunity to study the unexplored ablations of two recent developments:
the use of language model pretraining (specifically BERT) and span-level NER.
This meta-analysis emphasizes the need for rigor in the report of both the
evaluation setting and the datasets statistics and we call for unifying the
evaluation setting in end-to-end RE.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sontakke_S/0/1/0/all/0/1">Sumedh A. Sontakke</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrjou_A/0/1/0/all/0/1">Arash Mehrjou</a>, <a href="http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1">Laurent Itti</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03110">
                                        <div class="article-summary-box-inner">
                                            <span><p>Animals exhibit an innate ability to learn regularities of the world through
interaction. By performing experiments in their environment, they are able to
discern the causal factors of variation and infer how they affect the world's
dynamics. Inspired by this, we attempt to equip reinforcement learning agents
with the ability to perform experiments that facilitate a categorization of the
rolled-out trajectories, and to subsequently infer the causal factors of the
environment in a hierarchical manner. We introduce {\em causal curiosity}, a
novel intrinsic reward, and show that it allows our agents to learn optimal
sequences of actions and discover causal factors in the dynamics of the
environment. The learned behavior allows the agents to infer a binary quantized
representation for the ground-truth causal factors in every environment.
Additionally, we find that these experimental behaviors are semantically
meaningful (e.g., our agents learn to lift blocks to categorize them by
weight), and are learnt in a self-supervised manner with approximately 2.5
times less data than conventional supervised planners. We show that these
behaviors can be re-purposed and fine-tuned (e.g., from lifting to pushing or
other downstream tasks). Finally, we show that the knowledge of causal factor
representations aids zero-shot learning for more complex tasks. Visit
https://sites.google.com/usc.edu/causal-curiosity/home for website.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1">Lalith Bharadwaj B</a>, <a href="http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1">Rohit Boddeda</a>, <a href="http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1">Sai Vardhan K</a>, <a href="http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1">Madhu G</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05690">
                                        <div class="article-summary-box-inner">
                                            <span><p>The issue of COVID-19, increasing with a massive mortality rate. This led to
the WHO declaring it as a pandemic. In this situation, it is crucial to perform
efficient and fast diagnosis. The reverse transcript polymerase chain reaction
(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is
time-consuming and instead chest CT (or Chest X-ray) can be used for a fast and
accurate diagnosis. Automated diagnosis is considered to be important as it
reduces human effort and provides accurate and low-cost tests. The
contributions of our research are three-fold. First, it is aimed to analyse the
behaviour and performance of variant vision models ranging from Inception to
NAS networks with the appropriate fine-tuning procedure. Second, the behaviour
of these models is visually analysed by plotting CAMs for individual networks
and determining classification performance with AUCROC curves. Thirdly, stacked
ensembles techniques are imparted to provide higher generalisation on combining
the fine-tuned models, in which six ensemble neural networks are designed by
combining the existing fine-tuned networks. Implying these stacked ensembles
provides a great generalization to the models. The ensemble model designed by
combining all the fine-tuned networks obtained a state-of-the-art accuracy
score of 99.17%. The precision and recall for the COVID-19 class are 99.99% and
89.79% respectively, which resembles the robustness of the stacked ensembles.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ MGIC: Multigrid-in-Channels Neural Network Architectures.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Eliasof_M/0/1/0/all/0/1">Moshe Eliasof</a>, <a href="http://arxiv.org/find/cs/1/au:+Ephrath_J/0/1/0/all/0/1">Jonathan Ephrath</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruthotto_L/0/1/0/all/0/1">Lars Ruthotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Treister_E/0/1/0/all/0/1">Eran Treister</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09128">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a multigrid-in-channels (MGIC) approach that tackles the quadratic
growth of the number of parameters with respect to the number of channels in
standard convolutional neural networks (CNNs). Thereby our approach addresses
the redundancy in CNNs that is also exposed by the recent success of
lightweight CNNs. Lightweight CNNs can achieve comparable accuracy to standard
CNNs with fewer parameters; however, the number of weights still scales
quadratically with the CNN's width. Our MGIC architectures replace each CNN
block with an MGIC counterpart that utilizes a hierarchy of nested grouped
convolutions of small group size to address this.
</p>
<p>Hence, our proposed architectures scale linearly with respect to the
network's width while retaining full coupling of the channels as in standard
CNNs.
</p>
<p>Our extensive experiments on image classification, segmentation, and point
cloud classification show that applying this strategy to different
architectures like ResNet and MobileNetV3 reduces the number of parameters
while obtaining similar or better accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Anchored-STFT and GNAA: An extension of STFT in conjunction with an adversarial data augmentation technique for the decoding of neural signals.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/q-bio/1/au:+Ali_O/0/1/0/all/0/1">Omair Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Saif_ur_Rehman_M/0/1/0/all/0/1">Muhammad Saif-ur-Rehman</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dyck_S/0/1/0/all/0/1">Susanne Dyck</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Glasmachers_T/0/1/0/all/0/1">Tobias Glasmachers</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Iossifidis_I/0/1/0/all/0/1">Ioannis Iossifidis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Klaes_C/0/1/0/all/0/1">Christian Klaes</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14694">
                                        <div class="article-summary-box-inner">
                                            <span><p>Brain-computer interfaces (BCIs) enable communication between humans and
machines by translating brain activity into control commands.
Electroencephalography (EEG) signals are one of the most used brain signals in
non-invasive BCI applications but are often contaminated with noise. Therefore,
it is possible that meaningful patterns for classifying EEG signals are deeply
hidden. State-of-the-art deep-learning algorithms are successful in learning
hidden, meaningful patterns. However, the quality and the quantity of the
presented inputs is pivotal. Here, we propose a novel feature extraction method
called anchored Short Time Fourier Transform (anchored-STFT), which is an
advanced version of STFT, as it minimizes the trade-off between temporal and
spectral resolution presented by STFT. In addition, we propose a novel
augmentation method, called gradient norm adversarial augmentation (GNAA). GNAA
is not only an augmentation method but is also used to harness adversarial
inputs in EEG data, which not only improves the classification accuracy but
also enhances the robustness of the classifier. In addition, we also propose a
new CNN architecture, namely Skip-Net, for the classification of EEG signals.
The proposed pipeline outperforms all state-of-the-art methods and yields an
average classification accuracy of 90.7 % and 89.54 % on BCI competition II
dataset III and BCI competition IV dataset 2b, respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Deep Gravity: enhancing mobility flows generation with deep neural networks and geographic information.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Simini_F/0/1/0/all/0/1">Filippo Simini</a>, <a href="http://arxiv.org/find/cs/1/au:+Barlacchi_G/0/1/0/all/0/1">Gianni Barlacchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luca_M/0/1/0/all/0/1">Massimiliano Luca</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappalardo_L/0/1/0/all/0/1">Luca Pappalardo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00489">
                                        <div class="article-summary-box-inner">
                                            <span><p>The movements of individuals within and among cities influence critical
aspects of our society, such as well-being, the spreading of epidemics, and the
quality of the environment. When information about mobility flows is not
available for a particular region of interest, we must rely on mathematical
models to generate them. In this work, we propose the Deep Gravity model, an
effective method to generate flow probabilities that exploits many variables
(e.g., land use, road network, transport, food, health facilities) extracted
from voluntary geographic data, and uses deep neural networks to discover
non-linear relationships between those variables and mobility flows. Our
experiments, conducted on mobility flows in England, Italy, and New York State,
show that Deep Gravity has good geographic generalization capability, achieving
a significant increase in performance (especially in densely populated regions
of interest) with respect to the classic gravity model and models that do not
use deep neural networks or geographic data. We also show how flows generated
by Deep Gravity may be explained in terms of the geographic features using
explainable AI techniques.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ChartPointFlow for Topology-Aware 3D Point Cloud Generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kimura_T/0/1/0/all/0/1">Takumi Kimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsubara_T/0/1/0/all/0/1">Takashi Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_K/0/1/0/all/0/1">Kuniaki Uehara</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02346">
                                        <div class="article-summary-box-inner">
                                            <span><p>A point cloud serves as a representation of the surface of a
three-dimensional (3D) shape. Deep generative models have been adapted to model
their variations typically using a map from a ball-like set of latent
variables. However, previous approaches did not pay much attention to the
topological structure of a point cloud, despite that a continuous map cannot
express the varying numbers of holes and intersections. Moreover, a point cloud
is often composed of multiple subparts, and it is also difficult to express. In
this study, we propose ChartPointFlow, a flow-based generative model with
multiple latent labels for 3D point clouds. Each label is assigned to points in
an unsupervised manner. Then, a map conditioned on a label is assigned to a
continuous subset of a point cloud, similar to a chart of a manifold. This
enables our proposed model to preserve the topological structure with clear
boundaries, whereas previous approaches tend to generate blurry point clouds
and fail to generate holes. The experimental results demonstrate that
ChartPointFlow achieves state-of-the-art performance in terms of generation and
reconstruction compared with other point cloud generators. Moreover,
ChartPointFlow divides an object into semantic subparts using charts, and it
demonstrates superior performance in case of unsupervised segmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Deep learning Local Reduced Density Matrices for Many-body Hamiltonian Estimation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/quant-ph/1/au:+Ma_X/0/1/0/all/0/1">Xinran Ma</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tu_Z/0/1/0/all/0/1">Z. C. Tu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03019">
                                        <div class="article-summary-box-inner">
                                            <span><p>Human experts cannot efficiently access the physical information of quantum
many-body states by simply "reading" the coefficients, but have to reply on the
previous knowledge such as order parameters and quantum measurements. In this
work, we demonstrate that convolutional neural network (CNN) can learn from the
coefficients of local reduced density matrices to estimate the physical
parameters of the many-body Hamiltonians, such as coupling strengths and
magnetic fields, provided the states as the ground states. We propose QubismNet
that consists of two main parts: the Qubism map that visualizes the ground
states (or the purified reduced density matrices) as images, and a CNN that
maps the images to the target physical parameters. By assuming certain
constraints on the training set for the sake of balance, QubismNet exhibits
impressive powers of learning and generalization on several quantum spin
models. While the training samples are restricted to the states from certain
ranges of the parameters, QubismNet can accurately estimate the parameters of
the states beyond such training regions. For instance, our results show that
QubismNet can estimate the magnetic fields near the critical point by learning
from the states away from the critical vicinity. Our work illuminates a
data-driven way to infer the Hamiltonians that give the designed ground states,
and therefore would benefit the existing and future generalizations of quantum
technologies such as Hamiltonian-based quantum simulations and state
tomography.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Differential Evolution for Neural Architecture Search.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Awad_N/0/1/0/all/0/1">Noor Awad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mallik_N/0/1/0/all/0/1">Neeratyoy Mallik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06400">
                                        <div class="article-summary-box-inner">
                                            <span><p>Neural architecture search (NAS) methods rely on a search strategy for
deciding which architectures to evaluate next and a performance estimation
strategy for assessing their performance (e.g., using full evaluations,
multi-fidelity evaluations, or the one-shot model). In this paper, we focus on
the search strategy. We introduce the simple yet powerful evolutionary
algorithm of differential evolution to the NAS community. Using the simplest
performance evaluation strategy of full evaluations, we comprehensively compare
this search strategy to regularized evolution and Bayesian optimization and
demonstrate that it yields improved and more robust results for 13 tabular NAS
benchmarks based on NAS-Bench-101, NAS-Bench-1Shot1, NAS-Bench-201 and NAS-HPO
bench.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Alternating linear scheme in a Bayesian framework for low-rank tensor approximation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Menzen_C/0/1/0/all/0/1">Clara Menzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kok_M/0/1/0/all/0/1">Manon Kok</a>, <a href="http://arxiv.org/find/cs/1/au:+Batselier_K/0/1/0/all/0/1">Kim Batselier</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11228">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multiway data often naturally occurs in a tensorial format which can be
approximately represented by a low-rank tensor decomposition. This is useful
because complexity can be significantly reduced and the treatment of
large-scale data sets can be facilitated. In this paper, we find a low-rank
representation for a given tensor by solving a Bayesian inference problem. This
is achieved by dividing the overall inference problem into sub-problems where
we sequentially infer the posterior distribution of one tensor decomposition
component at a time. This leads to a probabilistic interpretation of the
well-known iterative algorithm alternating linear scheme (ALS). In this way,
the consideration of measurement noise is enabled, as well as the incorporation
of application-specific prior knowledge and the uncertainty quantification of
the low-rank tensor estimate. To compute the low-rank tensor estimate from the
posterior distributions of the tensor decomposition components, we present an
algorithm that performs the unscented transform in tensor train format.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced Bengali Language.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Md. Rezaul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1">Sumon Kanti Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1">Sagor Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_M/0/1/0/all/0/1">Mehadi Hasan Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_K/0/1/0/all/0/1">Kabir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md. Azam Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_S/0/1/0/all/0/1">Stefan Decker</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14353">
                                        <div class="article-summary-box-inner">
                                            <span><p>The exponential growths of social media and micro-blogging sites not only
provide platforms for empowering freedom of expressions and individual voices,
but also enables people to express anti-social behaviour like online
harassment, cyberbullying, and hate speech. Numerous works have been proposed
to utilize textual data for social and anti-social behaviour analysis, by
predicting the contexts mostly for highly-resourced languages like English.
However, some languages are under-resourced, e.g., South Asian languages like
Bengali, that lack computational resources for accurate natural language
processing (NLP). In this paper, we propose an explainable approach for hate
speech detection from the under-resourced Bengali language, which we called
DeepHateExplainer. Bengali texts are first comprehensively preprocessed, before
classifying them into political, personal, geopolitical, and religious hates
using a neural ensemble method of transformer-based neural architectures (i.e.,
monolingual Bangla BERT-base, multilingual BERT-cased/uncased, and
XLM-RoBERTa). Important(most and least) terms are then identified using
sensitivity analysis and layer-wise relevance propagation(LRP), before
providing human-interpretable explanations. Finally, we compute
comprehensiveness and sufficiency scores to measure the quality of explanations
w.r.t faithfulness. Evaluations against machine learning~(linear and tree-based
models) and neural networks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word
embeddings) baselines yield F1-scores of 78%, 91%, 89%, and 84%, for political,
personal, geopolitical, and religious hates, respectively, outperforming both
ML and DNN baselines.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Transfer Learning for Future Wireless Networks: A Comprehensive Survey.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Cong T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_N/0/1/0/all/0/1">Nguyen Van Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_N/0/1/0/all/0/1">Nam H. Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Saputra_Y/0/1/0/all/0/1">Yuris Mulya Saputra</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1">Dinh Thai Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Diep N. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1">Quoc-Viet Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1">Dusit Niyato</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutkiewicz_E/0/1/0/all/0/1">Eryk Dutkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Won-Joo Hwang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07572">
                                        <div class="article-summary-box-inner">
                                            <span><p>With outstanding features, Machine Learning (ML) has been the backbone of
numerous applications in wireless networks. However, the conventional ML
approaches have been facing many challenges in practical implementation, such
as the lack of labeled data, the constantly changing wireless environments, the
long training process, and the limited capacity of wireless devices. These
challenges, if not addressed, will impede the effectiveness and applicability
of ML in future wireless networks. To address these problems, Transfer Learning
(TL) has recently emerged to be a very promising solution. The core idea of TL
is to leverage and synthesize distilled knowledge from similar tasks as well as
from valuable experiences accumulated from the past to facilitate the learning
of new problems. Doing so, TL techniques can reduce the dependence on labeled
data, improve the learning speed, and enhance the ML methods' robustness to
different wireless environments. This article aims to provide a comprehensive
survey on applications of TL in wireless networks. Particularly, we first
provide an overview of TL including formal definitions, classification, and
various types of TL techniques. We then discuss diverse TL approaches proposed
to address emerging issues in wireless networks. The issues include spectrum
management, localization, signal recognition, security, human activity
recognition and caching, which are all important to next-generation networks
such as 5G and beyond. Finally, we highlight important challenges, open issues,
and future research directions of TL in future wireless networks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Combinatorial Bandits under Strategic Manipulations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Baoxiang Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12722">
                                        <div class="article-summary-box-inner">
                                            <span><p>Strategic behavior against sequential learning methods, such as "click
framing" in real recommendation systems, has been widely observed. Motivated by
such behavior we study the problem of combinatorial multi-armed bandits (CMAB)
under strategic manipulations of rewards, where each arm can modify the emitted
reward signals for its own interest. This characterization of the adversarial
behavior is a relaxation of previously well-studied settings such as
adversarial attacks and adversarial corruption. We propose a strategic variant
of the combinatorial UCB algorithm, which has a regret of at most $O(m\log T +
m B_{max})$ under strategic manipulations, where $T$ is the time horizon, $m$
is the number of arms, and $B_{max}$ is the maximum budget of an arm. We
provide lower bounds on the budget for arms to incur certain regret of the
bandit algorithm. Extensive experiments on online worker selection for
crowdsourcing systems, online influence maximization and online recommendations
with both synthetic and real datasets corroborate our theoretical findings on
robustness and regret bounds, in a variety of regimes of manipulation budgets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Adaptive Consistency Regularization for Semi-Supervised Transfer Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xingjian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Cheng-Zhong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02193">
                                        <div class="article-summary-box-inner">
                                            <span><p>While recent studies on semi-supervised learning have shown remarkable
progress in leveraging both labeled and unlabeled data, most of them presume a
basic setting of the model is randomly initialized. In this work, we consider
semi-supervised learning and transfer learning jointly, leading to a more
practical and competitive paradigm that can utilize both powerful pre-trained
models from source domain as well as labeled/unlabeled data in the target
domain. To better exploit the value of both pre-trained weights and unlabeled
target examples, we introduce adaptive consistency regularization that consists
of two complementary components: Adaptive Knowledge Consistency (AKC) on the
examples between the source and target model, and Adaptive Representation
Consistency (ARC) on the target model between labeled and unlabeled examples.
Examples involved in the consistency regularization are adaptively selected
according to their potential contributions to the target task. We conduct
extensive experiments on popular benchmarks including CIFAR-10, CUB-200, and
MURA, by fine-tuning the ImageNet pre-trained ResNet-50 model. Results show
that our proposed adaptive consistency regularization outperforms
state-of-the-art semi-supervised learning techniques such as Pseudo Label, Mean
Teacher, and FixMatch. Moreover, our algorithm is orthogonal to existing
methods and thus able to gain additional improvements on top of MixMatch and
FixMatch. Our code is available at
https://github.com/SHI-Labs/Semi-Supervised-Transfer-Learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Convolution Neural Network Hyperparameter Optimization Using Simplified Swarm Optimization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yeh_W/0/1/0/all/0/1">Wei-Chang Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yi-Ping Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yun-Chia Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chyh-Ming Lai</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03995">
                                        <div class="article-summary-box-inner">
                                            <span><p>Convolutional neural networks (CNNs) are widely used in image recognition.
Numerous CNN models, such as LeNet, AlexNet, VGG, ResNet, and GoogLeNet, have
been proposed by increasing the number of layers, to improve the performance of
CNNs. However, performance deteriorates beyond a certain number of layers.
Hence, hyperparameter optimisation is a more efficient way to improve CNNs. To
validate this concept, a new algorithm based on simplified swarm optimisation
is proposed to optimise the hyperparameters of the simplest CNN model, which is
LeNet. The results of experiments conducted on the MNIST, Fashion MNIST, and
Cifar10 datasets showed that the accuracy of the proposed algorithm is higher
than the original LeNet model and PSO-LeNet and that it has a high potential to
be extended to more complicated models, such as AlexNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Practical Relative Order Attack in Deep Ranking.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05248">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent studies unveil the vulnerabilities of deep ranking models, where an
imperceptible perturbation can trigger dramatic changes in the ranking result.
While previous attempts focus on manipulating absolute ranks of certain
candidates, the possibility of adjusting their relative order remains
under-explored. In this paper, we formulate a new adversarial attack against
deep ranking systems, i.e., the Order Attack, which covertly alters the
relative order among a selected set of candidates according to an
attacker-specified permutation, with limited interference to other unrelated
candidates. Specifically, it is formulated as a triplet-style loss imposing an
inequality chain reflecting the specified permutation. However, direct
optimization of such white-box objective is infeasible in a real-world attack
scenario due to various black-box limitations. To cope with them, we propose a
Short-range Ranking Correlation metric as a surrogate objective for black-box
Order Attack to approximate the white-box method. The Order Attack is evaluated
on the Fashion-MNIST and Stanford-Online-Products datasets under both white-box
and black-box threat models. The black-box attack is also successfully
implemented on a major e-commerce platform. Comprehensive experimental
evaluations demonstrate the effectiveness of the proposed methods, revealing a
new type of ranking model vulnerability.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Learning Linear Policies for Robust Bipedal Locomotion on Terrains with Varying Slopes.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Krishna_L/0/1/0/all/0/1">Lokesh Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_U/0/1/0/all/0/1">Utkarsh A. Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillo_G/0/1/0/all/0/1">Guillermo A. Castillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hereid_A/0/1/0/all/0/1">Ayonga Hereid</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolathaya_S/0/1/0/all/0/1">Shishir Kolathaya</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01662">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, with a view toward deployment of light-weight control
frameworks for bipedal walking robots, we realize end-foot trajectories that
are shaped by a single linear feedback policy. We learn this policy via a
model-free and a gradient-free learning algorithm, Augmented Random Search
(ARS), in the two robot platforms Rabbit and Digit. Our contributions are
two-fold: a) By using torso and support plane orientation as inputs, we achieve
robust walking on slopes of up to 20 degrees in simulation. b) We demonstrate
additional behaviors like walking backwards, stepping-in-place, and recovery
from external pushes of up to 120 N. The end result is a robust and a fast
feedback control law for bipedal walking on terrains with varying slopes.
Towards the end, we also provide preliminary results of hardware transfer to
Digit.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Detecting False Data Injection Attacks in Smart Grids with Modeling Errors: A Deep Transfer Learning Based Approach.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Xu_B/0/1/0/all/0/1">Bowen Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_F/0/1/0/all/0/1">Fanghong Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Wen_C/0/1/0/all/0/1">Changyun Wen</a>, <a href="http://arxiv.org/find/eess/1/au:+Deng_R/0/1/0/all/0/1">Ruilong Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_W/0/1/0/all/0/1">Wen-An Zhang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06307">
                                        <div class="article-summary-box-inner">
                                            <span><p>Most traditional false data injection attack (FDIA) detection approaches rely
on a key assumption, i.e., the power system can be accurately modeled. However,
the transmission line parameters are dynamic and cannot be accurately known
during operation and thus the involved modeling errors should not be neglected.
In this paper, an illustrative case has revealed that modeling errors in
transmission lines significantly weaken the detection effectiveness of
conventional FDIA approaches. To tackle this issue, we propose an FDIA
detection mechanism from the perspective of transfer learning. Specifically,
the simulated power system is treated as a source domain, which provides
abundant simulated normal and attack data. The real world's running system
whose transmission line parameters are unknown is taken as a target domain
where sufficient real normal data are collected for tracking the latest system
states online. The designed transfer strategy that aims at making full use of
data in hand is divided into two optimization stages. In the first stage, a
deep neural network (DNN) is built by simultaneously optimizing several
well-designed objective terms with both simulated data and real data, and then
it is fine-tuned via real data in the second stage. Several case studies on the
IEEE 14-bus and 118-bus systems verify the effectiveness of the proposed
mechanism.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Simultaneous Face Hallucination and Translation for Thermal to Visible Face Verification using Axial-GAN.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Immidisetti_R/0/1/0/all/0/1">Rakhil Immidisetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shuowen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06534">
                                        <div class="article-summary-box-inner">
                                            <span><p>Existing thermal-to-visible face verification approaches expect the thermal
and visible face images to be of similar resolution. This is unlikely in
real-world long-range surveillance systems, since humans are distant from the
cameras. To address this issue, we introduce the task of thermal-to-visible
face verification from low-resolution thermal images. Furthermore, we propose
Axial-Generative Adversarial Network (Axial-GAN) to synthesize high-resolution
visible images for matching. In the proposed approach we augment the GAN
framework with axial-attention layers which leverage the recent advances in
transformers for modelling long-range dependencies. We demonstrate the
effectiveness of the proposed method by evaluating on two different
thermal-visible face datasets. When compared to related state-of-the-art works,
our results show significant improvements in both image quality and face
verification performance, and are also much more efficient.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Nonlinear Level Set Learning for Function Approximation on Sparse Data with Applications to Parametric Differential Equations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Gruber_A/0/1/0/all/0/1">Anthony Gruber</a>, <a href="http://arxiv.org/find/stat/1/au:+Gunzburger_M/0/1/0/all/0/1">Max Gunzburger</a>, <a href="http://arxiv.org/find/stat/1/au:+Ju_L/0/1/0/all/0/1">Lili Ju</a>, <a href="http://arxiv.org/find/stat/1/au:+Teng_Y/0/1/0/all/0/1">Yuankai Teng</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Zhu Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14072">
                                        <div class="article-summary-box-inner">
                                            <span><p>A dimension reduction method based on the "Nonlinear Level set Learning"
(NLL) approach is presented for the pointwise prediction of functions which
have been sparsely sampled. Leveraging geometric information provided by the
Implicit Function Theorem, the proposed algorithm effectively reduces the input
dimension to the theoretical lower bound with minor accuracy loss, providing a
one-dimensional representation of the function which can be used for regression
and sensitivity analysis. Experiments and applications are presented which
compare this modified NLL with the original NLL and the Active Subspaces (AS)
method. While accommodating sparse input data, the proposed algorithm is shown
to train quickly and provide a much more accurate and informative reduction
than either AS or the original NLL on two example functions with
high-dimensional domains, as well as two state-dependent quantities depending
on the solutions to parametric differential equations.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Time Series Forecasting of New Cases and New Deaths Rate for COVID-19 using Deep Learning Methods.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ayoobi_N/0/1/0/all/0/1">Nooshin Ayoobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifrazi_D/0/1/0/all/0/1">Danial Sharifrazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1">Juan M. Gorriz</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosaei_H/0/1/0/all/0/1">Hossein Moosaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chofreh_A/0/1/0/all/0/1">Abdoulmohammad Gholamzadeh Chofreh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goni_F/0/1/0/all/0/1">Feybi Ariani Goni</a>, <a href="http://arxiv.org/find/cs/1/au:+Klemes_J/0/1/0/all/0/1">Jiri Jaromir Klemes</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosavi_A/0/1/0/all/0/1">Amir Mosavi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15007">
                                        <div class="article-summary-box-inner">
                                            <span><p>The first known case of Coronavirus disease 2019 (COVID-19) was identified in
December 2019. It has spread worldwide, leading to an ongoing pandemic, imposed
restrictions and costs to many countries. Predicting the number of new cases
and deaths during this period can be a useful step in predicting the costs and
facilities required in the future. The purpose of this study is to predict new
cases and deaths rate one, three and seven-day ahead during the next 100 days.
The motivation for predicting every n days (instead of just every day) is the
investigation of the possibility of computational cost reduction and still
achieving reasonable performance. Such a scenario may be encountered real-time
forecasting of time series. Six different deep learning methods are examined on
the data adopted from the WHO website. Three methods are LSTM, Convolutional
LSTM, and GRU. The bidirectional extension is then considered for each method
to forecast the rate of new cases and new deaths in Australia and Iran
countries.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Single-Training Collaborative Object Detectors Adaptive to Bandwidth and Computation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Assine_J/0/1/0/all/0/1">Juliano S. Assine</a>, <a href="http://arxiv.org/find/cs/1/au:+Filho_J/0/1/0/all/0/1">J. C. S. Santos Filho</a>, <a href="http://arxiv.org/find/cs/1/au:+Valle_E/0/1/0/all/0/1">Eduardo Valle</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00591">
                                        <div class="article-summary-box-inner">
                                            <span><p>In the past few years, mobile deep-learning deployment progressed by leaps
and bounds, but solutions still struggle to accommodate its severe and
fluctuating operational restrictions, which include bandwidth, latency,
computation, and energy. In this work, we help to bridge that gap, introducing
the first configurable solution for object detection that manages the triple
communication-computation-accuracy trade-off with a single set of weights. Our
solution shows state-of-the-art results on COCO-2017, adding only a minor
penalty on the base EfficientDet-D2 architecture. Our design is robust to the
choice of base architecture and compressor and should adapt well for future
architectures.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Do Context-Aware Translation Models Pay the Right Attention?.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kayo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1">Patrick Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1">Danish Pruthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1">Aditi Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; F. T. Martins</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1"><span class="highlight_author">Graham Neubig</span></a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06977">
                                        <div class="article-summary-box-inner">
                                            <span><p>Context-aware machine translation models are designed to leverage contextual
information, but often fail to do so. As a result, they inaccurately
disambiguate pronouns and polysemous words that require context for resolution.
In this paper, we ask several questions: What contexts do human translators use
to resolve ambiguous words? Are models paying large amounts of attention to the
same context? What if we explicitly train them to do so? To answer these
questions, we introduce SCAT (Supporting Context for Ambiguous Translations), a
new English-French dataset comprising supporting context words for 14K
translations that professional translators found useful for pronoun
disambiguation. Using SCAT, we perform an in-depth analysis of the context used
to disambiguate, examining positional and lexical characteristics of the
supporting words. Furthermore, we measure the degree of alignment between the
model's attention scores and the supporting context from SCAT, and apply a
guided attention strategy to encourage agreement between the two.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DCAP: Deep Cross Attentional Product Network for User Response Prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zekai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fangtian Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pless_R/0/1/0/all/0/1">Robert Pless</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuzhen Cheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08649">
                                        <div class="article-summary-box-inner">
                                            <span><p>User response prediction, which aims to predict the probability that a user
will provide a predefined positive response in a given context such as clicking
on an ad or purchasing an item, is crucial to many industrial applications such
as online advertising, recommender systems, and search ranking. However, due to
the high dimensionality and super sparsity of the data collected in these
tasks, handcrafting cross features is inevitably time expensive. Prior studies
in predicting user response leveraged the feature interactions by enhancing
feature vectors with products of features to model second-order or high-order
cross features, either explicitly or implicitly. Nevertheless, these existing
methods can be hindered by not learning sufficient cross features due to model
architecture limitations or modeling all high-order feature interactions with
equal weights. This work aims to fill this gap by proposing a novel
architecture Deep Cross Attentional Product Network (DCAP), which keeps cross
network's benefits in modeling high-order feature interactions explicitly at
the vector-wise level. Beyond that, it can differentiate the importance of
different cross features in each network layer inspired by the multi-head
attention mechanism and Product Neural Network (PNN), allowing practitioners to
perform a more in-depth analysis of user behaviors. Additionally, our proposed
model can be easily implemented and train in parallel. We conduct comprehensive
experiments on three real-world datasets. The results have robustly
demonstrated that our proposed model DCAP achieves superior prediction
performance compared with the state-of-the-art models.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Learning and Certification under Instance-targeted Poisoning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Ji Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1">Amin Karbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmoody_M/0/1/0/all/0/1">Mohammad Mahmoody</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08709">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we study PAC learnability and certification of predictions
under instance-targeted poisoning attacks, where the adversary who knows the
test instance may change a fraction of the training set with the goal of
fooling the learner at the test instance. Our first contribution is to
formalize the problem in various settings and to explicitly model subtle
aspects such as the proper or improper nature of the learning, learner's
randomness, and whether (or not) adversary's attack can depend on it. Our main
result shows that when the budget of the adversary scales sublinearly with the
sample complexity, (improper) PAC learnability and certification are
achievable; in contrast, when the adversary's budget grows linearly with the
sample complexity, the adversary can potentially drive up the expected 0-1 loss
to one. We also study distribution-specific PAC learning in the same attack
model and show that proper learning with certification is possible for learning
half spaces under natural distributions. Finally, we empirically study the
robustness of K nearest neighbour, logistic regression, multi-layer perceptron,
and convolutional neural network on real data sets against targeted-poisoning
attacks. Our experimental results show that many models, especially
state-of-the-art neural networks, are indeed vulnerable to these strong
attacks. Interestingly, we observe that methods with high standard accuracy
might be more vulnerable to instance-targeted poisoning attacks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Multi-Perspective Anomaly Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1">Peter Jakob</a>, <a href="http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1">Manav Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1">Tobias Schmid-Schirling</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09903">
                                        <div class="article-summary-box-inner">
                                            <span><p>Anomaly detection is a critical problem in the manufacturing industry. In
many applications, images of objects to be analyzed are captured from multiple
perspectives which can be exploited to improve the robustness of anomaly
detection. In this work, we build upon the deep support vector data description
algorithm and address multi-perspective anomaly detection using three different
fusion techniques, i.e., early fusion, late fusion, and late fusion with
multiple decoders. We employ different augmentation techniques with a denoising
process to deal with scarce one-class data, which further improves the
performance (ROC AUC $= 80\%$). Furthermore, we introduce the dices dataset,
which consists of over 2000 grayscale images of falling dices from multiple
perspectives, with 5\% of the images containing rare anomalies (e.g., drill
holes, sawing, or scratches). We evaluate our approach on the new dices dataset
using images from two different perspectives and also benchmark on the standard
MNIST dataset. Extensive experiments demonstrate that our proposed
{multi-perspective} approach exceeds the state-of-the-art {single-perspective
anomaly detection on both the MNIST and dices datasets}. To the best of our
knowledge, this is the first work that focuses on addressing multi-perspective
anomaly detection in images by jointly using different perspectives together
with one single objective function for anomaly detection.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ GNNIE: GNN Inference Engine with Load-balancing and Graph-Specific Caching.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1">Sudipta Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Manasi_S/0/1/0/all/0/1">Susmita Dey Manasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunal_K/0/1/0/all/0/1">Kishor Kunal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramprasath_S/0/1/0/all/0/1">S. Ramprasath</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapatnekar_S/0/1/0/all/0/1">Sachin S. Sapatnekar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10554">
                                        <div class="article-summary-box-inner">
                                            <span><p>Graph neural networks (GNN) analysis engines are vital for real-world
problems that use large graph models. Challenges for a GNN hardware platform
include the ability to (a) host a variety of GNNs, (b) handle high sparsity in
input vertex feature vectors and the graph adjacency matrix and the
accompanying random memory access patterns, and (c) maintain load-balanced
computation in the face of uneven workloads, induced by high sparsity and
power-law vertex degree distributions. This paper proposes GNNIE, an
accelerator designed to run a broad range of GNNs. It tackles workload
imbalance by (i)~splitting vertex feature operands into blocks, (ii)~reordering
and redistributing computations, (iii)~using a novel flexible MAC architecture.
It adopts a graph-specific, degree-aware caching policy that is well suited to
real-world graph characteristics. The policy enhances on-chip data reuse and
avoids random memory access to DRAM.
</p>
<p>GNNIE achieves average speedups of 21233x over a CPU and 699x over a GPU over
multiple datasets on graph attention networks (GATs), graph convolutional
networks (GCNs), GraphSAGE, GINConv, and DiffPool. Compared to prior
approaches, GNNIE achieves an average speedup of 35x over HyGCN (which cannot
implement GATs) for GCN, GraphSAGE, and GINConv, and, using 3.4x fewer
processing units, an average speedup of 2.1x over AWB-GCN (which runs only
GCNs).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Towards a method to anticipate dark matter signals with deep learning at the LHC.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/hep-ph/1/au:+Arganda_E/0/1/0/all/0/1">Ernesto Arganda</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Medina_A/0/1/0/all/0/1">Anibal D. Medina</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Perez_A/0/1/0/all/0/1">Andres D. Perez</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Szynkman_A/0/1/0/all/0/1">Alejandro Szynkman</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12018">
                                        <div class="article-summary-box-inner">
                                            <span><p>We study several simplified dark matter (DM) models and their signatures at
the LHC using neural networks. We focus on the usual monojet plus missing
transverse energy channel, but to train the algorithms we organize the data in
2D histograms instead of event-by-event arrays. This results in a large
performance boost to distinguish between standard model (SM) only and SM plus
new physics signals. We use the kinematic monojet features as input data which
allow us to describe families of models with a single data sample. We found
that the neural network performance does not depend on the simulated number of
background events if they are presented as a function of $S/\sqrt{B}$, where
$S$ and $B$ are the number of signal and background events per histogram,
respectively. This provides flexibility to the method, since testing a
particular model in that case only requires knowing the new physics monojet
cross section. Furthermore, we also discuss the network performance under
incorrect assumptions about the true DM nature. Finally, we propose multimodel
classifiers to search and identify new signals in a more general way, for the
next LHC run.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ M6-T: Exploring Sparse Expert Models and Beyond.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">An Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Junyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Le Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xianyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Ang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiamang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Di Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Lin Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15082">
                                        <div class="article-summary-box-inner">
                                            <span><p>Mixture-of-Experts (MoE) models can achieve promising results with outrageous
large amount of parameters but constant computation cost, and thus it has
become a trend in model scaling. Still it is a mystery how MoE layers bring
quality gains by leveraging the parameters with sparse activation. In this
work, we investigate several key factors in sparse expert models. We observe
that load imbalance may not be a significant problem affecting model quality,
contrary to the perspectives of recent studies, while the number of sparsely
activated experts $k$ and expert capacity $C$ in top-$k$ routing can
significantly make a difference in this context. Furthermore, we take a step
forward to propose a simple method called expert prototyping that splits
experts into different prototypes and applies $k$ top-$1$ routing. This
strategy improves the model quality but maintains constant computational costs,
and our further exploration on extremely large-scale models reflects that it is
more effective in training larger models. We push the model scale to over $1$
trillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in
comparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model
achieves substantial speedup in convergence over the same-size baseline.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Predicting Quantum Potentials by Deep Neural Network and Metropolis Sampling.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/quant-ph/1/au:+Hong_R/0/1/0/all/0/1">Rui Hong</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhou_P/0/1/0/all/0/1">Peng-Fei Zhou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Xi_B/0/1/0/all/0/1">Bin Xi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ji_A/0/1/0/all/0/1">An-Chun Ji</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03126">
                                        <div class="article-summary-box-inner">
                                            <span><p>The hybridizations of machine learning and quantum physics have caused
essential impacts to the methodology in both fields. Inspired by quantum
potential neural network, we here propose to solve the potential in the
Schrodinger equation provided the eigenstate, by combining Metropolis sampling
with deep neural network, which we dub as Metropolis potential neural network
(MPNN). A loss function is proposed to explicitly involve the energy in the
optimization for its accurate evaluation. Benchmarking on the harmonic
oscillator and hydrogen atom, MPNN shows excellent accuracy and stability on
predicting not just the potential to satisfy the Schrodinger equation, but also
the eigen-energy. Our proposal could be potentially applied to the ab-initio
simulations, and to inversely solving other partial differential equations in
physics and beyond.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Score Matching Model for Unbounded Data Score.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongjun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Seungjae Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kyungwoo Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1">Wanmo Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1">Il-Chul Moon</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05527">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent advance in diffusion models incorporates the Stochastic Differential
Equation (SDE), which brings the state-of-the art performance on image
generation tasks. This paper improves such diffusion models by analyzing the
model at the zero diffusion time. In real datasets, the score function diverges
as the diffusion time ($t$) decreases to zero, and this observation leads an
argument that the score estimation fails at $t=0$ with any neural network
structure. Subsequently, we introduce Unbounded Diffusion Model (UDM) that
resolves the score diverging problem with an easily applicable modification to
any diffusion models. Additionally, we introduce a new SDE that overcomes the
theoretic and practical limitations of Variance Exploding SDE. On top of that,
the introduced Soft Truncation method improves the sample quality by mitigating
the loss scale issue that happens at $t=0$. We further provide a theoretic
result of the proposed method to uncover the behind mechanism of the diffusion
models.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Model-Based Reinforcement Learning via Latent-Space Collocation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rybkin_O/0/1/0/all/0/1">Oleh Rybkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chuning Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagabandi_A/0/1/0/all/0/1">Anusha Nagabandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1">Kostas Daniilidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13229">
                                        <div class="article-summary-box-inner">
                                            <span><p>The ability to plan into the future while utilizing only raw high-dimensional
observations, such as images, can provide autonomous agents with broad
capabilities. Visual model-based reinforcement learning (RL) methods that plan
future actions directly have shown impressive results on tasks that require
only short-horizon reasoning, however, these methods struggle on temporally
extended tasks. We argue that it is easier to solve long-horizon tasks by
planning sequences of states rather than just actions, as the effects of
actions greatly compound over time and are harder to optimize. To achieve this,
we draw on the idea of collocation, which has shown good results on
long-horizon tasks in optimal control literature, and adapt it to the
image-based setting by utilizing learned latent state space models. The
resulting latent collocation method (LatCo) optimizes trajectories of latent
states, which improves over previously proposed shooting methods for visual
model-based RL on tasks with sparse rewards and long-term goals. Videos and
code at https://orybkin.github.io/latco/.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Limitations of machine learning for building energy prediction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Miller_C/0/1/0/all/0/1">Clayton Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Picchetti_B/0/1/0/all/0/1">Bianca Picchetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chun Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantelic_J/0/1/0/all/0/1">Jovan Pantelic</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13475">
                                        <div class="article-summary-box-inner">
                                            <span><p>Machine learning for building energy prediction has exploded in popularity in
recent years, yet understanding its limitations and potential for improvement
are lacking. The ASHRAE Great Energy Predictor III (GEPIII) Kaggle competition
was the largest building energy meter machine learning competition ever held
with 4,370 participants who submitted 39,403 predictions. The test data set
included two years of hourly electricity, hot water, chilled water, and steam
readings from 2,380 meters in 1,448 buildings at 16 locations. This paper
analyzes the various sources and types of residual model error from an
aggregation of the competition's top 50 solutions. This analysis reveals the
limitations for machine learning using the standard model inputs of historical
meter, weather, and basic building metadata. The types of error are classified
according to the amount of time errors occur in each instance, abrupt versus
gradual behavior, the magnitude of error, and whether the error existed on
single buildings or several buildings at once from a single location. The
results show machine learning models have errors within a range of
acceptability on 79.1% of the test data. Lower magnitude model errors occur in
16.1% of the test data. These discrepancies can likely be addressed through
additional training data sources or innovations in machine learning. Higher
magnitude errors occur in 4.8% of the test data and are unlikely to be
accurately predicted regardless of innovation. There is a diversity of error
behavior depending on the energy meter type (electricity prediction models have
unacceptable error in under 10% of test data, while hot water is over 60%) and
building use type (public service less than 14%, while technology/science is
just over 46%).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Ranger21: a synergistic deep learning optimizer.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wright_L/0/1/0/all/0/1">Less Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Demeure_N/0/1/0/all/0/1">Nestor Demeure</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13731">
                                        <div class="article-summary-box-inner">
                                            <span><p>As optimizers are critical to the performances of neural networks, every year
a large number of papers innovating on the subject are published. However,
while most of these publications provide incremental improvements to existing
algorithms, they tend to be presented as new optimizers rather than composable
algorithms. Thus, many worthwhile improvements are rarely seen out of their
initial publication. Taking advantage of this untapped potential, we introduce
Ranger21, a new optimizer which combines AdamW with eight components, carefully
selected after reviewing and testing ideas from the literature. We found that
the resulting optimizer provides significantly improved validation accuracy and
training speed, smoother training curves, and is even able to train a ResNet50
on ImageNet2012 without Batch Normalization layers. A problem on which AdamW
stays systematically stuck in a bad initial state.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Ashwin Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1">Adriel Saporta</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Steven QH Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1">Du Nguyen Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tan Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambon_P/0/1/0/all/0/1">Pierre Chambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1">Curtis P. Langlotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
                                        <div class="article-summary-box-inner">
                                            <span><p>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Interactive Dimensionality Reduction for Comparative Analysis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fujiwara_T/0/1/0/all/0/1">Takanori Fujiwara</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xinhai Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kwan-Liu Ma</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15481">
                                        <div class="article-summary-box-inner">
                                            <span><p>Finding the similarities and differences between groups of datasets is a
fundamental analysis task. For high-dimensional data, dimensionality reduction
(DR) methods are often used to find the characteristics of each group. However,
existing DR methods provide limited capability and flexibility for such
comparative analysis as each method is designed only for a narrow analysis
target, such as identifying factors that most differentiate groups. This paper
presents an interactive DR framework where we integrate our new DR method,
called ULCA (unified linear comparative analysis), with an interactive visual
interface. ULCA unifies two DR schemes, discriminant analysis and contrastive
learning, to support various comparative analysis tasks. To provide flexibility
for comparative analysis, we develop an optimization algorithm that enables
analysts to interactively refine ULCA results. Additionally, the interactive
visualization interface facilitates interpretation and refinement of the ULCA
results. We evaluate ULCA and the optimization algorithm to show their
efficiency as well as present multiple case studies using real-world datasets
to demonstrate the usefulness of this framework.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Blind Source Separation in Polyphonic Music Recordings Using Deep Neural Networks Trained via Policy Gradients.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Schulze_S/0/1/0/all/0/1">S&#xf6;ren Schulze</a>, <a href="http://arxiv.org/find/eess/1/au:+Leuschner_J/0/1/0/all/0/1">Johannes Leuschner</a>, <a href="http://arxiv.org/find/eess/1/au:+King_E/0/1/0/all/0/1">Emily J. King</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04235">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose a method for the blind separation of sounds of musical instruments
in audio signals. We describe the individual tones via a parametric model,
training a dictionary to capture the relative amplitudes of the harmonics. The
model parameters are predicted via a U-Net, which is a type of deep neural
network. The network is trained without ground truth information, based on the
difference between the model prediction and the individual time frames of the
short-time Fourier transform. Since some of the model parameters do not yield a
useful backpropagation gradient, we model them stochastically and employ the
policy gradient instead. To provide phase information and account for
inaccuracies in the dictionary-based representation, we also let the network
output a direct prediction, which we then use to resynthesize the audio signals
for the individual instruments. Due to the flexibility of the neural network,
inharmonicity can be incorporated seamlessly and no preprocessing of the input
spectra is required. Our algorithm yields high-quality separation results with
particularly low interference on a variety of different audio samples, both
acoustic and synthetic, provided that the sample contains enough data for the
training and that the spectral characteristics of the musical instruments are
sufficiently stable to be approximated by the dictionary.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Modeling Accurate Human Activity Recognition for Embedded Devices Using Multi-level <span class="highlight_title">Distillation</span>.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Runze Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haiyong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1">Xuechun Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhiqing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yida Zhu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07331">
                                        <div class="article-summary-box-inner">
                                            <span><p>Human Activity Recognition (HAR) based on IMU sensors is a crucial area in
ubiquitous computing. Because of the trend of deploying AI on IoT devices or
smartphones, more researchers are designing different HAR models for embedded
devices. Deployment of models in embedded devices can help enhance the
efficiency of HAR. We propose a multi-level HAR modeling pipeline called
Stage-Logits-Memory Distillation (SMLDist) for constructing deep convolutional
HAR models with embedded hardware support. SMLDist includes stage distillation,
memory distillation, and logits distillation. Stage distillation constrains the
learning direction of the intermediate features. The teacher model teaches the
student models how to explain and store the inner relationship among
high-dimensional features based on Hopfield networks in memory distillation.
Logits distillation builds logits distilled by a smoothed conditional rule to
preserve the probability distribution and enhance the softer target accuracy.
We compare the accuracy, F1 macro score, and energy cost on embedded platforms
of a MobileNet V3 model built by our SMLDist with those of various
state-of-the-art HAR frameworks. The product model has a good balance with
robustness and efficiency. SMLDist can also compress models with a minor
performance loss at an equal compression ratio to other advanced knowledge
distillation methods on seven public datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Autonomy 2.0: Why is self-driving always 5 years away?.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ashesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Pero_L/0/1/0/all/0/1">Luca Del Pero</a>, <a href="http://arxiv.org/find/cs/1/au:+Grimmett_H/0/1/0/all/0/1">Hugo Grimmett</a>, <a href="http://arxiv.org/find/cs/1/au:+Ondruska_P/0/1/0/all/0/1">Peter Ondruska</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08142">
                                        <div class="article-summary-box-inner">
                                            <span><p>Despite the numerous successes of machine learning over the past decade
(image recognition, decision-making, NLP, image synthesis), self-driving
technology has not yet followed the same trend. In this paper, we study the
history, composition, and development bottlenecks of the modern self-driving
stack. We argue that the slow progress is caused by approaches that require too
much hand-engineering, an over-reliance on road testing, and high fleet
deployment costs. We observe that the classical stack has several bottlenecks
that preclude the necessary scale needed to capture the long tail of rare
events. To resolve these problems, we outline the principles of Autonomy 2.0,
an ML-first approach to self-driving, as a viable alternative to the currently
adopted state-of-the-art. This approach is based on (i) a fully differentiable
AV stack trainable from human demonstrations, (ii) closed-loop data-driven
reactive simulation, and (iii) large-scale, low-cost data collections as
critical solutions towards scalability issues. We outline the general
architecture, survey promising works in this direction and propose key
challenges to be addressed by the community in the future.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Using Undervolting as an On-Device Defense Against Adversarial Machine Learning Attacks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1">Saikat Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Samavatian_M/0/1/0/all/0/1">Mohammad Hossein Samavatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Barber_K/0/1/0/all/0/1">Kristin Barber</a>, <a href="http://arxiv.org/find/cs/1/au:+Teodorescu_R/0/1/0/all/0/1">Radu Teodorescu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09804">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep neural network (DNN) classifiers are powerful tools that drive a broad
spectrum of important applications, from image recognition to autonomous
vehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks
that affect virtually all state-of-the-art models. These attacks make small
imperceptible modifications to inputs that are sufficient to induce the DNNs to
produce the wrong classification.
</p>
<p>In this paper we propose a novel, lightweight adversarial correction and/or
detection mechanism for image classifiers that relies on undervolting (running
a chip at a voltage that is slightly below its safe margin). We propose using
controlled undervolting of the chip running the inference process in order to
introduce a limited number of compute errors. We show that these errors disrupt
the adversarial input in a way that can be used either to correct the
classification or detect the input as adversarial. We evaluate the proposed
solution in an FPGA design and through software simulation. We evaluate 10
attacks and show average detection rates of 77% and 90% on two popular DNNs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Bridging the Gap between Spatial and Spectral Domains: A Unified Framework for Graph Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiqian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fanglan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_T/0/1/0/all/0/1">Taoran Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1">Kaiqun Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Feng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1">Charu Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chang-Tien Lu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10234">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep learning's performance has been extensively recognized recently. Graph
neural networks (GNNs) are designed to deal with graph-structural data that
classical deep learning does not easily manage. Since most GNNs were created
using distinct theories, direct comparisons are impossible. Prior research has
primarily concentrated on categorizing existing models, with little attention
paid to their intrinsic connections. The purpose of this study is to establish
a unified framework that integrates GNNs based on spectral graph and
approximation theory. The framework incorporates a strong integration between
spatial- and spectral-based GNNs while tightly associating approaches that
exist within each respective domain.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ High Dimensional Differentially Private Stochastic Optimization with Heavy-tailed Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lijie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_S/0/1/0/all/0/1">Shuo Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Hanshen Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11136">
                                        <div class="article-summary-box-inner">
                                            <span><p>As one of the most fundamental problems in machine learning, statistics and
differential privacy, Differentially Private Stochastic Convex Optimization
(DP-SCO) has been extensively studied in recent years. However, most of the
previous work can only handle either regular data distribution or irregular
data in the low dimensional space case. To better understand the challenges
arising from irregular data distribution, in this paper we provide the first
study on the problem of DP-SCO with heavy-tailed data in the high dimensional
space. In the first part we focus on the problem over some polytope constraint
(such as the $\ell_1$-norm ball). We show that if the loss function is smooth
and its gradient has bounded second order moment, it is possible to get a (high
probability) error bound (excess population risk) of $\tilde{O}(\frac{\log
d}{(n\epsilon)^\frac{1}{3}})$ in the $\epsilon$-DP model, where $n$ is the
sample size and $d$ is the dimensionality of the underlying space. Next, for
LASSO, if the data distribution that has bounded fourth-order moments, we
improve the bound to $\tilde{O}(\frac{\log d}{(n\epsilon)^\frac{2}{5}})$ in the
$(\epsilon, \delta)$-DP model. In the second part of the paper, we study sparse
learning with heavy-tailed data. We first revisit the sparse linear model and
propose a truncated DP-IHT method whose output could achieve an error of
$\tilde{O}(\frac{s^{*2}\log d}{n\epsilon})$, where $s^*$ is the sparsity of the
underlying parameter. Then we study a more general problem over the sparsity
({\em i.e.,} $\ell_0$-norm) constraint, and show that it is possible to achieve
an error of $\tilde{O}(\frac{s^{*\frac{3}{2}}\log d}{n\epsilon})$, which is
also near optimal up to a factor of $\tilde{O}{(\sqrt{s^*})}$, if the loss
function is smooth and strongly convex.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tsung-Han Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hsin-Ying Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Ping-Chia Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11769">
                                        <div class="article-summary-box-inner">
                                            <span><p>Despite the success of deep learning on supervised point cloud semantic
segmentation, obtaining large-scale point-by-point manual annotations is still
a significant challenge. To reduce the huge annotation burden, we propose a
Region-based and Diversity-aware Active Learning (ReDAL), a general framework
for many deep learning approaches, aiming to automatically select only
informative and diverse sub-scene regions for label acquisition. Observing that
only a small portion of annotated regions are sufficient for 3D scene
understanding with deep learning, we use softmax entropy, color discontinuity,
and structural complexity to measure the information of sub-scene regions. A
diversity-aware selection algorithm is also developed to avoid redundant
annotations resulting from selecting informative but similar regions in a
querying batch. Extensive experiments show that our method highly outperforms
previous active learning strategies, and we achieve the performance of 90%
fully supervised learning, while less than 15% and 5% annotations are required
on S3DIS and SemanticKITTI datasets, respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Decentralized Federated Learning: Balancing Communication and Computing Costs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenyi Zhang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12048">
                                        <div class="article-summary-box-inner">
                                            <span><p>Decentralized federated learning (DFL) is a powerful framework of distributed
machine learning and decentralized stochastic gradient descent (SGD) is a
driving engine for DFL. The performance of decentralized SGD is jointly
influenced by communication-efficiency and convergence rate. In this paper, we
propose a general decentralized federated learning framework to strike a
balance between communication-efficiency and convergence performance. The
proposed framework performs both multiple local updates and multiple inter-node
communications periodically, unifying traditional decentralized SGD methods. We
establish strong convergence guarantees for the proposed DFL algorithm without
the assumption of convex objective function. The balance of communication and
computation rounds is essential to optimize decentralized federated learning
under constrained communication and computation resources. For further
improving communication-efficiency of DFL, compressed communication is applied
to DFL, named DFL with compressed communication (C-DFL). The proposed C-DFL
exhibits linear convergence for strongly convex objectives. Experiment results
based on MNIST and CIFAR-10 datasets illustrate the superiority of DFL over
traditional decentralized SGD methods and show that C-DFL further enhances
communication-efficiency.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Boshen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12619">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, the problem of inaccurate learning targets in crowd counting draws
increasing attention. Inspired by a few pioneering work, we solve this problem
by trying to predict the indices of pre-defined interval bins of counts instead
of the count values themselves. However, an inappropriate interval setting
might make the count error contributions from different intervals extremely
imbalanced, leading to inferior counting performance. Therefore, we propose a
novel count interval partition criterion called Uniform Error Partition (UEP),
which always keeps the expected counting error contributions equal for all
intervals to minimize the prediction risk. Then to mitigate the inevitably
introduced discretization errors in the count quantization process, we propose
another criterion called Mean Count Proxies (MCP). The MCP criterion selects
the best count proxy for each interval to represent its count value during
inference, making the overall expected discretization error of an image nearly
negligible. As far as we are aware, this work is the first to delve into such a
classification task and ends up with a promising solution for count interval
partition. Following the above two theoretically demonstrated criterions, we
propose a simple yet effective model termed Uniform Error Partition Network
(UEPNet), which achieves state-of-the-art performance on several challenging
datasets. The codes will be available at:
https://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Greedy Gradient Ensemble for Robust Visual Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xinzhe Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12651">
                                        <div class="article-summary-box-inner">
                                            <span><p>Language bias is a critical issue in Visual Question Answering (VQA), where
models often exploit dataset biases for the final decision without considering
the image information. As a result, they suffer from performance drop on
out-of-distribution data and inadequate visual explanation. Based on
experimental analysis for existing robust VQA methods, we stress the language
bias in VQA that comes from two aspects, i.e., distribution bias and shortcut
bias. We further propose a new de-bias framework, Greedy Gradient Ensemble
(GGE), which combines multiple biased models for unbiased base model learning.
With the greedy strategy, GGE forces the biased models to over-fit the biased
data distribution in priority, thus makes the base model pay more attention to
examples that are hard to solve by biased models. The experiments demonstrate
that our method makes better use of visual information and achieves
state-of-the-art performance on diagnosing dataset VQA-CP without using extra
annotations.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ MARViN -- Multiple Arithmetic Resolutions Vacillating in Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kummer_L/0/1/0/all/0/1">Lorenz Kummer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidak_K/0/1/0/all/0/1">Kevin Sidak</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichmann_T/0/1/0/all/0/1">Tabea Reichmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gansterer_W/0/1/0/all/0/1">Wilfried Gansterer</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13490">
                                        <div class="article-summary-box-inner">
                                            <span><p>Quantization is a technique for reducing deep neural networks (DNNs) training
and inference times, which is crucial for training in resource constrained
environments or time critical inference applications. State-of-the-art (SOTA)
quantization approaches focus on post-training quantization, i.e. quantization
of pre-trained DNNs for speeding up inference. Very little work on quantized
training exists, which neither al-lows dynamic intra-epoch precision switches
nor em-ploys an information theory based switching heuristic. Usually, existing
approaches require full precision refinement afterwards and enforce a global
word length across the whole DNN. This leads to suboptimal quantization
mappings and resource usage. Recognizing these limits, we introduce MARViN, a
new quantized training strategy using information theory-based intra-epoch
precision switching, which decides on a per-layer basis which precision should
be used in order to minimize quantization-induced information loss. Note that
any quantization must leave enough precision such that future learning steps do
not suffer from vanishing gradients. We achieve an average speedup of 1.86
compared to a float32 basis while limiting mean accuracy degradation on
AlexNet/ResNet to only -0.075%.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ ManiSkill: Learning-from-Demonstrations Benchmark for Generalizable Manipulation Skills.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tongzhou Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zhan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_F/0/1/0/all/0/1">Fanbo Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Derek Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuanlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1">Stone Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhiwei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14483">
                                        <div class="article-summary-box-inner">
                                            <span><p>Learning generalizable manipulation skills is central for robots to achieve
task automation in environments with endless scene and object variations.
However, existing robot learning environments are limited in both scale and
diversity of 3D assets (especially of articulated objects), making it difficult
to train and evaluate the generalization ability of agents over novel objects.
In this work, we focus on object-level generalization and propose SAPIEN
Manipulation Skill Benchmark (abbreviated as ManiSkill), a large-scale
learning-from-demonstrations benchmark for articulated object manipulation with
3D visual input (point cloud and RGB-D image). ManiSkill supports object-level
variations by utilizing a rich and diverse set of articulated objects, and each
task is carefully designed for learning manipulations on a single category of
objects. We equip ManiSkill with a large number of high-quality demonstrations
to facilitate learning-from-demonstrations approaches and perform evaluations
on baseline algorithms. We believe that ManiSkill can encourage the robot
learning community to explore more on learning generalizable object
manipulation skills.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Incorporation of Deep Neural Network & Reinforcement Learning with Domain Knowledge.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Karn_A/0/1/0/all/0/1">Aryan Karn</a>, <a href="http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1">Ashutosh Acharya</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14613">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present a study of the manners by which Domain information has been
incorporated when building models with Neural Networks. Integrating space data
is uniquely important to the development of Knowledge understanding model, as
well as other fields that aid in understanding information by utilizing the
human-machine interface and Reinforcement Learning. On numerous such occasions,
machine-based model development may profit essentially from the human
information on the world encoded in an adequately exact structure. This paper
inspects expansive ways to affect encode such information as sensible and
mathematical limitations and portrays methods and results that came to a couple
of subcategories under all of those methodologies.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Faster Rates of Differentially Private Stochastic Convex Optimization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jinyan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00331">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we revisit the problem of Differentially Private Stochastic
Convex Optimization (DP-SCO) and provide excess population risks for some
special classes of functions that are faster than the previous results of
general convex and strongly convex functions. In the first part of the paper,
we study the case where the population risk function satisfies the Tysbakov
Noise Condition (TNC) with some parameter $\theta&gt;1$. Specifically, we first
show that under some mild assumptions on the loss functions, there is an
algorithm whose output could achieve an upper bound of
$\tilde{O}((\frac{1}{\sqrt{n}}+\frac{\sqrt{d\log
\frac{1}{\delta}}}{n\epsilon})^\frac{\theta}{\theta-1})$ for $(\epsilon,
\delta)$-DP when $\theta\geq 2$, here $n$ is the sample size and $d$ is the
dimension of the space. Then we address the inefficiency issue, improve the
upper bounds by $\text{Poly}(\log n)$ factors and extend to the case where
$\theta\geq \bar{\theta}&gt;1$ for some known $\bar{\theta}$. Next we show that
the excess population risk of population functions satisfying TNC with
parameter $\theta&gt;1$ is always lower bounded by
$\Omega((\frac{d}{n\epsilon})^\frac{\theta}{\theta-1}) $ and
$\Omega((\frac{\sqrt{d\log
\frac{1}{\delta}}}{n\epsilon})^\frac{\theta}{\theta-1})$ for $\epsilon$-DP and
$(\epsilon, \delta)$-DP, respectively. In the second part, we focus on a
special case where the population risk function is strongly convex. Unlike the
previous studies, here we assume the loss function is {\em non-negative} and
{\em the optimal value of population risk is sufficiently small}. With these
additional assumptions, we propose a new method whose output could achieve an
upper bound of
$O(\frac{d\log\frac{1}{\delta}}{n^2\epsilon^2}+\frac{1}{n^{\tau}})$ for any
$\tau\geq 1$ in $(\epsilon,\delta)$-DP model if the sample size $n$ is
sufficiently large.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Piecewise Linear Units Improve Deep Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Inturrisi_J/0/1/0/all/0/1">Jordan Inturrisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khoo_S/0/1/0/all/0/1">Sui Yang Khoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kouzani_A/0/1/0/all/0/1">Abbas Kouzani</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagliarella_R/0/1/0/all/0/1">Riccardo Pagliarella</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00700">
                                        <div class="article-summary-box-inner">
                                            <span><p>The activation function is at the heart of a deep neural networks
nonlinearity; the choice of the function has great impact on the success of
training. Currently, many practitioners prefer the Rectified Linear Unit (ReLU)
due to its simplicity and reliability, despite its few drawbacks. While most
previous functions proposed to supplant ReLU have been hand-designed, recent
work on learning the function during training has shown promising results. In
this paper we propose an adaptive piecewise linear activation function, the
Piecewise Linear Unit (PiLU), which can be learned independently for each
dimension of the neural network. We demonstrate how PiLU is a generalised
rectifier unit and note its similarities with the Adaptive Piecewise Linear
Units, namely adaptive and piecewise linear. Across a distribution of 30
experiments, we show that for the same model architecture, hyperparameters, and
pre-processing, PiLU significantly outperforms ReLU: reducing classification
error by 18.53% on CIFAR-10 and 13.13% on CIFAR-100, for a minor increase in
the number of neurons. Further work should be dedicated to exploring
generalised piecewise linear units, as well as verifying these results across
other challenging domains and larger problems.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ A Machine learning approach for rapid disaster response based on multi-modal data. The case of housing & shelter needs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ochoa_K/0/1/0/all/0/1">Karla Saldana Ochoa</a>, <a href="http://arxiv.org/find/cs/1/au:+Comes_T/0/1/0/all/0/1">Tina Comes</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00887">
                                        <div class="article-summary-box-inner">
                                            <span><p>Along with climate change, more frequent extreme events, such as flooding and
tropical cyclones, threaten the livelihoods and wellbeing of poor and
vulnerable populations. One of the most immediate needs of people affected by a
disaster is finding shelter. While the proliferation of data on disasters is
already helping to save lives, identifying damages in buildings, assessing
shelter needs, and finding appropriate places to establish emergency shelters
or settlements require a wide range of data to be combined rapidly. To address
this gap and make a headway in comprehensive assessments, this paper proposes a
machine learning workflow that aims to fuse and rapidly analyse multimodal
data. This workflow is built around open and online data to ensure scalability
and broad accessibility. Based on a database of 19 characteristics for more
than 200 disasters worldwide, a fusion approach at the decision level was used.
This technique allows the collected multimodal data to share a common semantic
space that facilitates the prediction of individual variables. Each fused
numerical vector was fed into an unsupervised clustering algorithm called
Self-Organizing-Maps (SOM). The trained SOM serves as a predictor for future
cases, allowing predicting consequences such as total deaths, total people
affected, and total damage, and provides specific recommendations for
assessments in the shelter and housing sector. To achieve such prediction, a
satellite image from before the disaster and the geographic and demographic
conditions are shown to the trained model, which achieved a prediction accuracy
of 62 %
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ GalaxAI: Machine learning toolbox for interpretable analysis of spacecraft telemetry data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kostovska_A/0/1/0/all/0/1">Ana Kostovska</a>, <a href="http://arxiv.org/find/cs/1/au:+Petkovic_M/0/1/0/all/0/1">Matej Petkovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Stepisnik_T/0/1/0/all/0/1">Toma&#x17e; Stepi&#x161;nik</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucas_L/0/1/0/all/0/1">Luke Lucas</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_T/0/1/0/all/0/1">Timothy Finn</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_Heras_J/0/1/0/all/0/1">Jos&#xe9; Mart&#xed;nez-Heras</a>, <a href="http://arxiv.org/find/cs/1/au:+Panov_P/0/1/0/all/0/1">Pan&#x10d;e Panov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dzeroski_S/0/1/0/all/0/1">Sa&#x161;o D&#x17e;eroski</a>, <a href="http://arxiv.org/find/cs/1/au:+Donati_A/0/1/0/all/0/1">Alessandro Donati</a>, <a href="http://arxiv.org/find/cs/1/au:+Simidjievski_N/0/1/0/all/0/1">Nikola Simidjievski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocev_D/0/1/0/all/0/1">Dragi Kocev</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01407">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present GalaxAI - a versatile machine learning toolbox for efficient and
interpretable end-to-end analysis of spacecraft telemetry data. GalaxAI employs
various machine learning algorithms for multivariate time series analyses,
classification, regression and structured output prediction, capable of
handling high-throughput heterogeneous data. These methods allow for the
construction of robust and accurate predictive models, that are in turn applied
to different tasks of spacecraft monitoring and operations planning. More
importantly, besides the accurate building of models, GalaxAI implements a
visualisation layer, providing mission specialists and operators with a full,
detailed and interpretable view of the data analysis process. We show the
utility and versatility of GalaxAI on two use-cases concerning two different
spacecraft: i) analysis and planning of Mars Express thermal power consumption
and ii) predicting of INTEGRAL's crossings through Van Allen belts.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Multi-task Federated Edge Learning (MtFEEL) in Wireless Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mahara_S/0/1/0/all/0/1">Sawan Singh Mahara</a>, <a href="http://arxiv.org/find/cs/1/au:+M%2E_S/0/1/0/all/0/1">Shruti M.</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharath_B/0/1/0/all/0/1">B. N. Bharath</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02517">
                                        <div class="article-summary-box-inner">
                                            <span><p>Federated Learning (FL) has evolved as a promising technique to handle
distributed machine learning across edge devices. A single neural network (NN)
that optimises a global objective is generally learned in most work in FL,
which could be suboptimal for edge devices. Although works finding a NN
personalised for edge device specific tasks exist, they lack generalisation
and/or convergence guarantees. In this paper, a novel communication efficient
FL algorithm for personalised learning in a wireless setting with guarantees is
presented. The algorithm relies on finding a ``better`` empirical estimate of
losses at each device, using a weighted average of the losses across different
devices. It is devised from a Probably Approximately Correct (PAC) bound on the
true loss in terms of the proposed empirical loss and is bounded by (i) the
Rademacher complexity, (ii) the discrepancy, (iii) and a penalty term. Using a
signed gradient feedback to find a personalised NN at each device, it is also
proven to converge in a Rayleigh flat fading (in the uplink) channel, at a rate
of the order max{1/SNR,1/sqrt(T)} Experimental results show that the proposed
algorithm outperforms locally trained devices as well as the conventionally
used FedAvg and FedSGD algorithms under practical SNR regimes.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Optimal Transport for Unsupervised Restoration Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wen_F/0/1/0/all/0/1">Fei Wen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Z/0/1/0/all/0/1">Zeyu Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Ying_R/0/1/0/all/0/1">Rendong Ying</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1">Peilin Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02574">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, much progress has been made in unsupervised restoration learning.
However, existing methods more or less rely on some assumptions on the signal
and/or degradation model, which limits their practical performance. How to
construct an optimal criterion for unsupervised restoration learning without
any prior knowledge on the degradation model is still an open question. Toward
answering this question, this work proposes a criterion for unsupervised
restoration learning based on the optimal transport theory. This criterion has
favorable properties, e.g., approximately maximal preservation of the
information of the signal, whilst achieving perceptual reconstruction.
Furthermore, though a relaxed unconstrained formulation is used in practical
implementation, we show that the relaxed formulation in theory has the same
solution as the original constrained formulation. Experiments on synthetic and
real-world data, including realistic photographic, microscopy, depth, and raw
depth images, demonstrate that the proposed method even compares favorably with
supervised methods, e.g., approaching the PSNR of supervised methods while
having better perceptual quality. Particularly, for spatially correlated noise
and realistic microscopy images, the proposed method not only achieves better
perceptual quality but also has higher PSNR than supervised methods. Besides,
it shows remarkable superiority in harsh practical conditions with complex
noise, e.g., raw depth images.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Learning to Elect.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Anil_C/0/1/0/all/0/1">Cem Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_X/0/1/0/all/0/1">Xuchan Bao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02768">
                                        <div class="article-summary-box-inner">
                                            <span><p>Voting systems have a wide range of applications including recommender
systems, web search, product design and elections. Limited by the lack of
general-purpose analytical tools, it is difficult to hand-engineer desirable
voting rules for each use case. For this reason, it is appealing to
automatically discover voting rules geared towards each scenario. In this
paper, we show that set-input neural network architectures such as Set
Transformers, fully-connected graph networks and DeepSets are both
theoretically and empirically well-suited for learning voting rules. In
particular, we show that these network models can not only mimic a number of
existing voting rules to compelling accuracy --- both position-based (such as
Plurality and Borda) and comparison-based (such as Kemeny, Copeland and
Maximin) --- but also discover near-optimal voting rules that maximize
different social welfare functions. Furthermore, the learned voting rules
generalize well to different voter utility distributions and election sizes
unseen during training.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Is it Fake? News Disinformation Detection on South African News Websites.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wet_H/0/1/0/all/0/1">Harm de Wet</a>, <a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02941">
                                        <div class="article-summary-box-inner">
                                            <span><p>Disinformation through fake news is an ongoing problem in our society and has
become easily spread through social media. The most cost and time effective way
to filter these large amounts of data is to use a combination of human and
technical interventions to identify it. From a technical perspective, Natural
Language Processing (NLP) is widely used in detecting fake news. Social media
companies use NLP techniques to identify the fake news and warn their users,
but fake news may still slip through undetected. It is especially a problem in
more localised contexts (outside the United States of America). How do we
adjust fake news detection systems to work better for local contexts such as in
South Africa. In this work we investigate fake news detection on South African
websites. We curate a dataset of South African fake news and then train
detection models. We contrast this with using widely available fake news
datasets (from mostly USA website). We also explore making the datasets more
diverse by combining them and observe the differences in behaviour in writing
between nations' fake news using interpretable machine learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Simple Modifications to Improve Tabular Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fiedler_J/0/1/0/all/0/1">James Fiedler</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03214">
                                        <div class="article-summary-box-inner">
                                            <span><p>There is growing interest in neural network architectures for tabular data.
Many general-purpose tabular deep learning models have been introduced
recently, with performance sometimes rivaling gradient boosted decision trees
(GBDTs). These recent models draw inspiration from various sources, including
GBDTs, factorization machines, and neural networks from other application
domains. Previous tabular neural networks are also drawn upon, but are possibly
under-considered, especially models associated with specific tabular problems.
This paper focuses on several such models, and proposes modifications for
improving their performance. When modified, these models are shown to be
competitive with leading general-purpose tabular models, including GBDTs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Can a CNN trained on the Ising model detect the phase transition of the $q$-state Potts model?.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cond-mat/1/au:+Fukushima_K/0/1/0/all/0/1">Kimihiko Fukushima</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Sakai_K/0/1/0/all/0/1">Kazumitsu Sakai</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03632">
                                        <div class="article-summary-box-inner">
                                            <span><p>Employing a deep convolutional neural network (deep CNN) trained on spin
configurations of the 2D Ising model and the temperatures, we examine whether
the deep CNN can detect the phase transition of the 2D $q$-state Potts model.
To this end, we generate binarized images of spin configurations of the
$q$-state Potts model ($q\ge 3$) by replacing the spin variables
$\{0,1,\dots,\lfloor q/2\rfloor-1\}$ and $\{\lfloor q/2\rfloor,\dots,q-1\}$
with $\{0\}$ and $\{1\}$, respectively. Then, we input these images to the
trained CNN to output the predicted temperatures. The binarized images of the
$q$-state Potts model are entirely different from Ising spin configurations,
particularly at the transition temperature. Moreover, our CNN model is not
trained on the information about whether phases are ordered/disordered but is
naively trained by Ising spin configurations labeled with temperatures at which
they are generated. Nevertheless, the deep CNN can detect the transition point
with high accuracy, regardless of the type of transition. We also find that, in
the high-temperature region, the CNN outputs the temperature based on the
internal energy, whereas, in the low-temperature region, the output depends on
the magnetization and possibly the internal energy as well. However, in the
vicinity of the transition point, the CNN may use more general factors to
detect the transition point.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
        </ul>
    </section>
</body>

<footer>
    <time id="build-timestamp" datetime="2021-08-10T03:18:13.988261121Z">2021-08-10T03:18:13.988261121Z</time>
</footer>

</html>
