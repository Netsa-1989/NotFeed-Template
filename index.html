<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
</head>

<body>
<a href="https://github.com/AlongWY/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">AlongWY/ArxivDaily</a>
<h1></h1>
    <section class="daily-content">
        <h2 class="daily-heading">
            <time datetime="2021-08-09">2021-08-09</time>
        </h2>
        <ul class="sources card">
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.CL updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Hate Speech Detection in Roman Urdu.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Moin Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahzad_K/0/1/0/all/0/1">Khurram Shahzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1">Kamran Malik</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02830">
                                        <div class="article-summary-box-inner">
                                            <span><p>Hate speech is a specific type of controversial content that is widely
legislated as a crime that must be identified and blocked. However, due to the
sheer volume and velocity of the Twitter data stream, hate speech detection
cannot be performed manually. To address this issue, several studies have been
conducted for hate speech detection in European languages, whereas little
attention has been paid to low-resource South Asian languages, making the
social media vulnerable for millions of users. In particular, to the best of
our knowledge, no study has been conducted for hate speech detection in Roman
Urdu text, which is widely used in the sub-continent. In this study, we have
scrapped more than 90,000 tweets and manually parsed them to identify 5,000
Roman Urdu tweets. Subsequently, we have employed an iterative approach to
develop guidelines and used them for generating the Hate Speech Roman Urdu 2020
corpus. The tweets in the this corpus are classified at three levels:
Neutral-Hostile, Simple-Complex, and Offensive-Hate speech. As another
contribution, we have used five supervised learning techniques, including a
deep learning technique, to evaluate and compare their effectiveness for hate
speech detection. The results show that Logistic Regression outperformed all
other techniques, including deep learning techniques for the two levels of
classification, by achieved an F1 score of 0.906 for distinguishing between
Neutral-Hostile tweets, and 0.756 for distinguishing between Offensive-Hate
speech tweets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ GENder-IT: An Annotated English-Italian Parallel Challenge Set for Cross-Linguistic Natural Gender Phenomena.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Vanmassenhove_E/0/1/0/all/0/1">Eva Vanmassenhove</a>, <a href="http://arxiv.org/find/cs/1/au:+Monti_J/0/1/0/all/0/1">Johanna Monti</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02854">
                                        <div class="article-summary-box-inner">
                                            <span><p>Languages differ in terms of the absence or presence of gender features, the
number of gender classes and whether and where gender features are explicitly
marked. These cross-linguistic differences can lead to ambiguities that are
difficult to resolve, especially for sentence-level MT systems. The
identification of ambiguity and its subsequent resolution is a challenging task
for which currently there aren't any specific resources or challenge sets
available. In this paper, we introduce gENder-IT, an English--Italian challenge
set focusing on the resolution of natural gender phenomena by providing
word-level gender tags on the English source side and multiple gender
alternative translations, where needed, on the Italian target side.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Analyzing the Abstractiveness-Factuality Tradeoff With Nonlinear Abstractiveness Constraints.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Dreyer_M/0/1/0/all/0/1">Markus Dreyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nan_F/0/1/0/all/0/1">Feng Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Atluri_S/0/1/0/all/0/1">Sandeep Atluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1">Sujith Ravi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02859">
                                        <div class="article-summary-box-inner">
                                            <span><p>We analyze the tradeoff between factuality and abstractiveness of summaries.
We introduce abstractiveness constraints to control the degree of
abstractiveness at decoding time, and we apply this technique to characterize
the abstractiveness-factuality tradeoff across multiple widely-studied
datasets, using extensive human evaluations. We train a neural summarization
model on each dataset and visualize the rates of change in factuality as we
gradually increase abstractiveness using our abstractiveness constraints. We
observe that, while factuality generally drops with increased abstractiveness,
different datasets lead to different rates of factuality decay. We propose new
measures to quantify the tradeoff between factuality and abstractiveness, incl.
muQAGS, which balances factuality with abstractiveness. We also quantify this
tradeoff in previous works, aiming to establish baselines for the
abstractiveness-factuality tradeoff that future publications can compare
against.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Dual Reader-Parser on Hybrid Textual and Tabular Evidence for Open Domain Question Answering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Alexander Hanbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_P/0/1/0/all/0/1">Patrick Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Henghui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiguo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1">Bing Xiang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02866">
                                        <div class="article-summary-box-inner">
                                            <span><p>The current state-of-the-art generative models for open-domain question
answering (ODQA) have focused on generating direct answers from unstructured
textual information. However, a large amount of world's knowledge is stored in
structured databases, and need to be accessed using query languages such as
SQL. Furthermore, query languages can answer questions that require complex
reasoning, as well as offering full explainability. In this paper, we propose a
hybrid framework that takes both textual and tabular evidence as input and
generates either direct answers or SQL queries depending on which form could
better answer the question. The generated SQL queries can then be executed on
the associated databases to obtain the final answers. To the best of our
knowledge, this is the first paper that applies Text2SQL to ODQA tasks.
Empirically, we demonstrate that on several ODQA datasets, the hybrid methods
consistently outperforms the baseline models that only take homogeneous input
by a large margin. Specifically we achieve state-of-the-art performance on
OpenSQuAD dataset using a T5-base model. In a detailed analysis, we demonstrate
that the being able to generate structural SQL queries can always bring gains,
especially for those questions that requires complex reasoning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Evolution of emotion semantics.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1">Aotao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stellar_J/0/1/0/all/0/1">Jennifer E. Stellar</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yang Xu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02887">
                                        <div class="article-summary-box-inner">
                                            <span><p>Humans possess the unique ability to communicate emotions through language.
Although concepts like anger or awe are abstract, there is a shared consensus
about what these English emotion words mean. This consensus may give the
impression that their meaning is static, but we propose this is not the case.
We cannot travel back to earlier periods to study emotion concepts directly,
but we can examine text corpora, which have partially preserved the meaning of
emotion words. Using natural language processing of historical text, we found
evidence for semantic change in emotion words over the past century and that
varying rates of change were predicted in part by an emotion concept's
prototypicality - how representative it is of the broader category of
"emotion". Prototypicality negatively correlated with historical rates of
emotion semantic change obtained from text-based word embeddings, beyond more
established variables including usage frequency in English and a second
comparison language, French. This effect for prototypicality did not
consistently extend to the semantic category of birds, suggesting its relevance
for predicting semantic change may be category-dependent. Our results suggest
emotion semantics are evolving over time, with prototypical emotion words
remaining semantically stable, while other emotion words evolve more freely.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Lights, Camera, Action! A Framework to Improve NLP Accuracy over OCR documents.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gupte_A/0/1/0/all/0/1">Amit Gupte</a>, <a href="http://arxiv.org/find/cs/1/au:+Romanov_A/0/1/0/all/0/1">Alexey Romanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantravadi_S/0/1/0/all/0/1">Sahitya Mantravadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banda_D/0/1/0/all/0/1">Dalitso Banda</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jianjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1">Raza Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Meenal_L/0/1/0/all/0/1">Lakshmanan Ramu Meenal</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Benjamin Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Soundar Srinivasan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02899">
                                        <div class="article-summary-box-inner">
                                            <span><p>Document digitization is essential for the digital transformation of our
societies, yet a crucial step in the process, Optical Character Recognition
(OCR), is still not perfect. Even commercial OCR systems can produce
questionable output depending on the fidelity of the scanned documents. In this
paper, we demonstrate an effective framework for mitigating OCR errors for any
downstream NLP task, using Named Entity Recognition (NER) as an example. We
first address the data scarcity problem for model training by constructing a
document synthesis pipeline, generating realistic but degraded data with NER
labels. We measure the NER accuracy drop at various degradation levels and show
that a text restoration model, trained on the degraded data, significantly
closes the NER accuracy gaps caused by OCR errors, including on an
out-of-domain dataset. For the benefit of the community, we have made the
document synthesis pipeline available as an open-source project.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ LadRa-Net: Locally-Aware Dynamic Re-read Attention Net for Sentence Semantic Matching.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1">Guangyi Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Le Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02915">
                                        <div class="article-summary-box-inner">
                                            <span><p>Sentence semantic matching requires an agent to determine the semantic
relation between two sentences, which is widely used in various natural
language tasks, such as Natural Language Inference (NLI), Paraphrase
Identification (PI), and so on. Much recent progress has been made in this
area, especially attention-based methods and pre-trained language model based
methods. However, most of these methods focus on all the important parts in
sentences in a static way and only emphasize how important the words are to the
query, inhibiting the ability of attention mechanism. In order to overcome this
problem and boost the performance of attention mechanism, we propose a novel
dynamic re-read attention, which can pay close attention to one small region of
sentences at each step and re-read the important parts for better sentence
representations. Based on this attention variation, we develop a novel Dynamic
Re-read Network (DRr-Net) for sentence semantic matching. Moreover, selecting
one small region in dynamic re-read attention seems insufficient for sentence
semantics, and employing pre-trained language models as input encoders will
introduce incomplete and fragile representation problems. To this end, we
extend DRrNet to Locally-Aware Dynamic Re-read Attention Net (LadRa-Net), in
which local structure of sentences is employed to alleviate the shortcoming of
Byte-Pair Encoding (BPE) in pre-trained language models and boost the
performance of dynamic reread attention. Extensive experiments on two popular
sentence semantic matching tasks demonstrate that DRr-Net can significantly
improve the performance of sentence semantic matching. Meanwhile, LadRa-Net is
able to achieve better performance by considering the local structures of
sentences. In addition, it is exceedingly interesting that some discoveries in
our experiments are consistent with some findings of psychological research.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ StrucTexT: Structured Text Understanding with <span class="highlight_title">Multi-Modal</span> <span class="highlight_title">Transformer</span>s.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yulin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yuxi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yuchen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1">Xiameng Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chengquan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_K/0/1/0/all/0/1">Kun Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Junyu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingtuo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02923">
                                        <div class="article-summary-box-inner">
                                            <span><p>Structured text understanding on Visually Rich Documents (VRDs) is a crucial
part of Document Intelligence. Due to the complexity of content and layout in
VRDs, structured text understanding has been a challenging task. Most existing
studies decoupled this problem into two sub-tasks: entity labeling and entity
linking, which require an entire understanding of the context of documents at
both token and segment levels. However, little work has been concerned with the
solutions that efficiently extract the structured data from different levels.
This paper proposes a unified framework named StrucTexT, which is flexible and
effective for handling both sub-tasks. Specifically, based on the transformer,
we introduce a segment-token aligned encoder to deal with the entity labeling
and entity linking tasks at different levels of granularity. Moreover, we
design a novel pre-training strategy with three self-supervised tasks to learn
a richer representation. StrucTexT uses the existing Masked Visual Language
Modeling task and the new Sentence Length Prediction and Paired Boxes Direction
tasks to incorporate the multi-modal information across text, image, and
layout. We evaluate our method for structured text understanding at
segment-level and token-level and show it outperforms the state-of-the-art
counterparts with significantly superior performance on the FUNSD, SROIE, and
EPHOIE datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Is it Fake? News Disinformation Detection on South African News Websites.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wet_H/0/1/0/all/0/1">Harm de Wet</a>, <a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02941">
                                        <div class="article-summary-box-inner">
                                            <span><p>Disinformation through fake news is an ongoing problem in our society and has
become easily spread through social media. The most cost and time effective way
to filter these large amounts of data is to use a combination of human and
technical interventions to identify it. From a technical perspective, Natural
Language Processing (NLP) is widely used in detecting fake news. Social media
companies use NLP techniques to identify the fake news and warn their users,
but fake news may still slip through undetected. It is especially a problem in
more localised contexts (outside the United States of America). How do we
adjust fake news detection systems to work better for local contexts such as in
South Africa. In this work we investigate fake news detection on South African
websites. We curate a dataset of South African fake news and then train
detection models. We contrast this with using widely available fake news
datasets (from mostly USA website). We also explore making the datasets more
diverse by combining them and observe the differences in behaviour in writing
between nations' fake news using interpretable machine learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Sentence Semantic Regression for Text Generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Piji Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hai-Tao Zheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02984">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recall the classical text generation works, the generation framework can be
briefly divided into two phases: \textbf{idea reasoning} and \textbf{surface
realization}. The target of idea reasoning is to figure out the main idea which
will be presented in the following talking/writing periods. Surface realization
aims to arrange the most appropriate sentence to depict and convey the
information distilled from the main idea. However, the current popular
token-by-token text generation methods ignore this crucial process and suffer
from many serious issues, such as idea/topic drift. To tackle the problems and
realize this two-phase paradigm, we propose a new framework named Sentence
Semantic Regression (\textbf{SSR}) based on sentence-level language modeling.
For idea reasoning, two architectures \textbf{SSR-AR} and \textbf{SSR-NonAR}
are designed to conduct sentence semantic regression autoregressively (like
GPT2/3) and bidirectionally (like BERT). In the phase of surface realization, a
mixed-granularity sentence decoder is designed to generate text with better
consistency by jointly incorporating the predicted sentence-level main idea as
well as the preceding contextual token-level information. We conduct
experiments on four tasks of story ending prediction, story ending generation,
dialogue generation, and sentence infilling. The results show that SSR can
obtain better performance in terms of automatic metrics and human evaluation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Tell me a story about yourself: The words of shopping experience and self-satisfaction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Petruzzellis_L/0/1/0/all/0/1">L Petruzzellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1">A Fronzetti Colladon</a>, <a href="http://arxiv.org/find/cs/1/au:+Visentin_M/0/1/0/all/0/1">M Visentin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chebat_J/0/1/0/all/0/1">J.-C. Chebat</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03016">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper we investigate the verbal expression of shopping experience
obtained by a sample of customers asked to freely verbalize how they felt when
entering a store. Using novel tools of Text Mining and Social Network Analysis,
we analyzed the interviews to understand the connection between the emotions
aroused during the shopping experience, satisfaction and the way participants
link these concepts to self-satisfaction and self-identity. The results show a
prominent role of emotions in the discourse about the shopping experience
before purchasing and an inward-looking connection to the self. Our results
also suggest that modern retail environment should enhance the hedonic shopping
experience in terms of fun, fantasy, moods, and emotions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Deriving Disinformation Insights from Geolocalized Twitter Callouts.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tuxworth_D/0/1/0/all/0/1">David Tuxworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Antypas_D/0/1/0/all/0/1">Dimosthenis Antypas</a>, <a href="http://arxiv.org/find/cs/1/au:+Espinosa_Anke_L/0/1/0/all/0/1">Luis Espinosa-Anke</a>, <a href="http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1">Jose Camacho-Collados</a>, <a href="http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1">Alun Preece</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_D/0/1/0/all/0/1">David Rogers</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03067">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper demonstrates a two-stage method for deriving insights from social
media data relating to disinformation by applying a combination of geospatial
classification and embedding-based language modelling across multiple
languages. In particular, the analysis in centered on Twitter and
disinformation for three European languages: English, French and Spanish.
Firstly, Twitter data is classified into European and non-European sets using
BERT. Secondly, Word2vec is applied to the classified texts resulting in
Eurocentric, non-Eurocentric and global representations of the data for the
three target languages. This comparative analysis demonstrates not only the
efficacy of the classification method but also highlights geographic, temporal
and linguistic differences in the disinformation-related media. Thus, the
contributions of the work are threefold: (i) a novel language-independent
transformer-based geolocation method; (ii) an analytical approach that exploits
lexical specificity and word embeddings to interrogate user-generated content;
and (iii) a dataset of 36 million disinformation related tweets in English,
French and Spanish.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ SWSR: A Chinese Dataset and Lexicon for Online Sexism Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jiang_A/0/1/0/all/0/1">Aiqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaohan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1">Arkaitz Zubiaga</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03070">
                                        <div class="article-summary-box-inner">
                                            <span><p>Online sexism has become an increasing concern in social media platforms as
it has affected the healthy development of the Internet and can have negative
effects in society. While research in the sexism detection domain is growing,
most of this research focuses on English as the language and on Twitter as the
platform. Our objective here is to broaden the scope of this research by
considering the Chinese language on Sina Weibo. We propose the first Chinese
sexism dataset -- Sina Weibo Sexism Review (SWSR) dataset --, as well as a
large Chinese lexicon SexHateLex made of abusive and gender-related terms. We
introduce our data collection and annotation process, and provide an
exploratory analysis of the dataset characteristics to validate its quality and
to show how sexism is manifested in Chinese. The SWSR dataset provides labels
at different levels of granularity including (i) sexism or non-sexism, (ii)
sexism category and (iii) target type, which can be exploited, among others,
for building computational methods to identify and investigate finer-grained
gender-related abusive language. We conduct experiments for the three sexism
classification tasks making use of state-of-the-art machine learning models.
Our results show competitive performance, providing a benchmark for sexism
detection in the Chinese language, as well as an error analysis highlighting
open challenges needing more research in Chinese NLP. The SWSR dataset and
SexHateLex lexicon are publicly available.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Cross-lingual Capsule Network for Hate Speech Detection in Social Media.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jiang_A/0/1/0/all/0/1">Aiqi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1">Arkaitz Zubiaga</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03089">
                                        <div class="article-summary-box-inner">
                                            <span><p>Most hate speech detection research focuses on a single language, generally
English, which limits their generalisability to other languages. In this paper
we investigate the cross-lingual hate speech detection task, tackling the
problem by adapting the hate speech resources from one language to another. We
propose a cross-lingual capsule network learning model coupled with extra
domain-specific lexical semantics for hate speech (CCNL-Ex). Our model achieves
state-of-the-art performance on benchmark datasets from AMI@Evalita2018 and
AMI@Ibereval2018 involving three languages: English, Spanish and Italian,
outperforming state-of-the-art baselines on all six language pairs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Analyzing Information Leakage of Updates to Natural Language Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zanella_Beguelin_S/0/1/0/all/0/1">Santiago Zanella-B&#xe9;guelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wutschitz_L/0/1/0/all/0/1">Lukas Wutschitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1">Shruti Tople</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruhle_V/0/1/0/all/0/1">Victor R&#xfc;hle</a>, <a href="http://arxiv.org/find/cs/1/au:+Paverd_A/0/1/0/all/0/1">Andrew Paverd</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohrimenko_O/0/1/0/all/0/1">Olga Ohrimenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopf_B/0/1/0/all/0/1">Boris K&#xf6;pf</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1">Marc Brockschmidt</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.07942">
                                        <div class="article-summary-box-inner">
                                            <span><p>To continuously improve quality and reflect changes in data, machine learning
applications have to regularly retrain and update their core models. We show
that a differential analysis of language model snapshots before and after an
update can reveal a surprising amount of detailed information about changes in
the training data. We propose two new metrics---\emph{differential score} and
\emph{differential rank}---for analyzing the leakage due to updates of natural
language models. We perform leakage analysis using these metrics across models
trained on several different datasets using different methods and
configurations. We discuss the privacy implications of our findings, propose
mitigation strategies and evaluate their effect.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1">Hannah Kirk</a>, <a href="http://arxiv.org/find/cs/1/au:+Jun_Y/0/1/0/all/0/1">Yennie Jun</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1">Haider Iqbal</a>, <a href="http://arxiv.org/find/cs/1/au:+Benussi_E/0/1/0/all/0/1">Elias Benussi</a>, <a href="http://arxiv.org/find/cs/1/au:+Volpin_F/0/1/0/all/0/1">Filippo Volpin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dreyer_F/0/1/0/all/0/1">Frederic A. Dreyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Shtedritski_A/0/1/0/all/0/1">Aleksandar Shtedritski</a>, <a href="http://arxiv.org/find/cs/1/au:+Asano_Y/0/1/0/all/0/1">Yuki M. Asano</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04130">
                                        <div class="article-summary-box-inner">
                                            <span><p>The capabilities of natural language models trained on large-scale data have
increased immensely over the past few years. Open source libraries such as
HuggingFace have made these models easily available and accessible. While prior
research has identified biases in large language models, this paper considers
biases contained in the most popular versions of these models when applied
`out-of-the-box' for downstream tasks. We focus on generative language models
as they are well-suited for extracting biases inherited from training data.
Specifically, we conduct an in-depth analysis of GPT-2, which is the most
downloaded text generation model on HuggingFace, with over half a million
downloads in the past month alone. We assess biases related to occupational
associations for different protected categories by intersecting gender with
religion, sexuality, ethnicity, political affiliation, and continental name
origin. Using a template-based data collection pipeline, we collect 396K
sentence completions made by GPT-2 and find: (i) The machine-predicted jobs are
less diverse and more stereotypical for women than for men, especially for
intersections; (ii) Intersectional interactions are highly relevant for
occupational associations, which we quantify by fitting 262 logistic models;
(iii) For most occupations, GPT-2 reflects the skewed gender and ethnicity
distribution found in US Labour Bureau data, and even pulls the
societally-skewed distribution towards gender parity in cases where its
predictions deviate from real labor market observations. This raises the
normative question of what language models _should_ learn - whether they should
reflect or correct for existing inequalities.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ An Efficient Group-based Search Engine Marketing System for E-Commerce.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jie_C/0/1/0/all/0/1">Cheng Jie</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Da Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zigeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wei Shen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12700">
                                        <div class="article-summary-box-inner">
                                            <span><p>With the increasing scale of search engine marketing, designing an efficient
bidding system is becoming paramount for the success of e-commerce companies.
The critical challenges faced by a modern industrial-level bidding system
include: 1. the catalog is enormous, and the relevant bidding features are of
high sparsity; 2. the large volume of bidding requests induces significant
computation burden to both the offline and online serving. Leveraging
extraneous user-item information proves essential to mitigate the sparsity
issue, for which we exploit the natural language signals from the users' query
and the contextual knowledge from the products. In particular, we extract the
vector representations of ads via the Transformer model and leverage their
geometric relation to building collaborative bidding predictions via
clustering. The two-step procedure also significantly reduces the computation
stress of bid evaluation and optimization. In this paper, we introduce the
end-to-end structure of the bidding system for search engine marketing for
Walmart e-commerce, which successfully handles tens of millions of bids each
day. We analyze the online and offline performances of our approach and discuss
how we find it as a production-efficient solution.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Exploiting <span class="highlight_title">BERT</span> For Multimodal Target Sentiment Classification Through Input Space Translation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khan_Z/0/1/0/all/0/1">Zaid Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yun Fu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01682">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multimodal target/aspect sentiment classification combines multimodal
sentiment analysis and aspect/target sentiment classification. The goal of the
task is to combine vision and language to understand the sentiment towards a
target entity in a sentence. Twitter is an ideal setting for the task because
it is inherently multimodal, highly emotional, and affects real world events.
However, multimodal tweets are short and accompanied by complex, possibly
irrelevant images. We introduce a two-stream model that translates images in
input space using an object-aware transformer followed by a single-pass
non-autoregressive text generation approach. We then leverage the translation
to construct an auxiliary sentence that provides multimodal information to a
language model. Our approach increases the amount of text available to the
language model and distills the object-level information in complex images. We
achieve state-of-the-art performance on two multimodal Twitter datasets without
modifying the internals of the language model to accept multimodal data,
demonstrating the effectiveness of our translation. In addition, we explain a
failure mode of a popular approach for aspect sentiment analysis when applied
to tweets. Our code is available at
\textcolor{blue}{\url{https://github.com/codezakh/exploiting-BERT-thru-translation}}.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.IR updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Real-Time Visual Analysis of High-Volume Social Media Posts.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Knittel_J/0/1/0/all/0/1">Johannes Knittel</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_S/0/1/0/all/0/1">Steffen Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1">Tan Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yingcai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shixia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ertl_T/0/1/0/all/0/1">Thomas Ertl</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03052">
                                        <div class="article-summary-box-inner">
                                            <span><p>Breaking news and first-hand reports often trend on social media platforms
before traditional news outlets cover them. The real-time analysis of posts on
such platforms can reveal valuable and timely insights for journalists,
politicians, business analysts, and first responders, but the high number and
diversity of new posts pose a challenge. In this work, we present an
interactive system that enables the visual analysis of streaming social media
data on a large scale in real-time. We propose an efficient and explainable
dynamic clustering algorithm that powers a continuously updated visualization
of the current thematic landscape as well as detailed visual summaries of
specific topics of interest. Our parallel clustering strategy provides an
adaptive stream with a digestible but diverse selection of recent posts related
to relevant topics. We also integrate familiar visual metaphors that are highly
interlinked for enabling both explorative and more focused monitoring tasks.
Analysts can gradually increase the resolution to dive deeper into particular
topics. In contrast to previous work, our system also works with non-geolocated
posts and avoids extensive preprocessing such as detecting events. We evaluated
our dynamic clustering algorithm and discuss several use cases that show the
utility of our system.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Improving Bi-encoder Document Ranking Models with Two Rankers and Multi-teacher <span class="highlight_title">Distillation</span>.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jaekeol Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1">Euna Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_J/0/1/0/all/0/1">Jangwon Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhee_W/0/1/0/all/0/1">Wonjong Rhee</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06523">
                                        <div class="article-summary-box-inner">
                                            <span><p>BERT-based Neural Ranking Models (NRMs) can be classified according to how
the query and document are encoded through BERT's self-attention layers -
bi-encoder versus cross-encoder. Bi-encoder models are highly efficient because
all the documents can be pre-processed before the query time, but their
performance is inferior compared to cross-encoder models. Both models utilize a
ranker that receives BERT representations as the input and generates a
relevance score as the output. In this work, we propose a method where
multi-teacher distillation is applied to a cross-encoder NRM and a bi-encoder
NRM to produce a bi-encoder NRM with two rankers. The resulting student
bi-encoder achieves an improved performance by simultaneously learning from a
cross-encoder teacher and a bi-encoder teacher and also by combining relevance
scores from the two rankers. We call this method TRMD (Two Rankers and
Multi-teacher Distillation). In the experiments, TwinBERT and ColBERT are
considered as baseline bi-encoders. When monoBERT is used as the cross-encoder
teacher, together with either TwinBERT or ColBERT as the bi-encoder teacher,
TRMD produces a student bi-encoder that performs better than the corresponding
baseline bi-encoder. For P@20, the maximum improvement was 11.4%, and the
average improvement was 6.8%. As an additional experiment, we considered
producing cross-encoder students with TRMD, and found that it could also
improve the cross-encoders.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Variational Bandwidth Auto-encoder for Hybrid Recommender Systems.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yaochen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenzhong Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07597">
                                        <div class="article-summary-box-inner">
                                            <span><p>Hybrid recommendations have recently attracted a lot of attention where user
features are utilized as auxiliary information to address the sparsity problem
caused by insufficient user-item interactions. However, extracted user features
generally contain rich multimodal information, and most of them are irrelevant
to the recommendation purpose. Therefore, excessive reliance on these features
will make the model overfit on noise and difficult to generalize. In this
article, we propose a variational bandwidth auto-encoder (VBAE) for
recommendations, aiming to address the sparsity and noise problems
simultaneously. VBAE first encodes user collaborative and feature information
into Gaussian latent variables via deep neural networks to capture non-linear
user similarities. Moreover, by considering the fusion of collaborative and
feature variables as a virtual communication channel from an
information-theoretic perspective, we introduce a user-dependent channel to
dynamically control the information allowed to be accessed from the feature
embeddings. A quantum-inspired uncertainty measurement of the hidden rating
embeddings is proposed accordingly to infer the channel bandwidth by
disentangling the uncertainty information in the ratings from the semantic
information. Through this mechanism, VBAE incorporates adequate auxiliary
information from user features if collaborative information is insufficient,
while avoiding excessive reliance on noisy user features to improve its
generalization ability to new users. Extensive experiments conducted on three
real-world datasets demonstrate the effectiveness of the proposed method. Codes
and datasets are released at https://github.com/yaochenzhu/vbae.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Zipf Matrix Factorization : Matrix Factorization with Matthew Effect Reduction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07347">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recommender system recommends interesting items to users based on users' past
information history. Researchers have been paying attention to improvement of
algorithmic performance such as MAE and precision@K. Major techniques such as
matrix factorization and learning to rank are optimized based on such
evaluation metrics. However, the intrinsic Matthew Effect problem poses great
threat to the fairness of the recommender system, and the unfairness problem
cannot be resolved by optimization of traditional metrics. In this paper, we
propose a novel algorithm that incorporates Matthew Effect reduction with the
matrix factorization framework. We demonstrate that our approach can boost the
fairness of the algorithm and enhances performance evaluated by traditional
metrics.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.MM updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Few-shot Unsupervised Domain Adaptation with Image-to-class Sparse Similarity Encoding.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shengqi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wanqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luping Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02953">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper investigates a valuable setting called few-shot unsupervised
domain adaptation (FS-UDA), which has not been sufficiently studied in the
literature. In this setting, the source domain data are labelled, but with
few-shot per category, while the target domain data are unlabelled. To address
the FS-UDA setting, we develop a general UDA model to solve the following two
key issues: the few-shot labeled data per category and the domain adaptation
between support and query sets. Our model is general in that once trained it
will be able to be applied to various FS-UDA tasks from the same source and
target domains. Inspired by the recent local descriptor based few-shot learning
(FSL), our general UDA model is fully built upon local descriptors (LDs) for
image classification and domain adaptation. By proposing a novel concept called
similarity patterns (SPs), our model not only effectively considers the spatial
relationship of LDs that was ignored in previous FSL methods, but also makes
the learned image similarity better serve the required domain alignment.
Specifically, we propose a novel IMage-to-class sparse Similarity Encoding
(IMSE) method. It learns SPs to extract the local discriminative information
for classification and meanwhile aligns the covariance matrix of the SPs for
domain adaptation. Also, domain adversarial training and multi-scale local
feature matching are performed upon LDs. Extensive experiments conducted on a
multi-domain benchmark dataset DomainNet demonstrates the state-of-the-art
performance of our IMSE for the novel setting of FS-UDA. In addition, for FSL,
our IMSE can also show better performance than most of recent FSL methods on
miniImageNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.CV updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ <span class="highlight_title">Self-Supervised</span> Learning from Unlabeled Fundus Photographs Improves Segmentation of the Retina.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kukacka_J/0/1/0/all/0/1">Jan Kuka&#x10d;ka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenz_A/0/1/0/all/0/1">Anja Zenz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kollovieh_M/0/1/0/all/0/1">Marcel Kollovieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Justel_D/0/1/0/all/0/1">Dominik J&#xfc;stel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntziachristos_V/0/1/0/all/0/1">Vasilis Ntziachristos</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02798">
                                        <div class="article-summary-box-inner">
                                            <span><p>Fundus photography is the primary method for retinal imaging and essential
for diabetic retinopathy prevention. Automated segmentation of fundus
photographs would improve the quality, capacity, and cost-effectiveness of eye
care screening programs. However, current segmentation methods are not robust
towards the diversity in imaging conditions and pathologies typical for
real-world clinical applications. To overcome these limitations, we utilized
contrastive self-supervised learning to exploit the large variety of unlabeled
fundus images in the publicly available EyePACS dataset. We pre-trained an
encoder of a U-Net, which we later fine-tuned on several retinal vessel and
lesion segmentation datasets. We demonstrate for the first time that by using
contrastive self-supervised learning, the pre-trained network can recognize
blood vessels, optic disc, fovea, and various lesions without being provided
any labels. Furthermore, when fine-tuned on a downstream blood vessel
segmentation task, such pre-trained networks achieve state-of-the-art
performance on images from different datasets. Additionally, the pre-training
also leads to shorter training times and an improved few-shot performance on
both blood vessel and lesion segmentation tasks. Altogether, our results
showcase the benefits of contrastive self-supervised pre-training which can
play a crucial role in real-world clinical applications requiring robust models
able to adapt to new devices with only a few annotated samples.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A volumetric change detection framework using UAV oblique photogrammetry - A case study of ultra-high-resolution monitoring of progressive building collapse.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1">Ningli Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Debao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shuang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1">Xiao Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Strasbaugh_C/0/1/0/all/0/1">Chris Strasbaugh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yilmaz_A/0/1/0/all/0/1">Alper Yilmaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sezen_H/0/1/0/all/0/1">Halil Sezen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02800">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we present a case study that performs an unmanned aerial
vehicle (UAV) based fine-scale 3D change detection and monitoring of
progressive collapse performance of a building during a demolition event.
Multi-temporal oblique photogrammetry images are collected with 3D point clouds
generated at different stages of the demolition. The geometric accuracy of the
generated point clouds has been evaluated against both airborne and terrestrial
LiDAR point clouds, achieving an average distance of 12 cm and 16 cm for roof
and facade respectively. We propose a hierarchical volumetric change detection
framework that unifies multi-temporal UAV images for pose estimation (free of
ground control points), reconstruction, and a coarse-to-fine 3D density change
analysis. This work has provided a solution capable of addressing change
detection on full 3D time-series datasets where dramatic scene content changes
are presented progressively. Our change detection results on the building
demolition event have been evaluated against the manually marked ground-truth
changes and have achieved an F-1 score varying from 0.78 to 0.92, with
consistently high precision (0.92 - 0.99). Volumetric changes through the
demolition progress are derived from change detection and have shown to
favorably reflect the qualitative and quantitative building demolition
progression.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Neural Twins Talk & Alternative Calculations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zohourianshahzadi_Z/0/1/0/all/0/1">Zanyar Zohourianshahzadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1">Jugal K. Kalita</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02807">
                                        <div class="article-summary-box-inner">
                                            <span><p>Inspired by how the human brain employs a higher number of neural pathways
when describing a highly focused subject, we show that deep attentive models
used for the main vision-language task of image captioning, could be extended
to achieve better performance. Image captioning bridges a gap between computer
vision and natural language processing. Automated image captioning is used as a
tool to eliminate the need for human agent for creating descriptive captions
for unseen images.Automated image captioning is challenging and yet
interesting. One reason is that AI based systems capable of generating
sentences that describe an input image could be used in a wide variety of tasks
beyond generating captions for unseen images found on web or uploaded to social
media. For example, in biology and medical sciences, these systems could
provide researchers and physicians with a brief linguistic description of
relevant images, potentially expediting their work.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Evaluating CLIP: Towards Characterization of Broader Capabilities and Downstream Implications.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sandhini Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Krueger_G/0/1/0/all/0/1">Gretchen Krueger</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1">Jack Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Radford_A/0/1/0/all/0/1">Alec Radford</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jong Wook Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Brundage_M/0/1/0/all/0/1">Miles Brundage</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02818">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, there have been breakthroughs in computer vision ("CV") models that
are more generalizable with the advent of models such as CLIP and ALIGN. In
this paper, we analyze CLIP and highlight some of the challenges such models
pose. CLIP reduces the need for task specific training data, potentially
opening up many niche tasks to automation. CLIP also allows its users to
flexibly specify image classification classes in natural language, which we
find can shift how biases manifest. Additionally, through some preliminary
probes we find that CLIP can inherit biases found in prior computer vision
systems. Given the wide and unpredictable domain of uses for such models, this
raises questions regarding what sufficiently safe behaviour for such systems
may look like. These results add evidence to the growing body of work calling
for a change in the notion of a 'better' model--to move beyond simply looking
at higher accuracy at task-oriented capability evaluations, and towards a
broader 'better' that takes into account deployment-critical features such as
different use contexts, and people who interact with the model when thinking
about model deployment.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Ada-VSR: Adaptive Video Super-Resolution with Meta-Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Gupta_A/0/1/0/all/0/1">Akash Gupta</a>, <a href="http://arxiv.org/find/eess/1/au:+Jonnalagedda_P/0/1/0/all/0/1">Padmaja Jonnalagedda</a>, <a href="http://arxiv.org/find/eess/1/au:+Bhanu_B/0/1/0/all/0/1">Bir Bhanu</a>, <a href="http://arxiv.org/find/eess/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1">Amit K. Roy-Chowdhury</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02832">
                                        <div class="article-summary-box-inner">
                                            <span><p>Most of the existing works in supervised spatio-temporal video
super-resolution (STVSR) heavily rely on a large-scale external dataset
consisting of paired low-resolution low-frame rate (LR-LFR)and high-resolution
high-frame-rate (HR-HFR) videos. Despite their remarkable performance, these
methods make a prior assumption that the low-resolution video is obtained by
down-scaling the high-resolution video using a known degradation kernel, which
does not hold in practical settings. Another problem with these methods is that
they cannot exploit instance-specific internal information of video at testing
time. Recently, deep internal learning approaches have gained attention due to
their ability to utilize the instance-specific statistics of a video. However,
these methods have a large inference time as they require thousands of gradient
updates to learn the intrinsic structure of the data. In this work, we
presentAdaptiveVideoSuper-Resolution (Ada-VSR) which leverages external, as
well as internal, information through meta-transfer learning and internal
learning, respectively. Specifically, meta-learning is employed to obtain
adaptive parameters, using a large-scale external dataset, that can adapt
quickly to the novel condition (degradation model) of the given test video
during the internal learning task, thereby exploiting external and internal
information of a video for super-resolution. The model trained using our
approach can quickly adapt to a specific video condition with only a few
gradient updates, which reduces the inference time significantly. Extensive
experiments on standard datasets demonstrate that our method performs favorably
against various state-of-the-art approaches.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Elaborative Rehearsal for Zero-shot Action Recognition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shizhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02833">
                                        <div class="article-summary-box-inner">
                                            <span><p>The growing number of action classes has posed a new challenge for video
understanding, making Zero-Shot Action Recognition (ZSAR) a thriving direction.
The ZSAR task aims to recognize target (unseen) actions without training
examples by leveraging semantic representations to bridge seen and unseen
actions. However, due to the complexity and diversity of actions, it remains
challenging to semantically represent action classes and transfer knowledge
from seen data. In this work, we propose an ER-enhanced ZSAR model inspired by
an effective human memory technique Elaborative Rehearsal (ER), which involves
elaborating a new concept and relating it to known concepts. Specifically, we
expand each action class as an Elaborative Description (ED) sentence, which is
more discriminative than a class name and less costly than manual-defined
attributes. Besides directly aligning class semantics with videos, we
incorporate objects from the video as Elaborative Concepts (EC) to improve
video semantics and generalization from seen actions to unseen actions. Our
ER-enhanced ZSAR model achieves state-of-the-art results on three existing
benchmarks. Moreover, we propose a new ZSAR evaluation protocol on the Kinetics
dataset to overcome limitations of current benchmarks and demonstrate the first
case where ZSAR performance is comparable to few-shot learning baselines on
this more realistic setting. We will release our codes and collected EDs at
https://github.com/DeLightCMU/ElaborativeRehearsal.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Attention-based fusion of semantic boundary and non-boundary information to improve semantic segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fontinele_J/0/1/0/all/0/1">Jefferson Fontinele</a>, <a href="http://arxiv.org/find/cs/1/au:+Lefundes_G/0/1/0/all/0/1">Gabriel Lefundes</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_L/0/1/0/all/0/1">Luciano Oliveira</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02840">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper introduces a method for image semantic segmentation grounded on a
novel fusion scheme, which takes place inside a deep convolutional neural
network. The main goal of our proposal is to explore object boundary
information to improve the overall segmentation performance. Unlike previous
works that combine boundary and segmentation features, or those that use
boundary information to regularize semantic segmentation, we instead propose a
novel approach that embodies boundary information onto segmentation. For that,
our semantic segmentation method uses two streams, which are combined through
an attention gate, forming an end-to-end Y-model. To the best of our knowledge,
ours is the first work to show that boundary detection can improve semantic
segmentation when fused through a semantic fusion gate (attention model). We
performed an extensive evaluation of our method over public data sets. We found
competitive results on all data sets after comparing our proposed model with
other twelve state-of-the-art segmenters, considering the same training
conditions. Our proposed model achieved the best mIoU on the CityScapes,
CamVid, and Pascal Context data sets, and the second best on Mapillary Vistas.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Communicative Learning with Natural Gestures for Embodied Navigation Agents with Human-in-the-Scene.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cheng-Ju Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yixin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Joo_J/0/1/0/all/0/1">Jungseock Joo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02846">
                                        <div class="article-summary-box-inner">
                                            <span><p>Human-robot collaboration is an essential research topic in artificial
intelligence (AI), enabling researchers to devise cognitive AI systems and
affords an intuitive means for users to interact with the robot. Of note,
communication plays a central role. To date, prior studies in embodied agent
navigation have only demonstrated that human languages facilitate communication
by instructions in natural languages. Nevertheless, a plethora of other forms
of communication is left unexplored. In fact, human communication originated in
gestures and oftentimes is delivered through multimodal cues, e.g. "go there"
with a pointing gesture. To bridge the gap and fill in the missing dimension of
communication in embodied agent navigation, we propose investigating the
effects of using gestures as the communicative interface instead of verbal
cues. Specifically, we develop a VR-based 3D simulation environment, named
Ges-THOR, based on AI2-THOR platform. In this virtual environment, a human
player is placed in the same virtual scene and shepherds the artificial agent
using only gestures. The agent is tasked to solve the navigation problem guided
by natural gestures with unknown semantics; we do not use any predefined
gestures due to the diversity and versatile nature of human gestures. We argue
that learning the semantics of natural gestures is mutually beneficial to
learning the navigation task--learn to communicate and communicate to learn. In
a series of experiments, we demonstrate that human gesture cues, even without
predefined semantics, improve the object-goal navigation for an embodied agent,
outperforming various state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ 3DRIMR: 3D Reconstruction and Imaging via mmWave Radar based on Deep Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yue Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhuoming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Honggang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Deqiang Xu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02858">
                                        <div class="article-summary-box-inner">
                                            <span><p>mmWave radar has been shown as an effective sensing technique in low
visibility, smoke, dusty, and dense fog environment. However tapping the
potential of radar sensing to reconstruct 3D object shapes remains a great
challenge, due to the characteristics of radar data such as sparsity, low
resolution, specularity, high noise, and multi-path induced shadow reflections
and artifacts. In this paper we propose 3D Reconstruction and Imaging via
mmWave Radar (3DRIMR), a deep learning based architecture that reconstructs 3D
shape of an object in dense detailed point cloud format, based on sparse raw
mmWave radar intensity data. The architecture consists of two back-to-back
conditional GAN deep neural networks: the first generator network generates 2D
depth images based on raw radar intensity data, and the second generator
network outputs 3D point clouds based on the results of the first generator.
The architecture exploits both convolutional neural network's convolutional
operation (that extracts local structure neighborhood information) and the
efficiency and detailed geometry capture capability of point clouds (other than
costly voxelization of 3D space or distance fields). Our experiments have
demonstrated 3DRIMR's effectiveness in reconstructing 3D objects, and its
performance improvement over standard techniques.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Data Augmented Approach to Transfer Learning for Covid-19 Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Henna_S/0/1/0/all/0/1">Shagufta Henna</a>, <a href="http://arxiv.org/find/cs/1/au:+Reji_A/0/1/0/all/0/1">Aparna Reji</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02870">
                                        <div class="article-summary-box-inner">
                                            <span><p>Covid-19 detection at an early stage can aid in an effective treatment and
isolation plan to prevent its spread. Recently, transfer learning has been used
for Covid-19 detection using X-ray, ultrasound, and CT scans. One of the major
limitations inherent to these proposed methods is limited labeled dataset size
that affects the reliability of Covid-19 diagnosis and disease progression. In
this work, we demonstrate that how we can augment limited X-ray images data by
using Contrast limited adaptive histogram equalization (CLAHE) to train the
last layer of the pre-trained deep learning models to mitigate the bias of
transfer learning for Covid-19 detection. We transfer learned various
pre-trained deep learning models including AlexNet, ZFNet, VGG-16, ResNet-18,
and GoogLeNet, and fine-tune the last layer by using CLAHE-augmented dataset.
The experiment results reveal that the CLAHE-based augmentation to various
pre-trained deep learning models significantly improves the model efficiency.
The pre-trained VCG-16 model with CLAHEbased augmented images achieves a
sensitivity of 95% using 15 epochs. AlexNet works show good sensitivity when
trained on non-augmented data. Other models demonstrate a value of less than
60% when trained on non-augmented data. Our results reveal that the sample bias
can negatively impact the performance of transfer learning which is
significantly improved by using CLAHE-based augmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Disentangled Lifespan Face Synthesis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Sen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wentong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Michael Ying Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tao Xiang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02874">
                                        <div class="article-summary-box-inner">
                                            <span><p>A lifespan face synthesis (LFS) model aims to generate a set of
photo-realistic face images of a person's whole life, given only one snapshot
as reference. The generated face image given a target age code is expected to
be age-sensitive reflected by bio-plausible transformations of shape and
texture, while being identity preserving. This is extremely challenging because
the shape and texture characteristics of a face undergo separate and highly
nonlinear transformations w.r.t. age. Most recent LFS models are based on
generative adversarial networks (GANs) whereby age code conditional
transformations are applied to a latent face representation. They benefit
greatly from the recent advancements of GANs. However, without explicitly
disentangling their latent representations into the texture, shape and identity
factors, they are fundamentally limited in modeling the nonlinear age-related
transformation on texture and shape whilst preserving identity. In this work, a
novel LFS model is proposed to disentangle the key face characteristics
including shape, texture and identity so that the unique shape and texture age
transformations can be modeled effectively. This is achieved by extracting
shape, texture and identity features separately from an encoder. Critically,
two transformation modules, one conditional convolution based and the other
channel attention based, are designed for modeling the nonlinear shape and
texture feature transformations respectively. This is to accommodate their
rather distinct aging processes and ensure that our synthesized images are both
age-sensitive and identity preserving. Extensive experiments show that our LFS
model is clearly superior to the state-of-the-art alternatives. Codes and demo
are available on our project website:
\url{https://senhe.github.io/projects/iccv_2021_lifespan_face}.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Out-of-domain Generalization from a Single Source: A Uncertainty Quantification Approach.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_F/0/1/0/all/0/1">Fengchun Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Long Zhao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02888">
                                        <div class="article-summary-box-inner">
                                            <span><p>We study a worst-case scenario in generalization: Out-of-domain
generalization from a single source. The goal is to learn a robust model from a
single source and expect it to generalize over many unknown distributions. This
challenging problem has been seldom investigated while existing solutions
suffer from various limitations such as the ignorance of uncertainty assessment
and label augmentation. In this paper, we propose uncertainty-guided domain
generalization to tackle the aforementioned limitations. The key idea is to
augment the source capacity in both feature and label spaces, while the
augmentation is guided by uncertainty assessment. To the best of our knowledge,
this is the first work to (1) quantify the generalization uncertainty from a
single source and (2) leverage it to guide both feature and label augmentation
for robust generalization. The model training and deployment are effectively
organized in a Bayesian meta-learning framework. We conduct extensive
comparisons and ablation study to validate our approach. The results prove our
superior performance in a wide scope of tasks including image classification,
semantic segmentation, text classification, and speech recognition.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Basis Scaling and Double Pruning for Efficient Transfer Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1">Ken C. L. Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashyap_S/0/1/0/all/0/1">Satyananda Kashyap</a>, <a href="http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1">Mehdi Moradi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02893">
                                        <div class="article-summary-box-inner">
                                            <span><p>Transfer learning allows the reuse of deep learning features on new datasets
with limited data. However, the resulting models could be unnecessarily large
and thus inefficient. Although network pruning can be applied to improve
inference efficiency, existing algorithms usually require fine-tuning and may
not be suitable for small datasets. In this paper, we propose an algorithm that
transforms the convolutional weights into the subspaces of orthonormal bases
where a model is pruned. Using singular value decomposition, we decompose a
convolutional layer into two layers: a convolutional layer with the orthonormal
basis vectors as the filters, and a layer that we name "BasisScalingConv",
which is responsible for rescaling the features and transforming them back to
the original space. As the filters in each transformed layer are linearly
independent with known relative importance, pruning can be more effective and
stable, and fine tuning individual weights is unnecessary. Furthermore, as the
numbers of input and output channels of the original convolutional layer remain
unchanged, basis pruning is applicable to virtually all network architectures.
Basis pruning can also be combined with existing pruning algorithms for double
pruning to further increase the pruning capability. With less than 1% reduction
in the classification accuracy, we can achieve pruning ratios up to 98.9% in
parameters and 98.6% in FLOPs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ StrucTexT: Structured Text Understanding with <span class="highlight_title">Multi-Modal</span> <span class="highlight_title">Transformer</span>s.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yulin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yuxi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yuchen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1">Xiameng Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chengquan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_K/0/1/0/all/0/1">Kun Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Junyu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingtuo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02923">
                                        <div class="article-summary-box-inner">
                                            <span><p>Structured text understanding on Visually Rich Documents (VRDs) is a crucial
part of Document Intelligence. Due to the complexity of content and layout in
VRDs, structured text understanding has been a challenging task. Most existing
studies decoupled this problem into two sub-tasks: entity labeling and entity
linking, which require an entire understanding of the context of documents at
both token and segment levels. However, little work has been concerned with the
solutions that efficiently extract the structured data from different levels.
This paper proposes a unified framework named StrucTexT, which is flexible and
effective for handling both sub-tasks. Specifically, based on the transformer,
we introduce a segment-token aligned encoder to deal with the entity labeling
and entity linking tasks at different levels of granularity. Moreover, we
design a novel pre-training strategy with three self-supervised tasks to learn
a richer representation. StrucTexT uses the existing Masked Visual Language
Modeling task and the new Sentence Length Prediction and Paired Boxes Direction
tasks to incorporate the multi-modal information across text, image, and
layout. We evaluate our method for structured text understanding at
segment-level and token-level and show it outperforms the state-of-the-art
counterparts with significantly superior performance on the FUNSD, SROIE, and
EPHOIE datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Interpretable Visual Understanding with Cognitive Attention Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xuejiao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_K/0/1/0/all/0/1">Kea Turner</a>, <a href="http://arxiv.org/find/cs/1/au:+Derr_T/0/1/0/all/0/1">Tyler Derr</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1">Eirini Ntoutsi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02924">
                                        <div class="article-summary-box-inner">
                                            <span><p>While image understanding on recognition-level has achieved remarkable
advancements, reliable visual scene understanding requires comprehensive image
understanding on recognition-level but also cognition-level, which calls for
exploiting the multi-source information as well as learning different levels of
understanding and extensive commonsense knowledge. In this paper, we propose a
novel Cognitive Attention Network (CAN) for visual commonsense reasoning to
achieve interpretable visual understanding. Specifically, we first introduce an
image-text fusion module to fuse information from images and text collectively.
Second, a novel inference module is designed to encode commonsense among image,
query and response. Extensive experiments on large-scale Visual Commonsense
Reasoning (VCR) benchmark dataset demonstrate the effectiveness of our
approach. The implementation is publicly available at
https://github.com/tanjatang/CAN
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Min Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1">Miao Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Baorong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">Xuetong Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jizhou Huang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02927">
                                        <div class="article-summary-box-inner">
                                            <span><p>Image Retrieval is a fundamental task of obtaining images similar to the
query one from a database. A common image retrieval practice is to firstly
retrieve candidate images via similarity search using global image features and
then re-rank the candidates by leveraging their local features. Previous
learning-based studies mainly focus on either global or local image
representation learning to tackle the retrieval task. In this paper, we abandon
the two-stage paradigm and seek to design an effective single-stage solution by
integrating local and global information inside images into compact image
representations. Specifically, we propose a Deep Orthogonal Local and Global
(DOLG) information fusion framework for end-to-end image retrieval. It
attentively extracts representative local information with multi-atrous
convolutions and self-attention at first. Components orthogonal to the global
image representation are then extracted from the local information. At last,
the orthogonal components are concatenated with the global representation as a
complementary, and then aggregation is performed to generate the final
representation. The whole framework is end-to-end differentiable and can be
trained with image-level labels. Extensive experimental results validate the
effectiveness of our solution and show that our model achieves state-of-the-art
image retrieval performances on Revisited Oxford and Paris datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ VinaFood21: A Novel Dataset for Evaluating Vietnamese Food Recognition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thuan Trong Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thuan Q. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_D/0/1/0/all/0/1">Dung Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Vi Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_N/0/1/0/all/0/1">Ngoc Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_N/0/1/0/all/0/1">Nguyen D. Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kiet Van Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Khang Nguyen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02929">
                                        <div class="article-summary-box-inner">
                                            <span><p>Vietnam is such an attractive tourist destination with its stunning and
pristine landscapes and its top-rated unique food and drink. Among thousands of
Vietnamese dishes, foreigners and native people are interested in easy-to-eat
tastes and easy-to-do recipes, along with reasonable prices, mouthwatering
flavors, and popularity. Due to the diversity and almost all the dishes have
significant similarities and the lack of quality Vietnamese food datasets, it
is hard to implement an auto system to classify Vietnamese food, therefore,
make people easier to discover Vietnamese food. This paper introduces a new
Vietnamese food dataset named VinaFood21, which consists of 13,950 images
corresponding to 21 dishes. We use 10,044 images for model training and 6,682
test images to classify each food in the VinaFood21 dataset and achieved an
average accuracy of 74.81% when fine-tuning CNN EfficientNet-B0.
(https://github.com/nguyenvd-uit/uit-together-dataset)
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Detailed Avatar Recovery from Single Image.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xinxin Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haotian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xun Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruigang Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02931">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper presents a novel framework to recover \emph{detailed} avatar from
a single image. It is a challenging task due to factors such as variations in
human shapes, body poses, texture, and viewpoints. Prior methods typically
attempt to recover the human body shape using a parametric-based template that
lacks the surface details. As such resulting body shape appears to be without
clothing. In this paper, we propose a novel learning-based framework that
combines the robustness of the parametric model with the flexibility of
free-form 3D deformation. We use the deep neural networks to refine the 3D
shape in a Hierarchical Mesh Deformation (HMD) framework, utilizing the
constraints from body joints, silhouettes, and per-pixel shading information.
Our method can restore detailed human body shapes with complete textures beyond
skinned models. Experiments demonstrate that our method has outperformed
previous state-of-the-art approaches, achieving better accuracy in terms of
both 2D IoU number and 3D metric distance.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ From Synthetic to Real: Image Dehazing Collaborating with Unlabeled Real Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Ye Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_S/0/1/0/all/0/1">Shunda Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jing Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_L/0/1/0/all/0/1">Liang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Wei Feng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02934">
                                        <div class="article-summary-box-inner">
                                            <span><p>Single image dehazing is a challenging task, for which the domain shift
between synthetic training data and real-world testing images usually leads to
degradation of existing methods. To address this issue, we propose a novel
image dehazing framework collaborating with unlabeled real data. First, we
develop a disentangled image dehazing network (DID-Net), which disentangles the
feature representations into three component maps, i.e. the latent haze-free
image, the transmission map, and the global atmospheric light estimate,
respecting the physical model of a haze process. Our DID-Net predicts the three
component maps by progressively integrating features across scales, and refines
each map by passing an independent refinement network. Then a
disentangled-consistency mean-teacher network (DMT-Net) is employed to
collaborate unlabeled real data for boosting single image dehazing.
Specifically, we encourage the coarse predictions and refinements of each
disentangled component to be consistent between the student and teacher
networks by using a consistency loss on unlabeled real data. We make comparison
with 13 state-of-the-art dehazing methods on a new collected dataset (Haze4K)
and two widely-used dehazing datasets (i.e., SOTS and HazeRD), as well as on
real-world hazy images. Experimental results demonstrate that our method has
obvious quantitative and qualitative improvements over the existing methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ High-frequency shape recovery from shading by CNN and domain adaptation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tokieda_K/0/1/0/all/0/1">Kodai Tokieda</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwaguchi_T/0/1/0/all/0/1">Takafumi Iwaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawasaki_H/0/1/0/all/0/1">Hiroshi Kawasaki</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02937">
                                        <div class="article-summary-box-inner">
                                            <span><p>Importance of structured-light based one-shot scanning technique is
increasing because of its simple system configuration and ability of capturing
moving objects. One severe limitation of the technique is that it can capture
only sparse shape, but not high frequency shapes, because certain area of
projection pattern is required to encode spatial information. In this paper, we
propose a technique to recover high-frequency shapes by using shading
information, which is captured by one-shot RGB-D sensor based on structured
light with single camera. Since color image comprises shading information of
object surface, high-frequency shapes can be recovered by shape from shading
techniques. Although multiple images with different lighting positions are
required for shape from shading techniques, we propose a learning based
approach to recover shape from a single image. In addition, to overcome the
problem of preparing sufficient amount of data for training, we propose a new
data augmentation method for high-frequency shapes using synthetic data and
domain adaptation. Experimental results are shown to confirm the effectiveness
of the proposed method.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jooyoung Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungwon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1">Yonghyun Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gwon_Y/0/1/0/all/0/1">Youngjune Gwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02938">
                                        <div class="article-summary-box-inner">
                                            <span><p>Denoising diffusion probabilistic models (DDPM) have shown remarkable
performance in unconditional image generation. However, due to the
stochasticity of the generative process in DDPM, it is challenging to generate
images with the desired semantics. In this work, we propose Iterative Latent
Variable Refinement (ILVR), a method to guide the generative process in DDPM to
generate high-quality images based on a given reference image. Here, the
refinement of the generative process in DDPM enables a single DDPM to sample
images from various sets directed by the reference image. The proposed ILVR
method generates high-quality images while controlling the generation. The
controllability of our method allows adaptation of a single DDPM without any
additional learning in various image generation tasks, such as generation from
various downsampling factors, multi-domain image translation, paint-to-image,
and editing with scribbles.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Evaluating Adversarial Attacks on Driving Safety in Vision-Based Autonomous Vehicles.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jindi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Kejie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaohua Jia</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02940">
                                        <div class="article-summary-box-inner">
                                            <span><p>In recent years, many deep learning models have been adopted in autonomous
driving. At the same time, these models introduce new vulnerabilities that may
compromise the safety of autonomous vehicles. Specifically, recent studies have
demonstrated that adversarial attacks can cause a significant decline in
detection precision of deep learning-based 3D object detection models. Although
driving safety is the ultimate concern for autonomous driving, there is no
comprehensive study on the linkage between the performance of deep learning
models and the driving safety of autonomous vehicles under adversarial attacks.
In this paper, we investigate the impact of two primary types of adversarial
attacks, perturbation attacks and patch attacks, on the driving safety of
vision-based autonomous vehicles rather than the detection precision of deep
learning models. In particular, we consider two state-of-the-art models in
vision-based 3D object detection, Stereo R-CNN and DSGN. To evaluate driving
safety, we propose an end-to-end evaluation framework with a set of driving
safety performance metrics. By analyzing the results of our extensive
evaluation experiments, we find that (1) the attack's impact on the driving
safety of autonomous vehicles and the attack's impact on the precision of 3D
object detectors are decoupled, and (2) the DSGN model demonstrates stronger
robustness to adversarial attacks than the Stereo R-CNN model. In addition, we
further investigate the causes behind the two findings with an ablation study.
The findings of this paper provide a new perspective to evaluate adversarial
attacks and guide the selection of deep learning models in autonomous driving.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Vision-Based Food Analysis for Automatic Dietary Assessment.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_W/0/1/0/all/0/1">Weiqing Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haisheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shuqiang Jiang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02947">
                                        <div class="article-summary-box-inner">
                                            <span><p>Background: Maintaining a healthy diet is vital to avoid health-related
issues, e.g., undernutrition, obesity and many non-communicable diseases. An
indispensable part of the health diet is dietary assessment. Traditional manual
recording methods are burdensome and contain substantial biases and errors.
Recent advances in Artificial Intelligence, especially computer vision
technologies, have made it possible to develop automatic dietary assessment
solutions, which are more convenient, less time-consuming and even more
accurate to monitor daily food intake.
</p>
<p>Scope and approach: This review presents one unified Vision-Based Dietary
Assessment (VBDA) framework, which generally consists of three stages: food
image analysis, volume estimation and nutrient derivation. Vision-based food
analysis methods, including food recognition, detection and segmentation, are
systematically summarized, and methods of volume estimation and nutrient
derivation are also given. The prosperity of deep learning makes VBDA gradually
move to an end-to-end implementation, which applies food images to a single
network to directly estimate the nutrition. The recently proposed end-to-end
methods are also discussed. We further analyze existing dietary assessment
datasets, indicating that one large-scale benchmark is urgently needed, and
finally highlight key challenges and future trends for VBDA.
</p>
<p>Key findings and conclusions: After thorough exploration, we find that
multi-task end-to-end deep learning approaches are one important trend of VBDA.
Despite considerable research progress, many challenges remain for VBDA due to
the meal complexity. We also provide the latest ideas for future development of
VBDA, e.g., fine-grained food analysis and accurate volume estimation. This
survey aims to encourage researchers to propose more practical solutions for
VBDA.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Deep Learning-based Biological Anatomical Landmark Detection in Colonoscopy Videos.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Che_K/0/1/0/all/0/1">Kaiwei Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1">Chengwei Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yibing Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_N/0/1/0/all/0/1">Nachuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiankun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_M/0/1/0/all/0/1">Max Q.-H. Meng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02948">
                                        <div class="article-summary-box-inner">
                                            <span><p>Colonoscopy is a standard imaging tool for visualizing the entire
gastrointestinal (GI) tract of patients to capture lesion areas. However, it
takes the clinicians excessive time to review a large number of images
extracted from colonoscopy videos. Thus, automatic detection of biological
anatomical landmarks within the colon is highly demanded, which can help reduce
the burden of clinicians by providing guidance information for the locations of
lesion areas. In this article, we propose a novel deep learning-based approach
to detect biological anatomical landmarks in colonoscopy videos. First, raw
colonoscopy video sequences are pre-processed to reject interference frames.
Second, a ResNet-101 based network is used to detect three biological
anatomical landmarks separately to obtain the intermediate detection results.
Third, to achieve more reliable localization of the landmark periods within the
whole video period, we propose to post-process the intermediate detection
results by identifying the incorrectly predicted frames based on their temporal
distribution and reassigning them back to the correct class. Finally, the
average detection accuracy reaches 99.75\%. Meanwhile, the average IoU of 0.91
shows a high degree of similarity between our predicted landmark periods and
ground truth. The experimental results demonstrate that our proposed model is
capable of accurately detecting and localizing biological anatomical landmarks
from colonoscopy videos.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Few-shot Unsupervised Domain Adaptation with Image-to-class Sparse Similarity Encoding.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shengqi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wanqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luping Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02953">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper investigates a valuable setting called few-shot unsupervised
domain adaptation (FS-UDA), which has not been sufficiently studied in the
literature. In this setting, the source domain data are labelled, but with
few-shot per category, while the target domain data are unlabelled. To address
the FS-UDA setting, we develop a general UDA model to solve the following two
key issues: the few-shot labeled data per category and the domain adaptation
between support and query sets. Our model is general in that once trained it
will be able to be applied to various FS-UDA tasks from the same source and
target domains. Inspired by the recent local descriptor based few-shot learning
(FSL), our general UDA model is fully built upon local descriptors (LDs) for
image classification and domain adaptation. By proposing a novel concept called
similarity patterns (SPs), our model not only effectively considers the spatial
relationship of LDs that was ignored in previous FSL methods, but also makes
the learned image similarity better serve the required domain alignment.
Specifically, we propose a novel IMage-to-class sparse Similarity Encoding
(IMSE) method. It learns SPs to extract the local discriminative information
for classification and meanwhile aligns the covariance matrix of the SPs for
domain adaptation. Also, domain adversarial training and multi-scale local
feature matching are performed upon LDs. Extensive experiments conducted on a
multi-domain benchmark dataset DomainNet demonstrates the state-of-the-art
performance of our IMSE for the novel setting of FS-UDA. In addition, for FSL,
our IMSE can also show better performance than most of recent FSL methods on
miniImageNet.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Smooth Mesh Estimation from Depth Data using Non-Smooth Convex Optimization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Rosinol_A/0/1/0/all/0/1">Antoni Rosinol</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlone_L/0/1/0/all/0/1">Luca Carlone</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02957">
                                        <div class="article-summary-box-inner">
                                            <span><p>Meshes are commonly used as 3D maps since they encode the topology of the
scene while being lightweight.
</p>
<p>Unfortunately, 3D meshes are mathematically difficult to handle directly
because of their combinatorial and discrete nature.
</p>
<p>Therefore, most approaches generate 3D meshes of a scene after fusing depth
data using volumetric or other representations.
</p>
<p>Nevertheless, volumetric fusion remains computationally expensive both in
terms of speed and memory.
</p>
<p>In this paper, we leapfrog these intermediate representations and build a 3D
mesh directly from a depth map and the sparse landmarks triangulated with
visual odometry.
</p>
<p>To this end, we formulate a non-smooth convex optimization problem that we
solve using a primal-dual method.
</p>
<p>Our approach generates a smooth and accurate 3D mesh that substantially
improves the state-of-the-art on direct mesh reconstruction while running in
real-time.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Learning Meta-class Memory for Few-Shot Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhonghua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiangxi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+lin_G/0/1/0/all/0/1">Guosheng lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02958">
                                        <div class="article-summary-box-inner">
                                            <span><p>Currently, the state-of-the-art methods treat few-shot semantic segmentation
task as a conditional foreground-background segmentation problem, assuming each
class is independent. In this paper, we introduce the concept of meta-class,
which is the meta information (e.g. certain middle-level features) shareable
among all classes. To explicitly learn meta-class representations in few-shot
segmentation task, we propose a novel Meta-class Memory based few-shot
segmentation method (MM-Net), where we introduce a set of learnable memory
embeddings to memorize the meta-class information during the base class
training and transfer to novel classes during the inference stage. Moreover,
for the $k$-shot scenario, we propose a novel image quality measurement module
to select images from the set of support images. A high-quality class prototype
could be obtained with the weighted sum of support image features based on the
quality measure. Experiments on both PASCAL-$5^i$ and COCO dataset shows that
our proposed method is able to achieve state-of-the-art results in both 1-shot
and 5-shot settings. Particularly, our proposed MM-Net achieves 37.5\% mIoU on
the COCO dataset in 1-shot setting, which is 5.1\% higher than the previous
state-of-the-art.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Dual-Tuning: Joint Prototype Transfer and Structure Regularization for Compatible Feature Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yan Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1">Jile Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shengsen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yihang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xuetao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_L/0/1/0/all/0/1">Ling-Yu Duan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02959">
                                        <div class="article-summary-box-inner">
                                            <span><p>Visual retrieval system faces frequent model update and deployment. It is a
heavy workload to re-extract features of the whole database every time.Feature
compatibility enables the learned new visual features to be directly compared
with the old features stored in the database. In this way, when updating the
deployed model, we can bypass the inflexible and time-consuming feature
re-extraction process. However, the old feature space that needs to be
compatible is not ideal and faces the distribution discrepancy problem with the
new space caused by different supervision losses. In this work, we propose a
global optimization Dual-Tuning method to obtain feature compatibility against
different networks and losses. A feature-level prototype loss is proposed to
explicitly align two types of embedding features, by transferring global
prototype information. Furthermore, we design a component-level mutual
structural regularization to implicitly optimize the feature intrinsic
structure. Experimental results on million-scale datasets demonstrate that our
Dual-Tuning is able to obtain feature compatibility without sacrificing
performance. (Our code will be avaliable at
https://github.com/yanbai1993/Dual-Tuning)
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Reducing Spatial Labeling Redundancy for Semi-supervised Crowd Counting.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongtuo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Sucheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1">Liangyu Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hanjie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jing Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shengfeng He</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02970">
                                        <div class="article-summary-box-inner">
                                            <span><p>Labeling is onerous for crowd counting as it should annotate each individual
in crowd images. Recently, several methods have been proposed for
semi-supervised crowd counting to reduce the labeling efforts. Given a limited
labeling budget, they typically select a few crowd images and densely label all
individuals in each of them. Despite the promising results, we argue the
None-or-All labeling strategy is suboptimal as the densely labeled individuals
in each crowd image usually appear similar while the massive unlabeled crowd
images may contain entirely diverse individuals. To this end, we propose to
break the labeling chain of previous methods and make the first attempt to
reduce spatial labeling redundancy for semi-supervised crowd counting. First,
instead of annotating all the regions in each crowd image, we propose to
annotate the representative ones only. We analyze the region representativeness
from both vertical and horizontal directions, and formulate them as cluster
centers of Gaussian Mixture Models. Additionally, to leverage the rich
unlabeled regions, we exploit the similarities among individuals in each crowd
image to directly supervise the unlabeled regions via feature propagation
instead of the error-prone label propagation employed in the previous methods.
In this way, we can transfer the original spatial labeling redundancy caused by
individual similarities to effective supervision signals on the unlabeled
regions. Extensive experiments on the widely-used benchmarks demonstrate that
our method can outperform previous best approaches by a large margin.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Fine-grained Domain Adaptive Crowd Counting via Point-derived Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongtuo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Sucheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hanjie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hongmin Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shengfeng He</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02980">
                                        <div class="article-summary-box-inner">
                                            <span><p>Existing domain adaptation methods for crowd counting view each crowd image
as a whole and reduce domain discrepancies on crowds and backgrounds
simultaneously. However, we argue that these methods are suboptimal, as crowds
and backgrounds have quite different characteristics and backgrounds may vary
dramatically in different crowd scenes (see Fig.~\ref{teaser}). This makes
crowds not well aligned across domains together with backgrounds in a holistic
manner. To this end, we propose to untangle crowds and backgrounds from crowd
images and design fine-grained domain adaption methods for crowd counting.
Different from other tasks which possess region-based fine-grained annotations
(e.g., segments or bounding boxes), crowd counting only annotates one point on
each human head, which impedes the implementation of fine-grained adaptation
methods. To tackle this issue, we propose a novel and effective schema to learn
crowd segmentation from point-level crowd counting annotations in the context
of Multiple Instance Learning. We further leverage the derived segments to
propose a crowd-aware fine-grained domain adaptation framework for crowd
counting, which consists of two novel adaptation modules, i.e., Crowd Region
Transfer (CRT) and Crowd Density Alignment (CDA). Specifically, the CRT module
is designed to guide crowd features transfer across domains beyond background
distractions, and the CDA module dedicates to constraining the target-domain
crowd density distributions. Extensive experiments on multiple cross-domain
settings (i.e., Synthetic $\rightarrow$ Real, Fixed $\rightarrow$ Fickle,
Normal $\rightarrow$ BadWeather) demonstrate the superiority of the proposed
method compared with state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Improving <span class="highlight_title">Contrastive Learning</span> by Visualizing Feature Transformation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1">Rui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Bingchen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhenglong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chang Wen Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02982">
                                        <div class="article-summary-box-inner">
                                            <span><p>Contrastive learning, which aims at minimizing the distance between positive
pairs while maximizing that of negative ones, has been widely and successfully
applied in unsupervised feature learning, where the design of positive and
negative (pos/neg) pairs is one of its keys. In this paper, we attempt to
devise a feature-level data manipulation, differing from data augmentation, to
enhance the generic contrastive self-supervised learning. To this end, we first
design a visualization scheme for pos/neg score (Pos/neg score indicates cosine
similarity of pos/neg pair.) distribution, which enables us to analyze,
interpret and understand the learning process. To our knowledge, this is the
first attempt of its kind. More importantly, leveraging this tool, we gain some
significant observations, which inspire our novel Feature Transformation
proposals including the extrapolation of positives. This operation creates
harder positives to boost the learning because hard positives enable the model
to be more view-invariant. Besides, we propose the interpolation among
negatives, which provides diversified negatives and makes the model more
discriminative. It is the first attempt to deal with both challenges
simultaneously. Experiment results show that our proposed Feature
Transformation can improve at least 6.0% accuracy on ImageNet-100 over MoCo
baseline, and about 2.0% accuracy on ImageNet-1K over the MoCoV2 baseline.
Transferring to the downstream tasks successfully demonstrate our model is less
task-bias. Visualization tools and codes
https://github.com/DTennant/CL-Visualizing-Feature-Transformation .
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Efficient and Generic Interactive Segmentation Framework to Correct Mispredictions during Clinical Evaluation of Medical Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sambaturu_B/0/1/0/all/0/1">Bhavani Sambaturu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Ashutosh Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1">C.V. Jawahar</a>, <a href="http://arxiv.org/find/cs/1/au:+Arora_C/0/1/0/all/0/1">Chetan Arora</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02996">
                                        <div class="article-summary-box-inner">
                                            <span><p>Semantic segmentation of medical images is an essential first step in
computer-aided diagnosis systems for many applications. However, given many
disparate imaging modalities and inherent variations in the patient data, it is
difficult to consistently achieve high accuracy using modern deep neural
networks (DNNs). This has led researchers to propose interactive image
segmentation techniques where a medical expert can interactively correct the
output of a DNN to the desired accuracy. However, these techniques often need
separate training data with the associated human interactions, and do not
generalize to various diseases, and types of medical images. In this paper, we
suggest a novel conditional inference technique for DNNs which takes the
intervention by a medical expert as test time constraints and performs
inference conditioned upon these constraints. Our technique is generic can be
used for medical images from any modality. Unlike other methods, our approach
can correct multiple structures simultaneously and add structures missed at
initial segmentation. We report an improvement of 13.3, 12.5, 17.8, 10.2, and
12.4 times in user annotation time than full human annotation for the nucleus,
multiple cells, liver and tumor, organ, and brain segmentation respectively. We
report a time saving of 2.8, 3.0, 1.9, 4.4, and 8.6 fold compared to other
interactive segmentation techniques. Our method can be useful to clinicians for
diagnosis and post-surgical follow-up with minimal intervention from the
medical expert. The source-code and the detailed results are available here
[1].
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ AI-based Aortic Vessel Tree Segmentation for Cardiovascular Diseases Treatment: Status Quo.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yuan Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pepe_A/0/1/0/all/0/1">Antonio Pepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianning Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gsaxner_C/0/1/0/all/0/1">Christina Gsaxner</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fen-hua Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleesiek_J/0/1/0/all/0/1">Jens Kleesiek</a>, <a href="http://arxiv.org/find/cs/1/au:+Frangi_A/0/1/0/all/0/1">Alejandro F. Frangi</a>, <a href="http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1">Jan Egger</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02998">
                                        <div class="article-summary-box-inner">
                                            <span><p>The aortic vessel tree is composed of the aorta and its branching arteries,
and plays a key role in supplying the whole body with blood. Aortic diseases,
like aneurysms or dissections, can lead to an aortic rupture, whose treatment
with open surgery is highly risky. Therefore, patients commonly undergo drug
treatment under constant monitoring, which requires regular inspections of the
vessels through imaging. The standard imaging modality for diagnosis and
monitoring is computed tomography (CT), which can provide a detailed picture of
the aorta and its branching vessels if combined with a contrast agent,
resulting in a CT angiography (CTA). Optimally, the whole aortic vessel tree
geometry from consecutive CTAs, are overlaid and compared. This allows to not
only detect changes in the aorta, but also more peripheral vessel tree changes,
caused by the primary pathology or newly developed. When performed manually,
this reconstruction requires slice by slice contouring, which could easily take
a whole day for a single aortic vessel tree and, hence, is not feasible in
clinical practice. Automatic or semi-automatic vessel tree segmentation
algorithms, on the other hand, can complete this task in a fraction of the
manual execution time and run in parallel to the clinical routine of the
clinicians. In this paper, we systematically review computing techniques for
the automatic and semi-automatic segmentation of the aortic vessel tree. The
review concludes with an in-depth discussion on how close these
state-of-the-art approaches are to an application in clinical practice and how
active this research field is, taking into account the number of publications,
datasets and challenges.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ AceNAS: Learning to Rank Ace Neural Architectures with Weak Supervision of Weight Sharing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuge Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chenqian Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanlu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Lyna Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiaotian Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuqing Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03001">
                                        <div class="article-summary-box-inner">
                                            <span><p>Architecture performance predictors have been widely used in neural
architecture search (NAS). Although they are shown to be simple and effective,
the optimization objectives in previous arts (e.g., precise accuracy estimation
or perfect ranking of all architectures in the space) did not capture the
ranking nature of NAS. In addition, a large number of ground-truth
architecture-accuracy pairs are usually required to build a reliable predictor,
making the process too computationally expensive. To overcome these, in this
paper, we look at NAS from a novel point of view and introduce Learning to Rank
(LTR) methods to select the best (ace) architectures from a space.
Specifically, we propose to use Normalized Discounted Cumulative Gain (NDCG) as
the target metric and LambdaRank as the training algorithm. We also propose to
leverage weak supervision from weight sharing by pretraining architecture
representation on weak labels obtained from the super-net and then finetuning
the ranking model using a small number of architectures trained from scratch.
Extensive experiments on NAS benchmarks and large-scale search spaces
demonstrate that our approach outperforms SOTA with a significantly reduced
search cost.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Fast and Accurate Low-Rank Tensor Completion Methods Based on QR Decomposition and $L_{2,1}$ Norm Minimization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Zhang_H/0/1/0/all/0/1">HongBing Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1">XinYi Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Fan_H/0/1/0/all/0/1">HongTao Fan</a>, <a href="http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1">YaJing Li</a>, <a href="http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1">Yinlin Ye</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03002">
                                        <div class="article-summary-box-inner">
                                            <span><p>More recently, an Approximate SVD Based on Qatar Riyal (QR) Decomposition
(CSVD-QR) method for matrix complete problem is presented, whose computational
complexity is $O(r^2(m+n))$, which is mainly due to that $r$ is far less than
$\min\{m,n\}$, where $r$ represents the largest number of singular values of
matrix $X$. What is particularly interesting is that after replacing the
nuclear norm with the $L_{2,1}$ norm proposed based on this decomposition, as
the upper bound of the nuclear norm, when the intermediate matrix $D$ in its
decomposition is close to the diagonal matrix, it will converge to the nuclear
norm, and is exactly equal, when the $D$ matrix is equal to the diagonal
matrix, to the nuclear norm, which ingeniously avoids the calculation of the
singular value of the matrix. To the best of our knowledge, there is no
literature to generalize and apply it to solve tensor complete problems.
Inspired by this, in this paper we propose a class of tensor minimization model
based on $L_{2,1}$ norm and CSVD-QR method for the tensor complete problem,
which is convex and therefore has a global minimum solution.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ MmWave Radar and Vision Fusion based Object Detection for Autonomous Driving: A Survey.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhiqing Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fengkai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shuo Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yangyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huici Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhiyong Feng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03004">
                                        <div class="article-summary-box-inner">
                                            <span><p>With autonomous driving developing in a booming stage, accurate object
detection in complex scenarios attract wide attention to ensure the safety of
autonomous driving. Millimeter wave (mmWave) radar and vision fusion is a
mainstream solution for accurate obstacle detection. This article presents a
detailed survey on mmWave radar and vision fusion based obstacle detection
methods. Firstly, we introduce the tasks, evaluation criteria and datasets of
object detection for autonomous driving. Then, the process of mmWave radar and
vision fusion is divided into three parts: sensor deployment, sensor
calibration and sensor fusion, which are reviewed comprehensively. Especially,
we classify the fusion methods into data level, decision level and feature
level fusion methods. Besides, we introduce the fusion of lidar and vision in
autonomous driving in the aspects of obstacle detection, object classification
and road segmentation, which is promising in the future. Finally, we summarize
this article.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Feature Detection for Hand Hygiene Stages.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bakshi_R/0/1/0/all/0/1">Rashmi Bakshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Courtney_J/0/1/0/all/0/1">Jane Courtney</a>, <a href="http://arxiv.org/find/cs/1/au:+Berry_D/0/1/0/all/0/1">Damon Berry</a>, <a href="http://arxiv.org/find/cs/1/au:+Gavin_G/0/1/0/all/0/1">Graham Gavin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03015">
                                        <div class="article-summary-box-inner">
                                            <span><p>The process of hand washing involves complex hand movements. There are six
principal sequential steps for washing hands as per the World Health
Organisation (WHO) guidelines. In this work, a detailed description of an
aluminium rig construction for creating a robust hand-washing dataset is
discussed. The preliminary results with the help of image processing and
computer vision algorithms for hand pose extraction and feature detection such
as Harris detector, Shi-Tomasi and SIFT are demonstrated. The hand hygiene
pose- Rub hands palm to palm was captured as an input image for running all the
experiments. The future work will focus upon processing the video recordings of
hand movements captured and applying deep-learning solutions for the
classification of hand-hygiene stages.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Adapting Segmentation Networks to New Domains by Disentangling Latent Representations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Barbato_F/0/1/0/all/0/1">Francesco Barbato</a>, <a href="http://arxiv.org/find/cs/1/au:+Michieli_U/0/1/0/all/0/1">Umberto Michieli</a>, <a href="http://arxiv.org/find/cs/1/au:+Toldo_M/0/1/0/all/0/1">Marco Toldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanuttigh_P/0/1/0/all/0/1">Pietro Zanuttigh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03021">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep learning models achieve outstanding accuracy in semantic segmentation,
however they require a huge amount of labeled data for their optimization.
Hence, domain adaptation approaches have come into play to transfer knowledge
acquired on a label-abundant source domain to a related label-scarce target
domain. However, such models do not generalize well to data with statistical
properties not perfectly matching the ones of the training samples. In this
work, we design and carefully analyze multiple latent space-shaping
regularization strategies that work in conjunction to reduce the domain
discrepancy in semantic segmentation. In particular, we devise a feature
clustering strategy to increase domain alignment, a feature perpendicularity
constraint to space apart feature belonging to different semantic classes,
including those not present in the current batch, and a feature norm alignment
strategy to separate active and inactive channels. Additionally, we propose a
novel performance metric to capture the relative efficacy of an adaptation
strategy compared to supervised training. We verify the effectiveness of our
framework in synthetic-to-real and real-to-real adaptation scenarios,
outperforming previous state-of-the-art methods on multiple road scenes
benchmarks and using different backbones.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Simpler is Better: Few-shot Semantic Segmentation with Classifier Weight <span class="highlight_title">Transformer</span>.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+lu_Z/0/1/0/all/0/1">Zhihe lu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Sen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tao Xiang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03032">
                                        <div class="article-summary-box-inner">
                                            <span><p>A few-shot semantic segmentation model is typically composed of a CNN
encoder, a CNN decoder and a simple classifier (separating foreground and
background pixels). Most existing methods meta-learn all three model components
for fast adaptation to a new class. However, given that as few as a single
support set image is available, effective model adaption of all three
components to the new class is extremely challenging. In this work we propose
to simplify the meta-learning task by focusing solely on the simplest
component, the classifier, whilst leaving the encoder and decoder to
pre-training. We hypothesize that if we pre-train an off-the-shelf segmentation
model over a set of diverse training classes with sufficient annotations, the
encoder and decoder can capture rich discriminative features applicable for any
unseen classes, rendering the subsequent meta-learning stage unnecessary. For
the classifier meta-learning, we introduce a Classifier Weight Transformer
(CWT) designed to dynamically adapt the supportset trained classifier's weights
to each query image in an inductive way. Extensive experiments on two standard
benchmarks show that despite its simplicity, our method outperforms the
state-of-the-art alternatives, often by a large margin.Code is available on
https://github.com/zhiheLu/CWTfor-FSS.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Spatiotemporal <span class="highlight_title">Contrastive Learning</span> of Facial Expressions in Videos.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Shuvendu Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1">Ali Etemad</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03064">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose a self-supervised contrastive learning approach for facial
expression recognition (FER) in videos. We propose a novel temporal
sampling-based augmentation scheme to be utilized in addition to standard
spatial augmentations used for contrastive learning. Our proposed temporal
augmentation scheme randomly picks from one of three temporal sampling
techniques: (1) pure random sampling, (2) uniform sampling, and (3) sequential
sampling. This is followed by a combination of up to three standard spatial
augmentations. We then use a deep R(2+1)D network for FER, which we train in a
self-supervised fashion based on the augmentations and subsequently fine-tune.
Experiments are performed on the Oulu-CASIA dataset and the performance is
compared to other works in FER. The results indicate that our method achieves
an accuracy of 89.4%, setting a new state-of-the-art by outperforming other
works. Additional experiments and analysis confirm the considerable
contribution of the proposed temporal augmentation versus the existing spatial
ones.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ STR-GQN: Scene Representation and Rendering for Unknown Cameras Based on Spatial Transformation Routing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wen-Cheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Min-Chun Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chu-Song Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03072">
                                        <div class="article-summary-box-inner">
                                            <span><p>Geometry-aware modules are widely applied in recent deep learning
architectures for scene representation and rendering. However, these modules
require intrinsic camera information that might not be obtained accurately. In
this paper, we propose a Spatial Transformation Routing (STR) mechanism to
model the spatial properties without applying any geometric prior. The STR
mechanism treats the spatial transformation as the message passing process, and
the relation between the view poses and the routing weights is modeled by an
end-to-end trainable neural network. Besides, an Occupancy Concept Mapping
(OCM) framework is proposed to provide explainable rationals for scene-fusion
processes. We conducted experiments on several datasets and show that the
proposed STR mechanism improves the performance of the Generative Query Network
(GQN). The visualization results reveal that the routing process can pass the
observed information from one location of some view to the associated location
in the other view, which demonstrates the advantage of the proposed model in
terms of spatial cognition.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Beyond the Hausdorff Metric in Digital Topology.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Boxer_L/0/1/0/all/0/1">Laurence Boxer</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03114">
                                        <div class="article-summary-box-inner">
                                            <span><p>Two objects may be close in the Hausdor? metric, yet have very different
geometric and topological properties. We examine other methods of comparing
digital images such that objects close in each of these measures have some
similar geometric or topological property. Such measures may be combined with
the Hausdorff metric to yield a metric in which close images are similar with
respect to multiple properties.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ TS4Net: Two-Stage Sample Selective Strategy for Rotating Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Feng_K/0/1/0/all/0/1">Kai Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weixing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Feng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">Dongdong Zheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03116">
                                        <div class="article-summary-box-inner">
                                            <span><p>Rotating object detection has wide applications in aerial photographs, remote
sensing images, UAVs, etc. At present, most of the rotating object detection
datasets focus on the field of remote sensing, and these images are usually
shot in high-altitude scenes. However, image datasets captured at low-altitude
areas also should be concerned, such as drone-based datasets. So we present a
low-altitude dronebased dataset, named UAV-ROD, aiming to promote the research
and development in rotating object detection and UAV applications. The UAV-ROD
consists of 1577 images and 30,090 instances of car category annotated by
oriented bounding boxes. In particular, The UAV-ROD can be utilized for the
rotating object detection, vehicle orientation recognition and object counting
tasks. Compared with horizontal object detection, the regression stage of the
rotation detection is a tricky problem. In this paper, we propose a rotating
object detector TS4Net, which contains anchor refinement module (ARM) and
two-stage sample selective strategy (TS4). The ARM can convert preseted
horizontal anchors into high-quality rotated anchors through twostage anchor
refinement. The TS4 module utilizes different constrained sample selective
strategies to allocate positive and negative samples, which is adaptive to the
regression task in different stages. Benefiting from the ARM and TS4, the
TS4Net can achieve superior performance for rotating object detection solely
with one preseted horizontal anchor. Extensive experimental results on UAV-ROD
dataset and three remote sensing datasets DOTA, HRSC2016 and UCAS-AOD
demonstrate that our method achieves competitive performance against most
state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Uncertainty-Based Dynamic Graph Neighborhoods For Medical Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Demir_U/0/1/0/all/0/1">Ufuk Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozer_A/0/1/0/all/0/1">Atahan Ozer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahin_Y/0/1/0/all/0/1">Yusuf H. Sahin</a>, <a href="http://arxiv.org/find/cs/1/au:+Unal_G/0/1/0/all/0/1">Gozde Unal</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03117">
                                        <div class="article-summary-box-inner">
                                            <span><p>In recent years, deep learning based methods have shown success in essential
medical image analysis tasks such as segmentation. Post-processing and refining
the results of segmentation is a common practice to decrease the
misclassifications originating from the segmentation network. In addition to
widely used methods like Conditional Random Fields (CRFs) which focus on the
structure of the segmented volume/area, a graph-based recent approach makes use
of certain and uncertain points in a graph and refines the segmentation
according to a small graph convolutional network (GCN). However, there are two
drawbacks of the approach: most of the edges in the graph are assigned randomly
and the GCN is trained independently from the segmentation network. To address
these issues, we define a new neighbor-selection mechanism according to feature
distances and combine the two networks in the training procedure. According to
the experimental results on pancreas segmentation from Computed Tomography (CT)
images, we demonstrate improvement in the quantitative measures. Also,
examining the dynamic neighbors created by our method, edges between
semantically similar image parts are observed. The proposed method also shows
qualitative enhancements in the segmentation maps, as demonstrated in the
visual results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ <span class="highlight_title">Contrastive Learning</span> for View Classification of Echocardiograms.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chartsias_A/0/1/0/all/0/1">Agisilaos Chartsias</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mumith_A/0/1/0/all/0/1">Angela Mumith</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_J/0/1/0/all/0/1">Jorge Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatia_K/0/1/0/all/0/1">Kanwal Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>, <a href="http://arxiv.org/find/cs/1/au:+Beqiri_A/0/1/0/all/0/1">Arian Beqiri</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03124">
                                        <div class="article-summary-box-inner">
                                            <span><p>Analysis of cardiac ultrasound images is commonly performed in routine
clinical practice for quantification of cardiac function. Its increasing
automation frequently employs deep learning networks that are trained to
predict disease or detect image features. However, such models are extremely
data-hungry and training requires labelling of many thousands of images by
experienced clinicians. Here we propose the use of contrastive learning to
mitigate the labelling bottleneck. We train view classification models for
imbalanced cardiac ultrasound datasets and show improved performance for
views/classes for which minimal labelled data is available. Compared to a naive
baseline model, we achieve an improvement in F1 score of up to 26% in those
views while maintaining state-of-the-art performance for the views with
sufficiently many labelled training observations.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ COVID-Net US: A Tailored, Highly Efficient, Self-Attention Deep Convolutional Neural Network Design for Detection of COVID-19 Patient Cases from Point-of-care Ultrasound Imaging.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+MacLean_A/0/1/0/all/0/1">Alexander MacLean</a>, <a href="http://arxiv.org/find/eess/1/au:+Abbasi_S/0/1/0/all/0/1">Saad Abbasi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ebadi_A/0/1/0/all/0/1">Ashkan Ebadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_A/0/1/0/all/0/1">Andy Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Pavlova_M/0/1/0/all/0/1">Maya Pavlova</a>, <a href="http://arxiv.org/find/eess/1/au:+Gunraj_H/0/1/0/all/0/1">Hayden Gunraj</a>, <a href="http://arxiv.org/find/eess/1/au:+Xi_P/0/1/0/all/0/1">Pengcheng Xi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kohli_S/0/1/0/all/0/1">Sonny Kohli</a>, <a href="http://arxiv.org/find/eess/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03131">
                                        <div class="article-summary-box-inner">
                                            <span><p>The Coronavirus Disease 2019 (COVID-19) pandemic has impacted many aspects of
life globally, and a critical factor in mitigating its effects is screening
individuals for infections, thereby allowing for both proper treatment for
those individuals as well as action to be taken to prevent further spread of
the virus. Point-of-care ultrasound (POCUS) imaging has been proposed as a
screening tool as it is a much cheaper and easier to apply imaging modality
than others that are traditionally used for pulmonary examinations, namely
chest x-ray and computed tomography. Given the scarcity of expert radiologists
for interpreting POCUS examinations in many highly affected regions around the
world, low-cost deep learning-driven clinical decision support solutions can
have a large impact during the on-going pandemic. Motivated by this, we
introduce COVID-Net US, a highly efficient, self-attention deep convolutional
neural network design tailored for COVID-19 screening from lung POCUS images.
Experimental results show that the proposed COVID-Net US can achieve an AUC of
over 0.98 while achieving 353X lower architectural complexity, 62X lower
computational complexity, and 14.3X faster inference times on a Raspberry Pi.
Clinical validation was also conducted, where select cases were reviewed and
reported on by a practicing clinician (20 years of clinical practice)
specializing in intensive care (ICU) and 15 years of expertise in POCUS
interpretation. To advocate affordable healthcare and artificial intelligence
for resource-constrained environments, we have made COVID-Net US open source
and publicly available as part of the COVID-Net open source initiative.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Lung Ultrasound Segmentation and Adaptation between COVID-19 and Community-Acquired Pneumonia.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mason_H/0/1/0/all/0/1">Harry Mason</a>, <a href="http://arxiv.org/find/cs/1/au:+Cristoni_L/0/1/0/all/0/1">Lorenzo Cristoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Walden_A/0/1/0/all/0/1">Andrew Walden</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazzari_R/0/1/0/all/0/1">Roberto Lazzari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulimood_T/0/1/0/all/0/1">Thomas Pulimood</a>, <a href="http://arxiv.org/find/cs/1/au:+Grandjean_L/0/1/0/all/0/1">Louis Grandjean</a>, <a href="http://arxiv.org/find/cs/1/au:+Wheeler_Kingshott_C/0/1/0/all/0/1">Claudia AM Gandini Wheeler-Kingshott</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Baum_Z/0/1/0/all/0/1">Zachary MC Baum</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03138">
                                        <div class="article-summary-box-inner">
                                            <span><p>Lung ultrasound imaging has been shown effective in detecting typical
patterns for interstitial pneumonia, as a point-of-care tool for both patients
with COVID-19 and other community-acquired pneumonia (CAP). In this work, we
focus on the hyperechoic B-line segmentation task. Using deep neural networks,
we automatically outline the regions that are indicative of pathology-sensitive
artifacts and their associated sonographic patterns. With a real-world
data-scarce scenario, we investigate approaches to utilize both COVID-19 and
CAP lung ultrasound data to train the networks; comparing fine-tuning and
unsupervised domain adaptation. Segmenting either type of lung condition at
inference may support a range of clinical applications during evolving epidemic
stages, but also demonstrates value in resource-constrained clinical scenarios.
Adapting real clinical data acquired from COVID-19 patients to those from CAP
patients significantly improved Dice scores from 0.60 to 0.87 (p &lt; 0.001) and
from 0.43 to 0.71 (p &lt; 0.001), on independent COVID-19 and CAP test cases,
respectively. It is of practical value that the improvement was demonstrated
with only a small amount of data in both training and adaptation data sets, a
common constraint for deploying machine learning models in clinical practice.
Interestingly, we also report that the inverse adaptation, from labelled CAP
data to unlabeled COVID-19 data, did not demonstrate an improvement when tested
on either condition. Furthermore, we offer a possible explanation that
correlates the segmentation performance to label consistency and data domain
diversity in this point-of-care lung ultrasound application.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ SELM: Siamese Extreme Learning Machine with Application to Face Biometrics.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kudisthalert_W/0/1/0/all/0/1">Wasu Kudisthalert</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasupa_K/0/1/0/all/0/1">Kitsuchart Pasupa</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1">Aythami Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Julian Fierrez</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03140">
                                        <div class="article-summary-box-inner">
                                            <span><p>Extreme Learning Machine is a powerful classification method very competitive
existing classification methods. It is extremely fast at training.
Nevertheless, it cannot perform face verification tasks properly because face
verification tasks require comparison of facial images of two individuals at
the same time and decide whether the two faces identify the same person. The
structure of Extreme Leaning Machine was not designed to feed two input data
streams simultaneously, thus, in 2-input scenarios Extreme Learning Machine
methods are normally applied using concatenated inputs. However, this setup
consumes two times more computational resources and it is not optimized for
recognition tasks where learning a separable distance metric is critical. For
these reasons, we propose and develop a Siamese Extreme Learning Machine
(SELM). SELM was designed to be fed with two data streams in parallel
simultaneously. It utilizes a dual-stream Siamese condition in the extra
Siamese layer to transform the data before passing it along to the hidden
layer. Moreover, we propose a Gender-Ethnicity-Dependent triplet feature
exclusively trained on a variety of specific demographic groups. This feature
enables learning and extracting of useful facial features of each group.
Experiments were conducted to evaluate and compare the performances of SELM,
Extreme Learning Machine, and DCNN. The experimental results showed that the
proposed feature was able to perform correct classification at 97.87% accuracy
and 99.45% AUC. They also showed that using SELM in conjunction with the
proposed feature provided 98.31% accuracy and 99.72% AUC. They outperformed the
well-known DCNN and Extreme Leaning Machine methods by a wide margin.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ELSED: Enhanced Line SEgment Drawing.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Suarez_I/0/1/0/all/0/1">Iago Su&#xe1;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Buenaposada_J/0/1/0/all/0/1">Jos&#xe9; M. Buenaposada</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumela_L/0/1/0/all/0/1">Luis Baumela</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03144">
                                        <div class="article-summary-box-inner">
                                            <span><p>Detecting local features, such as corners, segments or blobs, is the first
step in the pipeline of many Computer Vision applications. Its speed is crucial
for real time applications. In this paper we present ELSED, the fastest line
segment detector in the literature. The key for its efficiency is a local
segment growing algorithm that connects gradient aligned pixels in presence of
small discontinuities. The proposed algorithm not only runs in devices with
very low end hardware, but may also be parametrized to foster the detection of
short or longer segments, depending on the task at hand. We also introduce new
metrics to evaluate the accuracy and repeatability of segment detectors. In our
experiments with different public benchmarks we prove that our method is the
most efficient in the literature and quantify the accuracy traded for such
gain.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Full-Duplex Strategy for Video Object Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1">Ge-Peng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1">Keren Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhe Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jianbing Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03151">
                                        <div class="article-summary-box-inner">
                                            <span><p>Appearance and motion are two important sources of information in video
object segmentation (VOS). Previous methods mainly focus on using simplex
solutions, lowering the upper bound of feature collaboration among and across
these two cues. In this paper, we study a novel framework, termed the FSNet
(Full-duplex Strategy Network), which designs a relational cross-attention
module (RCAM) to achieve the bidirectional message propagation across embedding
subspaces. Furthermore, the bidirectional purification module (BPM) is
introduced to update the inconsistent features between the spatial-temporal
embeddings, effectively improving the model robustness. By considering the
mutual restraint within the full-duplex strategy, our FSNet performs the
cross-modal feature-passing (i.e., transmission and receiving) simultaneously
before the fusion and decoding stage, making it robust to various challenging
scenarios (e.g., motion blur, occlusion) in VOS. Extensive experiments on five
popular benchmarks (i.e., DAVIS$_{16}$, FBMS, MCL, SegTrack-V2, and
DAVSOD$_{19}$) show that our FSNet outperforms other state-of-the-arts for both
the VOS and video salient object detection tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Source-Free Domain Adaptation for Image Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Bateson_M/0/1/0/all/0/1">Mathilde Bateson</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolz_J/0/1/0/all/0/1">Jose Dolz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kervadec_H/0/1/0/all/0/1">Hoel Kervadec</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombaert_H/0/1/0/all/0/1">Herv&#xe9; Lombaert</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03152">
                                        <div class="article-summary-box-inner">
                                            <span><p>Domain adaptation (DA) has drawn high interest for its capacity to adapt a
model trained on labeled source data to perform well on unlabeled or weakly
labeled target data from a different domain. Most common DA techniques require
concurrent access to the input images of both the source and target domains.
However, in practice, privacy concerns often impede the availability of source
images in the adaptation phase. This is a very frequent DA scenario in medical
imaging, where, for instance, the source and target images could come from
different clinical sites. We introduce a source-free domain adaptation for
image segmentation. Our formulation is based on minimizing a label-free entropy
loss defined over target-domain data, which we further guide with a
domain-invariant prior on the segmentation regions. Many priors can be derived
from anatomical information. Here, a class ratio prior is estimated from
anatomical knowledge and integrated in the form of a Kullback Leibler (KL)
divergence in our overall loss function. Furthermore, we motivate our overall
loss with an interesting link to maximizing the mutual information between the
target images and their label predictions. We show the effectiveness of our
prior aware entropy minimization in a variety of domain-adaptation scenarios,
with different modalities and applications, including spine, prostate, and
cardiac segmentation. Our method yields comparable results to several state of
the art adaptation techniques, despite having access to much less information,
as the source images are entirely absent in our adaptation phase. Our
straightforward adaptation strategy uses only one network, contrary to popular
adversarial techniques, which are not applicable to a source-free DA setting.
Our framework can be readily used in a breadth of segmentation problems, and
our code is publicly available: https://github.com/mathilde-b/SFDA
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Pattern Recognition in Vital Signs Using Spectrograms.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Sribhashyam_S/0/1/0/all/0/1">Sidharth Srivatsav Sribhashyam</a>, <a href="http://arxiv.org/find/eess/1/au:+Salekin_M/0/1/0/all/0/1">Md Sirajus Salekin</a>, <a href="http://arxiv.org/find/eess/1/au:+Goldgof_D/0/1/0/all/0/1">Dmitry Goldgof</a>, <a href="http://arxiv.org/find/eess/1/au:+Zamzmi_G/0/1/0/all/0/1">Ghada Zamzmi</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_Y/0/1/0/all/0/1">Yu Sun</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03168">
                                        <div class="article-summary-box-inner">
                                            <span><p>Spectrograms visualize the frequency components of a given signal which may
be an audio signal or even a time-series signal. Audio signals have higher
sampling rate and high variability of frequency with time. Spectrograms can
capture such variations well. But, vital signs which are time-series signals
have less sampling frequency and low-frequency variability due to which,
spectrograms fail to express variations and patterns. In this paper, we propose
a novel solution to introduce frequency variability using frequency modulation
on vital signs. Then we apply spectrograms on frequency modulated signals to
capture the patterns. The proposed approach has been evaluated on 4 different
medical datasets across both prediction and classification tasks. Significant
results are found showing the efficacy of the approach for vital sign signals.
The results from the proposed approach are promising with an accuracy of 91.55%
and 91.67% in prediction and classification tasks respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Dynamic Semantic Occupancy Mapping using 3D Scene Flow and Closed-Form Bayesian Inference.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Unnikrishnan_A/0/1/0/all/0/1">Aishwarya Unnikrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_J/0/1/0/all/0/1">Joseph Wilson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1">Lu Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Capodieci_A/0/1/0/all/0/1">Andrew Capodieci</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayakumar_P/0/1/0/all/0/1">Paramsothy Jayakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Barton_K/0/1/0/all/0/1">Kira Barton</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Maani Ghaffari</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03180">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper reports on a dynamic semantic mapping framework that incorporates
3D scene flow measurements into a closed-form Bayesian inference model.
Existence of dynamic objects in the environment cause artifacts and traces in
current mapping algorithms, leading to an inconsistent map posterior. We
leverage state-of-the-art semantic segmentation and 3D flow estimation using
deep learning to provide measurements for map inference. We develop a
continuous (i.e., can be queried at arbitrary resolution) Bayesian model that
propagates the scene with flow and infers a 3D semantic occupancy map with
better performance than its static counterpart. Experimental results using
publicly available data sets show that the proposed framework generalizes its
predecessors and improves over direct measurements from deep neural networks
consistently.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ GLASS: Geometric Latent Augmentation for Shape Spaces.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Muralikrishnan_S/0/1/0/all/0/1">Sanjeev Muralikrishnan</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Siddhartha Chaudhuri</a> (2 and 3), <a href="http://arxiv.org/find/cs/1/au:+Aigerman_N/0/1/0/all/0/1">Noam Aigerman</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Kim_V/0/1/0/all/0/1">Vladimir Kim</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Fisher_M/0/1/0/all/0/1">Matthew Fisher</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1">Niloy Mitra</a> (1 and 2) ((1) University College London, (2) Adobe Research, (3) IIT Bombay), ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03225">
                                        <div class="article-summary-box-inner">
                                            <span><p>We investigate the problem of training generative models on a very sparse
collection of 3D models. We use geometrically motivated energies to augment and
thus boost a sparse collection of example (training) models. We analyze the
Hessian of the as-rigid-as-possible (ARAP) energy to sample from and project to
the underlying (local) shape space, and use the augmented dataset to train a
variational autoencoder (VAE). We iterate the process of building latent spaces
of VAE and augmenting the associated dataset, to progressively reveal a richer
and more expressive generative space for creating geometrically and
semantically valid samples. Our framework allows us to train generative 3D
models even with a small set of good quality 3D models, which are typically
hard to curate. We extensively evaluate our method against a set of strong
baselines, provide ablation studies and demonstrate application towards
establishing shape correspondences. We present multiple examples of interesting
and meaningful shape variations even when starting from as few as 3-10 training
shapes.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Bird's-Eye-View Panoptic Segmentation Using Monocular Frontal View Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gosala_N/0/1/0/all/0/1">Nikhil Gosala</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03227">
                                        <div class="article-summary-box-inner">
                                            <span><p>Bird's-Eye-View (BEV) maps have emerged as one of the most powerful
representations for scene understanding due to their ability to provide rich
spatial context while being easy to interpret and process. However, generating
BEV maps requires complex multi-stage paradigms that encapsulate a series of
distinct tasks such as depth estimation, ground plane estimation, and semantic
segmentation. These sub-tasks are often learned in a disjoint manner which
prevents the model from holistic reasoning and results in erroneous BEV maps.
Moreover, existing algorithms only predict the semantics in the BEV space,
which limits their use in applications where the notion of object instances is
critical. In this work, we present the first end-to-end learning approach for
directly predicting dense panoptic segmentation maps in the BEV, given a single
monocular image in the frontal view (FV). Our architecture follows the top-down
paradigm and incorporates a novel dense transformer module consisting of two
distinct transformers that learn to independently map vertical and flat regions
in the input image from the FV to the BEV. Additionally, we derive a
mathematical formulation for the sensitivity of the FV-BEV transformation which
allows us to intelligently weight pixels in the BEV space to account for the
varying descriptiveness across the FV image. Extensive evaluations on the
KITTI-360 and nuScenes datasets demonstrate that our approach exceeds the
state-of-the-art in the PQ metric by 3.61 pp and 4.93 pp respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Reconstruction of 3D Porous Media From 2D Slices.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Volkhonskiy_D/0/1/0/all/0/1">Denis Volkhonskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Muravleva_E/0/1/0/all/0/1">Ekaterina Muravleva</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudakov_O/0/1/0/all/0/1">Oleg Sudakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Orlov_D/0/1/0/all/0/1">Denis Orlov</a>, <a href="http://arxiv.org/find/cs/1/au:+Belozerov_B/0/1/0/all/0/1">Boris Belozerov</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Koroteev_D/0/1/0/all/0/1">Dmitry Koroteev</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.10233">
                                        <div class="article-summary-box-inner">
                                            <span><p>In many branches of earth sciences, the problem of rock study on the
micro-level arises. However, a significant number of representative samples is
not always feasible. Thus the problem of the generation of samples with similar
properties becomes actual. In this paper, we propose a novel deep learning
architecture for three-dimensional porous media reconstruction from
two-dimensional slices. We fit a distribution on all possible three-dimensional
structures of a specific type based on the given dataset of samples. Then,
given partial information (central slices), we recover the three-dimensional
structure around such slices as the most probable one according to that
constructed distribution. Technically, we implement this in the form of a deep
neural network with encoder, generator and discriminator modules. Numerical
experiments show that this method provides a good reconstruction in terms of
Minkowski functionals.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ TightCap: 3D Human Shape Capture with Clothing Tightness Field.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_A/0/1/0/all/0/1">Anqi Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xui_L/0/1/0/all/0/1">Lan Xui</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jingyi Yu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.02601">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we present TightCap, a data-driven scheme to capture both the
human shape and dressed garments accurately with only a single 3D human scan,
which enables numerous applications such as virtual try-on, biometrics and body
evaluation. To break the severe variations of the human poses and garments, we
propose to model the clothing tightness - the displacements from the garments
to the human shape implicitly in the global UV texturing domain. To this end,
we utilize an enhanced statistical human template and an effective multi-stage
alignment scheme to map the 3D scan into a hybrid 2D geometry image. Based on
this 2D representation, we propose a novel framework to predicted clothing
tightness via a novel tightness formulation, as well as an effective
optimization scheme to further reconstruct multi-layer human shape and garments
under various clothing categories and human postures. We further propose a new
clothing tightness dataset (CTD) of human scans with a large variety of
clothing styles, poses and corresponding ground-truth human shapes to stimulate
further research. Extensive experiments demonstrate the effectiveness of our
TightCap to achieve high-quality human shape and dressed garments
reconstruction, as well as the further applications for clothing segmentation,
retargeting and animation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Learning and Segmenting Dense Voxel Embeddings for 3D Neuron Reconstruction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kisuk Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Ran Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luther_K/0/1/0/all/0/1">Kyle Luther</a>, <a href="http://arxiv.org/find/cs/1/au:+Seung_H/0/1/0/all/0/1">H. Sebastian Seung</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.09872">
                                        <div class="article-summary-box-inner">
                                            <span><p>We show dense voxel embeddings learned via deep metric learning can be
employed to produce a highly accurate segmentation of neurons from 3D electron
microscopy images. A "metric graph" on a set of edges between voxels is
constructed from the dense voxel embeddings generated by a convolutional
network. Partitioning the metric graph with long-range edges as repulsive
constraints yields an initial segmentation with high precision, with
substantial accuracy gain for very thin objects. The convolutional embedding
net is reused without any modification to agglomerate the systematic splits
caused by complex "self-contact" motifs. Our proposed method achieves
state-of-the-art accuracy on the challenging problem of 3D neuron
reconstruction from the brain images acquired by serial section electron
microscopy. Our alternative, object-centered representation could be more
generally useful for other computational tasks in automated neural circuit
reconstruction.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ FrequentNet : A New Interpretable Deep Learning Baseline for Image Classification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yifei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kuangyan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yiming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Liao Zhu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.01034">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper has proposed a new baseline deep learning model of more benefits
for image classification. Different from the convolutional neural network(CNN)
practice where filters are trained by back propagation to represent different
patterns of an image, we are inspired by a method called "PCANet" in "PCANet: A
Simple Deep Learning Baseline for Image Classification?" to choose filter
vectors from basis vectors in frequency domain like Fourier coefficients or
wavelets without back propagation. Researchers have demonstrated that those
basis in frequency domain can usually provide physical insights, which adds to
the interpretability of the model by analyzing the frequencies selected.
Besides, the training process will also be more time efficient, mathematically
clear and interpretable compared with the "black-box" training process of CNN.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ SofGAN: A Portrait Image Generator with Dynamic Styling.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Anpei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Ling Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jingyi Yu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03780">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently, Generative Adversarial Networks (GANs)} have been widely used for
portrait image generation. However, in the latent space learned by GANs,
different attributes, such as pose, shape, and texture style, are generally
entangled, making the explicit control of specific attributes difficult. To
address this issue, we propose a SofGAN image generator to decouple the latent
space of portraits into two subspaces: a geometry space and a texture space.
The latent codes sampled from the two subspaces are fed to two network branches
separately, one to generate the 3D geometry of portraits with canonical pose,
and the other to generate textures. The aligned 3D geometries also come with
semantic part segmentation, encoded as a semantic occupancy field (SOF). The
SOF allows the rendering of consistent 2D semantic segmentation maps at
arbitrary views, which are then fused with the generated texture maps and
stylized to a portrait photo using our semantic instance-wise (SIW) module.
Through extensive experiments, we show that our system can generate high
quality portrait images with independently controllable geometry and texture
attributes. The method also generalizes well in various applications such as
appearance-consistent facial animation and dynamic styling.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On Adversarial Robustness: A Neural Architecture Search perspective.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Devaguptapu_C/0/1/0/all/0/1">Chaitanya Devaguptapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_D/0/1/0/all/0/1">Devansh Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_G/0/1/0/all/0/1">Gaurav Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08428">
                                        <div class="article-summary-box-inner">
                                            <span><p>Adversarial robustness of deep learning models has gained much traction in
the last few years. Various attacks and defenses are proposed to improve the
adversarial robustness of modern-day deep learning architectures. While all
these approaches help improve the robustness, one promising direction for
improving adversarial robustness is un-explored, i.e., the complex topology of
the neural network architecture. In this work, we answer the following
question: "Can the complex topology of a neural network give adversarial
robustness without any form of adversarial training?" empirically by
experimenting with different hand-crafted and NAS based architectures. Our
findings show that, for small-scale attacks, NAS-based architectures are more
robust for small-scale datasets and simple tasks than hand-crafted
architectures. However, as the dataset's size or the task's complexity
increase, hand-crafted architectures are more robust than NAS-based
architectures. We perform the first large scale study to understand adversarial
robustness purely from an architectural perspective. Our results show that
random sampling in the search space of DARTS (a popular NAS method) with simple
ensembling can improve the robustness to PGD attack by nearly ~12\%. We show
that NAS, which is popular for SoTA accuracy, can provide adversarial accuracy
as a free add-on without any form of adversarial training. Our results show
that leveraging the power of neural network topology with methods like
ensembles can be an excellent way to achieve adversarial robustness without any
form of adversarial training. We also introduce a metric that can be used to
calculate the trade-off between clean accuracy and adversarial robustness.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ COV-ELM classifier: An Extreme Learning Machine based identification of COVID-19 using Chest X-Ray Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Rajpal_S/0/1/0/all/0/1">Sheetal Rajpal</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_M/0/1/0/all/0/1">Manoj Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Rajpal_A/0/1/0/all/0/1">Ankit Rajpal</a>, <a href="http://arxiv.org/find/eess/1/au:+Lakhyani_N/0/1/0/all/0/1">Navin Lakhyani</a>, <a href="http://arxiv.org/find/eess/1/au:+Saggar_A/0/1/0/all/0/1">Arpita Saggar</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_N/0/1/0/all/0/1">Naveen Kumar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08637">
                                        <div class="article-summary-box-inner">
                                            <span><p>Coronaviruses constitute a family of viruses that gives rise to respiratory
diseases. As COVID-19 is highly contagious, early diagnosis of COVID-19 is
crucial for an effective treatment strategy. However, the RT-PCR test which is
considered to be a gold standard in the diagnosis of COVID-19 suffers from a
high false-negative rate. Chest X-ray (CXR) image analysis has emerged as a
feasible and effective diagnostic technique towards this objective. In this
work, we propose the COVID-19 classification problem as a three-class
classification problem to distinguish between COVID-19, normal, and pneumonia
classes. We propose a three-stage framework, named COV-ELM. Stage one deals
with preprocessing and transformation while stage two deals with feature
extraction. These extracted features are passed as an input to the ELM at the
third stage, resulting in the identification of COVID-19. The choice of ELM in
this work has been motivated by its faster convergence, better generalization
capability, and shorter training time in comparison to the conventional
gradient-based learning algorithms. As bigger and diverse datasets become
available, ELM can be quickly retrained as compared to its gradient-based
competitor models. The proposed model achieved a macro average F1-score of 0.95
and the overall sensitivity of ${0.94 \pm 0.02} at a 95% confidence interval.
When compared to state-of-the-art machine learning algorithms, the COV-ELM is
found to outperform its competitors in this three-class classification
scenario. Further, LIME has been integrated with the proposed COV-ELM model to
generate annotated CXR images. The annotations are based on the superpixels
that have contributed to distinguish between the different classes. It was
observed that the superpixels correspond to the regions of the human lungs that
are clinically observed in COVID-19 and Pneumonia cases.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ An Empirical <span class="highlight_title">Study</span> of the Collapsing Problem in Semi-Supervised 2D Human Pose Estimation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1">Rongchang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chunyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yizhou Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12498">
                                        <div class="article-summary-box-inner">
                                            <span><p>Semi-supervised learning aims to boost the accuracy of a model by exploring
unlabeled images. The state-of-the-art methods are consistency-based which
learn about unlabeled images by encouraging the model to give consistent
predictions for images under different augmentations. However, when applied to
pose estimation, the methods degenerate and predict every pixel in unlabeled
images as background. This is because contradictory predictions are gradually
pushed to the background class due to highly imbalanced class distribution. But
this is not an issue in supervised learning because it has accurate labels.
This inspires us to stabilize the training by obtaining reliable pseudo labels.
Specifically, we learn two networks to mutually teach each other. In
particular, for each image, we compose an easy-hard pair by applying different
augmentations and feed them to both networks. The more reliable predictions on
easy images in each network are used to teach the other network to learn about
the corresponding hard images. The approach successfully avoids degeneration
and achieves promising results on public datasets. The source code will be
released.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ PREDATOR: Registration of 3D Point Clouds with Low Overlap.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shengyu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gojcic_Z/0/1/0/all/0/1">Zan Gojcic</a>, <a href="http://arxiv.org/find/cs/1/au:+Usvyatsov_M/0/1/0/all/0/1">Mikhail Usvyatsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Wieser_A/0/1/0/all/0/1">Andreas Wieser</a>, <a href="http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1">Konrad Schindler</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13005">
                                        <div class="article-summary-box-inner">
                                            <span><p>We introduce PREDATOR, a model for pairwise point-cloud registration with
deep attention to the overlap region. Different from previous work, our model
is specifically designed to handle (also) point-cloud pairs with low overlap.
Its key novelty is an overlap-attention block for early information exchange
between the latent encodings of the two point clouds. In this way the
subsequent decoding of the latent representations into per-point features is
conditioned on the respective other point cloud, and thus can predict which
points are not only salient, but also lie in the overlap region between the two
point clouds. The ability to focus on points that are relevant for matching
greatly improves performance: PREDATOR raises the rate of successful
registrations by more than 20% in the low-overlap scenario, and also sets a new
state of the art for the 3DMatch benchmark with 89% registration recall.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Photoacoustic Reconstruction Using Sparsity in Curvelet Frame: Image versus Data Domain.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1">Bolin Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Arridge_S/0/1/0/all/0/1">Simon R. Arridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucka_F/0/1/0/all/0/1">Felix Lucka</a>, <a href="http://arxiv.org/find/cs/1/au:+Cox_B/0/1/0/all/0/1">Ben T. Cox</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_N/0/1/0/all/0/1">Nam Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Beard_P/0/1/0/all/0/1">Paul C. Beard</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1">Edward Z. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Betcke_M/0/1/0/all/0/1">Marta M. Betcke</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13080">
                                        <div class="article-summary-box-inner">
                                            <span><p>Curvelet frame is of special significance for photoacoustic tomography (PAT)
due to its sparsifying and microlocalisation properties. We derive a one-to-one
map between wavefront directions in image and data spaces in PAT which suggests
near equivalence between the recovery of the initial pressure and PAT data from
compressed/subsampled measurements when assuming sparsity in Curvelet frame. As
the latter is computationally more tractable, investigation to which extent
this equivalence holds conducted in this paper is of immediate practical
significance. To this end we formulate and compare DR, a two step approach
based on the recovery of the complete volume of the photoacoustic data from the
subsampled data followed by the acoustic inversion, and p0R, a one step
approach where the photoacoustic image (the initial pressure, p0) is directly
recovered from the subsampled data. Effective representation of the
photoacoustic data requires basis defined on the range of the photoacoustic
forward operator. To this end we propose a novel wedge-restriction of Curvelet
transform which enables us to construct such basis. Both recovery problems are
formulated in a variational framework. As the Curvelet frame is heavily
overdetermined, we use reweighted l1 norm penalties to enhance the sparsity of
the solution. The data reconstruction problem DR is a standard compressed
sensing recovery problem, which we solve using an ADMMtype algorithm, SALSA.
Subsequently, the initial pressure is recovered using time reversal as
implemented in the k-Wave Toolbox. The p0 reconstruction problem, p0R, aims to
recover the photoacoustic image directly via FISTA, or ADMM when in addition
including a non-negativity constraint. We compare and discuss the relative
merits of the two approaches and illustrate them on 2D simulated and 3D real
data in a fair and rigorous manner.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ FPCC: Fast Point Cloud Clustering for Instance Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yajun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Arai_S/0/1/0/all/0/1">Shogo Arai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Diyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fangzhou Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosuge_K/0/1/0/all/0/1">Kazuhiro Kosuge</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14618">
                                        <div class="article-summary-box-inner">
                                            <span><p>Instance segmentation is an important pre-processing task in numerous
real-world applications, such as robotics, autonomous vehicles, and
human-computer interaction. Compared with the rapid development of deep
learning for two-dimensional (2D) image tasks, deep learning-based instance
segmentation of 3D point cloud still has a lot of room for development. In
particular, distinguishing a large number of occluded objects of the same class
is a highly challenging problem, which is seen in a robotic bin-picking. In a
usual bin-picking scene, many indentical objects are stacked together and the
model of the objects is known. Thus, the semantic information can be ignored;
instead, the focus in the bin-picking is put on the segmentation of instances.
Based on this task requirement, we propose a Fast Point Cloud Clustering (FPCC)
for instance segmentation of bin-picking scene. FPCC includes a network named
FPCC-Net and a fast clustering algorithm. FPCC-net has two subnets, one for
inferring the geometric centers for clustering and the other for describing
features of each point. FPCC-Net extracts features of each point and infers
geometric center points of each instance simultaneously. After that, the
proposed clustering algorithm clusters the remaining points to the closest
geometric center in feature embedding space. Experiments show that FPCC also
surpasses the existing works in bin-picking scenes and is more computationally
efficient. Our code and data are available at https://github.com/xyjbaal/FPCC.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Hand-Based Person Identification using Global and Part-Aware Deep Feature Representation Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Baisa_N/0/1/0/all/0/1">Nathanael L. Baisa</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zheheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vyas_R/0/1/0/all/0/1">Ritesh Vyas</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_B/0/1/0/all/0/1">Bryan Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmani_H/0/1/0/all/0/1">Hossein Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Angelov_P/0/1/0/all/0/1">Plamen Angelov</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_S/0/1/0/all/0/1">Sue Black</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05260">
                                        <div class="article-summary-box-inner">
                                            <span><p>In cases of serious crime, including sexual abuse, often the only available
information with demonstrated potential for identification is images of the
hands. Since this evidence is captured in uncontrolled situations, it is
difficult to analyse. As global approaches to feature comparison are limited in
this case, it is important to extend to consider local information. In this
work, we propose hand-based person identification by learning both global and
local deep feature representation. Our proposed method, Global and Part-Aware
Network (GPA-Net), creates global and local branches on the conv-layer for
learning robust discriminative global and part-level features. For learning the
local (part-level) features, we perform uniform partitioning on the conv-layer
in both horizontal and vertical directions. We retrieve the parts by conducting
a soft partition without explicitly partitioning the images or requiring
external cues such as pose estimation. We make extensive evaluations on two
large multi-ethnic and publicly available hand datasets, demonstrating that our
proposed method significantly outperforms competing approaches.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yu Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1">Guansong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuanhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rajvinder Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Verjans_J/0/1/0/all/0/1">Johan W. Verjans</a>, <a href="http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1">Gustavo Carneiro</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10030">
                                        <div class="article-summary-box-inner">
                                            <span><p>Anomaly detection with weakly supervised video-level labels is typically
formulated as a multiple instance learning (MIL) problem, in which we aim to
identify snippets containing abnormal events, with each video represented as a
bag of video snippets. Although current methods show effective detection
performance, their recognition of the positive instances, i.e., rare abnormal
snippets in the abnormal videos, is largely biased by the dominant negative
instances, especially when the abnormal events are subtle anomalies that
exhibit only small differences compared with normal events. This issue is
exacerbated in many methods that ignore important video temporal dependencies.
To address this issue, we introduce a novel and theoretically sound method,
named Robust Temporal Feature Magnitude learning (RTFM), which trains a feature
magnitude learning function to effectively recognise the positive instances,
substantially improving the robustness of the MIL approach to the negative
instances from abnormal videos. RTFM also adapts dilated convolutions and
self-attention mechanisms to capture long- and short-range temporal
dependencies to learn the feature magnitude more faithfully. Extensive
experiments show that the RTFM-enabled MIL model (i) outperforms several
state-of-the-art methods by a large margin on four benchmark data sets
(ShanghaiTech, UCF-Crime, XD-Violence and UCSD-Peds) and (ii) achieves
significantly improved subtle anomaly discriminability and sample efficiency.
Code is available at https://github.com/tianyu0207/RTFM.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ BiconNet: An Edge-preserved Connectivity-based Approach for Salient Object Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziyun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltanian_Zadeh_S/0/1/0/all/0/1">Somayyeh Soltanian-Zadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Farsiu_S/0/1/0/all/0/1">Sina Farsiu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00334">
                                        <div class="article-summary-box-inner">
                                            <span><p>Salient object detection (SOD) is viewed as a pixel-wise saliency modeling
task by traditional deep learning-based methods. A limitation of current SOD
models is insufficient utilization of inter-pixel information, which usually
results in imperfect segmentation near edge regions and low spatial coherence.
As we demonstrate, using a saliency mask as the only label is suboptimal. To
address this limitation, we propose a connectivity-based approach called
bilateral connectivity network (BiconNet), which uses connectivity masks
together with saliency masks as labels for effective modeling of inter-pixel
relationships and object saliency. Moreover, we propose a bilateral voting
module to enhance the output connectivity map, and a novel edge feature
enhancement method that efficiently utilizes edge-specific features. Through
comprehensive experiments on five benchmark datasets, we demonstrate that our
proposed method can be plugged into any existing state-of-the-art
saliency-based SOD framework to improve its performance with negligible
parameter increase.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Colonoscopy Polyp Detection and Classification: Dataset Creation and Comparative Evaluations.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kaidong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathan_M/0/1/0/all/0/1">Mohammad I. Fathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_K/0/1/0/all/0/1">Krushi Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianxiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1">Cuncong Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1">Ajay Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1">Amit Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jean S. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10824">
                                        <div class="article-summary-box-inner">
                                            <span><p>Colorectal cancer (CRC) is one of the most common types of cancer with a high
mortality rate. Colonoscopy is the preferred procedure for CRC screening and
has proven to be effective in reducing CRC mortality. Thus, a reliable
computer-aided polyp detection and classification system can significantly
increase the effectiveness of colonoscopy. In this paper, we create an
endoscopic dataset collected from various sources and annotate the ground truth
of polyp location and classification results with the help of experienced
gastroenterologists. The dataset can serve as a benchmark platform to train and
evaluate the machine learning models for polyp classification. We have also
compared the performance of eight state-of-the-art deep learning-based object
detection models. The results demonstrate that deep CNN models are promising in
CRC screening. This work can serve as a baseline for future research in polyp
detection and classification.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Semi-Supervised Semantic Segmentation with Pixel-Level <span class="highlight_title">Contrastive Learning</span> from a Class-wise Memory Bank.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Alonso_I/0/1/0/all/0/1">Inigo Alonso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabater_A/0/1/0/all/0/1">Alberto Sabater</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferstl_D/0/1/0/all/0/1">David Ferstl</a>, <a href="http://arxiv.org/find/cs/1/au:+Montesano_L/0/1/0/all/0/1">Luis Montesano</a>, <a href="http://arxiv.org/find/cs/1/au:+Murillo_A/0/1/0/all/0/1">Ana C. Murillo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13415">
                                        <div class="article-summary-box-inner">
                                            <span><p>This work presents a novel approach for semi-supervised semantic
segmentation. The key element of this approach is our contrastive learning
module that enforces the segmentation network to yield similar pixel-level
feature representations for same-class samples across the whole dataset. To
achieve this, we maintain a memory bank continuously updated with relevant and
high-quality feature vectors from labeled data. In an end-to-end training, the
features from both labeled and unlabeled data are optimized to be similar to
same-class samples from the memory bank. Our approach outperforms the current
state-of-the-art for semi-supervised semantic segmentation and semi-supervised
domain adaptation on well-known public benchmarks, with larger improvements on
the most challenging scenarios, i.e., less available labeled data.
https://github.com/Shathe/SemiSeg-Contrastive
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ SHD360: A Benchmark Dataset for Salient Human Detection in 360{\deg} Videos.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1">Wassim Hamidouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Deforges_O/0/1/0/all/0/1">Olivier Deforges</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11578">
                                        <div class="article-summary-box-inner">
                                            <span><p>Salient human detection (SHD) in dynamic 360{\deg} immersive videos is of
great importance for various applications such as robotics, inter-human and
human-object interaction in augmented reality. However, 360{\deg} video SHD has
been seldom discussed in the computer vision community due to a lack of
datasets with large-scale omnidirectional videos and rich annotations. To this
end, we propose SHD360, the first 360{\deg} video SHD dataset which contains
various real-life daily scenes. Our SHD360 provides six-level hierarchical
annotations for 6,268 key frames uniformly sampled from 37,403 omnidirectional
video frames at 4K resolution. Specifically, each collected frame is labeled
with a super-class, a sub-class, associated attributes (e.g., geometrical
distortion), bounding boxes and per-pixel object-/instance-level masks. As a
result, our SHD360 contains totally 16,238 salient human instances with
manually annotated pixel-wise ground truth. Since so far there is no method
proposed for 360{\deg} image/video SHD, we systematically benchmark 11
representative state-of-the-art salient object detection (SOD) approaches on
our SHD360, and explore key issues derived from extensive experimenting
results. We hope our proposed dataset and benchmark could serve as a good
starting point for advancing human-centric researches towards 360{\deg}
panoramic data. Our dataset and benchmark is publicly available at
https://github.com/PanoAsh/SHD360.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Athey_T/0/1/0/all/0/1">Thomas L. Athey</a>, <a href="http://arxiv.org/find/cs/1/au:+Tward_D/0/1/0/all/0/1">Daniel J. Tward</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_U/0/1/0/all/0/1">Ulrich Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1">Michael I. Miller</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02701">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent advances in brain clearing and imaging have made it possible to image
entire mammalian brains at sub-micron resolution. These images offer the
potential to assemble brain-wide atlases of projection neuron morphology, but
manual neuron reconstruction remains a bottleneck. In this paper we present a
probabilistic method which combines a hidden Markov state process that encodes
neuron geometric properties with a random field appearance model of the
flourescence process. Our method utilizes dynamic programming to efficiently
compute the global maximizers of what we call the "most probable" neuron path.
We applied our algorithm to the output of image segmentation models where false
negatives severed neuronal processes, and showed that it can follow axons in
the presence of noise or nearby neurons. Our method has the potential to be
integrated into a semi or fully automated reconstruction pipeline.
Additionally, it creates a framework for conditioning the probability to fixed
start and endpoints through which users can intervene with hard constraints to,
for example, rule out certain reconstructions, or assign axons to particular
cell bodies.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ <span class="highlight_title">Contrastive</span> Semi-Supervised Learning for 2D Medical Image Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1">Prashant Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1">Ajey Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatt_N/0/1/0/all/0/1">Nisarg Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1">Prasenjit Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Makharia_G/0/1/0/all/0/1">Govind Makharia</a>, <a href="http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1">Prathosh AP</a>, <a href="http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1">Mausam</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06801">
                                        <div class="article-summary-box-inner">
                                            <span><p>Contrastive Learning (CL) is a recent representation learning approach, which
encourages inter-class separability and intra-class compactness in learned
image representations. Since medical images often contain multiple semantic
classes in an image, using CL to learn representations of local features (as
opposed to global) is important. In this work, we present a novel
semi-supervised 2D medical segmentation solution that applies CL on image
patches, instead of full images. These patches are meaningfully constructed
using the semantic information of different classes obtained via pseudo
labeling. We also propose a novel consistency regularization (CR) scheme, which
works in synergy with CL. It addresses the problem of confirmation bias, and
encourages better clustering in the feature space. We evaluate our method on
four public medical segmentation datasets and a novel histopathology dataset
that we introduce. Our method obtains consistent improvements over
state-of-the-art semi-supervised segmentation approaches for all datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Computer-aided Interpretable Features for Leaf Image Classification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lakshika_J/0/1/0/all/0/1">Jayani P. G. Lakshika</a>, <a href="http://arxiv.org/find/cs/1/au:+Talagala_T/0/1/0/all/0/1">Thiyanga S. Talagala</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08077">
                                        <div class="article-summary-box-inner">
                                            <span><p>Plant species identification is time consuming, costly, and requires lots of
efforts, and expertise knowledge. In recent, many researchers use deep learning
methods to classify plants directly using plant images. While deep learning
models have achieved a great success, the lack of interpretability limit their
widespread application. To overcome this, we explore the use of interpretable,
measurable and computer-aided features extracted from plant leaf images. Image
processing is one of the most challenging, and crucial steps in
feature-extraction. The purpose of image processing is to improve the leaf
image by removing undesired distortion. The main image processing steps of our
algorithm involves: i) Convert original image to RGB (Red-Green-Blue) image,
ii) Gray scaling, iii) Gaussian smoothing, iv) Binary thresholding, v) Remove
stalk, vi) Closing holes, and vii) Resize image. The next step after image
processing is to extract features from plant leaf images. We introduced 52
computationally efficient features to classify plant species. These features
are mainly classified into four groups as: i) shape-based features, ii)
color-based features, iii) texture-based features, and iv) scagnostic features.
Length, width, area, texture correlation, monotonicity and scagnostics are to
name few of them. We explore the ability of features to discriminate the
classes of interest under supervised learning and unsupervised learning
settings. For that, supervised dimensionality reduction technique, Linear
Discriminant Analysis (LDA), and unsupervised dimensionality reduction
technique, Principal Component Analysis (PCA) are used to convert and visualize
the images from digital-image space to feature space. The results show that the
features are sufficient to discriminate the classes of interest under both
supervised and unsupervised learning settings.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ End-to-End Semi-Supervised Object Detection with Soft Teacher.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengde Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Han Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Fangyun Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09018">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper presents an end-to-end semi-supervised object detection approach,
in contrast to previous more complex multi-stage methods. The end-to-end
training gradually improves pseudo label qualities during the curriculum, and
the more and more accurate pseudo labels in turn benefit object detection
training. We also propose two simple yet effective techniques within this
framework: a soft teacher mechanism where the classification loss of each
unlabeled bounding box is weighed by the classification score produced by the
teacher network; a box jittering approach to select reliable pseudo boxes for
the learning of box regression. On the COCO benchmark, the proposed approach
outperforms previous methods by a large margin under various labeling ratios,
i.e. 1\%, 5\% and 10\%. Moreover, our approach proves to perform also well when
the amount of labeled data is relatively large. For example, it can improve a
40.9 mAP baseline detector trained using the full COCO training set by +3.6
mAP, reaching 44.5 mAP, by leveraging the 123K unlabeled images of COCO. On the
state-of-the-art Swin Transformer based object detector (58.9 mAP on test-dev),
it can still significantly improve the detection accuracy by +1.5 mAP, reaching
60.4 mAP, and improve the instance segmentation accuracy by +1.2 mAP, reaching
52.4 mAP. Further incorporating with the Object365 pre-trained model, the
detection accuracy reaches 61.3 mAP and the instance segmentation accuracy
reaches 53.0 mAP, pushing the new state-of-the-art.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On Designing Good Representation Learning Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Garibaldi_J/0/1/0/all/0/1">Jonathan M Garibaldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_G/0/1/0/all/0/1">Guoping Qiu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05948">
                                        <div class="article-summary-box-inner">
                                            <span><p>The goal of representation learning is different from the ultimate objective
of machine learning such as decision making, it is therefore very difficult to
establish clear and direct objectives for training representation learning
models. It has been argued that a good representation should disentangle the
underlying variation factors, yet how to translate this into training
objectives remains unknown. This paper presents an attempt to establish direct
training criterions and design principles for developing good representation
learning models. We propose that a good representation learning model should be
maximally expressive, i.e., capable of distinguishing the maximum number of
input configurations. We formally define expressiveness and introduce the
maximum expressiveness (MEXS) theorem of a general learning model. We propose
to train a model by maximizing its expressiveness while at the same time
incorporating general priors such as model smoothness. We present a conscience
competitive learning algorithm which encourages the model to reach its MEXS
whilst at the same time adheres to model smoothness prior. We also introduce a
label consistent training (LCT) technique to boost model smoothness by
encouraging it to assign consistent labels to similar samples. We present
extensive experimental results to show that our method can indeed design
representation learning models capable of developing representations that are
as good as or better than state of the art. We also show that our technique is
computationally efficient, robust against different parameter settings and can
work effectively on a variety of datasets. Code available at
https://github.com/qlilx/odgrlm.git
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ <span class="highlight_title">Self-Supervised</span> <span class="highlight_title">Multi-Modal</span> Alignment for Whole Body Medical Imaging.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Windsor_R/0/1/0/all/0/1">Rhydian Windsor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamaludin_A/0/1/0/all/0/1">Amir Jamaludin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadir_T/0/1/0/all/0/1">Timor Kadir</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1">Andrew Zisserman</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06652">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper explores the use of self-supervised deep learning in medical
imaging in cases where two scan modalities are available for the same subject.
Specifically, we use a large publicly-available dataset of over 20,000 subjects
from the UK Biobank with both whole body Dixon technique magnetic resonance
(MR) scans and also dual-energy x-ray absorptiometry (DXA) scans. We make three
contributions: (i) We introduce a multi-modal image-matching contrastive
framework, that is able to learn to match different-modality scans of the same
subject with high accuracy. (ii) Without any adaption, we show that the
correspondences learnt during this contrastive training step can be used to
perform automatic cross-modal scan registration in a completely unsupervised
manner. (iii) Finally, we use these registrations to transfer segmentation maps
from the DXA scans to the MR scans where they are used to train a network to
segment anatomical regions without requiring ground-truth MR examples. To aid
further research, our code will be made publicly available.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ YOLOX: Exceeding YOLO Series in 2021.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zheng Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Songtao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Feng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zeming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08430">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this report, we present some experienced improvements to YOLO series,
forming a new high-performance detector -- YOLOX. We switch the YOLO detector
to an anchor-free manner and conduct other advanced detection techniques, i.e.,
a decoupled head and the leading label assignment strategy SimOTA to achieve
state-of-the-art results across a large scale range of models: For YOLO-Nano
with only 0.91M parameters and 1.08G FLOPs, we get 25.3% AP on COCO, surpassing
NanoDet by 1.8% AP; for YOLOv3, one of the most widely used detectors in
industry, we boost it to 47.3% AP on COCO, outperforming the current best
practice by 3.0% AP; for YOLOX-L with roughly the same amount of parameters as
YOLOv4-CSP, YOLOv5-L, we achieve 50.0% AP on COCO at a speed of 68.9 FPS on
Tesla V100, exceeding YOLOv5-L by 1.8% AP. Further, we won the 1st Place on
Streaming Perception Challenge (Workshop on Autonomous Driving at CVPR 2021)
using a single YOLOX-L model. We hope this report can provide useful experience
for developers and researchers in practical scenes, and we also provide deploy
versions with ONNX, TensorRT, NCNN, and Openvino supported. Source code is at
https://github.com/Megvii-BaseDetection/YOLOX.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Image Fusion <span class="highlight_title">Transformer</span>.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+VS_V/0/1/0/all/0/1">Vibashan VS</a>, <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Oza_P/0/1/0/all/0/1">Poojan Oza</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09011">
                                        <div class="article-summary-box-inner">
                                            <span><p>In image fusion, images obtained from different sensors are fused to generate
a single image with enhanced information. In recent years, state-of-the-art
methods have adopted Convolution Neural Networks (CNNs) to encode meaningful
features for image fusion. Specifically, CNN-based methods perform image fusion
by fusing local features. However, they do not consider long-range dependencies
that are present in the image. Transformer-based models are designed to
overcome this by modeling the long-range dependencies with the help of
self-attention mechanism. This motivates us to propose a novel Image Fusion
Transformer (IFT) where we develop a transformer-based multi-scale fusion
strategy that attends to both local and long-range information (or global
context). The proposed method follows a two-stage training approach. In the
first stage, we train an auto-encoder to extract deep features at multiple
scales. In the second stage, multi-scale features are fused using a
Spatio-Transformer (ST) fusion strategy. The ST fusion blocks are comprised of
a CNN and a transformer branch which capture local and long-range features,
respectively. Extensive experiments on multiple benchmark datasets show that
the proposed method performs better than many competitive fusion algorithms.
Furthermore, we show the effectiveness of the proposed ST fusion strategy with
an ablation analysis. The source code is available at:
https://github.com/Vibashan/Image-Fusion-Transformer.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Human Pose Transfer with Disentangled Feature Consistency.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1">Chengxiang Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1">Zhengping Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1"><span class="highlight_author">Jian Tang</span></a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Z/0/1/0/all/0/1">Zheng Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Gangyi Ding</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10984">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep generative models have made great progress in synthesizing images with
arbitrary human poses and transferring poses of one person to others. However,
most existing approaches explicitly leverage the pose information extracted
from the source images as a conditional input for the generative networks.
Meanwhile, they usually focus on the visual fidelity of the synthesized images
but neglect the inherent consistency, which further confines their performance
of pose transfer. To alleviate the current limitations and improve the quality
of the synthesized images, we propose a pose transfer network with Disentangled
Feature Consistency (DFC-Net) to facilitate human pose transfer. Given a pair
of images containing the source and target person, DFC-Net extracts pose and
static information from the source and target respectively, then synthesizes an
image of the target person with the desired pose from the source. Moreover,
DFC-Net leverages disentangled feature consistency losses in the adversarial
training to strengthen the transfer coherence and integrates the keypoint
amplifier to enhance the pose feature extraction. Additionally, an unpaired
support dataset Mixamo-Sup providing more extra pose information has been
further utilized during the training to improve the generality and robustness
of DFC-Net. Extensive experimental results on Mixamo-Pose and EDN-10k have
demonstrated DFC-Net achieves state-of-the-art performance on pose transfer.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Exploiting <span class="highlight_title">BERT</span> For Multimodal Target Sentiment Classification Through Input Space Translation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khan_Z/0/1/0/all/0/1">Zaid Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yun Fu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01682">
                                        <div class="article-summary-box-inner">
                                            <span><p>Multimodal target/aspect sentiment classification combines multimodal
sentiment analysis and aspect/target sentiment classification. The goal of the
task is to combine vision and language to understand the sentiment towards a
target entity in a sentence. Twitter is an ideal setting for the task because
it is inherently multimodal, highly emotional, and affects real world events.
However, multimodal tweets are short and accompanied by complex, possibly
irrelevant images. We introduce a two-stream model that translates images in
input space using an object-aware transformer followed by a single-pass
non-autoregressive text generation approach. We then leverage the translation
to construct an auxiliary sentence that provides multimodal information to a
language model. Our approach increases the amount of text available to the
language model and distills the object-level information in complex images. We
achieve state-of-the-art performance on two multimodal Twitter datasets without
modifying the internals of the language model to accept multimodal data,
demonstrating the effectiveness of our translation. In addition, we explain a
failure mode of a popular approach for aspect sentiment analysis when applied
to tweets. Our code is available at
\textcolor{blue}{\url{https://github.com/codezakh/exploiting-BERT-thru-translation}}.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ M2IOSR: Maximal Mutual Information Open Set Recognition.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Henghui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_K/0/1/0/all/0/1">Keck-Voon Ling</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02373">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this work, we aim to address the challenging task of open set recognition
(OSR). Many recent OSR methods rely on auto-encoders to extract class-specific
features by a reconstruction strategy, requiring the network to restore the
input image on pixel-level. This strategy is commonly over-demanding for OSR
since class-specific features are generally contained in target objects, not in
all pixels. To address this shortcoming, here we discard the pixel-level
reconstruction strategy and pay more attention to improving the effectiveness
of class-specific feature extraction. We propose a mutual information-based
method with a streamlined architecture, Maximal Mutual Information Open Set
Recognition (M2IOSR). The proposed M2IOSR only uses an encoder to extract
class-specific features by maximizing the mutual information between the given
input and its latent features across multiple scales. Meanwhile, to further
reduce the open space risk, latent features are constrained to class
conditional Gaussian distributions by a KL-divergence loss function. In this
way, a strong function is learned to prevent the network from mapping different
observations to similar latent features and help the network extract
class-specific features with desired statistical characteristics. The proposed
method significantly improves the performance of baselines and achieves new
state-of-the-art results on several benchmarks consistently.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Global and Local Texture Randomization for Synthetic-to-Real Semantic Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Duo Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1">Yinjie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingqiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pingping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02376">
                                        <div class="article-summary-box-inner">
                                            <span><p>Semantic segmentation is a crucial image understanding task, where each pixel
of image is categorized into a corresponding label. Since the pixel-wise
labeling for ground-truth is tedious and labor intensive, in practical
applications, many works exploit the synthetic images to train the model for
real-word image semantic segmentation, i.e., Synthetic-to-Real Semantic
Segmentation (SRSS). However, Deep Convolutional Neural Networks (CNNs) trained
on the source synthetic data may not generalize well to the target real-world
data. In this work, we propose two simple yet effective texture randomization
mechanisms, Global Texture Randomization (GTR) and Local Texture Randomization
(LTR), for Domain Generalization based SRSS. GTR is proposed to randomize the
texture of source images into diverse unreal texture styles. It aims to
alleviate the reliance of the network on texture while promoting the learning
of the domain-invariant cues. In addition, we find the texture difference is
not always occurred in entire image and may only appear in some local areas.
Therefore, we further propose a LTR mechanism to generate diverse local regions
for partially stylizing the source images. Finally, we implement a
regularization of Consistency between GTR and LTR (CGL) aiming to harmonize the
two proposed mechanisms during training. Extensive experiments on five publicly
available datasets (i.e., GTA5, SYNTHIA, Cityscapes, BDDS and Mapillary) with
various SRSS settings (i.e., GTA5/SYNTHIA to Cityscapes/BDDS/Mapillary)
demonstrate that the proposed method is superior to the state-of-the-art
methods for domain generalization based SRSS.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ MFuseNet: Robust Depth Estimation with Learned Multiscopic Fusion.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weihao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1">Rui Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Michael Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02448">
                                        <div class="article-summary-box-inner">
                                            <span><p>We design a multiscopic vision system that utilizes a low-cost monocular RGB
camera to acquire accurate depth estimation. Unlike multi-view stereo with
images captured at unconstrained camera poses, the proposed system controls the
motion of a camera to capture a sequence of images in horizontally or
vertically aligned positions with the same parallax. In this system, we propose
a new heuristic method and a robust learning-based method to fuse multiple cost
volumes between the reference image and its surrounding images. To obtain
training data, we build a synthetic dataset with multiscopic images. The
experiments on the real-world Middlebury dataset and real robot demonstration
show that our multiscopic vision system outperforms traditional two-frame
stereo matching methods in depth estimation. Our code and dataset are available
at https://sites.google.com/view/multiscopic.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Recursive Fusion and Deformable Spatiotemporal Attention for Video Compression Artifact Reduction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Zhao_M/0/1/0/all/0/1">Minyi Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1">Shuigeng Zhou</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02110">
                                        <div class="article-summary-box-inner">
                                            <span><p>A number of deep learning based algorithms have been proposed to recover
high-quality videos from low-quality compressed ones. Among them, some restore
the missing details of each frame via exploring the spatiotemporal information
of neighboring frames. However, these methods usually suffer from a narrow
temporal scope, thus may miss some useful details from some frames outside the
neighboring ones. In this paper, to boost artifact removal, on the one hand, we
propose a Recursive Fusion (RF) module to model the temporal dependency within
a long temporal range. Specifically, RF utilizes both the current reference
frames and the preceding hidden state to conduct better spatiotemporal
compensation. On the other hand, we design an efficient and effective
Deformable Spatiotemporal Attention (DSTA) module such that the model can pay
more effort on restoring the artifact-rich areas like the boundary area of a
moving object. Extensive experiments show that our method outperforms the
existing ones on the MFQE 2.0 dataset in terms of both fidelity and perceptual
effect. Code is available at https://github.com/zhaominyiz/RFDA-PyTorch.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
                <li class="source">
                    <!--<details>-->
                    <!--<summary>-->
                    <h3 class="source-name">
                        <a class="source-name__link" href="">cs.LG updates on arXiv.org </a>
                    </h3>
                    <!--</summary>-->
                    <section>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Quantum Continual Learning Overcoming Catastrophic Forgetting.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenjie Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhide Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_D/0/1/0/all/0/1">Dong-Ling Deng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02786">
                                        <div class="article-summary-box-inner">
                                            <span><p>Catastrophic forgetting describes the fact that machine learning models will
likely forget the knowledge of previously learned tasks after the learning
process of a new one. It is a vital problem in the continual learning scenario
and recently has attracted tremendous concern across different communities. In
this paper, we explore the catastrophic forgetting phenomena in the context of
quantum machine learning. We find that, similar to those classical learning
models based on neural networks, quantum learning systems likewise suffer from
such forgetting problem in classification tasks emerging from various
application scenes. We show that based on the local geometrical information in
the loss function landscape of the trained model, a uniform strategy can be
adapted to overcome the forgetting problem in the incremental learning setting.
Our results uncover the catastrophic forgetting phenomena in quantum machine
learning and offer a practical method to overcome this problem, which opens a
new avenue for exploring potential quantum advantages towards continual
learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ <span class="highlight_title">Self-Supervised</span> Learning from Unlabeled Fundus Photographs Improves Segmentation of the Retina.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kukacka_J/0/1/0/all/0/1">Jan Kuka&#x10d;ka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenz_A/0/1/0/all/0/1">Anja Zenz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kollovieh_M/0/1/0/all/0/1">Marcel Kollovieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Justel_D/0/1/0/all/0/1">Dominik J&#xfc;stel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntziachristos_V/0/1/0/all/0/1">Vasilis Ntziachristos</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02798">
                                        <div class="article-summary-box-inner">
                                            <span><p>Fundus photography is the primary method for retinal imaging and essential
for diabetic retinopathy prevention. Automated segmentation of fundus
photographs would improve the quality, capacity, and cost-effectiveness of eye
care screening programs. However, current segmentation methods are not robust
towards the diversity in imaging conditions and pathologies typical for
real-world clinical applications. To overcome these limitations, we utilized
contrastive self-supervised learning to exploit the large variety of unlabeled
fundus images in the publicly available EyePACS dataset. We pre-trained an
encoder of a U-Net, which we later fine-tuned on several retinal vessel and
lesion segmentation datasets. We demonstrate for the first time that by using
contrastive self-supervised learning, the pre-trained network can recognize
blood vessels, optic disc, fovea, and various lesions without being provided
any labels. Furthermore, when fine-tuned on a downstream blood vessel
segmentation task, such pre-trained networks achieve state-of-the-art
performance on images from different datasets. Additionally, the pre-training
also leads to shorter training times and an improved few-shot performance on
both blood vessel and lesion segmentation tasks. Altogether, our results
showcase the benefits of contrastive self-supervised pre-training which can
play a crucial role in real-world clinical applications requiring robust models
able to adapt to new devices with only a few annotated samples.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Using Machine Learning to Predict Game Outcomes Based on Player-Champion Experience in League of Legends.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1">Tiffany D. Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Seong Ioi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dylan S. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+McMillian_M/0/1/0/all/0/1">Matthew G. McMillian</a>, <a href="http://arxiv.org/find/cs/1/au:+McMahan_R/0/1/0/all/0/1">Ryan P. McMahan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02799">
                                        <div class="article-summary-box-inner">
                                            <span><p>League of Legends (LoL) is the most widely played multiplayer online battle
arena (MOBA) game in the world. An important aspect of LoL is competitive
ranked play, which utilizes a skill-based matchmaking system to form fair
teams. However, players' skill levels vary widely depending on which champion,
or hero, that they choose to play as. In this paper, we propose a method for
predicting game outcomes in ranked LoL games based on players' experience with
their selected champion. Using a deep neural network, we found that game
outcomes can be predicted with 75.1% accuracy after all players have selected
champions, which occurs before gameplay begins. Our results have important
implications for playing LoL and matchmaking. Firstly, individual champion
skill plays a significant role in the outcome of a match, regardless of team
composition. Secondly, even after the skill-based matchmaking, there is still a
wide variance in team skill before gameplay begins. Finally, players should
only play champions that they have mastered, if they want to win games.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Quantum Topological Data Analysis with Linear Depth and Exponential Speedup.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/quant-ph/1/au:+Ubaru_S/0/1/0/all/0/1">Shashanka Ubaru</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Akhalwaya_I/0/1/0/all/0/1">Ismail Yunus Akhalwaya</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Squillante_M/0/1/0/all/0/1">Mark S. Squillante</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Clarkson_K/0/1/0/all/0/1">Kenneth L. Clarkson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Horesh_L/0/1/0/all/0/1">Lior Horesh</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02811">
                                        <div class="article-summary-box-inner">
                                            <span><p>Quantum computing offers the potential of exponential speedups for certain
classical computations. Over the last decade, many quantum machine learning
(QML) algorithms have been proposed as candidates for such exponential
improvements. However, two issues unravel the hope of exponential speedup for
some of these QML algorithms: the data-loading problem and, more recently, the
stunning dequantization results of Tang et al. A third issue, namely the
fault-tolerance requirements of most QML algorithms, has further hindered their
practical realization. The quantum topological data analysis (QTDA) algorithm
of Lloyd, Garnerone and Zanardi was one of the first QML algorithms that
convincingly offered an expected exponential speedup. From the outset, it did
not suffer from the data-loading problem. A recent result has also shown that
the generalized problem solved by this algorithm is likely classically
intractable, and would therefore be immune to any dequantization efforts.
However, the QTDA algorithm of Lloyd et~al. has a time complexity of
$O(n^4/(\epsilon^2 \delta))$ (where $n$ is the number of data points,
$\epsilon$ is the error tolerance, and $\delta$ is the smallest nonzero
eigenvalue of the restricted Laplacian) and requires fault-tolerant quantum
computing, which has not yet been achieved. In this paper, we completely
overhaul the QTDA algorithm to achieve an improved exponential speedup and
depth complexity of $O(n\log(1/(\delta\epsilon)))$. Our approach includes three
key innovations: (a) an efficient realization of the combinatorial Laplacian as
a sum of Pauli operators; (b) a quantum rejection sampling approach to restrict
the superposition to the simplices in the complex; and (c) a stochastic rank
estimation method to estimate the Betti numbers. We present a theoretical error
analysis, and the circuit and computational time and depth complexities for
Betti number estimation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Potential Applications of Artificial Intelligence and Machine Learning in Radiochemistry and Radiochemical Engineering.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Webb_E/0/1/0/all/0/1">E. William Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+Scott_P/0/1/0/all/0/1">Peter J.H. Scott</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02814">
                                        <div class="article-summary-box-inner">
                                            <span><p>Artificial intelligence and machine learning are poised to disrupt PET
imaging from bench to clinic. In this perspective we offer insights into how
the technology could be applied to improve the design and synthesis of new
radiopharmaceuticals for PET imaging, including identification of an optimal
labeling approach as well as strategies for radiolabeling reaction
optimization.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ THALIS: Human-Machine Analysis of Longitudinal Symptoms in Cancer Therapy.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Floricel_C/0/1/0/all/0/1">Carla Floricel</a>, <a href="http://arxiv.org/find/cs/1/au:+Nipu_N/0/1/0/all/0/1">Nafiul Nipu</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggs_M/0/1/0/all/0/1">Mikayla Biggs</a>, <a href="http://arxiv.org/find/cs/1/au:+Wentzel_A/0/1/0/all/0/1">Andrew Wentzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Canahuate_G/0/1/0/all/0/1">Guadalupe Canahuate</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijk_L/0/1/0/all/0/1">Lisanne Van Dijk</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Abdallah Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuller_C/0/1/0/all/0/1">C. David Fuller</a>, <a href="http://arxiv.org/find/cs/1/au:+Marai_G/0/1/0/all/0/1">G. Elisabeta Marai</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02817">
                                        <div class="article-summary-box-inner">
                                            <span><p>Although cancer patients survive years after oncologic therapy, they are
plagued with long-lasting or permanent residual symptoms, whose severity, rate
of development, and resolution after treatment vary largely between survivors.
The analysis and interpretation of symptoms is complicated by their partial
co-occurrence, variability across populations and across time, and, in the case
of cancers that use radiotherapy, by further symptom dependency on the tumor
location and prescribed treatment. We describe THALIS, an environment for
visual analysis and knowledge discovery from cancer therapy symptom data,
developed in close collaboration with oncology experts. Our approach leverages
unsupervised machine learning methodology over cohorts of patients, and, in
conjunction with custom visual encodings and interactions, provides context for
new patients based on patients with similar diagnostic features and symptom
evolution. We evaluate this approach on data collected from a cohort of head
and neck cancer patients. Feedback from our clinician collaborators indicates
that THALIS supports knowledge discovery beyond the limits of machines or
humans alone, and that it serves as a valuable tool in both the clinic and
symptom research.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ An Elementary Proof that Q-learning Converges Almost Surely.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Regehr_M/0/1/0/all/0/1">Matthew T. Regehr</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayoub_A/0/1/0/all/0/1">Alex Ayoub</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02827">
                                        <div class="article-summary-box-inner">
                                            <span><p>Watkins' and Dayan's Q-learning is a model-free reinforcement learning
algorithm that iteratively refines an estimate for the optimal action-value
function of an MDP by stochastically "visiting" many state-ation pairs [Watkins
and Dayan, 1992]. Variants of the algorithm lie at the heart of numerous recent
state-of-the-art achievements in reinforcement learning, including the
superhuman Atari-playing deep Q-network [Mnih et al., 2015]. The goal of this
paper is to reproduce a precise and (nearly) self-contained proof that
Q-learning converges. Much of the available literature leverages powerful
theory to obtain highly generalizable results in this vein. However, this
approach requires the reader to be familiar with and make many deep connections
to different research areas. A student seeking to deepen their understand of
Q-learning risks becoming caught in a vicious cycle of "RL-learning Hell". For
this reason, we give a complete proof from start to finish using only one
external result from the field of stochastic approximation, despite the fact
that this minimal dependence on other results comes at the expense of some
"shininess".
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Hate Speech Detection in Roman Urdu.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Moin Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahzad_K/0/1/0/all/0/1">Khurram Shahzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1">Kamran Malik</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02830">
                                        <div class="article-summary-box-inner">
                                            <span><p>Hate speech is a specific type of controversial content that is widely
legislated as a crime that must be identified and blocked. However, due to the
sheer volume and velocity of the Twitter data stream, hate speech detection
cannot be performed manually. To address this issue, several studies have been
conducted for hate speech detection in European languages, whereas little
attention has been paid to low-resource South Asian languages, making the
social media vulnerable for millions of users. In particular, to the best of
our knowledge, no study has been conducted for hate speech detection in Roman
Urdu text, which is widely used in the sub-continent. In this study, we have
scrapped more than 90,000 tweets and manually parsed them to identify 5,000
Roman Urdu tweets. Subsequently, we have employed an iterative approach to
develop guidelines and used them for generating the Hate Speech Roman Urdu 2020
corpus. The tweets in the this corpus are classified at three levels:
Neutral-Hostile, Simple-Complex, and Offensive-Hate speech. As another
contribution, we have used five supervised learning techniques, including a
deep learning technique, to evaluate and compare their effectiveness for hate
speech detection. The results show that Logistic Regression outperformed all
other techniques, including deep learning techniques for the two levels of
classification, by achieved an F1 score of 0.906 for distinguishing between
Neutral-Hostile tweets, and 0.756 for distinguishing between Offensive-Hate
speech tweets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Differentially Private n-gram Extraction.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kunho Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1">Sivakanth Gopi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1">Janardhan Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yekhanin_S/0/1/0/all/0/1">Sergey Yekhanin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02831">
                                        <div class="article-summary-box-inner">
                                            <span><p>We revisit the problem of $n$-gram extraction in the differential privacy
setting. In this problem, given a corpus of private text data, the goal is to
release as many $n$-grams as possible while preserving user level privacy.
Extracting $n$-grams is a fundamental subroutine in many NLP applications such
as sentence completion, response generation for emails etc. The problem also
arises in other applications such as sequence mining, and is a generalization
of recently studied differentially private set union (DPSU). In this paper, we
develop a new differentially private algorithm for this problem which, in our
experiments, significantly outperforms the state-of-the-art. Our improvements
stem from combining recent advances in DPSU, privacy accounting, and new
heuristics for pruning in the tree-based approach initiated by Chen et al.
(2012).
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Efficient recurrent neural network methods for anomalously diffusing single particle short and noisy trajectories.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Orts_O/0/1/0/all/0/1">&#xd2;scar Garibo i Orts</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_March_M/0/1/0/all/0/1">Miguel A. Garcia-March</a>, <a href="http://arxiv.org/find/cs/1/au:+Conejero_J/0/1/0/all/0/1">J. Alberto Conejero</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02834">
                                        <div class="article-summary-box-inner">
                                            <span><p>Anomalous diffusion occurs at very different scales in nature, from atomic
systems to motions in cell organelles, biological tissues or ecology, and also
in artificial materials, such as cement. Being able to accurately measure the
anomalous exponent associated with a given particle trajectory, thus
determining whether the particle subdiffuses, superdiffuses or performs normal
diffusion is of key importance to understand the diffusion process. Also, it is
often important to trustingly identify the model behind the trajectory, as this
gives a large amount of information on the system dynamics. Both aspects are
particularly difficult when the input data are short and noisy trajectories. It
is even more difficult if one cannot guarantee that the trajectories output in
experiments is homogeneous, hindering the statistical methods based on
ensembles of trajectories. We present a data-driven method able to infer the
anomalous exponent and to identify the type of anomalous diffusion process
behind single, noisy and short trajectories, with good accuracy. This model was
used in our participation in the Anomalous Diffusion (AnDi) Challenge. A
combination of convolutional and recurrent neural networks were used to achieve
state-of-the-art results when compared to methods participating in the AnDi
Challenge, ranking top 4 in both classification and diffusion exponent
regression.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Lossless Multi-Scale Constitutive Elastic Relations with Artificial Intelligence.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cond-mat/1/au:+Mianroodi_J/0/1/0/all/0/1">Jaber Rezaei Mianroodi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Rezaei_S/0/1/0/all/0/1">Shahed Rezaei</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Siboni_N/0/1/0/all/0/1">Nima H. Siboni</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Xu_B/0/1/0/all/0/1">Bai-Xiang Xu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Raabe_D/0/1/0/all/0/1">Dierk Raabe</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02837">
                                        <div class="article-summary-box-inner">
                                            <span><p>The elastic properties of materials derive from their electronic and atomic
nature. However, simulating bulk materials fully at these scales is not
feasible, so that typically homogenized continuum descriptions are used
instead. A seamless and lossless transition of the constitutive description of
the elastic response of materials between these two scales has been so far
elusive. Here we show how this problem can be overcome by using Artificial
Intelligence (AI). A Convolutional Neural Network (CNN) model is trained, by
taking the structure image of a nanoporous material as input and the
corresponding elasticity tensor, calculated from Molecular Statics (MS), as
output. Trained with the atomistic data, the CNN model captures the size- and
pore-dependency of the material's elastic properties which, on the physics
side, can stem from surfaces and non-local effects. Such effects are often
ignored in upscaling from atomistic to classical continuum theory. To
demonstrate the accuracy and the efficiency of the trained CNN model, a Finite
Element Method (FEM) based result of an elastically deformed nanoporous beam
equipped with the CNN as constitutive law is compared with that by a full
atomistic simulation. The good agreement between the atomistic simulations and
the FEM-AI combination for a system with size and surface effects establishes a
new lossless scale bridging approach to such problems. The trained CNN model
deviates from the atomistic result by 9.6\% for porosity scenarios of up to
90\% but it is about 230 times faster than the MS calculation and does not
require to change simulation methods between different scales. The efficiency
of the CNN evaluation together with the preservation of important atomistic
effects makes the trained model an effective atomistically-informed
constitutive model for macroscopic simulations of nanoporous materials and
solving of inverse problems.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Two-Stage Sector Rotation Methodology Using Machine Learning and Deep Learning Techniques.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/q-fin/1/au:+Karatas_T/0/1/0/all/0/1">Tugce Karatas</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Hirsa_A/0/1/0/all/0/1">Ali Hirsa</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02838">
                                        <div class="article-summary-box-inner">
                                            <span><p>Market indicators such as CPI and GDP have been widely used over decades to
identify the stage of business cycles and also investment attractiveness of
sectors given market conditions. In this paper, we propose a two-stage
methodology that consists of predicting ETF prices for each sector using market
indicators and ranking sectors based on their predicted rate of returns. We
initially start with choosing sector specific macroeconomic indicators and
implement Recursive Feature Elimination algorithm to select the most important
features for each sector. Using our prediction tool, we implement different
Recurrent Neural Networks models to predict the future ETF prices for each
sector. We then rank the sectors based on their predicted rate of returns. We
select the best performing model by evaluating the annualized return,
annualized Sharpe ratio, and Calmar ratio of the portfolios that includes the
top four ranked sectors chosen by the model. We also test the robustness of the
model performance with respect to lookback windows and look ahead windows. Our
empirical results show that our methodology beats the equally weighted
portfolio performance even in the long run. We also find that Echo State
Networks exhibits an outstanding performance compared to other models yet it is
faster to implement compared to other RNN models.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Multimodal Meta-Learning for Time Series Regression.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Arango_S/0/1/0/all/0/1">Sebastian Pineda Arango</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinrich_F/0/1/0/all/0/1">Felix Heinrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Madhusudhanan_K/0/1/0/all/0/1">Kiran Madhusudhanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1">Lars Schmidt-Thieme</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02842">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent work has shown the efficiency of deep learning models such as Fully
Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with
Time Series Regression (TSR) problems. These models sometimes need a lot of
data to be able to generalize, yet the time series are sometimes not long
enough to be able to learn patterns. Therefore, it is important to make use of
information across time series to improve learning. In this paper, we will
explore the idea of using meta-learning for quickly adapting model parameters
to new short-history time series by modifying the original idea of Model
Agnostic Meta-Learning (MAML) \cite{finn2017model}. Moreover, based on prior
work on multimodal MAML \cite{vuorio2019multimodal}, we propose a method for
conditioning parameters of the model through an auxiliary network that encodes
global information of the time series to extract meta-features. Finally, we
apply the data to time series of different domains, such as pollution
measurements, heart-rate sensors, and electrical battery data. We show
empirically that our proposed meta-learning method learns TSR with few data
fast and outperforms the baselines in 9 of 12 experiments.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Communicative Learning with Natural Gestures for Embodied Navigation Agents with Human-in-the-Scene.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cheng-Ju Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yixin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Joo_J/0/1/0/all/0/1">Jungseock Joo</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02846">
                                        <div class="article-summary-box-inner">
                                            <span><p>Human-robot collaboration is an essential research topic in artificial
intelligence (AI), enabling researchers to devise cognitive AI systems and
affords an intuitive means for users to interact with the robot. Of note,
communication plays a central role. To date, prior studies in embodied agent
navigation have only demonstrated that human languages facilitate communication
by instructions in natural languages. Nevertheless, a plethora of other forms
of communication is left unexplored. In fact, human communication originated in
gestures and oftentimes is delivered through multimodal cues, e.g. "go there"
with a pointing gesture. To bridge the gap and fill in the missing dimension of
communication in embodied agent navigation, we propose investigating the
effects of using gestures as the communicative interface instead of verbal
cues. Specifically, we develop a VR-based 3D simulation environment, named
Ges-THOR, based on AI2-THOR platform. In this virtual environment, a human
player is placed in the same virtual scene and shepherds the artificial agent
using only gestures. The agent is tasked to solve the navigation problem guided
by natural gestures with unknown semantics; we do not use any predefined
gestures due to the diversity and versatile nature of human gestures. We argue
that learning the semantics of natural gestures is mutually beneficial to
learning the navigation task--learn to communicate and communicate to learn. In
a series of experiments, we demonstrate that human gesture cues, even without
predefined semantics, improve the object-goal navigation for an embodied agent,
outperforming various state-of-the-art methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unsupervised Domain Adaptation in Speech Recognition using Phonetic Features.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Ojha_R/0/1/0/all/0/1">Rupam Ojha</a>, <a href="http://arxiv.org/find/eess/1/au:+Sekhar_C/0/1/0/all/0/1">C Chandra Sekhar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02850">
                                        <div class="article-summary-box-inner">
                                            <span><p>Automatic speech recognition is a difficult problem in pattern recognition
because several sources of variability exist in the speech input like the
channel variations, the input might be clean or noisy, the speakers may have
different accent and variations in the gender, etc. As a result, domain
adaptation is important in speech recognition where we train the model for a
particular source domain and test it on a different target domain. In this
paper, we propose a technique to perform unsupervised gender-based domain
adaptation in speech recognition using phonetic features. The experiments are
performed on the TIMIT dataset and there is a considerable decrease in the
phoneme error rate using the proposed approach.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Supervised Neural Networks for Illiquid Alternative Asset Cash Flow Forecasting.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/q-fin/1/au:+Karatas_T/0/1/0/all/0/1">Tugce Karatas</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Klinkert_F/0/1/0/all/0/1">Federico Klinkert</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Hirsa_A/0/1/0/all/0/1">Ali Hirsa</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02853">
                                        <div class="article-summary-box-inner">
                                            <span><p>Institutional investors have been increasing the allocation of the illiquid
alternative assets such as private equity funds in their portfolios, yet there
exists a very limited literature on cash flow forecasting of illiquid
alternative assets. The net cash flow of private equity funds typically follow
a J-curve pattern, however the timing and the size of the contributions and
distributions depend on the investment opportunities. In this paper, we develop
a benchmark model and present two novel approaches (direct vs. indirect) to
predict the cash flows of private equity funds. We introduce a sliding window
approach to apply on our cash flow data because different vintage year funds
contain different lengths of cash flow information. We then pass the data to an
LSTM/ GRU model to predict the future cash flows either directly or indirectly
(based on the benchmark model). We further integrate macroeconomic indicators
into our data, which allows us to consider the impact of market environment on
cash flows and to apply stress testing. Our results indicate that the direct
model is easier to implement compared to the benchmark model and the indirect
model, but still the predicted cash flows align better with the actual cash
flows. We also show that macroeconomic variables improve the performance of the
direct model whereas the impact is not obvious on the indirect model.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Enterprise Analytics using Graph Database and Graph-based Deep Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Henna_S/0/1/0/all/0/1">Shagufta Henna</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalliadan_S/0/1/0/all/0/1">Shyam Krishnan Kalliadan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02867">
                                        <div class="article-summary-box-inner">
                                            <span><p>In a business-to-business (B2B) customer relationship management (CRM) use
case, each client is a potential business organization/company with a solid
business strategy and focused and rational decisions. This paper introduces a
graph-based analytics approach to improve CRM within a B2B environment. In our
approach, in the first instance, we have designed a graph database using the
Neo4j platform. Secondly, the graph database has been investigated by using
data mining and exploratory analysis coupled with cypher graph query language.
Specifically, we have applied the graph convolution network (GCN) to enable CRM
analytics to forecast sales. This is the first step towards a GCN-based binary
classification based on graph databases in the domain of B2B CRM. We evaluate
the performance of the proposed GCN model on graph databases and compare it
with Random Forest (RF), Convolutional Neural Network (CNN), and Artificial
Neural Network (ANN). The proposed GCN approach is further augmented with the
shortest path and eigenvector centrality attribute to significantly improve the
accuracy of sales prediction. Experimental results reveal that the proposed
graph-based deep learning approach outperforms the Random Forests (RsF) and two
deep learning models, i.e., CNN and ANN under different combinations of graph
features.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A Data Augmented Approach to Transfer Learning for Covid-19 Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Henna_S/0/1/0/all/0/1">Shagufta Henna</a>, <a href="http://arxiv.org/find/cs/1/au:+Reji_A/0/1/0/all/0/1">Aparna Reji</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02870">
                                        <div class="article-summary-box-inner">
                                            <span><p>Covid-19 detection at an early stage can aid in an effective treatment and
isolation plan to prevent its spread. Recently, transfer learning has been used
for Covid-19 detection using X-ray, ultrasound, and CT scans. One of the major
limitations inherent to these proposed methods is limited labeled dataset size
that affects the reliability of Covid-19 diagnosis and disease progression. In
this work, we demonstrate that how we can augment limited X-ray images data by
using Contrast limited adaptive histogram equalization (CLAHE) to train the
last layer of the pre-trained deep learning models to mitigate the bias of
transfer learning for Covid-19 detection. We transfer learned various
pre-trained deep learning models including AlexNet, ZFNet, VGG-16, ResNet-18,
and GoogLeNet, and fine-tune the last layer by using CLAHE-augmented dataset.
The experiment results reveal that the CLAHE-based augmentation to various
pre-trained deep learning models significantly improves the model efficiency.
The pre-trained VCG-16 model with CLAHEbased augmented images achieves a
sensitivity of 95% using 15 epochs. AlexNet works show good sensitivity when
trained on non-augmented data. Other models demonstrate a value of less than
60% when trained on non-augmented data. Our results reveal that the sample bias
can negatively impact the performance of transfer learning which is
significantly improved by using CLAHE-based augmentation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Understanding Human Innate Immune System Dependencies using Graph Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Henna_S/0/1/0/all/0/1">Shagufta Henna</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02872">
                                        <div class="article-summary-box-inner">
                                            <span><p>Since the rapid outbreak of Covid-19 and with no approved vaccines to date,
profound research interest has emerged to understand the innate immune response
to viruses. This understanding can help to inhibit virus replication, prolong
adaptive immune response, accelerated virus clearance, and tissue recovery, a
key milestone to propose a vaccine to combat coronaviruses (CoVs), e.g.,
Covid-19. Although an innate immune system triggers inflammatory responses
against CoVs upon recognition of viruses, however, a vaccine is the ultimate
protection against CoV spread. The development of this vaccine is
time-consuming and requires a deep understanding of the innate immune response
system. In this work, we propose a graph neural network-based model that
exploits the interactions between pattern recognition receptors (PRRs), i.e.,
the human immune response system. These interactions can help to recognize
pathogen-associated molecular patterns (PAMPs) to predict the activation
requirements of each PRR. The immune response information of each PRR is
derived from combining its historical PAMPs activation coupled with the modeled
effect on the same from PRRs in its neighborhood. On one hand, this work can
help to understand how long Covid-19 can confer immunity where a strong immune
response means people already been infected can safely return to work. On the
other hand, this GNN-based understanding can also abode well for vaccine
development efforts. Our proposal has been evaluated using CoVs immune response
dataset, with results showing an average IFNs activation prediction accuracy of
90%, compared to 85% using feed-forward neural networks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Interpolation can hurt robust generalization even when there is no noise.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Donhauser_K/0/1/0/all/0/1">Konstantin Donhauser</a>, <a href="http://arxiv.org/find/stat/1/au:+Tifrea_A/0/1/0/all/0/1">Alexandru &#x162;ifrea</a>, <a href="http://arxiv.org/find/stat/1/au:+Aerni_M/0/1/0/all/0/1">Michael Aerni</a>, <a href="http://arxiv.org/find/stat/1/au:+Heckel_R/0/1/0/all/0/1">Reinhard Heckel</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_F/0/1/0/all/0/1">Fanny Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02883">
                                        <div class="article-summary-box-inner">
                                            <span><p>Numerous recent works show that overparameterization implicitly reduces
variance for min-norm interpolators and max-margin classifiers. These findings
suggest that ridge regularization has vanishing benefits in high dimensions. We
challenge this narrative by showing that, even in the absence of noise,
avoiding interpolation through ridge regularization can significantly improve
generalization. We prove this phenomenon for the robust risk of both linear
regression and classification and hence provide the first theoretical result on
robust overfitting.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ RIS-assisted UAV Communications for IoT with Wireless Power Transfer Using Deep Reinforcement Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Nguyen_K/0/1/0/all/0/1">Khoi Khac Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Masaracchia_A/0/1/0/all/0/1">Antonino Masaracchia</a>, <a href="http://arxiv.org/find/eess/1/au:+Do_Duy_T/0/1/0/all/0/1">Tan Do-Duy</a>, <a href="http://arxiv.org/find/eess/1/au:+Poor_H/0/1/0/all/0/1">H. Vincent Poor</a>, <a href="http://arxiv.org/find/eess/1/au:+Duong_T/0/1/0/all/0/1">Trung Q. Duong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02889">
                                        <div class="article-summary-box-inner">
                                            <span><p>Many of the devices used in Internet-of-Things (IoT) applications are
energy-limited, and thus supplying energy while maintaining seamless
connectivity for IoT devices is of considerable importance. In this context, we
propose a simultaneous wireless power transfer and information transmission
scheme for IoT devices with support from reconfigurable intelligent surface
(RIS)-aided unmanned aerial vehicle (UAV) communications. In particular, in a
first phase, IoT devices harvest energy from the UAV through wireless power
transfer; and then in a second phase, the UAV collects data from the IoT
devices through information transmission. To characterise the agility of the
UAV, we consider two scenarios: a hovering UAV and a mobile UAV. Aiming at
maximizing the total network sum-rate, we jointly optimize the trajectory of
the UAV, the energy harvesting scheduling of IoT devices, and the phaseshift
matrix of the RIS. We formulate a Markov decision process and propose two deep
reinforcement learning algorithms to solve the optimization problem of
maximizing the total network sum-rate. Numerical results illustrate the
effectiveness of the UAV's flying path optimization and the network's
throughput of our proposed techniques compared with other benchmark schemes.
Given the strict requirements of the RIS and UAV, the significant improvement
in processing time and throughput performance demonstrates that our proposed
scheme is well applicable for practical IoT applications.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ User Scheduling for Federated Learning Through Over-the-Air Computation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haijian Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1">Rose Qingyang Hu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02891">
                                        <div class="article-summary-box-inner">
                                            <span><p>A new machine learning (ML) technique termed as federated learning (FL) aims
to preserve data at the edge devices and to only exchange ML model parameters
in the learning process. FL not only reduces the communication needs but also
helps to protect the local privacy. Although FL has these advantages, it can
still experience large communication latency when there are massive edge
devices connected to the central parameter server (PS) and/or millions of model
parameters involved in the learning process. Over-the-air computation (AirComp)
is capable of computing while transmitting data by allowing multiple devices to
send data simultaneously by using analog modulation. To achieve good
performance in FL through AirComp, user scheduling plays a critical role. In
this paper, we investigate and compare different user scheduling policies,
which are based on various criteria such as wireless channel conditions and the
significance of model updates. Receiver beamforming is applied to minimize the
mean-square-error (MSE) of the distortion of function aggregation result via
AirComp. Simulation results show that scheduling based on the significance of
model updates has smaller fluctuations in the training process while scheduling
based on channel condition has the advantage on energy efficiency.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Deep Reinforcement Learning for Intelligent Reflecting Surface-assisted D2D Communications.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Nguyen_K/0/1/0/all/0/1">Khoi Khac Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Masaracchia_A/0/1/0/all/0/1">Antonino Masaracchia</a>, <a href="http://arxiv.org/find/eess/1/au:+Yin_C/0/1/0/all/0/1">Cheng Yin</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_L/0/1/0/all/0/1">Long D. Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Dobre_O/0/1/0/all/0/1">Octavia A. Dobre</a>, <a href="http://arxiv.org/find/eess/1/au:+Duong_T/0/1/0/all/0/1">Trung Q. Duong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02892">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we propose a deep reinforcement learning (DRL) approach for
solving the optimisation problem of the network's sum-rate in device-to-device
(D2D) communications supported by an intelligent reflecting surface (IRS). The
IRS is deployed to mitigate the interference and enhance the signal between the
D2D transmitter and the associated D2D receiver. Our objective is to jointly
optimise the transmit power at the D2D transmitter and the phase shift matrix
at the IRS to maximise the network sum-rate. We formulate a Markov decision
process and then propose the proximal policy optimisation for solving the
maximisation game. Simulation results show impressive performance in terms of
the achievable rate and processing time.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Lights, Camera, Action! A Framework to Improve NLP Accuracy over OCR documents.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Gupte_A/0/1/0/all/0/1">Amit Gupte</a>, <a href="http://arxiv.org/find/cs/1/au:+Romanov_A/0/1/0/all/0/1">Alexey Romanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantravadi_S/0/1/0/all/0/1">Sahitya Mantravadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banda_D/0/1/0/all/0/1">Dalitso Banda</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jianjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1">Raza Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Meenal_L/0/1/0/all/0/1">Lakshmanan Ramu Meenal</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Benjamin Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Soundar Srinivasan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02899">
                                        <div class="article-summary-box-inner">
                                            <span><p>Document digitization is essential for the digital transformation of our
societies, yet a crucial step in the process, Optical Character Recognition
(OCR), is still not perfect. Even commercial OCR systems can produce
questionable output depending on the fidelity of the scanned documents. In this
paper, we demonstrate an effective framework for mitigating OCR errors for any
downstream NLP task, using Named Entity Recognition (NER) as an example. We
first address the data scarcity problem for model training by constructing a
document synthesis pipeline, generating realistic but degraded data with NER
labels. We measure the NER accuracy drop at various degradation levels and show
that a text restoration model, trained on the degraded data, significantly
closes the NER accuracy gaps caused by OCR errors, including on an
out-of-domain dataset. For the benefit of the community, we have made the
document synthesis pipeline available as an open-source project.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Building a Foundation for Data-Driven, Interpretable, and Robust Policy Design using the AI Economist.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1">Alexander Trott</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasa_S/0/1/0/all/0/1">Sunil Srinivasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Wal_D/0/1/0/all/0/1">Douwe van der Wal</a>, <a href="http://arxiv.org/find/cs/1/au:+Haneuse_S/0/1/0/all/0/1">Sebastien Haneuse</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Stephan Zheng</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02904">
                                        <div class="article-summary-box-inner">
                                            <span><p>Optimizing economic and public policy is critical to address socioeconomic
issues and trade-offs, e.g., improving equality, productivity, or wellness, and
poses a complex mechanism design problem. A policy designer needs to consider
multiple objectives, policy levers, and behavioral responses from strategic
actors who optimize for their individual objectives. Moreover, real-world
policies should be explainable and robust to simulation-to-reality gaps, e.g.,
due to calibration issues. Existing approaches are often limited to a narrow
set of policy levers or objectives that are hard to measure, do not yield
explicit optimal policies, or do not consider strategic behavior, for example.
Hence, it remains challenging to optimize policy in real-world scenarios. Here
we show that the AI Economist framework enables effective, flexible, and
interpretable policy design using two-level reinforcement learning (RL) and
data-driven simulations. We validate our framework on optimizing the stringency
of US state policies and Federal subsidies during a pandemic, e.g., COVID-19,
using a simulation fitted to real data. We find that log-linear policies
trained using RL significantly improve social welfare, based on both public
health and economic outcomes, compared to past outcomes. Their behavior can be
explained, e.g., well-performing policies respond strongly to changes in
recovery and vaccination rates. They are also robust to calibration errors,
e.g., infection rates that are over or underestimated. As of yet, real-world
policymaking has not seen adoption of machine learning methods at large,
including RL and AI-driven simulations. Our results show the potential of AI to
guide policy design and improve social welfare amidst the complexity of the
real world.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Mitigating dataset harms requires stewardship: Lessons from 1000 papers.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kenny Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1">Arunesh Mathur</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_A/0/1/0/all/0/1">Arvind Narayanan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02922">
                                        <div class="article-summary-box-inner">
                                            <span><p>Concerns about privacy, bias, and harmful applications have shone a light on
the ethics of machine learning datasets, even leading to the retraction of
prominent datasets including DukeMTMC, MS-Celeb-1M, TinyImages, and VGGFace2.
In response, the machine learning community has called for higher ethical
standards, transparency efforts, and technical fixes in the dataset creation
process. The premise of our work is that these efforts can be more effective if
informed by an understanding of how datasets are used in practice in the
research community. We study three influential face and person recognition
datasets - DukeMTMC, MS-Celeb-1M, and Labeled Faces in the Wild (LFW) - by
analyzing nearly 1000 papers that cite them. We found that the creation of
derivative datasets and models, broader technological and social change, the
lack of clarity of licenses, and dataset management practices can introduce a
wide range of ethical concerns. We conclude by suggesting a distributed
approach that can mitigate these harms, making recommendations to dataset
creators, conference program committees, dataset users, and the broader
research community.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Incremental Feature Learning For Infinite Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Sadreddin_A/0/1/0/all/0/1">Armin Sadreddin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadaoui_S/0/1/0/all/0/1">Samira Sadaoui</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02932">
                                        <div class="article-summary-box-inner">
                                            <span><p>This study addresses the actual behavior of the credit-card fraud detection
environment where financial transactions containing sensitive data must not be
amassed in an enormous amount to conduct learning. We introduce a new adaptive
learning approach that adjusts frequently and efficiently to new transaction
chunks; each chunk is discarded after each incremental training step. Our
approach combines transfer learning and incremental feature learning. The
former improves the feature relevancy for subsequent chunks, and the latter, a
new paradigm, increases accuracy during training by determining the optimal
network architecture dynamically for each new chunk. The architectures of past
incremental approaches are fixed; thus, the accuracy may not improve with new
chunks. We show the effectiveness and superiority of our approach
experimentally on an actual fraud dataset.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Is it Fake? News Disinformation Detection on South African News Websites.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wet_H/0/1/0/all/0/1">Harm de Wet</a>, <a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02941">
                                        <div class="article-summary-box-inner">
                                            <span><p>Disinformation through fake news is an ongoing problem in our society and has
become easily spread through social media. The most cost and time effective way
to filter these large amounts of data is to use a combination of human and
technical interventions to identify it. From a technical perspective, Natural
Language Processing (NLP) is widely used in detecting fake news. Social media
companies use NLP techniques to identify the fake news and warn their users,
but fake news may still slip through undetected. It is especially a problem in
more localised contexts (outside the United States of America). How do we
adjust fake news detection systems to work better for local contexts such as in
South Africa. In this work we investigate fake news detection on South African
websites. We curate a dataset of South African fake news and then train
detection models. We contrast this with using widely available fake news
datasets (from mostly USA website). We also explore making the datasets more
diverse by combining them and observe the differences in behaviour in writing
between nations' fake news using interpretable machine learning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Unsupervised Learning of Debiased Representations with Pseudo-Attributes.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1">Seonguk Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joon-Young Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bohyung Han</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02943">
                                        <div class="article-summary-box-inner">
                                            <span><p>Dataset bias is a critical challenge in machine learning, and its negative
impact is aggravated when models capture unintended decision rules with
spurious correlations. Although existing works often handle this issue using
human supervision, the availability of the proper annotations is impractical
and even unrealistic. To better tackle this challenge, we propose a simple but
effective debiasing technique in an unsupervised manner. Specifically, we
perform clustering on the feature embedding space and identify pseudoattributes
by taking advantage of the clustering results even without an explicit
attribute supervision. Then, we employ a novel cluster-based reweighting scheme
for learning debiased representation; this prevents minority groups from being
discounted for minimizing the overall loss, which is desirable for worst-case
generalization. The extensive experiments demonstrate the outstanding
performance of our approach on multiple standard benchmarks, which is even as
competitive as the supervised counterpart.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Auxiliary Class Based Multiple Choice Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sihwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1">Dae Yon Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_T/0/1/0/all/0/1">Taejang Park</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02949">
                                        <div class="article-summary-box-inner">
                                            <span><p>The merit of ensemble learning lies in having different outputs from many
individual models on a single input, i.e., the diversity of the base models.
The high quality of diversity can be achieved when each model is specialized to
different subsets of the whole dataset. Moreover, when each model explicitly
knows to which subsets it is specialized, more opportunities arise to improve
diversity. In this paper, we propose an advanced ensemble method, called
Auxiliary class based Multiple Choice Learning (AMCL), to ultimately specialize
each model under the framework of multiple choice learning (MCL). The
advancement of AMCL is originated from three novel techniques which control the
framework from different directions: 1) the concept of auxiliary class to
provide more distinct information through the labels, 2) the strategy, named
memory-based assignment, to determine the association between the inputs and
the models, and 3) the feature fusion module to achieve generalized features.
To demonstrate the performance of our method compared to all variants of MCL
methods, we conduct extensive experiments on the image classification and
segmentation tasks. Overall, the performance of AMCL exceeds all others in most
of the public datasets trained with various networks as members of the
ensembles.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ AI-based Aortic Vessel Tree Segmentation for Cardiovascular Diseases Treatment: Status Quo.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yuan Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pepe_A/0/1/0/all/0/1">Antonio Pepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianning Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gsaxner_C/0/1/0/all/0/1">Christina Gsaxner</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fen-hua Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleesiek_J/0/1/0/all/0/1">Jens Kleesiek</a>, <a href="http://arxiv.org/find/cs/1/au:+Frangi_A/0/1/0/all/0/1">Alejandro F. Frangi</a>, <a href="http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1">Jan Egger</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02998">
                                        <div class="article-summary-box-inner">
                                            <span><p>The aortic vessel tree is composed of the aorta and its branching arteries,
and plays a key role in supplying the whole body with blood. Aortic diseases,
like aneurysms or dissections, can lead to an aortic rupture, whose treatment
with open surgery is highly risky. Therefore, patients commonly undergo drug
treatment under constant monitoring, which requires regular inspections of the
vessels through imaging. The standard imaging modality for diagnosis and
monitoring is computed tomography (CT), which can provide a detailed picture of
the aorta and its branching vessels if combined with a contrast agent,
resulting in a CT angiography (CTA). Optimally, the whole aortic vessel tree
geometry from consecutive CTAs, are overlaid and compared. This allows to not
only detect changes in the aorta, but also more peripheral vessel tree changes,
caused by the primary pathology or newly developed. When performed manually,
this reconstruction requires slice by slice contouring, which could easily take
a whole day for a single aortic vessel tree and, hence, is not feasible in
clinical practice. Automatic or semi-automatic vessel tree segmentation
algorithms, on the other hand, can complete this task in a fraction of the
manual execution time and run in parallel to the clinical routine of the
clinicians. In this paper, we systematically review computing techniques for
the automatic and semi-automatic segmentation of the aortic vessel tree. The
review concludes with an in-depth discussion on how close these
state-of-the-art approaches are to an application in clinical practice and how
active this research field is, taking into account the number of publications,
datasets and challenges.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Fast and Accurate Low-Rank Tensor Completion Methods Based on QR Decomposition and $L_{2,1}$ Norm Minimization.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Zhang_H/0/1/0/all/0/1">HongBing Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1">XinYi Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Fan_H/0/1/0/all/0/1">HongTao Fan</a>, <a href="http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1">YaJing Li</a>, <a href="http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1">Yinlin Ye</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03002">
                                        <div class="article-summary-box-inner">
                                            <span><p>More recently, an Approximate SVD Based on Qatar Riyal (QR) Decomposition
(CSVD-QR) method for matrix complete problem is presented, whose computational
complexity is $O(r^2(m+n))$, which is mainly due to that $r$ is far less than
$\min\{m,n\}$, where $r$ represents the largest number of singular values of
matrix $X$. What is particularly interesting is that after replacing the
nuclear norm with the $L_{2,1}$ norm proposed based on this decomposition, as
the upper bound of the nuclear norm, when the intermediate matrix $D$ in its
decomposition is close to the diagonal matrix, it will converge to the nuclear
norm, and is exactly equal, when the $D$ matrix is equal to the diagonal
matrix, to the nuclear norm, which ingeniously avoids the calculation of the
singular value of the matrix. To the best of our knowledge, there is no
literature to generalize and apply it to solve tensor complete problems.
Inspired by this, in this paper we propose a class of tensor minimization model
based on $L_{2,1}$ norm and CSVD-QR method for the tensor complete problem,
which is convex and therefore has a global minimum solution.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Inspecting the Process of Bank Credit Rating via Visual Analytics.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiangqiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Quan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhihua Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1">Tangzhi Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaojuan Ma</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03011">
                                        <div class="article-summary-box-inner">
                                            <span><p>Bank credit rating classifies banks into different levels based on publicly
disclosed and internal information, serving as an important input in financial
risk management. However, domain experts have a vague idea of exploring and
comparing different bank credit rating schemes. A loose connection between
subjective and quantitative analysis and difficulties in determining
appropriate indicator weights obscure understanding of bank credit ratings.
Furthermore, existing models fail to consider bank types by just applying a
unified indicator weight set to all banks. We propose RatingVis to assist
experts in exploring and comparing different bank credit rating schemes. It
supports interactively inferring indicator weights for banks by involving
domain knowledge and considers bank types in the analysis loop. We conduct a
case study with real-world bank data to verify the efficacy of RatingVis.
Expert feedback suggests that our approach helps them better understand
different rating schemes.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Interpretable Summaries of Black Box Incident Triaging with Subgroup Discovery.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Remil_Y/0/1/0/all/0/1">Youcef Remil</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendimerad_A/0/1/0/all/0/1">Anes Bendimerad</a>, <a href="http://arxiv.org/find/cs/1/au:+Plantevit_M/0/1/0/all/0/1">Marc Plantevit</a>, <a href="http://arxiv.org/find/cs/1/au:+Robardet_C/0/1/0/all/0/1">C&#xe9;line Robardet</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaytoue_M/0/1/0/all/0/1">Mehdi Kaytoue</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03013">
                                        <div class="article-summary-box-inner">
                                            <span><p>The need of predictive maintenance comes with an increasing number of
incidents reported by monitoring systems and equipment/software users. In the
front line, on-call engineers (OCEs) have to quickly assess the degree of
severity of an incident and decide which service to contact for corrective
actions. To automate these decisions, several predictive models have been
proposed, but the most efficient models are opaque (say, black box), strongly
limiting their adoption. In this paper, we propose an efficient black box model
based on 170K incidents reported to our company over the last 7 years and
emphasize on the need of automating triage when incidents are massively
reported on thousands of servers running our product, an ERP. Recent
developments in eXplainable Artificial Intelligence (XAI) help in providing
global explanations to the model, but also, and most importantly, with local
explanations for each model prediction/outcome. Sadly, providing a human with
an explanation for each outcome is not conceivable when dealing with an
important number of daily predictions. To address this problem, we propose an
original data-mining method rooted in Subgroup Discovery, a pattern mining
technique with the natural ability to group objects that share similar
explanations of their black box predictions and provide a description for each
group. We evaluate this approach and present our preliminary results which give
us good hope towards an effective OCE's adoption. We believe that this approach
provides a new way to address the problem of model agnostic outcome
explanation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Identifiable Energy-based Representations: An Application to Estimating Heterogeneous Causal Effects.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Berrevoets_J/0/1/0/all/0/1">Jeroen Berrevoets</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03039">
                                        <div class="article-summary-box-inner">
                                            <span><p>Conditional average treatment effects (CATEs) allow us to understand the
effect heterogeneity across a large population of individuals. However, typical
CATE learners assume all confounding variables are measured in order for the
CATE to be identifiable. Often, this requirement is satisfied by simply
collecting many variables, at the expense of increased sample complexity for
estimating CATEs. To combat this, we propose an energy-based model (EBM) that
learns a low-dimensional representation of the variables by employing a noise
contrastive loss function. With our EBM we introduce a preprocessing step that
alleviates the dimensionality curse for any existing model and learner
developed for estimating CATE. We prove that our EBM keeps the representations
partially identifiable up to some universal constant, as well as having
universal approximation capability to avoid excessive information loss from
model misspecification; these properties combined with our loss function,
enable the representations to converge and keep the CATE estimation consistent.
Experiments demonstrate the convergence of the representations, as well as show
that estimating CATEs on our representations performs better than on the
variables or the representations obtained via various benchmark dimensionality
reduction methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Spatiotemporal <span class="highlight_title">Contrastive Learning</span> of Facial Expressions in Videos.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Shuvendu Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1">Ali Etemad</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03064">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose a self-supervised contrastive learning approach for facial
expression recognition (FER) in videos. We propose a novel temporal
sampling-based augmentation scheme to be utilized in addition to standard
spatial augmentations used for contrastive learning. Our proposed temporal
augmentation scheme randomly picks from one of three temporal sampling
techniques: (1) pure random sampling, (2) uniform sampling, and (3) sequential
sampling. This is followed by a combination of up to three standard spatial
augmentations. We then use a deep R(2+1)D network for FER, which we train in a
self-supervised fashion based on the augmentations and subsequently fine-tune.
Experiments are performed on the Oulu-CASIA dataset and the performance is
compared to other works in FER. The results indicate that our method achieves
an accuracy of 89.4%, setting a new state-of-the-art by outperforming other
works. Additional experiments and analysis confirm the considerable
contribution of the proposed temporal augmentation versus the existing spatial
ones.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Deriving Disinformation Insights from Geolocalized Twitter Callouts.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Tuxworth_D/0/1/0/all/0/1">David Tuxworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Antypas_D/0/1/0/all/0/1">Dimosthenis Antypas</a>, <a href="http://arxiv.org/find/cs/1/au:+Espinosa_Anke_L/0/1/0/all/0/1">Luis Espinosa-Anke</a>, <a href="http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1">Jose Camacho-Collados</a>, <a href="http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1">Alun Preece</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_D/0/1/0/all/0/1">David Rogers</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03067">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper demonstrates a two-stage method for deriving insights from social
media data relating to disinformation by applying a combination of geospatial
classification and embedding-based language modelling across multiple
languages. In particular, the analysis in centered on Twitter and
disinformation for three European languages: English, French and Spanish.
Firstly, Twitter data is classified into European and non-European sets using
BERT. Secondly, Word2vec is applied to the classified texts resulting in
Eurocentric, non-Eurocentric and global representations of the data for the
three target languages. This comparative analysis demonstrates not only the
efficacy of the classification method but also highlights geographic, temporal
and linguistic differences in the disinformation-related media. Thus, the
contributions of the work are threefold: (i) a novel language-independent
transformer-based geolocation method; (ii) an analytical approach that exploits
lexical specificity and word embeddings to interrogate user-generated content;
and (iii) a dataset of 36 million disinformation related tweets in English,
French and Spanish.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Machine learning for surface prediction in ACTS.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/physics/1/au:+Huth_B/0/1/0/all/0/1">Benjamin Huth</a>, <a href="http://arxiv.org/find/physics/1/au:+Salzburger_A/0/1/0/all/0/1">Andreas Salzburger</a>, <a href="http://arxiv.org/find/physics/1/au:+Wettig_T/0/1/0/all/0/1">Tilo Wettig</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03068">
                                        <div class="article-summary-box-inner">
                                            <span><p>We present an ongoing R&amp;D activity for machine-learning-assisted navigation
through detectors to be used for track reconstruction. We investigate different
approaches of training neural networks for surface prediction and compare their
results. This work is carried out in the context of the ACTS tracking toolkit.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Rectified Euler k-means and Beyond.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yunxia Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+chen_S/0/1/0/all/0/1">Songcan chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03081">
                                        <div class="article-summary-box-inner">
                                            <span><p>Euler k-means (EulerK) first maps data onto the unit hyper-sphere surface of
equi-dimensional space via a complex mapping which induces the robust Euler
kernel and next employs the popular $k$-means. Consequently, besides enjoying
the virtues of k-means such as simplicity and scalability to large data sets,
EulerK is also robust to noises and outliers. Although so, the centroids
captured by EulerK deviate from the unit hyper-sphere surface and thus in
strict distributional sense, actually are outliers. This weird phenomenon also
occurs in some generic kernel clustering methods. Intuitively, using such
outlier-like centroids should not be quite reasonable but it is still seldom
attended. To eliminate the deviation, we propose two Rectified Euler k-means
methods, i.e., REK1 and REK2, which retain the merits of EulerK while acquire
real centroids residing on the mapped space to better characterize the data
structures. Specifically, REK1 rectifies EulerK by imposing the constraint on
the centroids while REK2 views each centroid as the mapped image from a
pre-image in the original space and optimizes these pre-images in Euler kernel
induced space. Undoubtedly, our proposed REKs can methodologically be extended
to solve problems of such a category. Finally, the experiments validate the
effectiveness of REK1 and REK2.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Transferring Knowledge <span class="highlight_title">Distillation</span> for Multilingual Social Event Detection.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jiaqian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jia Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1">Yongxin Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lihong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xu Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qiang Yang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03084">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recently published graph neural networks (GNNs) show promising performance at
social event detection tasks. However, most studies are oriented toward
monolingual data in languages with abundant training samples. This has left the
more common multilingual settings and lesser-spoken languages relatively
unexplored. Thus, we present a GNN that incorporates cross-lingual word
embeddings for detecting events in multilingual data streams. The first exploit
is to make the GNN work with multilingual data. For this, we outline a
construction strategy that aligns messages in different languages at both the
node and semantic levels. Relationships between messages are established by
merging entities that are the same but are referred to in different languages.
Non-English message representations are converted into English semantic space
via the cross-lingual word embeddings. The resulting message graph is then
uniformly encoded by a GNN model. In special cases where a lesser-spoken
language needs to be detected, a novel cross-lingual knowledge distillation
framework, called CLKD, exploits prior knowledge learned from similar threads
in English to make up for the paucity of annotated data. Experiments on both
synthetic and real-world datasets show the framework to be highly effective at
detection in both multilingual data and in languages where training samples are
scarce.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Detecting Requirements Smells With Deep Learning: Experiences, Challenges and Future Work.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Habib_M/0/1/0/all/0/1">Mohammad Kasra Habib</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_S/0/1/0/all/0/1">Stefan Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Graziotin_D/0/1/0/all/0/1">Daniel Graziotin</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03087">
                                        <div class="article-summary-box-inner">
                                            <span><p>Requirements Engineering (RE) is the initial step towards building a software
system. The success or failure of a software project is firmly tied to this
phase, based on communication among stakeholders using natural language. The
problem with natural language is that it can easily lead to different
understandings if it is not expressed precisely by the stakeholders involved,
which results in building a product different from the expected one. Previous
work proposed to enhance the quality of the software requirements detecting
language errors based on ISO 29148 requirements language criteria. The existing
solutions apply classical Natural Language Processing (NLP) to detect them. NLP
has some limitations, such as domain dependability which results in poor
generalization capability. Therefore, this work aims to improve the previous
work by creating a manually labeled dataset and using ensemble learning, Deep
Learning (DL), and techniques such as word embeddings and transfer learning to
overcome the generalization problem that is tied with classical NLP and improve
precision and recall metrics using a manually labeled dataset. The current
findings show that the dataset is unbalanced and which class examples should be
added more. It is tempting to train algorithms even if the dataset is not
considerably representative. Whence, the results show that models are
overfitting; in Machine Learning this issue is solved by adding more instances
to the dataset, improving label quality, removing noise, and reducing the
learning algorithms complexity, which is planned for this research.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Path classification by stochastic linear recurrent neural networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Bartolomaeus_W/0/1/0/all/0/1">Wiebke Bartolomaeus</a>, <a href="http://arxiv.org/find/stat/1/au:+Boutaib_Y/0/1/0/all/0/1">Youness Boutaib</a>, <a href="http://arxiv.org/find/stat/1/au:+Nestler_S/0/1/0/all/0/1">Sandra Nestler</a>, <a href="http://arxiv.org/find/stat/1/au:+Rauhut_H/0/1/0/all/0/1">Holger Rauhut</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03090">
                                        <div class="article-summary-box-inner">
                                            <span><p>We investigate the functioning of a classifying biological neural network
from the perspective of statistical learning theory, modelled, in a simplified
setting, as a continuous-time stochastic recurrent neural network (RNN) with
identity activation function. In the purely stochastic (robust) regime, we give
a generalisation error bound that holds with high probability, thus showing
that the empirical risk minimiser is the best-in-class hypothesis. We show that
RNNs retain a partial signature of the paths they are fed as the unique
information exploited for training and classification tasks. We argue that
these RNNs are easy to train and robust and back these observations with
numerical experiments on both synthetic and real data. We also exhibit a
trade-off phenomenon between accuracy and robustness.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Uncertainty-Based Dynamic Graph Neighborhoods For Medical Segmentation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Demir_U/0/1/0/all/0/1">Ufuk Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozer_A/0/1/0/all/0/1">Atahan Ozer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahin_Y/0/1/0/all/0/1">Yusuf H. Sahin</a>, <a href="http://arxiv.org/find/cs/1/au:+Unal_G/0/1/0/all/0/1">Gozde Unal</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03117">
                                        <div class="article-summary-box-inner">
                                            <span><p>In recent years, deep learning based methods have shown success in essential
medical image analysis tasks such as segmentation. Post-processing and refining
the results of segmentation is a common practice to decrease the
misclassifications originating from the segmentation network. In addition to
widely used methods like Conditional Random Fields (CRFs) which focus on the
structure of the segmented volume/area, a graph-based recent approach makes use
of certain and uncertain points in a graph and refines the segmentation
according to a small graph convolutional network (GCN). However, there are two
drawbacks of the approach: most of the edges in the graph are assigned randomly
and the GCN is trained independently from the segmentation network. To address
these issues, we define a new neighbor-selection mechanism according to feature
distances and combine the two networks in the training procedure. According to
the experimental results on pancreas segmentation from Computed Tomography (CT)
images, we demonstrate improvement in the quantitative measures. Also,
examining the dynamic neighbors created by our method, edges between
semantically similar image parts are observed. The proposed method also shows
qualitative enhancements in the segmentation maps, as demonstrated in the
visual results.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Stochastic Deep Model Reference Adaptive Control.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Joshi_G/0/1/0/all/0/1">Girish Joshi</a>, <a href="http://arxiv.org/find/eess/1/au:+Chowdhary_G/0/1/0/all/0/1">Girish Chowdhary</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03120">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we present a Stochastic Deep Neural Network-based Model
Reference Adaptive Control. Building on our work "Deep Model Reference Adaptive
Control", we extend the controller capability by using Bayesian deep neural
networks (DNN) to represent uncertainties and model non-linearities. Stochastic
Deep Model Reference Adaptive Control uses a Lyapunov-based method to adapt the
output-layer weights of the DNN model in real-time, while a data-driven
supervised learning algorithm is used to update the inner-layers parameters.
This asynchronous network update ensures boundedness and guaranteed tracking
performance with a learning-based real-time feedback controller. A Bayesian
approach to DNN learning helped avoid over-fitting the data and provide
confidence intervals over the predictions. The controller's stochastic nature
also ensured "Induced Persistency of excitation," leading to convergence of the
overall system signal.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ COVID-Net US: A Tailored, Highly Efficient, Self-Attention Deep Convolutional Neural Network Design for Detection of COVID-19 Patient Cases from Point-of-care Ultrasound Imaging.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+MacLean_A/0/1/0/all/0/1">Alexander MacLean</a>, <a href="http://arxiv.org/find/eess/1/au:+Abbasi_S/0/1/0/all/0/1">Saad Abbasi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ebadi_A/0/1/0/all/0/1">Ashkan Ebadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_A/0/1/0/all/0/1">Andy Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Pavlova_M/0/1/0/all/0/1">Maya Pavlova</a>, <a href="http://arxiv.org/find/eess/1/au:+Gunraj_H/0/1/0/all/0/1">Hayden Gunraj</a>, <a href="http://arxiv.org/find/eess/1/au:+Xi_P/0/1/0/all/0/1">Pengcheng Xi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kohli_S/0/1/0/all/0/1">Sonny Kohli</a>, <a href="http://arxiv.org/find/eess/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03131">
                                        <div class="article-summary-box-inner">
                                            <span><p>The Coronavirus Disease 2019 (COVID-19) pandemic has impacted many aspects of
life globally, and a critical factor in mitigating its effects is screening
individuals for infections, thereby allowing for both proper treatment for
those individuals as well as action to be taken to prevent further spread of
the virus. Point-of-care ultrasound (POCUS) imaging has been proposed as a
screening tool as it is a much cheaper and easier to apply imaging modality
than others that are traditionally used for pulmonary examinations, namely
chest x-ray and computed tomography. Given the scarcity of expert radiologists
for interpreting POCUS examinations in many highly affected regions around the
world, low-cost deep learning-driven clinical decision support solutions can
have a large impact during the on-going pandemic. Motivated by this, we
introduce COVID-Net US, a highly efficient, self-attention deep convolutional
neural network design tailored for COVID-19 screening from lung POCUS images.
Experimental results show that the proposed COVID-Net US can achieve an AUC of
over 0.98 while achieving 353X lower architectural complexity, 62X lower
computational complexity, and 14.3X faster inference times on a Raspberry Pi.
Clinical validation was also conducted, where select cases were reviewed and
reported on by a practicing clinician (20 years of clinical practice)
specializing in intensive care (ICU) and 15 years of expertise in POCUS
interpretation. To advocate affordable healthcare and artificial intelligence
for resource-constrained environments, we have made COVID-Net US open source
and publicly available as part of the COVID-Net open source initiative.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Rock<span class="highlight_title">GPT</span>: Reconstructing three-dimensional digital rocks from single two-dimensional slice from the perspective of video generation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Zheng_Q/0/1/0/all/0/1">Qiang Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_D/0/1/0/all/0/1">Dongxiao Zhang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03132">
                                        <div class="article-summary-box-inner">
                                            <span><p>Random reconstruction of three-dimensional (3D) digital rocks from
two-dimensional (2D) slices is crucial for elucidating the microstructure of
rocks and its effects on pore-scale flow in terms of numerical modeling, since
massive samples are usually required to handle intrinsic uncertainties. Despite
remarkable advances achieved by traditional process-based methods, statistical
approaches and recently famous deep learning-based models, few works have
focused on producing several kinds of rocks with one trained model and allowing
the reconstructed samples to satisfy certain given properties, such as
porosity. To fill this gap, we propose a new framework, named RockGPT, which is
composed of VQ-VAE and conditional GPT, to synthesize 3D samples based on a
single 2D slice from the perspective of video generation. The VQ-VAE is
utilized to compress high-dimensional input video, i.e., the sequence of
continuous rock slices, to discrete latent codes and reconstruct them. In order
to obtain diverse reconstructions, the discrete latent codes are modeled using
conditional GPT in an autoregressive manner, while incorporating conditional
information from a given slice, rock type, and porosity. We conduct two
experiments on five kinds of rocks, and the results demonstrate that RockGPT
can produce different kinds of rocks with the same model, and the reconstructed
samples can successfully meet certain specified porosities. In a broader sense,
through leveraging the proposed conditioning scheme, RockGPT constitutes an
effective way to build a general model to produce multiple kinds of rocks
simultaneously that also satisfy user-defined properties.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ SELM: Siamese Extreme Learning Machine with Application to Face Biometrics.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kudisthalert_W/0/1/0/all/0/1">Wasu Kudisthalert</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasupa_K/0/1/0/all/0/1">Kitsuchart Pasupa</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1">Aythami Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Julian Fierrez</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03140">
                                        <div class="article-summary-box-inner">
                                            <span><p>Extreme Learning Machine is a powerful classification method very competitive
existing classification methods. It is extremely fast at training.
Nevertheless, it cannot perform face verification tasks properly because face
verification tasks require comparison of facial images of two individuals at
the same time and decide whether the two faces identify the same person. The
structure of Extreme Leaning Machine was not designed to feed two input data
streams simultaneously, thus, in 2-input scenarios Extreme Learning Machine
methods are normally applied using concatenated inputs. However, this setup
consumes two times more computational resources and it is not optimized for
recognition tasks where learning a separable distance metric is critical. For
these reasons, we propose and develop a Siamese Extreme Learning Machine
(SELM). SELM was designed to be fed with two data streams in parallel
simultaneously. It utilizes a dual-stream Siamese condition in the extra
Siamese layer to transform the data before passing it along to the hidden
layer. Moreover, we propose a Gender-Ethnicity-Dependent triplet feature
exclusively trained on a variety of specific demographic groups. This feature
enables learning and extracting of useful facial features of each group.
Experiments were conducted to evaluate and compare the performances of SELM,
Extreme Learning Machine, and DCNN. The experimental results showed that the
proposed feature was able to perform correct classification at 97.87% accuracy
and 99.45% AUC. They also showed that using SELM in conjunction with the
proposed feature provided 98.31% accuracy and 99.72% AUC. They outperformed the
well-known DCNN and Extreme Leaning Machine methods by a wide margin.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Attainment Regions in Feature-Parameter Space for High-Level Debugging in Autonomous Robots.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1">Sim&#xf3;n C. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramamoorthy_S/0/1/0/all/0/1">Subramanian Ramamoorthy</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03150">
                                        <div class="article-summary-box-inner">
                                            <span><p>Understanding a controller's performance in different scenarios is crucial
for robots that are going to be deployed in safety-critical tasks. If we do not
have a model of the dynamics of the world, which is often the case in complex
domains, we may need to approximate a performance function of the robot based
on its interaction with the environment. Such a performance function gives us
insights into the behaviour of the robot, allowing us to fine-tune the
controller with manual interventions. In high-dimensionality systems, where the
actionstate space is large, fine-tuning a controller is non-trivial. To
overcome this problem, we propose a performance function whose domain is
defined by external features and parameters of the controller. Attainment
regions are defined over such a domain defined by feature-parameter pairs, and
serve the purpose of enabling prediction of successful execution of the task.
The use of the feature-parameter space -in contrast to the action-state space-
allows us to adapt, explain and finetune the controller over a simpler (i.e.,
lower dimensional space). When the robot successfully executes the task, we use
the attainment regions to gain insights into the limits of the controller, and
its robustness. When the robot fails to execute the task, we use the regions to
debug the controller and find adaptive and counterfactual changes to the
solutions. Another advantage of this approach is that we can generalise through
the use of Gaussian processes regression of the performance function in the
high-dimensional space. To test our approach, we demonstrate learning an
approximation to the performance function in simulation, with a mobile robot
traversing different terrain conditions. Then, with a sample-efficient method,
we propagate the attainment regions to a physical robot in a similar
environment.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Feature Augmented Hybrid CNN for Stress Recognition Using Wrist-based Photoplethysmography Sensor.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Rashid_N/0/1/0/all/0/1">Nafiul Rashid</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_L/0/1/0/all/0/1">Luke Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Dautta_M/0/1/0/all/0/1">Manik Dautta</a>, <a href="http://arxiv.org/find/eess/1/au:+Jimenez_A/0/1/0/all/0/1">Abel Jimenez</a>, <a href="http://arxiv.org/find/eess/1/au:+Tseng_P/0/1/0/all/0/1">Peter Tseng</a>, <a href="http://arxiv.org/find/eess/1/au:+Faruque_M/0/1/0/all/0/1">Mohammad Abdullah Al Faruque</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03166">
                                        <div class="article-summary-box-inner">
                                            <span><p>Stress is a physiological state that hampers mental health and has serious
consequences to physical health. Moreover, the COVID-19 pandemic has increased
stress levels among people across the globe. Therefore, continuous monitoring
and detection of stress are necessary. The recent advances in wearable devices
have allowed the monitoring of several physiological signals related to stress.
Among them, wrist-worn wearable devices like smartwatches are most popular due
to their convenient usage. And the photoplethysmography (PPG) sensor is the
most prevalent sensor in almost all consumer-grade wrist-worn smartwatches.
Therefore, this paper focuses on using a wrist-based PPG sensor that collects
Blood Volume Pulse (BVP) signals to detect stress which may be applicable for
consumer-grade wristwatches. Moreover, state-of-the-art works have used either
classical machine learning algorithms to detect stress using hand-crafted
features or have used deep learning algorithms like Convolutional Neural
Network (CNN) which automatically extracts features. This paper proposes a
novel hybrid CNN (H-CNN) classifier that uses both the hand-crafted features
and the automatically extracted features by CNN to detect stress using the BVP
signal. Evaluation on the benchmark WESAD dataset shows that, for 3-class
classification (Baseline vs. Stress vs. Amusement), our proposed H-CNN
outperforms traditional classifiers and normal CNN by 5% and 7% accuracy, and
10% and 7% macro F1 score, respectively. Also for 2-class classification
(Stress vs. Non-stress), our proposed H-CNN outperforms traditional classifiers
and normal CNN by 3% and ~5% accuracy, and ~3% and ~7% macro F1 score,
respectively.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Generalized Tensor Summation Compressive Sensing Network (GTSNET): An Easy to Learn Compressive Sensing Operation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Yamac_M/0/1/0/all/0/1">Mehmet Yamac</a>, <a href="http://arxiv.org/find/eess/1/au:+Akpinar_U/0/1/0/all/0/1">Ugur Akpinar</a>, <a href="http://arxiv.org/find/eess/1/au:+Sahin_E/0/1/0/all/0/1">Erdem Sahin</a>, <a href="http://arxiv.org/find/eess/1/au:+Kiranyaz_S/0/1/0/all/0/1">Serkan Kiranyaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Gabbouj_M/0/1/0/all/0/1">Moncef Gabbouj</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03167">
                                        <div class="article-summary-box-inner">
                                            <span><p>In CS literature, the efforts can be divided into two groups: finding a
measurement matrix that preserves the compressed information at the maximum
level, and finding a reconstruction algorithm for the compressed information.
In the traditional CS setup, the measurement matrices are selected as random
matrices, and optimization-based iterative solutions are used to recover the
signals. However, when we handle large signals, using random matrices become
cumbersome especially when it comes to iterative optimization-based solutions.
Even though recent deep learning-based solutions boost the reconstruction
accuracy performance while speeding up the recovery, still jointly learning the
whole measurement matrix is a difficult process. In this work, we introduce a
separable multi-linear learning of the CS matrix by representing it as the
summation of arbitrary number of tensors. For a special case where the CS
operation is set as a single tensor multiplication, the model is reduced to the
learning-based separable CS; while a dense CS matrix can be approximated and
learned as the summation of multiple tensors. Both cases can be used in CS of
two or multi-dimensional signals e.g., images, multi-spectral images, videos,
etc. Structural CS matrices can also be easily approximated and learned in our
multi-linear separable learning setup with structural tensor sum
representation. Hence, our learnable generalized tensor summation CS operation
encapsulates most CS setups including separable CS, non-separable CS
(traditional vector-matrix multiplication), structural CS, and CS of the
multi-dimensional signals. For both gray-scale and RGB images, the proposed
scheme surpasses most state-of-the-art solutions, especially in lower
measurement rates. Although the performance gain remains limited from tensor to
the sum of tensor representation for gray-scale images, it becomes significant
in the RGB case.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Responding to Illegal Activities Along the Canadian Coastlines Using Reinforcement Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Abouheaf_M/0/1/0/all/0/1">Mohammed Abouheaf</a>, <a href="http://arxiv.org/find/eess/1/au:+Qu_S/0/1/0/all/0/1">Shuzheng Qu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gueaieb_W/0/1/0/all/0/1">Wail Gueaieb</a>, <a href="http://arxiv.org/find/eess/1/au:+Abielmona_R/0/1/0/all/0/1">Rami Abielmona</a>, <a href="http://arxiv.org/find/eess/1/au:+Harb_M/0/1/0/all/0/1">Moufid Harb</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03169">
                                        <div class="article-summary-box-inner">
                                            <span><p>This article elaborates on how machine learning (ML) can leverage the
solution of a contemporary problem related to the security of maritime domains.
The worldwide ``Illegal, Unreported, and Unregulated'' (IUU) fishing incidents
have led to serious environmental and economic consequences which involve
drastic changes in our ecosystems in addition to financial losses caused by the
depletion of natural resources. The Fisheries and Aquatic Department (FAD) of
the United Nation's Food and Agriculture Organization (FAO) issued a report
which indicated that the annual losses due to IUU fishing reached $25 Billion.
This imposes negative impacts on the future-biodiversity of the marine
ecosystem and domestic Gross National Product (GNP). Hence, robust interception
mechanisms are increasingly needed for detecting and pursuing the unrelenting
illegal fishing incidents in maritime territories. This article addresses the
problem of coordinating the motion of a fleet of marine vessels (pursuers) to
catch an IUU vessel while still in local waters. The problem is formulated as a
pursuer-evader problem that is tackled within an ML framework. One or more
pursuers, such as law enforcement vessels, intercept an evader (i.e., the
illegal fishing ship) using an online reinforcement learning mechanism that is
based on a value iteration process. It employs real-time navigation
measurements of the evader ship as well as those of the pursuing vessels and
returns back model-free interception strategies.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Shift-invariant waveform learning on epileptic ECoG.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mendoza_Cardenas_C/0/1/0/all/0/1">Carlos H. Mendoza-Cardenas</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockmeier_A/0/1/0/all/0/1">Austin J. Brockmeier</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03177">
                                        <div class="article-summary-box-inner">
                                            <span><p>Seizure detection algorithms must discriminate abnormal neuronal activity
associated with a seizure from normal neural activity in a variety of
conditions. Our approach is to seek spatiotemporal waveforms with distinct
morphology in electrocorticographic (ECoG) recordings of epileptic patients
that are indicative of a subsequent seizure (preictal) versus non-seizure
segments (interictal). To find these waveforms we apply a shift-invariant
k-means algorithm to segments of spatially filtered signals to learn codebooks
of prototypical waveforms. The frequency of the cluster labels from the
codebooks is then used to train a binary classifier that predicts the class
(preictal or interictal) of a test ECoG segment. We use the Matthews
correlation coefficient to evaluate the performance of the classifier and the
quality of the codebooks. We found that our method finds recurrent
non-sinusoidal waveforms that could be used to build interpretable features for
seizure prediction and that are also physiologically meaningful.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Temporally Abstract Partial Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Khetarpal_K/0/1/0/all/0/1">Khimya Khetarpal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1">Zafarali Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Comanici_G/0/1/0/all/0/1">Gheorghe Comanici</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03213">
                                        <div class="article-summary-box-inner">
                                            <span><p>Humans and animals have the ability to reason and make predictions about
different courses of action at many time scales. In reinforcement learning,
option models (Sutton, Precup \&amp; Singh, 1999; Precup, 2000) provide the
framework for this kind of temporally abstract prediction and reasoning.
Natural intelligent agents are also able to focus their attention on courses of
action that are relevant or feasible in a given situation, sometimes termed
affordable actions. In this paper, we define a notion of affordances for
options, and develop temporally abstract partial option models, that take into
account the fact that an option might be affordable only in certain situations.
We analyze the trade-offs between estimation and approximation error in
planning and learning when using such models, and identify some interesting
special cases. Additionally, we demonstrate empirically the potential impact of
partial option models on the efficiency of planning.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Simple Modifications to Improve Tabular Neural Networks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fiedler_J/0/1/0/all/0/1">James Fiedler</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03214">
                                        <div class="article-summary-box-inner">
                                            <span><p>There is growing interest in neural network architectures for tabular data.
Many general-purpose tabular deep learning models have been introduced
recently, with performance sometimes rivaling gradient boosted decision trees
(GBDTs). These recent models draw inspiration from various sources, including
GBDTs, factorization machines, and neural networks from other application
domains. Previous tabular neural networks are also drawn upon, but are possibly
under-considered, especially models associated with specific tabular problems.
This paper focuses on several such models, and proposes modifications for
improving their performance. When modified, these models are shown to be
competitive with leading general-purpose tabular models, including GBDTs.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ Analysis of Driving Scenario Trajectories with Active Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Jarl_S/0/1/0/all/0/1">Sanna Jarl</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahrovani_S/0/1/0/all/0/1">Sadegh Rahrovani</a>, <a href="http://arxiv.org/find/cs/1/au:+Chehreghani_M/0/1/0/all/0/1">Morteza Haghir Chehreghani</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03217">
                                        <div class="article-summary-box-inner">
                                            <span><p>Annotating the driving scenario trajectories based only on explicit rules
(i.e., knowledge-based methods) can be subject to errors, such as false
positive/negative classification of scenarios that lie on the border of two
scenario classes, missing unknown scenario classes, and also anomalies. On the
other side, verifying the labels by the annotators is not cost-efficient. For
this purpose, active learning (AL) could potentially improve the annotation
procedure by inclusion of an annotator/expert in an efficient way. In this
study, we develop an active learning framework to annotate driving trajectory
time-series data. At the first step, we compute an embedding of the time-series
trajectories into a latent space in order to extract the temporal nature. For
this purpose, we study three different latent space representations:
multivariate Time Series t-Distributed Stochastic Neighbor Embedding (mTSNE),
Recurrent Auto-Encoder (RAE) and Variational Recurrent Auto-Encoder (VRAE). We
then apply different active learning paradigms with different classification
models to the embedded data. In particular, we study the two classifiers Neural
Network (NN) and Support Vector Machines (SVM), with three active learning
query strategies (i.e., entropy, margin and random). In the following, we
explore the possibilities of the framework to discover unknown classes and
demonstrate how it can be used to identify the out-of-class trajectories.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ A <span class="highlight_title">Study</span> on Dense and Sparse (Visual) Rewards in Robot Policy Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Mohtasib_A/0/1/0/all/0/1">Abdalkarim Mohtasib</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuayahuitl_H/0/1/0/all/0/1">Heriberto Cuayahuitl</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03222">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep Reinforcement Learning (DRL) is a promising approach for teaching robots
new behaviour. However, one of its main limitations is the need for carefully
hand-coded reward signals by an expert. We argue that it is crucial to automate
the reward learning process so that new skills can be taught to robots by their
users. To address such automation, we consider task success classifiers using
visual observations to estimate the rewards in terms of task success. In this
work, we study the performance of multiple state-of-the-art deep reinforcement
learning algorithms under different types of reward: Dense, Sparse, Visual
Dense, and Visual Sparse rewards. Our experiments in various simulation tasks
(Pendulum, Reacher, Pusher, and Fetch Reach) show that while DRL agents can
learn successful behaviours using visual rewards when the goal targets are
distinguishable, their performance may decrease if the task goal is not clearly
visible. Our results also show that visual dense rewards are more successful
than visual sparse rewards and that there is no single best algorithm for all
tasks.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Meta Label Correction for Noisy Label Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1">Guoqing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed Hassan Awadallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumais_S/0/1/0/all/0/1">Susan Dumais</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03809">
                                        <div class="article-summary-box-inner">
                                            <span><p>Leveraging weak or noisy supervision for building effective machine learning
models has long been an important research problem. Its importance has further
increased recently due to the growing need for large-scale datasets to train
deep learning models. Weak or noisy supervision could originate from multiple
sources including non-expert annotators or automatic labeling based on
heuristics or user interaction signals. There is an extensive amount of
previous work focusing on leveraging noisy labels. Most notably, recent work
has shown impressive gains by using a meta-learned instance re-weighting
approach where a meta-learning framework is used to assign instance weights to
noisy labels. In this paper, we extend this approach via posing the problem as
label correction problem within a meta-learning framework. We view the label
correction procedure as a meta-process and propose a new meta-learning based
framework termed MLC (Meta Label Correction) for learning with noisy labels.
Specifically, a label correction network is adopted as a meta-model to produce
corrected labels for noisy labels while the main model is trained to leverage
the corrected labeled. Both models are jointly trained by solving a bi-level
optimization problem. We run extensive experiments with different label noise
levels and types on both image recognition and text classification tasks. We
compare the reweighing and correction approaches showing that the correction
framing addresses some of the limitation of reweighting. We also show that the
proposed MLC approach achieves large improvements over previous methods in many
settings.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Analyzing Information Leakage of Updates to Natural Language Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zanella_Beguelin_S/0/1/0/all/0/1">Santiago Zanella-B&#xe9;guelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wutschitz_L/0/1/0/all/0/1">Lukas Wutschitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1">Shruti Tople</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruhle_V/0/1/0/all/0/1">Victor R&#xfc;hle</a>, <a href="http://arxiv.org/find/cs/1/au:+Paverd_A/0/1/0/all/0/1">Andrew Paverd</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohrimenko_O/0/1/0/all/0/1">Olga Ohrimenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopf_B/0/1/0/all/0/1">Boris K&#xf6;pf</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1">Marc Brockschmidt</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.07942">
                                        <div class="article-summary-box-inner">
                                            <span><p>To continuously improve quality and reflect changes in data, machine learning
applications have to regularly retrain and update their core models. We show
that a differential analysis of language model snapshots before and after an
update can reveal a surprising amount of detailed information about changes in
the training data. We propose two new metrics---\emph{differential score} and
\emph{differential rank}---for analyzing the leakage due to updates of natural
language models. We perform leakage analysis using these metrics across models
trained on several different datasets using different methods and
configurations. We discuss the privacy implications of our findings, propose
mitigation strategies and evaluate their effect.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ DriveML: An R Package for Driverless Machine Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Putatunda_S/0/1/0/all/0/1">Sayan Putatunda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ubrangala_D/0/1/0/all/0/1">Dayananda Ubrangala</a>, <a href="http://arxiv.org/find/cs/1/au:+Rama_K/0/1/0/all/0/1">Kiran Rama</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1">Ravi Kondapalli</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00478">
                                        <div class="article-summary-box-inner">
                                            <span><p>In recent years, the concept of automated machine learning has become very
popular. Automated Machine Learning (AutoML) mainly refers to the automated
methods for model selection and hyper-parameter optimization of various
algorithms such as random forests, gradient boosting, neural networks, etc. In
this paper, we introduce a new package i.e. DriveML for automated machine
learning. DriveML helps in implementing some of the pillars of an automated
machine learning pipeline such as automated data preparation, feature
engineering, model building and model explanation by running the function
instead of writing lengthy R codes. The DriveML package is available in CRAN.
We compare the DriveML package with other relevant packages in CRAN/Github and
find that DriveML performs the best across different parameters. We also
provide an illustration by applying the DriveML package with default
configuration on a real world dataset. Overall, the main benefits of DriveML
are in development time savings, reduce developer's errors, optimal tuning of
machine learning models and reproducibility.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Approximate Gradient Coding with Optimal Decoding.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Glasgow_M/0/1/0/all/0/1">Margalit Glasgow</a>, <a href="http://arxiv.org/find/stat/1/au:+Wootters_M/0/1/0/all/0/1">Mary Wootters</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09638">
                                        <div class="article-summary-box-inner">
                                            <span><p>In distributed optimization problems, a technique called gradient coding,
which involves replicating data points, has been used to mitigate the effect of
straggling machines. Recent work has studied approximate gradient coding, which
concerns coding schemes where the replication factor of the data is too low to
recover the full gradient exactly. Our work is motivated by the challenge of
creating approximate gradient coding schemes that simultaneously work well in
both the adversarial and stochastic models. To that end, we introduce novel
approximate gradient codes based on expander graphs, in which each machine
receives exactly two blocks of data points. We analyze the decoding error both
in the random and adversarial straggler setting, when optimal decoding
coefficients are used. We show that in the random setting, our schemes achieve
an error to the gradient that decays exponentially in the replication factor.
In the adversarial setting, the error is nearly a factor of two smaller than
any existing code with similar performance in the random setting. We show
convergence bounds both in the random and adversarial setting for gradient
descent under standard assumptions using our codes. In the random setting, our
convergence rate improves upon block-box bounds. In the adversarial setting, we
show that gradient descent can converge down to a noise floor that scales
linearly with the adversarial error to the gradient. We demonstrate empirically
that our schemes achieve near-optimal error in the random setting and converge
faster than algorithms which do not use the optimal decoding coefficients.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On Adversarial Robustness: A Neural Architecture Search perspective.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Devaguptapu_C/0/1/0/all/0/1">Chaitanya Devaguptapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_D/0/1/0/all/0/1">Devansh Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_G/0/1/0/all/0/1">Gaurav Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08428">
                                        <div class="article-summary-box-inner">
                                            <span><p>Adversarial robustness of deep learning models has gained much traction in
the last few years. Various attacks and defenses are proposed to improve the
adversarial robustness of modern-day deep learning architectures. While all
these approaches help improve the robustness, one promising direction for
improving adversarial robustness is un-explored, i.e., the complex topology of
the neural network architecture. In this work, we answer the following
question: "Can the complex topology of a neural network give adversarial
robustness without any form of adversarial training?" empirically by
experimenting with different hand-crafted and NAS based architectures. Our
findings show that, for small-scale attacks, NAS-based architectures are more
robust for small-scale datasets and simple tasks than hand-crafted
architectures. However, as the dataset's size or the task's complexity
increase, hand-crafted architectures are more robust than NAS-based
architectures. We perform the first large scale study to understand adversarial
robustness purely from an architectural perspective. Our results show that
random sampling in the search space of DARTS (a popular NAS method) with simple
ensembling can improve the robustness to PGD attack by nearly ~12\%. We show
that NAS, which is popular for SoTA accuracy, can provide adversarial accuracy
as a free add-on without any form of adversarial training. Our results show
that leveraging the power of neural network topology with methods like
ensembles can be an excellent way to achieve adversarial robustness without any
form of adversarial training. We also introduce a metric that can be used to
calculate the trade-off between clean accuracy and adversarial robustness.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ COV-ELM classifier: An Extreme Learning Machine based identification of COVID-19 using Chest X-Ray Images.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Rajpal_S/0/1/0/all/0/1">Sheetal Rajpal</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_M/0/1/0/all/0/1">Manoj Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Rajpal_A/0/1/0/all/0/1">Ankit Rajpal</a>, <a href="http://arxiv.org/find/eess/1/au:+Lakhyani_N/0/1/0/all/0/1">Navin Lakhyani</a>, <a href="http://arxiv.org/find/eess/1/au:+Saggar_A/0/1/0/all/0/1">Arpita Saggar</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_N/0/1/0/all/0/1">Naveen Kumar</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08637">
                                        <div class="article-summary-box-inner">
                                            <span><p>Coronaviruses constitute a family of viruses that gives rise to respiratory
diseases. As COVID-19 is highly contagious, early diagnosis of COVID-19 is
crucial for an effective treatment strategy. However, the RT-PCR test which is
considered to be a gold standard in the diagnosis of COVID-19 suffers from a
high false-negative rate. Chest X-ray (CXR) image analysis has emerged as a
feasible and effective diagnostic technique towards this objective. In this
work, we propose the COVID-19 classification problem as a three-class
classification problem to distinguish between COVID-19, normal, and pneumonia
classes. We propose a three-stage framework, named COV-ELM. Stage one deals
with preprocessing and transformation while stage two deals with feature
extraction. These extracted features are passed as an input to the ELM at the
third stage, resulting in the identification of COVID-19. The choice of ELM in
this work has been motivated by its faster convergence, better generalization
capability, and shorter training time in comparison to the conventional
gradient-based learning algorithms. As bigger and diverse datasets become
available, ELM can be quickly retrained as compared to its gradient-based
competitor models. The proposed model achieved a macro average F1-score of 0.95
and the overall sensitivity of ${0.94 \pm 0.02} at a 95% confidence interval.
When compared to state-of-the-art machine learning algorithms, the COV-ELM is
found to outperform its competitors in this three-class classification
scenario. Further, LIME has been integrated with the proposed COV-ELM model to
generate annotated CXR images. The annotations are based on the superpixels
that have contributed to distinguish between the different classes. It was
observed that the superpixels correspond to the regions of the human lungs that
are clinically observed in COVID-19 and Pneumonia cases.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Replica Analysis of the Linear Model with Markov or Hidden Markov Signal Priors.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Truong_L/0/1/0/all/0/1">Lan V. Truong</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13370">
                                        <div class="article-summary-box-inner">
                                            <span><p>This paper estimates free energy, average mutual information, and minimum
mean square error (MMSE) of a linear model under two assumptions: (1) the
source is generated by a Markov chain, (2) the source is generated via a hidden
Markov model. Our estimates are based on the replica method in statistical
physics. We show that under the posterior mean estimator, the linear model with
Markov sources or hidden Markov sources is decoupled into single-input AWGN
channels with state information available at both encoder and decoder where the
state distribution follows the left Perron-Frobenius eigenvector with unit
Manhattan norm of the stochastic matrix of Markov chains. Numerical results
show that the free energies and MSEs obtained via the replica method are
closely approximate to their counterparts achieved by the Metropolis-Hastings
algorithm or some well-known approximate message passing algorithms in the
research literature.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Optimizing Large-Scale Fleet Management on a Road Network using Multi-Agent Deep Reinforcement Learning with Graph Neural Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Juhyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kihyun Kim</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06175">
                                        <div class="article-summary-box-inner">
                                            <span><p>We propose a novel approach to optimize fleet management by combining
multi-agent reinforcement learning with graph neural network. To provide
ride-hailing service, one needs to optimize dynamic resources and demands over
spatial domain. While the spatial structure was previously approximated with a
regular grid, our approach represents the road network with a graph, which
better reflects the underlying geometric structure. Dynamic resource allocation
is formulated as multi-agent reinforcement learning, whose action-value
function (Q function) is approximated with graph neural networks. We use
stochastic policy update rule over the graph with deep Q-networks (DQN), and
achieve superior results over the greedy policy update. We design a realistic
simulator that emulates the empirical taxi call data, and confirm the
effectiveness of the proposed model under various conditions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ PSD2 Explainable AI Model for Credit Scoring.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Torrent_N/0/1/0/all/0/1">Neus Llop Torrent</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Visani_G/0/1/0/all/0/1">Giorgio Visani</a> (2 and 3), <a href="http://arxiv.org/find/cs/1/au:+Bagli_E/0/1/0/all/0/1">Enrico Bagli</a> (2) ((1) Politecnico di Milano Graduate School of Business, (2) CRIF S.p.A, (3) University of Bologna School of Informatics and Engineering), ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10367">
                                        <div class="article-summary-box-inner">
                                            <span><p>The aim of this project is to develop and test advanced analytical methods to
improve the prediction accuracy of Credit Risk Models, preserving at the same
time the model interpretability. In particular, the project focuses on applying
an explainable machine learning model to bank-related databases. The input data
were obtained from open data. Over the total proven models, CatBoost has shown
the highest performance. The algorithm implementation produces a GINI of 0.68
after tuning the hyper-parameters. SHAP package is used to provide a global and
local interpretation of the model predictions to formulate a
human-comprehensive approach to understanding the decision-maker algorithm. The
20 most important features are selected using the Shapley values to present a
full human-understandable model that reveals how the attributes of an
individual are related to its model prediction.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Latent Programmer: Discrete Latent Codes for Program Synthesis.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Joey Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dohan_D/0/1/0/all/0/1">David Dohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rishabh Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_C/0/1/0/all/0/1">Charles Sutton</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">Manzil Zaheer</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00377">
                                        <div class="article-summary-box-inner">
                                            <span><p>In many sequence learning tasks, such as program synthesis and document
summarization, a key problem is searching over a large space of possible output
sequences. We propose to learn representations of the outputs that are
specifically meant for search: rich enough to specify the desired output but
compact enough to make search more efficient. Discrete latent codes are
appealing for this purpose, as they naturally allow sophisticated combinatorial
search strategies. The latent codes are learned using a self-supervised
learning principle, in which first a discrete autoencoder is trained on the
output sequences, and then the resulting latent codes are used as intermediate
targets for the end-to-end sequence prediction task. Based on these insights,
we introduce the \emph{Latent Programmer}, a program synthesis method that
first predicts a discrete latent code from input/output examples, and then
generates the program in the target language. We evaluate the Latent Programmer
on two domains: synthesis of string transformation programs, and generation of
programs from natural language descriptions. We demonstrate that the discrete
latent representation significantly improves synthesis accuracy.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Beyond Occam's Razor in System Identification: Double-Descent when Modeling Dynamics.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Ant&#xf4;nio H. Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendriks_J/0/1/0/all/0/1">Johannes N. Hendriks</a>, <a href="http://arxiv.org/find/cs/1/au:+Wills_A/0/1/0/all/0/1">Adrian G. Wills</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Thomas B. Sch&#xf6;n</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06341">
                                        <div class="article-summary-box-inner">
                                            <span><p>System identification aims to build models of dynamical systems from data.
Traditionally, choosing the model requires the designer to balance between two
goals of conflicting nature; the model must be rich enough to capture the
system dynamics, but not so flexible that it learns spurious random effects
from the dataset. It is typically observed that the model validation
performance follows a U-shaped curve as the model complexity increases. Recent
developments in machine learning and statistics, however, have observed
situations where a "double-descent" curve subsumes this U-shaped
model-performance curve. With a second decrease in performance occurring beyond
the point where the model has reached the capacity of interpolating - i.e.,
(near) perfectly fitting - the training data. To the best of our knowledge,
such phenomena have not been studied within the context of dynamic systems. The
present paper aims to answer the question: "Can such a phenomenon also be
observed when estimating parameters of dynamic systems?" We show that the
answer is yes, verifying such behavior experimentally both for artificially
generated and real-world datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Introduction to Normalizing Flows for Lattice Field Theory.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/hep-lat/1/au:+Albergo_M/0/1/0/all/0/1">Michael S. Albergo</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Boyda_D/0/1/0/all/0/1">Denis Boyda</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Hackett_D/0/1/0/all/0/1">Daniel C. Hackett</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1">Gurtej Kanwar</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Cranmer_K/0/1/0/all/0/1">Kyle Cranmer</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Racaniere_S/0/1/0/all/0/1">S&#xe9;bastien Racani&#xe8;re</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Rezende_D/0/1/0/all/0/1">Danilo Jimenez Rezende</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Shanahan_P/0/1/0/all/0/1">Phiala E. Shanahan</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08176">
                                        <div class="article-summary-box-inner">
                                            <span><p>This notebook tutorial demonstrates a method for sampling Boltzmann
distributions of lattice field theories using a class of machine learning
models known as normalizing flows. The ideas and approaches proposed in
<a href="/abs/1904.12072">arXiv:1904.12072</a>, <a href="/abs/2002.02428">arXiv:2002.02428</a>, and <a href="/abs/2003.06413">arXiv:2003.06413</a> are reviewed and a
concrete implementation of the framework is presented. We apply this framework
to a lattice scalar field theory and to U(1) gauge theory, explicitly encoding
gauge symmetries in the flow-based approach to the latter. This presentation is
intended to be interactive and working with the attached Jupyter notebook is
recommended.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Breaking the Deadly Triad with a Target Network.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shangtong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Hengshuai Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08862">
                                        <div class="article-summary-box-inner">
                                            <span><p>The deadly triad refers to the instability of a reinforcement learning
algorithm when it employs off-policy learning, function approximation, and
bootstrapping simultaneously. In this paper, we investigate the target network
as a tool for breaking the deadly triad, providing theoretical support for the
conventional wisdom that a target network stabilizes training. We first propose
and analyze a novel target network update rule which augments the commonly used
Polyak-averaging style update with two projections. We then apply the target
network and ridge regularization in several divergent algorithms and show their
convergence to regularized TD fixed points. Those algorithms are off-policy
with linear function approximation and bootstrapping, spanning both policy
evaluation and control, as well as both discounted and average-reward settings.
In particular, we provide the first convergent linear $Q$-learning algorithms
under nonrestrictive and changing behavior policies without bi-level
optimization.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Neural networks for Anatomical Therapeutic Chemical (ATC) classification.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/q-bio/1/au:+Nanni_L/0/1/0/all/0/1">Loris Nanni</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lumini_A/0/1/0/all/0/1">Alessandra Lumini</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Brahnam_S/0/1/0/all/0/1">Sheryl Brahnam</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11713">
                                        <div class="article-summary-box-inner">
                                            <span><p>Motivation: Automatic Anatomical Therapeutic Chemical (ATC) classification is
a critical and highly competitive area of research in bioinformatics because of
its potential for expediting drug develop-ment and research. Predicting an
unknown compound's therapeutic and chemical characteristics ac-cording to how
these characteristics affect multiple organs/systems makes automatic ATC
classifica-tion a challenging multi-label problem. Results: In this work, we
propose combining multiple multi-label classifiers trained on distinct sets of
features, including sets extracted from a Bidirectional Long Short-Term Memory
Network (BiLSTM). Experiments demonstrate the power of this approach, which is
shown to outperform the best methods reported in the literature, including the
state-of-the-art developed by the fast.ai research group. Availability: All
source code developed for this study is available at
https://github.com/LorisNanni. Contact: loris.nanni@unipd.it
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Meta-strategy for Learning Tuning Parameters with Guarantees.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1">Dimitri Meunier</a>, <a href="http://arxiv.org/find/stat/1/au:+Alquier_P/0/1/0/all/0/1">Pierre Alquier</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02504">
                                        <div class="article-summary-box-inner">
                                            <span><p>Online learning methods, like the online gradient algorithm (OGA) and
exponentially weighted aggregation (EWA), often depend on tuning parameters
that are difficult to set in practice. We consider an online meta-learning
scenario, and we propose a meta-strategy to learn these parameters from past
tasks. Our strategy is based on the minimization of a regret bound. It allows
to learn the initialization and the step size in OGA with guarantees. It also
allows to learn the prior or the learning rate in EWA. We provide a regret
analysis of the strategy. It allows to identify settings where meta-learning
indeed improves on learning each task in isolation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Noise Reduction in X-ray Photon Correlation Spectroscopy with Convolutional Neural Networks Encoder-Decoder Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cond-mat/1/au:+Konstantinova_T/0/1/0/all/0/1">Tatiana Konstantinova</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Wiegart_L/0/1/0/all/0/1">Lutz Wiegart</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Rakitin_M/0/1/0/all/0/1">Maksim Rakitin</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+DeGennaro_A/0/1/0/all/0/1">Anthony M. DeGennaro</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Barbour_A/0/1/0/all/0/1">Andi M. Barbour</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03877">
                                        <div class="article-summary-box-inner">
                                            <span><p>Like other experimental techniques, X-ray Photon Correlation Spectroscopy is
subject to various kinds of noise. Random and correlated fluctuations and
heterogeneities can be present in a two-time correlation function and obscure
the information about the intrinsic dynamics of a sample. Simultaneously
addressing the disparate origins of noise in the experimental data is
challenging. We propose a computational approach for improving the
signal-to-noise ratio in two-time correlation functions that is based on
Convolutional Neural Network Encoder-Decoder (CNN-ED) models. Such models
extract features from an image via convolutional layers, project them to a low
dimensional space and then reconstruct a clean image from this reduced
representation via transposed convolutional layers. Not only are ED models a
general tool for random noise removal, but their application to low
signal-to-noise data can enhance the data quantitative usage since they are
able to learn the functional form of the signal. We demonstrate that the CNN-ED
models trained on real-world experimental data help to effectively extract
equilibrium dynamics parameters from two-time correlation functions, containing
statistical noise and dynamic heterogeneities. Strategies for optimizing the
models performance and their applicability limits are discussed.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Robust Federated Learning with Attack-Adaptive Aggregation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1">Ching Pui Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05257">
                                        <div class="article-summary-box-inner">
                                            <span><p>Federated learning is vulnerable to various attacks, such as model poisoning
and backdoor attacks, even if some existing defense strategies are used. To
address this challenge, we propose an attack-adaptive aggregation strategy to
defend against various attacks for robust federated learning. The proposed
approach is based on training a neural network with an attention mechanism that
learns the vulnerability of federated learning models from a set of plausible
attacks. To the best of our knowledge, our aggregation strategy is the first
one that can be adapted to defend against various attacks in a data-driven
fashion. Our approach has achieved competitive performance in defending model
poisoning and backdoor attacks in federated learning tasks on image and text
datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Generalization in Quantum Machine Learning: a Quantum Information Perspective.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/quant-ph/1/au:+Banchi_L/0/1/0/all/0/1">Leonardo Banchi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pereira_J/0/1/0/all/0/1">Jason Pereira</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Pirandola_S/0/1/0/all/0/1">Stefano Pirandola</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08991">
                                        <div class="article-summary-box-inner">
                                            <span><p>Quantum classification and hypothesis testing are two tightly related
subjects, the main difference being that the former is data driven: how to
assign to quantum states $\rho(x)$ the corresponding class $c$ (or hypothesis)
is learnt from examples during training, where $x$ can be either tunable
experimental parameters or classical data "embedded" into quantum states. Does
the model generalize? This is the main question in any data-driven strategy,
namely the ability to predict the correct class even of previously unseen
states. Here we establish a link between quantum machine learning
classification and quantum hypothesis testing (state and channel
discrimination) and then show that the accuracy and generalization capability
of quantum classifiers depend on the (R\'enyi) mutual informations $I(C{:}Q)$
and $I_2(X{:}Q)$ between the quantum state space $Q$ and the classical
parameter space $X$ or class space $C$. Based on the above characterization, we
then show how different properties of $Q$ affect classification accuracy and
generalization, such as the dimension of the Hilbert space, the amount of
noise, and the amount of neglected information from $X$ via, e.g., pooling
layers. Moreover, we introduce a quantum version of the Information Bottleneck
principle that allows us to explore the various tradeoffs between accuracy and
generalization. Finally, in order to check our theoretical predictions, we
study the classification of the quantum phases of an Ising spin chain, and we
propose the Variational Quantum Information Bottleneck (VQIB) method to
optimize quantum embeddings of classical data to favor generalization.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Federated Learning for Physical Layer Design.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Elbir_A/0/1/0/all/0/1">Ahmet M. Elbir</a>, <a href="http://arxiv.org/find/eess/1/au:+Papazafeiropoulos_A/0/1/0/all/0/1">Anastasios K. Papazafeiropoulos</a>, <a href="http://arxiv.org/find/eess/1/au:+Chatzinotas_S/0/1/0/all/0/1">Symeon Chatzinotas</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11777">
                                        <div class="article-summary-box-inner">
                                            <span><p>Model-free techniques, such as machine learning (ML), have recently attracted
much interest towards the physical layer design, e.g., symbol detection,
channel estimation, and beamforming. Most of these ML techniques employ
centralized learning (CL) schemes and assume the availability of datasets at a
parameter server (PS), demanding the transmission of data from edge devices,
such as mobile phones, to the PS. Exploiting the data generated at the edge,
federated learning (FL) has been proposed recently as a distributed learning
scheme, in which each device computes the model parameters and sends them to
the PS for model aggregation while the datasets are kept intact at the edge.
Thus, FL is more communication-efficient and privacy-preserving than CL and
applicable to the wireless communication scenarios, wherein the data are
generated at the edge devices. This article presents the recent advances in
FL-based training for physical layer design problems. Compared to CL, the
effectiveness of FL is presented in terms of communication overhead with a
slight performance loss in the learning accuracy. The design challenges, such
as model, data, and hardware complexity, are also discussed in detail along
with possible solutions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Sample Complexity and Overparameterization Bounds for Temporal Difference Learning with Neural Network Approximation.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1">Semih Cayci</a>, <a href="http://arxiv.org/find/cs/1/au:+Satpathi_S/0/1/0/all/0/1">Siddhartha Satpathi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1">Niao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1">R. Srikant</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01391">
                                        <div class="article-summary-box-inner">
                                            <span><p>In this paper, we study the dynamics of temporal difference learning with
neural network-based value function approximation over a general state space,
namely, \emph{Neural TD learning}. We consider two practically used algorithms,
projection-free and max-norm regularized Neural TD learning, and establish the
first convergence bounds for these algorithms. An interesting observation from
our results is that max-norm regularization can dramatically improve the
performance of TD learning algorithms, both in terms of sample complexity and
overparameterization. In particular, we prove that max-norm regularization
improves state-of-the-art sample complexity and overparameterization bounds.
The results in this work rely on a novel Lyapunov drift analysis of the network
parameters as a stopped and controlled random process.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ A rigorous introduction for linear models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04240">
                                        <div class="article-summary-box-inner">
                                            <span><p>This survey is meant to provide an introduction to linear models and the
theories behind them. Our goal is to give a rigorous introduction to the
readers with prior exposure to ordinary least squares. In machine learning, the
output is usually a nonlinear function of the input. Deep learning even aims to
find a nonlinear dependence with many layers which require a large amount of
computation. However, most of these algorithms build upon simple linear models.
We then describe linear models from different views and find the properties and
theories behind the models. The linear model is the main technique in
regression problems and the primary tool for it is the least squares
approximation which minimizes a sum of squared errors. This is a natural choice
when we're interested in finding the regression function which minimizes the
corresponding expected squared error. This survey is primarily a summary of
purpose, significance of important theories behind linear models, e.g.,
distribution theory, minimum variance estimator. We first describe ordinary
least squares from three different points of view upon which we disturb the
model with random noise and Gaussian noise. By Gaussian noise, the model gives
rise to the likelihood so that we introduce a maximum likelihood estimator. It
also develops some distribution theories via this Gaussian disturbance. The
distribution theory of least squares will help us answer various questions and
introduce related applications. We then prove least squares is the best
unbiased linear model in the sense of mean squared error and most importantly,
it actually approaches the theoretical limit. We end up with linear models with
the Bayesian approach and beyond.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Good and Bad Optimization Models: Insights from Rockafellians.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/math/1/au:+Royset_J/0/1/0/all/0/1">Johannes O. Royset</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06073">
                                        <div class="article-summary-box-inner">
                                            <span><p>A basic requirement for a mathematical model is often that its solution
(output) shouldn't change much if the model's parameters (input) are perturbed.
This is important because the exact values of parameters may not be known and
one would like to avoid being mislead by an output obtained using incorrect
values. Thus, it's rarely enough to address an application by formulating a
model, solving the resulting optimization problem and presenting the solution
as the answer. One would need to confirm that the model is suitable, i.e.,
"good," and this can, at least in part, be achieved by considering a family of
optimization problems constructed by perturbing parameters of concern. The
resulting sensitivity analysis uncovers troubling situations with unstable
solutions, which we referred to as "bad" models, and indicates better model
formulations. Embedding an actual problem of interest within a family of
problems is also a primary path to optimality conditions as well as
computationally attractive, alternative problems, which under ideal
circumstances, and when properly tuned, may even furnish the minimum value of
the actual problem. The tuning of these alternative problems turns out to be
intimately tied to finding multipliers in optimality conditions and thus
emerges as a main component of several optimization algorithms. In fact, the
tuning amounts to solving certain dual optimization problems. In this tutorial,
we'll discuss the opportunities and insights afforded by this broad
perspective.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Provable Guarantees for <span class="highlight_title">Self-Supervised</span> Deep Learning with Spectral <span class="highlight_title">Contrastive</span> Loss.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+HaoChen_J/0/1/0/all/0/1">Jeff Z. HaoChen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1">Adrien Gaidon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04156">
                                        <div class="article-summary-box-inner">
                                            <span><p>Recent works in self-supervised learning have advanced the state-of-the-art
by relying on the contrastive learning paradigm, which learns representations
by pushing positive pairs, or similar examples from the same class, closer
together while keeping negative pairs far apart. Despite the empirical
successes, theoretical foundations are limited -- prior analyses assume
conditional independence of the positive pairs given the same class label, but
recent empirical applications use heavily correlated positive pairs (i.e., data
augmentations of the same image). Our work analyzes contrastive learning
without assuming conditional independence of positive pairs using a novel
concept of the augmentation graph on data. Edges in this graph connect
augmentations of the same data, and ground-truth classes naturally form
connected sub-graphs. We propose a loss that performs spectral decomposition on
the population augmentation graph and can be succinctly written as a
contrastive learning objective on neural net representations. Minimizing this
objective leads to features with provable accuracy guarantees under linear
probe evaluation. By standard generalization bounds, these accuracy guarantees
also hold when minimizing the training contrastive loss. Empirically, the
features learned by our objective can match or outperform several strong
baselines on benchmark vision datasets. In all, this work provides the first
provable analysis for contrastive learning where guarantees for linear probe
evaluation can apply to realistic empirical settings.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Residual Feedback Learning for Contact-Rich Manipulation Tasks with Uncertainty.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ranjbar_A/0/1/0/all/0/1">Alireza Ranjbar</a>, <a href="http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1">Ngo Anh Vien</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1">Hanna Ziesche</a>, <a href="http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1">Joschka Boedecker</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04306">
                                        <div class="article-summary-box-inner">
                                            <span><p>While classic control theory offers state of the art solutions in many
problem scenarios, it is often desired to improve beyond the structure of such
solutions and surpass their limitations. To this end, residual policy learning
(RPL) offers a formulation to improve existing controllers with reinforcement
learning (RL) by learning an additive "residual" to the output of a given
controller. However, the applicability of such an approach highly depends on
the structure of the controller. Often, internal feedback signals of the
controller limit an RL algorithm to adequately change the policy and, hence,
learn the task. We propose a new formulation that addresses these limitations
by also modifying the feedback signals to the controller with an RL policy and
show superior performance of our approach on a contact-rich peg-insertion task
under position and orientation uncertainty. In addition, we use a recent
Cartesian impedance control architecture as the control framework which can be
available to us as a black-box while assuming no knowledge about its
input/output structure, and show the difficulties of standard RPL. Furthermore,
we introduce an adaptive curriculum for the given task to gradually increase
the task difficulty in terms of position and orientation uncertainty. A video
showing the results can be found at https://youtu.be/SAZm_Krze7U .
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ★ ♻ Learning Based Proximity Matrix Factorization for Node Embedding.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xingyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1">Kun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1"><span class="highlight_author">Zengfeng Huang</span></a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05476">
                                        <div class="article-summary-box-inner">
                                            <span><p>Node embedding learns a low-dimensional representation for each node in the
graph. Recent progress on node embedding shows that proximity matrix
factorization methods gain superb performance and scale to large graphs with
millions of nodes. Existing approaches first define a proximity matrix and then
learn the embeddings that fit the proximity by matrix factorization. Most
existing matrix factorization methods adopt the same proximity for different
tasks, while it is observed that different tasks and datasets may require
different proximity, limiting their representation power.
</p>
<p>Motivated by this, we propose {\em Lemane}, a framework with trainable
proximity measures, which can be learned to best suit the datasets and tasks at
hand automatically. Our method is end-to-end, which incorporates differentiable
SVD in the pipeline so that the parameters can be trained via backpropagation.
However, this learning process is still expensive on large graphs. To improve
the scalability, we train proximity measures only on carefully subsampled
graphs, and then apply standard proximity matrix factorization on the original
graph using the learned proximity. Note that, computing the learned proximities
for each pair is still expensive for large graphs, and existing techniques for
computing proximities are not applicable to the learned proximities. Thus, we
present generalized push techniques to make our solution scalable to large
graphs with millions of nodes. Extensive experiments show that our proposed
solution outperforms existing solutions on both link prediction and node
classification tasks on almost all datasets.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ HASI: Hardware-Accelerated Stochastic Inference, A Defense Against Adversarial Machine Learning Attacks.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Samavatian_M/0/1/0/all/0/1">Mohammad Hossein Samavatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1">Saikat Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Barber_K/0/1/0/all/0/1">Kristin Barber</a>, <a href="http://arxiv.org/find/cs/1/au:+Teodorescu_R/0/1/0/all/0/1">Radu Teodorescu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05825">
                                        <div class="article-summary-box-inner">
                                            <span><p>Deep Neural Networks (DNNs) are employed in an increasing number of
applications, some of which are safety critical. Unfortunately, DNNs are known
to be vulnerable to so-called adversarial attacks that manipulate inputs to
cause incorrect results that can be beneficial to an attacker or damaging to
the victim. Multiple defenses have been proposed to increase the robustness of
DNNs. In general, these defenses have high overhead, some require
attack-specific re-training of the model or careful tuning to adapt to
different attacks.
</p>
<p>This paper presents HASI, a hardware-accelerated defense that uses a process
we call stochastic inference to detect adversarial inputs. We show that by
carefully injecting noise into the model at inference time, we can
differentiate adversarial inputs from benign ones. HASI uses the output
distribution characteristics of noisy inference compared to a non-noisy
reference to detect adversarial inputs. We show an adversarial detection rate
of 86% when applied to VGG16 and 93% when applied to ResNet50, which exceeds
the detection rate of the state of the art approaches, with a much lower
overhead. We demonstrate two software/hardware-accelerated co-designs, which
reduces the performance impact of stochastic inference to 1.58X-2X relative to
the unprotected baseline, compared to 15X-20X overhead for a software-only GPU
implementation.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Quantum-inspired event reconstruction with Tensor Networks: Matrix Product States.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/hep-ph/1/au:+Araz_J/0/1/0/all/0/1">Jack Y. Araz</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Spannowsky_M/0/1/0/all/0/1">Michael Spannowsky</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08334">
                                        <div class="article-summary-box-inner">
                                            <span><p>Tensor Networks are non-trivial representations of high-dimensional tensors,
originally designed to describe quantum many-body systems. We show that Tensor
Networks are ideal vehicles to connect quantum mechanical concepts to machine
learning techniques, thereby facilitating an improved interpretability of
neural networks. This study presents the discrimination of top quark signal
over QCD background processes using a Matrix Product State classifier. We show
that entanglement entropy can be used to interpret what a network learns, which
can be used to reduce the complexity of the network and feature space without
loss of generality or performance. For the optimisation of the network, we
compare the Density Matrix Renormalization Group (DMRG) algorithm to stochastic
gradient descent (SGD) and propose a joined training algorithm to harness the
explainability of DMRG with the efficiency of SGD.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Synthetic Benchmarks for Scientific Research in Explainable Machine Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandagale_S/0/1/0/all/0/1">Sujay Khandagale</a>, <a href="http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1">Colin White</a>, <a href="http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1">Willie Neiswanger</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12543">
                                        <div class="article-summary-box-inner">
                                            <span><p>As machine learning models grow more complex and their applications become
more high-stakes, tools for explaining model predictions have become
increasingly important. This has spurred a flurry of research in model
explainability and has given rise to feature attribution methods such as LIME
and SHAP. Despite their widespread use, evaluating and comparing different
feature attribution methods remains challenging: evaluations ideally require
human studies, and empirical evaluation metrics are often data-intensive or
computationally prohibitive on real-world datasets. In this work, we address
this issue by releasing XAI-Bench: a suite of synthetic datasets along with a
library for benchmarking feature attribution algorithms. Unlike real-world
datasets, synthetic datasets allow the efficient computation of conditional
expected values that are needed to evaluate ground-truth Shapley values and
other metrics. The synthetic datasets we release offer a wide variety of
parameters that can be configured to simulate real-world data. We demonstrate
the power of our library by benchmarking popular explainability techniques
across several evaluation metrics and across a variety of settings. The
versatility and efficiency of our library will help researchers bring their
explainability methods from development to deployment. Our code is available at
https://github.com/abacusai/xai-bench.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Learning-based Framework for Sensor Fault-Tolerant Building HVAC Control with Model-assisted Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Xu_S/0/1/0/all/0/1">Shichao Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_Y/0/1/0/all/0/1">Yangyang Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yixuan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+ONeill_Z/0/1/0/all/0/1">Zheng O&#x27;Neill</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14144">
                                        <div class="article-summary-box-inner">
                                            <span><p>As people spend up to 87% of their time indoors, intelligent Heating,
Ventilation, and Air Conditioning (HVAC) systems in buildings are essential for
maintaining occupant comfort and reducing energy consumption. These HVAC
systems in smart buildings rely on real-time sensor readings, which in practice
often suffer from various faults and could also be vulnerable to malicious
attacks. Such faulty sensor inputs may lead to the violation of indoor
environment requirements (e.g., temperature, humidity, etc.) and the increase
of energy consumption. While many model-based approaches have been proposed in
the literature for building HVAC control, it is costly to develop accurate
physical models for ensuring their performance and even more challenging to
address the impact of sensor faults. In this work, we present a novel
learning-based framework for sensor fault-tolerant HVAC control, which includes
three deep learning based components for 1) generating temperature proposals
with the consideration of possible sensor faults, 2) selecting one of the
proposals based on the assessment of their accuracy, and 3) applying
reinforcement learning with the selected temperature proposal. Moreover, to
address the challenge of training data insufficiency in building-related tasks,
we propose a model-assisted learning method leveraging an abstract model of
building physical dynamics. Through extensive experiments, we demonstrate that
the proposed fault-tolerant HVAC control framework can significantly reduce
building temperature violations under a variety of sensor fault patterns while
maintaining energy efficiency.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ On Designing Good Representation Learning Models.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Garibaldi_J/0/1/0/all/0/1">Jonathan M Garibaldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_G/0/1/0/all/0/1">Guoping Qiu</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05948">
                                        <div class="article-summary-box-inner">
                                            <span><p>The goal of representation learning is different from the ultimate objective
of machine learning such as decision making, it is therefore very difficult to
establish clear and direct objectives for training representation learning
models. It has been argued that a good representation should disentangle the
underlying variation factors, yet how to translate this into training
objectives remains unknown. This paper presents an attempt to establish direct
training criterions and design principles for developing good representation
learning models. We propose that a good representation learning model should be
maximally expressive, i.e., capable of distinguishing the maximum number of
input configurations. We formally define expressiveness and introduce the
maximum expressiveness (MEXS) theorem of a general learning model. We propose
to train a model by maximizing its expressiveness while at the same time
incorporating general priors such as model smoothness. We present a conscience
competitive learning algorithm which encourages the model to reach its MEXS
whilst at the same time adheres to model smoothness prior. We also introduce a
label consistent training (LCT) technique to boost model smoothness by
encouraging it to assign consistent labels to similar samples. We present
extensive experimental results to show that our method can indeed design
representation learning models capable of developing representations that are
as good as or better than state of the art. We also show that our technique is
computationally efficient, robust against different parameter settings and can
work effectively on a variety of datasets. Code available at
https://github.com/qlilx/odgrlm.git
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Inverse Reinforcement Learning Based Stochastic Driver Behavior Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Ozkan_M/0/1/0/all/0/1">Mehmet Fatih Ozkan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rocque_A/0/1/0/all/0/1">Abishek Joseph Rocque</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yao Ma</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06344">
                                        <div class="article-summary-box-inner">
                                            <span><p>Drivers have unique and rich driving behaviors when operating vehicles in
traffic. This paper presents a novel driver behavior learning approach that
captures the uniqueness and richness of human driver behavior in realistic
driving scenarios. A stochastic inverse reinforcement learning (SIRL) approach
is proposed to learn a distribution of cost function, which represents the
richness of the human driver behavior with a given set of driver-specific
demonstrations. Evaluations are conducted on the realistic driving data
collected from the 3D driver-in-the-loop driving simulation. The results show
that the learned stochastic driver model is capable of expressing the richness
of the human driving strategies under different realistic driving scenarios.
Compared to the deterministic baseline driver behavior model, the results
reveal that the proposed stochastic driver behavior model can better replicate
the driver's unique and rich driving strategies in a variety of traffic
conditions.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Zero-Round Active Learning.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Si Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ruoxi Jia</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06703">
                                        <div class="article-summary-box-inner">
                                            <span><p>Active learning (AL) aims at reducing labeling effort by identifying the most
valuable unlabeled data points from a large pool. Traditional AL frameworks
have two limitations: First, they perform data selection in a multi-round
manner, which is time-consuming and impractical. Second, they usually assume
that there are a small amount of labeled data points available in the same
domain as the data in the unlabeled pool. Recent work proposes a solution for
one-round active learning based on data utility learning and optimization,
which fixes the first issue but still requires the initially labeled data
points in the same domain. In this paper, we propose $\mathrm{D^2ULO}$ as a
solution that solves both issues. Specifically, $\mathrm{D^2ULO}$ leverages the
idea of domain adaptation (DA) to train a data utility model which can
effectively predict the utility for any given unlabeled data in the target
domain once labeled. The trained data utility model can then be used to select
high-utility data and at the same time, provide an estimate for the utility of
the selected data. Our algorithm does not rely on any feedback from annotators
in the target domain and hence, can be used to perform zero-round active
learning or warm-start existing multi-round active learning strategies. Our
experiments show that $\mathrm{D^2ULO}$ outperforms the existing
state-of-the-art AL strategies equipped with domain adaptation over various
domain shift settings (e.g., real-to-real data and synthetic-to-real data).
Particularly, $\mathrm{D^2ULO}$ is applicable to the scenario where source and
target labels have mismatches, which is not supported by the existing works.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Clustering and attention model based for intelligent trading.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/q-fin/1/au:+Rana_M/0/1/0/all/0/1">Mimansa Rana</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mao_N/0/1/0/all/0/1">Nanxiang Mao</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Ao_M/0/1/0/all/0/1">Ming Ao</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wu_X/0/1/0/all/0/1">Xiaohui Wu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Liang_P/0/1/0/all/0/1">Poning Liang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Khushi_M/0/1/0/all/0/1">Matloob Khushi</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06782">
                                        <div class="article-summary-box-inner">
                                            <span><p>The foreign exchange market has taken an important role in the global
financial market. While foreign exchange trading brings high-yield
opportunities to investors, it also brings certain risks. Since the
establishment of the foreign exchange market in the 20th century, foreign
exchange rate forecasting has become a hot issue studied by scholars from all
over the world. Due to the complexity and number of factors affecting the
foreign exchange market, technical analysis cannot respond to administrative
intervention or unexpected events. Our team chose several pairs of foreign
currency historical data and derived technical indicators from 2005 to 2021 as
the dataset and established different machine learning models for event-driven
price prediction for oversold scenario.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Zooming Into the Darknet: Characterizing Internet Background Radiation and its Structural Changes.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Kallitsis_M/0/1/0/all/0/1">Michalis Kallitsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Honavar_V/0/1/0/all/0/1">Vasant Honavar</a>, <a href="http://arxiv.org/find/cs/1/au:+Prajapati_R/0/1/0/all/0/1">Rupesh Prajapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dinghao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yen_J/0/1/0/all/0/1">John Yen</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00079">
                                        <div class="article-summary-box-inner">
                                            <span><p>Network telescopes or "Darknets" provide a unique window into Internet-wide
malicious activities associated with malware propagation, denial of service
attacks, scanning performed for network reconnaissance, and others. Analyses of
the resulting data can provide actionable insights to security analysts that
can be used to prevent or mitigate cyber-threats. Large Darknets, however,
observe millions of nefarious events on a daily basis which makes the
transformation of the captured information into meaningful insights
challenging. We present a novel framework for characterizing Darknet behavior
and its temporal evolution aiming to address this challenge. The proposed
framework: (i) Extracts a high dimensional representation of Darknet events
composed of features distilled from Darknet data and other external sources;
(ii) Learns, in an unsupervised fashion, an information-preserving
low-dimensional representation of these events (using deep representation
learning) that is amenable to clustering; (iv) Performs clustering of the
scanner data in the resulting representation space and provides interpretable
insights using optimal decision trees; and (v) Utilizes the clustering outcomes
as "signatures" that can be used to detect structural changes in the Darknet
activities. We evaluate the proposed system on a large operational Network
Telescope and demonstrate its ability to detect real-world, high-impact
cybersecurity incidents.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Auto-encoder based Model for High-dimensional Imbalanced Industrial Data.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Bom_S/0/1/0/all/0/1">Sthitie Bom</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02083">
                                        <div class="article-summary-box-inner">
                                            <span><p>With the proliferation of IoT devices, the distributed control systems are
now capturing and processing more sensors at higher frequency than ever before.
These new data, due to their volume and novelty, cannot be effectively consumed
without the help of data-driven techniques. Deep learning is emerging as a
promising technique to analyze these data, particularly in soft sensor
modeling. The strong representational capabilities of complex data and the
flexibility it offers from an architectural perspective make it a topic of
active applied research in industrial settings. However, the successful
applications of deep learning in soft sensing are still not widely integrated
in factory control systems, because most of the research on soft sensing do not
have access to large scale industrial data which are varied, noisy and
incomplete. The results published in most research papers are therefore not
easily reproduced when applied to the variety of data in industrial settings.
Here we provide manufacturing data sets that are much larger and more complex
than public open soft sensor data. Moreover, the data sets are from Seagate
factories on active service with only necessary anonymization, so that they
reflect the complex and noisy nature of real-world data. We introduce a
variance weighted multi-headed auto-encoder classification model that fits well
into the high-dimensional and highly imbalanced data. Besides the use of
weighting or sampling methods to handle the highly imbalanced data, the model
also simultaneously predicts multiple outputs by exploiting output-supervised
representation learning and multi-task weighting.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ ♻ Active Reinforcement Learning over MDPs.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Peng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Ke Tang</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02323">
                                        <div class="article-summary-box-inner">
                                            <span><p>The past decade has seen the rapid development of Reinforcement Learning,
which acquires impressive performance with numerous training resources.
However, one of the greatest challenges in RL is generalization efficiency
(i.e., generalization performance in a unit time). This paper proposes a
framework of Active Reinforcement Learning (ARL) over MDPs to improve
generalization efficiency in a limited resource by instance selection. Given a
number of instances, the algorithm chooses out valuable instances as training
sets while training the policy, thereby costing fewer resources. Unlike
existing approaches, we attempt to actively select and use training data rather
than train on all the given data, thereby costing fewer resources. Furthermore,
we introduce a general instance evaluation metrics and selection mechanism into
the framework. Experiments results reveal that the proposed framework with
Proximal Policy Optimization as policy optimizer can effectively improve
generalization efficiency than unselect-ed and unbiased selected methods.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander__title">
                                        ☆ DNN-HMM based Speaker Adaptive Emotion Recognition using Proposed Epoch and MFCC Features.
                                    </summary>
                                    <div class="article-authors">
                                        [<a href="http://arxiv.org/find/cs/1/au:+Fahad_M/0/1/0/all/0/1">Md. Shah Fahad</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_J/0/1/0/all/0/1">Jainath Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Pradhan_G/0/1/0/all/0/1">Gyadhar Pradhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deepak_A/0/1/0/all/0/1">Akshay Deepak</a>, ]
                                    </div>
                                    <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1806.00984">
                                        <div class="article-summary-box-inner">
                                            <span><p>Speech is produced when time varying vocal tract system is excited with time
varying excitation source. Therefore, the information present in a speech such
as message, emotion, language, speaker is due to the combined effect of both
excitation source and vocal tract system. However, there is very less
utilization of excitation source features to recognize emotion. In our earlier
work, we have proposed a novel method to extract glottal closure instants
(GCIs) known as epochs. In this paper, we have explored epoch features namely
instantaneous pitch, phase and strength of epochs for discriminating emotions.
We have combined the excitation source features and the well known
Male-frequency cepstral coefficient (MFCC) features to develop an emotion
recognition system with improved performance. DNN-HMM speaker adaptive models
have been developed using MFCC, epoch and combined features. IEMOCAP emotional
database has been used to evaluate the models. The average accuracy for emotion
recognition system when using MFCC and epoch features separately is 59.25% and
54.52% respectively. The recognition performance improves to 64.2% when MFCC
and epoch features are combined.
</p></span>
                                        </div>
                                    </a>
                                </details>
                            </article>
                    </section>
                    <!--</details>-->
                </li>
        </ul>
    </section>
</body>

<footer>
    <time id="build-timestamp" datetime="2021-08-09T14:59:34.801879586Z">2021-08-09T14:59:34.801879586Z</time>
</footer>

</html>
