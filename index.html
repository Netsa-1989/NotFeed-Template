<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-08-23T01:30:00Z">08-23</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models. (arXiv:2108.08877v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08877">
<div class="article-summary-box-inner">
<span><p>We provide the first exploration of text-to-text transformers (T5) sentence
embeddings. Sentence embeddings are broadly useful for language processing
tasks. While T5 achieves impressive performance on language tasks cast as
sequence-to-sequence mapping problems, it is unclear how to produce sentence
embeddings from encoder-decoder models. We investigate three methods for
extracting T5 sentence embeddings: two utilize only the T5 encoder and one uses
the full T5 encoder-decoder model. Our encoder-only models outperforms
BERT-based sentence embeddings on both transfer tasks and semantic textual
similarity (STS). Our encoder-decoder method achieves further improvement on
STS. Scaling up T5 from millions to billions of parameters is found to produce
consistent improvements on downstream tasks. Finally, we introduce a two-stage
contrastive learning approach that achieves a new state-of-art on STS using
sentence embeddings, outperforming both Sentence BERT and SimCSE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Framework for Neural Topic Modeling of Text Corpora. (arXiv:2108.08946v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08946">
<div class="article-summary-box-inner">
<span><p>Topic Modeling refers to the problem of discovering the main topics that have
occurred in corpora of textual data, with solutions finding crucial
applications in numerous fields. In this work, inspired by the recent
advancements in the Natural Language Processing domain, we introduce FAME, an
open-source framework enabling an efficient mechanism of extracting and
incorporating textual features and utilizing them in discovering topics and
clustering text documents that are semantically similar in a corpus. These
features range from traditional approaches (e.g., frequency-based) to the most
recent auto-encoding embeddings from transformer-based language models such as
BERT model family. To demonstrate the effectiveness of this library, we
conducted experiments on the well-known News-Group dataset. The library is
available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CIGLI: Conditional Image Generation from Language & Image. (arXiv:2108.08955v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08955">
<div class="article-summary-box-inner">
<span><p>Multi-modal generation has been widely explored in recent years. Current
research directions involve generating text based on an image or vice versa. In
this paper, we propose a new task called CIGLI: Conditional Image Generation
from Language and Image. Instead of generating an image based on text as in
text-image generation, this task requires the generation of an image from a
textual description and an image prompt. We designed a new dataset to ensure
that the text description describes information from both images, and that
solely analyzing the description is insufficient to generate an image. We then
propose a novel language-image fusion model which improves the performance over
two established baseline methods, as evaluated by quantitative (automatic) and
qualitative (human) evaluations. The code and dataset is available at
https://github.com/vincentlux/CIGLI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Localize, Group, and Select: Boosting Text-VQA by Scene Text Modeling. (arXiv:2108.08965v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08965">
<div class="article-summary-box-inner">
<span><p>As an important task in multimodal context understanding, Text-VQA (Visual
Question Answering) aims at question answering through reading text information
in images. It differentiates from the original VQA task as Text-VQA requires
large amounts of scene-text relationship understanding, in addition to the
cross-modal grounding capability. In this paper, we propose Localize, Group,
and Select (LOGOS), a novel model which attempts to tackle this problem from
multiple aspects. LOGOS leverages two grounding tasks to better localize the
key information of the image, utilizes scene text clustering to group
individual OCR tokens, and learns to select the best answer from different
sources of OCR (Optical Character Recognition) texts. Experiments show that
LOGOS outperforms previous state-of-the-art methods on two Text-VQA benchmarks
without using additional OCR annotation data. Ablation studies and analysis
demonstrate the capability of LOGOS to bridge different modalities and better
understand scene text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMedBERT: A Knowledge-Enhanced Pre-trained Language Model with Structured Semantics for Medical Text Mining. (arXiv:2108.08983v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08983">
<div class="article-summary-box-inner">
<span><p>Recently, the performance of Pre-trained Language Models (PLMs) has been
significantly improved by injecting knowledge facts to enhance their abilities
of language understanding. For medical domains, the background knowledge
sources are especially useful, due to the massive medical terms and their
complicated relations are difficult to understand in text. In this work, we
introduce SMedBERT, a medical PLM trained on large-scale medical corpora,
incorporating deep structured semantic knowledge from neighbors of
linked-entity.In SMedBERT, the mention-neighbor hybrid attention is proposed to
learn heterogeneous-entity information, which infuses the semantic
representations of entity types into the homogeneous neighboring entity
structure. Apart from knowledge integration as external features, we propose to
employ the neighbors of linked-entities in the knowledge graph as additional
global contexts of text mentions, allowing them to communicate via shared
neighbors, thus enrich their semantic representations. Experiments demonstrate
that SMedBERT significantly outperforms strong baselines in various
knowledge-intensive Chinese medical tasks. It also improves the performance of
other tasks such as question answering, question matching and natural language
inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Twitter User Representation using Weakly Supervised Graph Embedding. (arXiv:2108.08988v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08988">
<div class="article-summary-box-inner">
<span><p>Social media platforms provide convenient means for users to participate in
multiple online activities on various contents and create fast widespread
interactions. However, this rapidly growing access has also increased the
diverse information, and characterizing user types to understand people's
lifestyle decisions shared in social media is challenging. In this paper, we
propose a weakly supervised graph embedding based framework for understanding
user types. We evaluate the user embedding learned using weak supervision over
well-being related tweets from Twitter, focusing on 'Yoga', 'Keto diet'.
Experiments on real-world datasets demonstrate that the proposed framework
outperforms the baselines for detecting user types. Finally, we illustrate data
analysis on different types of users (e.g., practitioner vs. promotional) from
our dataset. While we focus on lifestyle-related tweets (i.e., yoga, keto), our
method for constructing user representation readily generalizes to other
domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SoMeSci- A 5 Star Open Data Gold Standard Knowledge Graph of Software Mentions in Scientific Articles. (arXiv:2108.09070v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09070">
<div class="article-summary-box-inner">
<span><p>Knowledge about software used in scientific investigations is important for
several reasons, for instance, to enable an understanding of provenance and
methods involved in data handling. However, software is usually not formally
cited, but rather mentioned informally within the scholarly description of the
investigation, raising the need for automatic information extraction and
disambiguation. Given the lack of reliable ground truth data, we present
SoMeSci (Software Mentions in Science) a gold standard knowledge graph of
software mentions in scientific articles. It contains high quality annotations
(IRR: $\kappa{=}.82$) of 3756 software mentions in 1367 PubMed Central
articles. Besides the plain mention of the software, we also provide relation
labels for additional information, such as the version, the developer, a URL or
citations. Moreover, we distinguish between different types, such as
application, plugin or programming environment, as well as different types of
mentions, such as usage or creation. To the best of our knowledge, SoMeSci is
the most comprehensive corpus about software mentions in scientific articles,
providing training samples for Named Entity Recognition, Relation Extraction,
Entity Disambiguation, and Entity Linking. Finally, we sketch potential use
cases and provide baseline results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fastformer: Additive Attention is All You Need. (arXiv:2108.09084v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09084">
<div class="article-summary-box-inner">
<span><p>Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GEDIT: Geographic-Enhanced and Dependency-Guided Tagging for Joint POI and Accessibility Extraction at Baidu Maps. (arXiv:2108.09104v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09104">
<div class="article-summary-box-inner">
<span><p>Providing timely accessibility reminders of a point-of-interest (POI) plays a
vital role in improving user satisfaction of finding places and making visiting
decisions. However, it is difficult to keep the POI database in sync with the
real-world counterparts due to the dynamic nature of business changes. To
alleviate this problem, we formulate and present a practical solution that
jointly extracts POI mentions and identifies their coupled accessibility labels
from unstructured text. We approach this task as a sequence tagging problem,
where the goal is to produce &lt;POI name, accessibility label&gt; pairs from
unstructured text. This task is challenging because of two main issues: (1) POI
names are often newly-coined words so as to successfully register new entities
or brands and (2) there may exist multiple pairs in the text, which
necessitates dealing with one-to-many or many-to-one mapping to make each POI
coupled with its accessibility label. To this end, we propose a
Geographic-Enhanced and Dependency-guIded sequence Tagging (GEDIT) model to
concurrently address the two challenges. First, to alleviate challenge #1, we
develop a geographic-enhanced pre-trained model to learn the text
representations. Second, to mitigate challenge #2, we apply a relational graph
convolutional network to learn the tree node representations from the parsed
dependency tree. Finally, we construct a neural sequence tagging model by
integrating and feeding the previously pre-learned representations into a CRF
layer. Extensive experiments conducted on a real-world dataset demonstrate the
superiority and effectiveness of GEDIT. In addition, it has already been
deployed in production at Baidu Maps. Statistics show that the proposed
solution can save significant human effort and labor costs to deal with the
same amount of documents, which confirms that it is a practical way for POI
accessibility maintenance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Airbert: In-domain Pretraining for Vision-and-Language Navigation. (arXiv:2108.09105v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09105">
<div class="article-summary-box-inner">
<span><p>Vision-and-language navigation (VLN) aims to enable embodied agents to
navigate in realistic environments using natural language instructions. Given
the scarcity of domain-specific training data and the high diversity of image
and language inputs, the generalization of VLN agents to unseen environments
remains challenging. Recent methods explore pretraining to improve
generalization, however, the use of generic image-caption datasets or existing
small-scale VLN environments is suboptimal and results in limited improvements.
In this work, we introduce BnB, a large-scale and diverse in-domain VLN
dataset. We first collect image-caption (IC) pairs from hundreds of thousands
of listings from online rental marketplaces. Using IC pairs we next propose
automatic strategies to generate millions of VLN path-instruction (PI) pairs.
We further propose a shuffling loss that improves the learning of temporal
order inside PI pairs. We use BnB pretrain our Airbert model that can be
adapted to discriminative and generative settings and show that it outperforms
state of the art for Room-to-Room (R2R) navigation and Remote Referring
Expression (REVERIE) benchmarks. Moreover, our in-domain pretraining
significantly increases performance on a challenging few-shot VLN evaluation,
where we train the model only on VLN instructions from a few houses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Communication with Adaptive Universal Transformer. (arXiv:2108.09119v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09119">
<div class="article-summary-box-inner">
<span><p>With the development of deep learning (DL), natural language processing (NLP)
makes it possible for us to analyze and understand a large amount of language
texts. Accordingly, we can achieve a semantic communication in terms of joint
semantic source and channel coding over a noisy channel with the help of NLP.
However, the existing method to realize this goal is to use a fixed transformer
of NLP while ignoring the difference of semantic information contained in each
sentence. To solve this problem, we propose a new semantic communication system
based on Universal Transformer. Compared with the traditional transformer, an
adaptive circulation mechanism is introduced in the Universal Transformer.
Through the introduction of the circulation mechanism, the new semantic
communication system can be more flexible to transmit sentences with different
semantic information, and achieve better end-to-end performance under various
channel conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Group-based Distinctive Image Captioning with Memory Attention. (arXiv:2108.09151v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09151">
<div class="article-summary-box-inner">
<span><p>Describing images using natural language is widely known as image captioning,
which has made consistent progress due to the development of computer vision
and natural language generation techniques. Though conventional captioning
models achieve high accuracy based on popular metrics, i.e., BLEU, CIDEr, and
SPICE, the ability of captions to distinguish the target image from other
similar images is under-explored. To generate distinctive captions, a few
pioneers employ contrastive learning or re-weighted the ground-truth captions,
which focuses on one single input image. However, the relationships between
objects in a similar image group (e.g., items or properties within the same
album or fine-grained events) are neglected. In this paper, we improve the
distinctiveness of image captions using a Group-based Distinctive Captioning
Model (GdisCap), which compares each image with other images in one similar
group and highlights the uniqueness of each image. In particular, we propose a
group-based memory attention (GMA) module, which stores object features that
are unique among the image group (i.e., with low similarity to objects in other
images). These unique object features are highlighted when generating captions,
resulting in more distinctive captions. Furthermore, the distinctive words in
the ground-truth captions are selected to supervise the language decoder and
GMA. Finally, we propose a new evaluation metric, distinctive word rate
(DisWordRate) to measure the distinctiveness of captions. Quantitative results
indicate that the proposed method significantly improves the distinctiveness of
several baseline models, and achieves the state-of-the-art performance on both
accuracy and distinctiveness. Results of a user study agree with the
quantitative evaluation and demonstrate the rationality of the new metric
DisWordRate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Neural Conversation Generation Model via Equivalent Shared Memory Investigation. (arXiv:2108.09164v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09164">
<div class="article-summary-box-inner">
<span><p>Conversation generation as a challenging task in Natural Language Generation
(NLG) has been increasingly attracting attention over the last years. A number
of recent works adopted sequence-to-sequence structures along with external
knowledge, which successfully enhanced the quality of generated conversations.
Nevertheless, few works utilized the knowledge extracted from similar
conversations for utterance generation. Taking conversations in customer
service and court debate domains as examples, it is evident that essential
entities/phrases, as well as their associated logic and inter-relationships can
be extracted and borrowed from similar conversation instances. Such information
could provide useful signals for improving conversation generation. In this
paper, we propose a novel reading and memory framework called Deep Reading
Memory Network (DRMN) which is capable of remembering useful information of
similar conversations for improving utterance generation. We apply our model to
two large-scale conversation datasets of justice and e-commerce fields.
Experiments prove that the proposed model outperforms the state-of-the-art
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smart Bird: Learnable Sparse Attention for Efficient and Effective Transformer. (arXiv:2108.09193v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09193">
<div class="article-summary-box-inner">
<span><p>Transformer has achieved great success in NLP. However, the quadratic
complexity of the self-attention mechanism in Transformer makes it inefficient
in handling long sequences. Many existing works explore to accelerate
Transformers by computing sparse self-attention instead of a dense one, which
usually attends to tokens at certain positions or randomly selected tokens.
However, manually selected or random tokens may be uninformative for context
modeling. In this paper, we propose Smart Bird, which is an efficient and
effective Transformer with learnable sparse attention. In Smart Bird, we first
compute a sketched attention matrix with a single-head low-dimensional
Transformer, which aims to find potential important interactions between
tokens. We then sample token pairs based on their probability scores derived
from the sketched attention matrix to generate different sparse attention index
matrices for different attention heads. Finally, we select token embeddings
according to the index matrices to form the input of sparse attention networks.
Extensive experiments on six benchmark datasets for different tasks validate
the efficiency and effectiveness of Smart Bird in text modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extracting Radiological Findings With Normalized Anatomical Information Using a Span-Based BERT Relation Extraction Model. (arXiv:2108.09211v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09211">
<div class="article-summary-box-inner">
<span><p>Medical imaging is critical to the diagnosis and treatment of numerous
medical problems, including many forms of cancer. Medical imaging reports
distill the findings and observations of radiologists, creating an unstructured
textual representation of unstructured medical images. Large-scale use of this
text-encoded information requires converting the unstructured text to a
structured, semantic representation. We explore the extraction and
normalization of anatomical information in radiology reports that is associated
with radiological findings. We investigate this extraction and normalization
task using a span-based relation extraction model that jointly extracts
entities and relations using BERT. This work examines the factors that
influence extraction and normalization performance, including the body
part/organ system, frequency of occurrence, span length, and span diversity. It
discusses approaches for improving performance and creating high-quality
semantic representations of radiological phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open Relation Modeling: Learning to Define Relations between Entities. (arXiv:2108.09241v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09241">
<div class="article-summary-box-inner">
<span><p>Relations between entities can be represented by different instances, e.g., a
sentence containing both entities or a fact in a Knowledge Graph (KG). However,
these instances may not well capture the general relations between entities,
may be difficult to understand by humans, even may not be found due to the
incompleteness of the knowledge source.
</p>
<p>In this paper, we introduce the Open Relation Modeling task - given two
entities, generate a coherent sentence describing the relation between them. To
solve this task, we propose to teach machines to generate definition-like
relation descriptions by letting them learn from definitions of entities.
Specifically, we fine-tune Pre-trained Language Models (PLMs) to produce
definitions conditioned on extracted entity pairs. To help PLMs reason between
entities and provide additional relational knowledge to PLMs for open relation
modeling, we incorporate reasoning paths in KGs and include a reasoning path
selection mechanism. We show that PLMs can select interpretable and informative
reasoning paths by confidence estimation, and the selected path can guide PLMs
to generate better relation descriptions. Experimental results show that our
model can generate concise but informative relation descriptions that capture
the representative characteristics of entities and relations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on Publicly Available Sinhala Natural Language Processing Tools and Research. (arXiv:1906.02358v9 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.02358">
<div class="article-summary-box-inner">
<span><p>Sinhala is the native language of the Sinhalese people who make up the
largest ethnic group of Sri Lanka. The language belongs to the globe-spanning
language tree, Indo-European. However, due to poverty in both linguistic and
economic capital, Sinhala, in the perspective of Natural Language Processing
tools and research, remains a resource-poor language which has neither the
economic drive its cousin English has nor the sheer push of the law of numbers
a language such as Chinese has. A number of research groups from Sri Lanka have
noticed this dearth and the resultant dire need for proper tools and research
for Sinhala natural language processing. However, due to various reasons, these
attempts seem to lack coordination and awareness of each other. The objective
of this paper is to fill that gap of a comprehensive literature survey of the
publicly available Sinhala natural language tools and research so that the
researchers working in this field can better utilize contributions of their
peers. As such, we shall be uploading this paper to arXiv and perpetually
update it periodically to reflect the advances made in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Empowered Representation Learning for Chinese Medical Reading Comprehension: Task, Model and Resources. (arXiv:2008.10327v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10327">
<div class="article-summary-box-inner">
<span><p>Machine Reading Comprehension (MRC) aims to extract answers to questions
given a passage. It has been widely studied recently, especially in open
domains. However, few efforts have been made on closed-domain MRC, mainly due
to the lack of large-scale training data. In this paper, we introduce a
multi-target MRC task for the medical domain, whose goal is to predict answers
to medical questions and the corresponding support sentences from medical
information sources simultaneously, in order to ensure the high reliability of
medical knowledge serving. A high-quality dataset is manually constructed for
the purpose, named Multi-task Chinese Medical MRC dataset (CMedMRC), with
detailed analysis conducted. We further propose the Chinese medical BERT model
for the task (CMedBERT), which fuses medical knowledge into pre-trained
language models by the dynamic fusion mechanism of heterogeneous features and
the multi-task learning strategy. Experiments show that CMedBERT consistently
outperforms strong baselines by fusing context-aware and knowledge-aware token
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Distillation for Singing Voice Detection. (arXiv:2011.04297v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04297">
<div class="article-summary-box-inner">
<span><p>Singing Voice Detection (SVD) has been an active area of research in music
information retrieval (MIR). Currently, two deep neural network-based methods,
one based on CNN and the other on RNN, exist in literature that learn optimized
features for the voice detection (VD) task and achieve state-of-the-art
performance on common datasets. Both these models have a huge number of
parameters (1.4M for CNN and 65.7K for RNN) and hence not suitable for
deployment on devices like smartphones or embedded sensors with limited
capacity in terms of memory and computation power. The most popular method to
address this issue is known as knowledge distillation in deep learning
literature (in addition to model compression) where a large pre-trained network
known as the teacher is used to train a smaller student network. Given the wide
applications of SVD in music information retrieval, to the best of our
knowledge, model compression for practical deployment has not yet been
explored. In this paper, efforts have been made to investigate this issue using
both conventional as well as ensemble knowledge distillation techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EasyTransfer -- A Simple and Scalable Deep Transfer Learning Platform for NLP Applications. (arXiv:2011.09463v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09463">
<div class="article-summary-box-inner">
<span><p>The literature has witnessed the success of leveraging Pre-trained Language
Models (PLMs) and Transfer Learning (TL) algorithms to a wide range of Natural
Language Processing (NLP) applications, yet it is not easy to build an
easy-to-use and scalable TL toolkit for this purpose. To bridge this gap, the
EasyTransfer platform is designed to develop deep TL algorithms for NLP
applications. EasyTransfer is backended with a high-performance and scalable
engine for efficient training and inference, and also integrates comprehensive
deep TL algorithms, to make the development of industrial-scale TL applications
easier. In EasyTransfer, the built-in data and model parallelism strategies,
combined with AI compiler optimization, show to be 4.0x faster than the
community version of distributed training. EasyTransfer supports various NLP
models in the ModelZoo, including mainstream PLMs and multi-modality models. It
also features various in-house developed TL algorithms, together with the
AppZoo for NLP applications. The toolkit is convenient for users to quickly
start model training, evaluation, and online deployment. EasyTransfer is
currently deployed at Alibaba to support a variety of business scenarios,
including item recommendation, personalized search, conversational question
answering, etc. Extensive experiments on real-world datasets and online
applications show that EasyTransfer is suitable for online production with
cutting-edge performance for various applications. The source code of
EasyTransfer is released at Github (https://github.com/alibaba/EasyTransfer).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Verification and Reranking for Open Fact Checking Over Tables. (arXiv:2012.15115v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15115">
<div class="article-summary-box-inner">
<span><p>Structured information is an important knowledge source for automatic
verification of factual claims. Nevertheless, the majority of existing research
into this task has focused on textual data, and the few recent inquiries into
structured data have been for the closed-domain setting where appropriate
evidence for each claim is assumed to have already been retrieved. In this
paper, we investigate verification over structured data in the open-domain
setting, introducing a joint reranking-and-verification model which fuses
evidence documents in the verification component. Our open-domain model
achieves performance comparable to the closed-domain state-of-the-art on the
TabFact dataset, and demonstrates performance gains from the inclusion of
multiple tables as well as a significant improvement over a heuristic retrieval
baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">De-identifying Hospital Discharge Summaries: An End-to-End Framework using Ensemble of Deep Learning Models. (arXiv:2101.00146v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00146">
<div class="article-summary-box-inner">
<span><p>Electronic Medical Records contain clinical narrative text that is of great
potential value to medical researchers. However, this information is mixed with
Personally Identifiable Information that presents risks to patient and
clinician confidentiality. This paper presents an end-to-end de-identification
framework to automatically remove PII from hospital discharge summaries. Our
corpus included 600 hospital discharge summaries which were extracted from the
EMRs of two principal referral hospitals in Sydney, Australia. Our end-to-end
de-identification framework consists of three components: 1) Annotation:
labelling of PII in the hospital discharge summaries using five pre-defined
categories: person, address, date of birth, individual identification number,
phone/fax number; 2) Modelling: training six named entity recognition deep
learning base-models on balanced and imbalanced datasets; and evaluating
ensembles that combine all six base-models, the three base-models with the best
F1 scores and the three base-models with the best recall scores respectively,
using token-level majority voting and stacking methods; and 3)
De-identification: removing PII from the hospital discharge summaries. Our
results showed that the ensemble model combined using the stacking Support
Vector Machine method on the three base-models with the best F1 scores achieved
excellent results with a F1 score of 99.16% on the test set of our corpus. We
also evaluated the robustness of our modelling component on the 2014 i2b2
de-identification dataset. Our ensemble model, which uses the token-level
majority voting method on all six base-models, achieved the highest F1 score of
96.24% at strict entity matching and the highest F1 score of 98.64% at binary
token-level matching compared to two state-of-the-art methods. The end-to-end
framework provides a robust solution to de-identifying clinical narrative
corpuses safely.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Czert -- Czech BERT-like Model for Language Representation. (arXiv:2103.13031v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13031">
<div class="article-summary-box-inner">
<span><p>This paper describes the training process of the first Czech monolingual
language representation models based on BERT and ALBERT architectures. We
pre-train our models on more than 340K of sentences, which is 50 times more
than multilingual models that include Czech data. We outperform the
multilingual models on 9 out of 11 datasets. In addition, we establish the new
state-of-the-art results on nine datasets. At the end, we discuss properties of
monolingual and multilingual models based upon our results. We publish all the
pre-trained and fine-tuned models freely for the research community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural Language Understanding with Privacy-Preserving BERT. (arXiv:2104.07504v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07504">
<div class="article-summary-box-inner">
<span><p>Privacy preservation remains a key challenge in data mining and Natural
Language Understanding (NLU). Previous research shows that the input text or
even text embeddings can leak private information. This concern motivates our
research on effective privacy preservation approaches for pretrained Language
Models (LMs). We investigate the privacy and utility implications of applying
dx-privacy, a variant of Local Differential Privacy, to BERT fine-tuning in NLU
applications. More importantly, we further propose privacy-adaptive LM
pretraining methods and show that our approach can boost the utility of BERT
dramatically while retaining the same level of privacy protection. We also
quantify the level of privacy preservation and provide guidance on privacy
configuration. Our experiments and findings lay the groundwork for future
explorations of privacy-preserving NLU with pretrained LMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reinforcement Learning from Reformulations in Conversational Question Answering over Knowledge Graphs. (arXiv:2105.04850v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04850">
<div class="article-summary-box-inner">
<span><p>The rise of personal assistants has made conversational question answering
(ConvQA) a very popular mechanism for user-system interaction. State-of-the-art
methods for ConvQA over knowledge graphs (KGs) can only learn from crisp
question-answer pairs found in popular benchmarks. In reality, however, such
training data is hard to come by: users would rarely mark answers explicitly as
correct or wrong. In this work, we take a step towards a more natural learning
paradigm - from noisy and implicit feedback via question reformulations. A
reformulation is likely to be triggered by an incorrect system response,
whereas a new follow-up question could be a positive signal on the previous
turn's answer. We present a reinforcement learning model, termed CONQUER, that
can learn from a conversational stream of questions and reformulations. CONQUER
models the answering process as multiple agents walking in parallel on the KG,
where the walks are determined by actions sampled using a policy network. This
policy network takes the question along with the conversational context as
inputs and is trained via noisy rewards obtained from the reformulation
likelihood. To evaluate CONQUER, we create and release ConvRef, a benchmark
with about 11k natural conversations containing around 205k reformulations.
Experiments show that CONQUER successfully learns to answer conversational
questions from noisy reward signals, significantly improving over a
state-of-the-art baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PRASEMap: A Probabilistic Reasoning and Semantic Embedding based Knowledge Graph Alignment System. (arXiv:2106.08801v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08801">
<div class="article-summary-box-inner">
<span><p>Knowledge Graph (KG) alignment aims at finding equivalent entities and
relations (i.e., mappings) between two KGs. The existing approaches utilize
either reasoning-based or semantic embedding-based techniques, but few studies
explore their combination. In this demonstration, we present PRASEMap, an
unsupervised KG alignment system that iteratively computes the Mappings with
both Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.
PRASEMap can support various embedding-based KG alignment approaches as the SE
module, and enables easy human computer interaction that additionally provides
an option for users to feed the mapping annotations back to the system for
better results. The demonstration showcases these features via a stand-alone
Web application with user friendly interfaces. The demo is available at
https://prasemap.qizhy.com.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Entity Extraction Method Based on Machine Reading Comprehension. (arXiv:2108.06444v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06444">
<div class="article-summary-box-inner">
<span><p>Entity extraction is a key technology for obtaining information from massive
texts in natural language processing. The further interaction between them does
not meet the standards of human reading comprehension, thus limiting the
understanding of the model, and also the omission or misjudgment of the answer
(ie the target entity) due to the reasoning question. An effective MRC-based
entity extraction model-MRC-I2DP, which uses the proposed gated
attention-attracting mechanism to adjust the restoration of each part of the
text pair, creating problems and thinking for multi-level interactive attention
calculations to increase the target entity It also uses the proposed 2D
probability coding module, TALU function and mask mechanism to strengthen the
detection of all possible targets of the target, thereby improving the
probability and accuracy of prediction. Experiments have proved that MRC-I2DP
represents an overall state-of-the-art model in 7 from the scientific and
public domains, achieving a performance improvement of up to compared to the
model model in F1.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-08-23 23:09:10.285394336 UTC">2021-08-23 23:09:10 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.1</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>