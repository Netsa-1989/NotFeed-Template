<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-08-12T01:30:00Z">08-12</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Post-hoc Interpretability for Neural NLP: A Survey. (arXiv:2108.04840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04840">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing (NLP) models have become increasingly more
complex and widespread. With recent developments in neural networks, a growing
concern is whether it is responsible to use these models. Concerns such as
safety and ethics can be partially addressed by providing explanations.
Furthermore, when models do fail, providing explanations is paramount for
accountability purposes. To this end, interpretability serves to provide these
explanations in terms that are understandable to humans. Central to what is
understandable is how explanations are communicated. Therefore, this survey
provides a categorization of how recent interpretability methods communicate
explanations and discusses the methods in depth. Furthermore, the survey
focuses on post-hoc methods, which provide explanations after a model is
learned and generally model-agnostic. A common concern for this class of
methods is whether they accurately reflect the model. Hence, how these post-hoc
methods are evaluated is discussed throughout the paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion. (arXiv:2108.04927v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04927">
<div class="article-summary-box-inner">
<span><p>Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis. (arXiv:2108.04938v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04938">
<div class="article-summary-box-inner">
<span><p>Vision-and-language(V&amp;L) models take image and text as input and learn to
capture the associations between them. Prior studies show that pre-trained V&amp;L
models can significantly improve the model performance for downstream tasks
such as Visual Question Answering (VQA). However, V&amp;L models are less effective
when applied in the medical domain (e.g., on X-ray images and clinical notes)
due to the domain gap. In this paper, we investigate the challenges of applying
pre-trained V&amp;L models in medical applications. In particular, we identify that
the visual representation in general V&amp;L models is not suitable for processing
medical data. To overcome this limitation, we propose BERTHop, a
transformer-based model based on PixelHop++ and VisualBERT, for better
capturing the associations between the two modalities. Experiments on the OpenI
dataset, a commonly used thoracic disease diagnosis benchmark, show that
BERTHop achieves an average Area Under the Curve (AUC) of 98.12% which is 1.62%
higher than state-of-the-art (SOTA) while it is trained on a 9 times smaller
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models. (arXiv:2108.04949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04949">
<div class="article-summary-box-inner">
<span><p>Social and behavioral determinants of health (SBDoH) have important roles in
shaping people's health. In clinical research studies, especially comparative
effectiveness studies, failure to adjust for SBDoH factors will potentially
cause confounding issues and misclassification errors in either statistical
analyses and machine learning-based models. However, there are limited studies
to examine SBDoH factors in clinical outcomes due to the lack of structured
SBDoH information in current electronic health record (EHR) systems, while much
of the SBDoH information is documented in clinical narratives. Natural language
processing (NLP) is thus the key technology to extract such information from
unstructured clinical text. However, there is not a mature clinical NLP system
focusing on SBDoH. In this study, we examined two state-of-the-art
transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH
concepts from clinical narratives, applied the best performing model to extract
SBDoH concepts on a lung cancer screening patient cohort, and examined the
difference of SBDoH information between NLP extracted results and structured
EHRs (SBDoH information captured in standard vocabularies such as the
International Classification of Diseases codes). The experimental results show
that the BERT-based NLP model achieved the best strict/lenient F1-score of
0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH
information and structured EHRs in the lung cancer patient cohort of 864
patients with 161,933 various types of clinical notes showed that much more
detailed information about smoking, education, and employment were only
captured in clinical narratives and that it is necessary to use both clinical
narratives and structured EHRs to construct a more complete picture of
patients' SBDoH factors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing. (arXiv:2108.04990v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04990">
<div class="article-summary-box-inner">
<span><p>Interpretability methods like Integrated Gradient and LIME are popular
choices for explaining natural language model predictions with relative word
importance scores. These interpretations need to be robust for trustworthy NLP
applications in high-stake areas like medicine or finance. Our paper
demonstrates how interpretations can be manipulated by making simple word
perturbations on an input text. Via a small portion of word-level swaps, these
adversarial perturbations aim to make the resulting text semantically and
spatially similar to its seed input (therefore sharing similar
interpretations). Simultaneously, the generated examples achieve the same
prediction label as the seed yet are given a substantially different
explanation by the interpretation methods. Our experiments generate fragile
interpretations to attack two SOTA interpretation methods, across three popular
Transformer models and on two different NLP datasets. We observe that the rank
order correlation drops by over 20% when less than 10% of words are perturbed
on average. Further, rank-order correlation keeps decreasing as more words get
perturbed. Furthermore, we demonstrate that candidates generated from our
method have good quality metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Transformer-based Math Language Model for Handwritten Math Expression Recognition. (arXiv:2108.05002v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05002">
<div class="article-summary-box-inner">
<span><p>Handwritten mathematical expressions (HMEs) contain ambiguities in their
interpretations, even for humans sometimes. Several math symbols are very
similar in the writing style, such as dot and comma or 0, O, and o, which is a
challenge for HME recognition systems to handle without using contextual
information. To address this problem, this paper presents a Transformer-based
Math Language Model (TMLM). Based on the self-attention mechanism, the
high-level representation of an input token in a sequence of tokens is computed
by how it is related to the previous tokens. Thus, TMLM can capture long
dependencies and correlations among symbols and relations in a mathematical
expression (ME). We trained the proposed language model using a corpus of
approximately 70,000 LaTeX sequences provided in CROHME 2016. TMLM achieved the
perplexity of 4.42, which outperformed the previous math language models, i.e.,
the N-gram and recurrent neural network-based language models. In addition, we
combine TMLM into a stochastic context-free grammar-based HME recognition
system using a weighting parameter to re-rank the top-10 best candidates. The
expression rates on the testing sets of CROHME 2016 and CROHME 2019 were
improved by 2.97 and 0.83 percentage points, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DEMix Layers: Disentangling Domains for Modular Language Modeling. (arXiv:2108.05036v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05036">
<div class="article-summary-box-inner">
<span><p>We introduce a new domain expert mixture (DEMix) layer that enables
conditioning a language model (LM) on the domain of the input text. A DEMix
layer is a collection of expert feedforward networks, each specialized to a
domain, that makes the LM modular: experts can be mixed, added or removed after
initial training. Extensive experiments with autoregressive transformer LMs (up
to 1.3B parameters) show that DEMix layers reduce test-time perplexity,
increase training efficiency, and enable rapid adaptation with little overhead.
We show that mixing experts during inference, using a parameter-free weighted
ensemble, allows the model to better generalize to heterogeneous or unseen
domains. We also show that experts can be added to iteratively incorporate new
domains without forgetting older ones, and that experts can be removed to
restrict access to unwanted domains, without additional training. Overall,
these results demonstrate benefits of explicitly conditioning on textual
domains during language modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report Generation With Alternate Learning. (arXiv:2108.05067v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05067">
<div class="article-summary-box-inner">
<span><p>Medical imaging technologies, including computed tomography (CT) or chest
X-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19.
Since manual report writing is usually too time-consuming, a more intelligent
auxiliary medical system that could generate medical reports automatically and
immediately is urgently needed. In this article, we propose to use the medical
visual language BERT (Medical-VLBERT) model to identify the abnormality on the
COVID-19 scans and generate the medical report automatically based on the
detected lesion regions. To produce more accurate medical reports and minimize
the visual-and-linguistic differences, this model adopts an alternate learning
strategy with two procedures that are knowledge pretraining and transferring.
To be more precise, the knowledge pretraining procedure is to memorize the
knowledge from medical texts, while the transferring procedure is to utilize
the acquired knowledge for professional medical sentences generations through
observations of medical images. In practice, for automatic medical report
generation on the COVID-19 cases, we constructed a dataset of 368 medical
findings in Chinese and 1104 chest CT scans from The First Affiliated Hospital
of Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun
Yat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of
the COVID-19 training samples, our model was first trained on the large-scale
Chinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for
further fine-tuning. The experimental results showed that Medical-VLBERT
achieved state-of-the-art performances on terminology prediction and report
generation with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The
Chinese COVID-19 CT dataset is available at https://covid19ct.github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PGCD: a position-guied contributive distribution unit for aspect based sentiment analysis. (arXiv:2108.05098v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05098">
<div class="article-summary-box-inner">
<span><p>Aspect based sentiment analysis (ABSA), exploring sentim- ent polarity of
aspect-given sentence, has drawn widespread applications in social media and
public opinion. Previously researches typically derive aspect-independent
representation by sentence feature generation only depending on text data. In
this paper, we propose a Position-Guided Contributive Distribution (PGCD) unit.
It achieves a position-dependent contributive pattern and generates
aspect-related statement feature for ABSA task. Quoted from Shapley Value, PGCD
can gain position-guided contextual contribution and enhance the aspect-based
representation. Furthermore, the unit can be used for improving effects on
multimodal ABSA task, whose datasets restructured by ourselves. Extensive
experiments on both text and text-audio level using dataset (SemEval) show that
by applying the proposed unit, the mainstream models advance performance in
accuracy and F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeliData: A dataset for deliberation in multi-party problem solving. (arXiv:2108.05271v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05271">
<div class="article-summary-box-inner">
<span><p>Dialogue systems research is traditionally focused on dialogues between two
interlocutors, largely ignoring group conversations. Moreover, most previous
research is focused either on task-oriented dialogue (e.g.\ restaurant
bookings) or user engagement (chatbots), while research on systems for
collaborative dialogues is an under-explored area. To this end, we introduce
the first publicly available dataset containing collaborative conversations on
solving a cognitive task, consisting of 500 group dialogues and 14k utterances.
Furthermore, we propose a novel annotation schema that captures deliberation
cues and release 50 dialogues annotated with it. Finally, we demonstrate the
usefulness of the annotated data in training classifiers to predict the
constructiveness of a conversation. The data collection platform, dataset and
annotated corpus are publicly available at https://delibot.xyz
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Icelandic Parallel Abstracts Corpus. (arXiv:2108.05289v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05289">
<div class="article-summary-box-inner">
<span><p>We present a new Icelandic-English parallel corpus, the Icelandic Parallel
Abstracts Corpus (IPAC), composed of abstracts from student theses and
dissertations. The texts were collected from the Skemman repository which keeps
records of all theses, dissertations and final projects from students at
Icelandic universities. The corpus was aligned based on sentence-level BLEU
scores, in both translation directions, from NMT models using Bleualign. The
result is a corpus of 64k sentence pairs from over 6 thousand parallel
abstracts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model Compression for Domain Adaptation through Causal Effect Estimation. (arXiv:2101.07086v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07086">
<div class="article-summary-box-inner">
<span><p>Recent improvements in the predictive quality of natural language processing
systems are often dependent on a substantial increase in the number of model
parameters. This has led to various attempts of compressing such models, but
existing methods have not considered the differences in the predictive power of
various model components or in the generalizability of the compressed models.
To understand the connection between model compression and out-of-distribution
generalization, we define the task of compressing language representation
models such that they perform best in a domain adaptation setting. We choose to
address this problem from a causal perspective, attempting to estimate the
average treatment effect (ATE) of a model component, such as a single layer, on
the model's predictions. Our proposed ATE-guided Model Compression scheme
(AMoC), generates many model candidates, differing by the model components that
were removed. Then, we select the best candidate through a stepwise regression
model that utilizes the ATE to predict the expected performance on the target
domain. AMoC outperforms strong baselines on dozens of domain pairs across
three text classification and sequence tagging tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-Trained Models: Past, Present and Future. (arXiv:2106.07139v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07139">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained models (PTMs) such as BERT and GPT have recently
achieved great success and become a milestone in the field of artificial
intelligence (AI). Owing to sophisticated pre-training objectives and huge
model parameters, large-scale PTMs can effectively capture knowledge from
massive labeled and unlabeled data. By storing knowledge into huge parameters
and fine-tuning on specific tasks, the rich knowledge implicitly encoded in
huge parameters can benefit a variety of downstream tasks, which has been
extensively demonstrated via experimental verification and empirical analysis.
It is now the consensus of the AI community to adopt PTMs as backbone for
downstream tasks rather than learning models from scratch. In this paper, we
take a deep look into the history of pre-training, especially its special
relation with transfer learning and self-supervised learning, to reveal the
crucial position of PTMs in the AI development spectrum. Further, we
comprehensively review the latest breakthroughs of PTMs. These breakthroughs
are driven by the surge of computational power and the increasing availability
of data, towards four important directions: designing effective architectures,
utilizing rich contexts, improving computational efficiency, and conducting
interpretation and theoretical analysis. Finally, we discuss a series of open
problems and research directions of PTMs, and hope our view can inspire and
advance the future study of PTMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Goal-Oriented Script Construction. (arXiv:2107.13189v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13189">
<div class="article-summary-box-inner">
<span><p>The knowledge of scripts, common chains of events in stereotypical scenarios,
is a valuable asset for task-oriented natural language understanding systems.
We propose the Goal-Oriented Script Construction task, where a model produces a
sequence of steps to accomplish a given goal. We pilot our task on the first
multilingual script learning dataset supporting 18 languages collected from
wikiHow, a website containing half a million how-to articles. For baselines, we
consider both a generation-based approach using a language model and a
retrieval-based approach by first retrieving the relevant steps from a large
candidate pool and then ordering them. We show that our task is practical,
feasible but challenging for state-of-the-art Transformer models, and that our
methods can be readily deployed for various other datasets and domains with
decent zero-shot performance.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-08-12 23:08:48.350129725 UTC">2021-08-12 23:08:48 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.1</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>