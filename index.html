<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-04T01:30:00Z">10-04</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Variance of Twitter Embeddings and Temporal Trends of COVID-19 cases. (arXiv:2110.00031v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00031">
<div class="article-summary-box-inner">
<span><p>The severity of the coronavirus pandemic necessitates the need of effective
administrative decisions. Over 4 lakh people in India succumbed to COVID-19,
with over 3 crore confirmed cases, and still counting. The threat of a
plausible third wave continues to haunt millions. In this ever changing dynamic
of the virus, predictive modeling methods can serve as an integral tool. The
pandemic has further triggered an unprecedented usage of social media. This
paper aims to propose a method for harnessing social media, specifically
Twitter, to predict the upcoming scenarios related to COVID-19 cases. In this
study, we seek to understand how the surges in COVID-19 related tweets can
indicate rise in the cases. This prospective analysis can be utilised to aid
administrators about timely resource allocation to lessen the severity of the
damage. Using word embeddings to capture the semantic meaning of tweets, we
identify Significant Dimensions (SDs).Our methodology predicts the rise in
cases with a lead time of 15 days and 30 days with R2 scores of 0.80 and 0.62
respectively. Finally, we explain the thematic utility of the SDs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">#ContextMatters: Advantages and Limitations of Using Machine Learning to Support Women in Politics. (arXiv:2110.00116v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00116">
<div class="article-summary-box-inner">
<span><p>The United Nations identified gender equality as a Sustainable Development
Goal in 2015, recognizing the underrepresentation of women in politics as a
specific barrier to achieving gender equality. Political systems around the
world experience gender inequality across all levels of elected government as
fewer women run for office than men. This is due in part to online abuse,
particularly on social media platforms like Twitter, where women seeking or in
power tend to be targeted with more toxic maltreatment than their male
counterparts. In this paper, we present reflections on ParityBOT - the first
natural language processing-based intervention designed to affect online
discourse for women in politics for the better, at scale. Deployed across
elections in Canada, the United States and New Zealand, ParityBOT was used to
analyse and classify more than 12 million tweets directed at women candidates
and counter toxic tweets with supportive ones. From these elections we present
three case studies highlighting the current limitations of, and future research
and application opportunities for, using a natural language processing-based
system to detect online toxicity, specifically with regards to contextually
important microaggressions. We examine the rate of false negatives, where
ParityBOT failed to pick up on insults directed at specific high profile women,
which would be obvious to human users. We examine the unaddressed harms of
microaggressions and the potential of yet unseen damage they cause for women in
these communities, and for progress towards gender equality overall, in light
of these technological blindspots. This work concludes with a discussion on the
benefits of partnerships between nonprofit social groups and technology experts
to develop responsible, socially impactful approaches to addressing online
hate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree-Constrained Graph Neural Networks For Argument Mining. (arXiv:2110.00124v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00124">
<div class="article-summary-box-inner">
<span><p>We propose a novel architecture for Graph Neural Networks that is inspired by
the idea behind Tree Kernels of measuring similarity between trees by taking
into account their common substructures, named fragments. By imposing a series
of regularization constraints to the learning problem, we exploit a pooling
mechanism that incorporates such notion of fragments within the node soft
assignment function that produces the embeddings. We present an extensive
experimental evaluation on a collection of sentence classification tasks
conducted on several argument mining corpora, showing that the proposed
approach performs well with respect to state-of-the-art techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MemBERT: Injecting Unstructured Knowledge into BERT. (arXiv:2110.00125v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00125">
<div class="article-summary-box-inner">
<span><p>Transformers changed modern NLP in many ways. However, they can hardly
exploit domain knowledge, and like other blackbox models, they lack
interpretability. Unfortunately, structured knowledge injection, in the long
run, risks to suffer from a knowledge acquisition bottleneck. We thus propose a
memory enhancement of transformer models that makes use of unstructured domain
knowledge expressed in plain natural language. An experimental evaluation
conducted on two challenging NLP tasks demonstrates that our approach yields
better performance and model interpretability than baseline transformer-based
architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UserIdentifier: Implicit User Representations for Simple and Effective Personalized Sentiment Analysis. (arXiv:2110.00135v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00135">
<div class="article-summary-box-inner">
<span><p>Global models are trained to be as generalizable as possible, with user
invariance considered desirable since the models are shared across multitudes
of users. As such, these models are often unable to produce personalized
responses for individual users, based on their data. Contrary to widely-used
personalization techniques based on few-shot learning, we propose
UserIdentifier, a novel scheme for training a single shared model for all
users. Our approach produces personalized responses by adding fixed,
non-trainable user identifiers to the input data. We empirically demonstrate
that this proposed method outperforms the prefix-tuning based state-of-the-art
approach by up to 13%, on a suite of sentiment analysis datasets. We also show
that, unlike prior work, this method needs neither any additional model
parameters nor any extra rounds of few-shot fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span Labeling Approach for Vietnamese and Chinese Word Segmentation. (arXiv:2110.00156v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00156">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a span labeling approach to model n-gram
information for Vietnamese word segmentation, namely SPAN SEG. We compare the
span labeling approach with the conditional random field by using encoders with
the same architecture. Since Vietnamese and Chinese have similar linguistic
phenomena, we evaluated the proposed method on the Vietnamese treebank
benchmark dataset and five Chinese benchmark datasets. Through our experimental
results, the proposed approach SpanSeg achieves higher performance than the
sequence tagging approach with the state-of-the-art F-score of 98.31% on the
Vietnamese treebank benchmark, when they both apply the contextual pre-trained
language model XLM-RoBERTa and the predicted word boundary information.
Besides, we do fine-tuning experiments for the span labeling approach on BERT
and ZEN pre-trained language model for Chinese with fewer parameters, faster
inference time, and competitive or higher F-scores than the previous
state-of-the-art approach, word segmentation with word-hood memory networks, on
five Chinese benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Under the Microscope: Interpreting Readability Assessment Models for Filipino. (arXiv:2110.00157v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00157">
<div class="article-summary-box-inner">
<span><p>Readability assessment is the process of identifying the level of ease or
difficulty of a certain piece of text for its intended audience. Approaches
have evolved from the use of arithmetic formulas to more complex
pattern-recognizing models trained using machine learning algorithms. While
using these approaches provide competitive results, limited work is done on
analyzing how linguistic variables affect model inference quantitatively. In
this work, we dissect machine learning-based readability assessment models in
Filipino by performing global and local model interpretation to understand the
contributions of varying linguistic features and discuss its implications in
the context of the Filipino language. Results show that using a model trained
with top features from global interpretation obtained higher performance than
the ones using features selected by Spearman correlation. Likewise, we also
empirically observed local feature weight boundaries for discriminating reading
difficulty at an extremely fine-grained level and their corresponding effects
if values are perturbed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building an Efficient and Effective Retrieval-based Dialogue System via Mutual Learning. (arXiv:2110.00159v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00159">
<div class="article-summary-box-inner">
<span><p>Establishing retrieval-based dialogue systems that can select appropriate
responses from the pre-built index has gained increasing attention from
researchers. For this task, the adoption of pre-trained language models (such
as BERT) has led to remarkable progress in a number of benchmarks. There exist
two common approaches, including cross-encoders which perform full attention
over the inputs, and bi-encoders that encode the context and response
separately. The former gives considerable improvements in accuracy but is often
inapplicable in practice for large-scale retrieval given the cost of the full
attention required for each sample at test time. The latter is efficient for
billions of indexes but suffers from sub-optimal performance. In this work, we
propose to combine the best of both worlds to build a retrieval system.
Specifically, we employ a fast bi-encoder to replace the traditional
feature-based pre-retrieval model (such as BM25) and set the response
re-ranking model as a more complicated architecture (such as cross-encoder). To
further improve the effectiveness of our framework, we train the pre-retrieval
model and the re-ranking model at the same time via mutual learning, which
enables two models to learn from each other throughout the training process. We
conduct experiments on two benchmarks and evaluation results demonstrate the
efficiency and effectiveness of our proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large-scale ASR Domain Adaptation by Self- and Semi-supervised Learning. (arXiv:2110.00165v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00165">
<div class="article-summary-box-inner">
<span><p>Self- and Semi-supervised learning methods have been actively investigated to
reduce labeled training data or enhance the model performance. However, the
approach mostly focus on in-domain performance for public datasets. In this
study, we utilize the combination of self- and semi-supervised learning methods
to solve unseen domain adaptation problem in a large-scale production setting
for online ASR model. This approach demonstrates that using the source domain
data with a small fraction of the target domain data (3%) can recover the
performance gap compared to a full data baseline: relative 13.5% WER
improvement for target domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT4GCN: Using BERT Intermediate Layers to Augment GCN for Aspect-based Sentiment Classification. (arXiv:2110.00171v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00171">
<div class="article-summary-box-inner">
<span><p>Graph-based Aspect-based Sentiment Classification (ABSC) approaches have
yielded state-of-the-art results, expecially when equipped with contextual word
embedding from pre-training language models (PLMs). However, they ignore
sequential features of the context and have not yet made the best of PLMs. In
this paper, we propose a novel model, BERT4GCN, which integrates the
grammatical sequential features from the PLM of BERT, and the syntactic
knowledge from dependency graphs. BERT4GCN utilizes outputs from intermediate
layers of BERT and positional information between words to augment GCN (Graph
Convolutional Network) to better encode the dependency graphs for the
downstream classification. Experimental results demonstrate that the proposed
BERT4GCN outperforms all state-of-the-art baselines, justifying that augmenting
GCN with the grammatical features from intermediate layers of BERT can
significantly empower ABSC models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey of Knowledge Enhanced Pre-trained Models. (arXiv:2110.00269v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00269">
<div class="article-summary-box-inner">
<span><p>Pre-trained models learn contextualized word representations on large-scale
text corpus through a self-supervised learning method, which has achieved
promising performance after fine-tuning. These models, however, suffer from
poor robustness and lack of interpretability. Pre-trained models with knowledge
injection, which we call knowledge enhanced pre-trained models (KEPTMs),
possess deep understanding and logical reasoning and introduce interpretability
to some extent. In this survey, we provide a comprehensive overview of KEPTMs
for natural language processing. We first introduce the progress of pre-trained
models and knowledge representation learning. Then we systematically categorize
existing KEPTMs from three different perspectives. Finally, we outline some
potential directions of KEPTMs for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Harmful Memes and Their Targets. (arXiv:2110.00413v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00413">
<div class="article-summary-box-inner">
<span><p>Among the various modes of communication in social media, the use of Internet
memes has emerged as a powerful means to convey political, psychological, and
socio-cultural opinions. Although memes are typically humorous in nature,
recent days have witnessed a proliferation of harmful memes targeted to abuse
various social entities. As most harmful memes are highly satirical and
abstruse without appropriate contexts, off-the-shelf multimodal models may not
be adequate to understand their underlying semantics. In this work, we propose
two novel problem formulations: detecting harmful memes and the social entities
that these harmful memes target. To this end, we present HarMeme, the first
benchmark dataset, containing 3,544 memes related to COVID-19. Each meme went
through a rigorous two-stage annotation process. In the first stage, we labeled
a meme as very harmful, partially harmful, or harmless; in the second stage, we
further annotated the type of target(s) that each harmful meme points to:
individual, organization, community, or society/general public/other. The
evaluation results using ten unimodal and multimodal models highlight the
importance of using multimodal signals for both tasks. We further discuss the
limitations of these models and we argue that more research is needed to
address these problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FiLMing Multimodal Sarcasm Detection with Attention. (arXiv:2110.00416v1 [cs.MM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00416">
<div class="article-summary-box-inner">
<span><p>Sarcasm detection identifies natural language expressions whose intended
meaning is different from what is implied by its surface meaning. It finds
applications in many NLP tasks such as opinion mining, sentiment analysis, etc.
Today, social media has given rise to an abundant amount of multimodal data
where users express their opinions through text and images. Our paper aims to
leverage multimodal data to improve the performance of the existing systems for
sarcasm detection. So far, various approaches have been proposed that uses text
and image modality and a fusion of both. We propose a novel architecture that
uses the RoBERTa model with a co-attention layer on top to incorporate context
incongruity between input text and image attributes. Further, we integrate
feature-wise affine transformation by conditioning the input image through
FiLMed ResNet blocks with the textual features using the GRU network to capture
the multimodal information. The output from both the models and the CLS token
from RoBERTa is concatenated and used for the final prediction. Our results
demonstrate that our proposed model outperforms the existing state-of-the-art
method by 6.14% F1 score on the public Twitter multimodal sarcasm detection
dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Non-Negative Matrix Factorization and n-stage Latent Dirichlet Allocation for Emotion Analysis in Turkish Tweets. (arXiv:2110.00418v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00418">
<div class="article-summary-box-inner">
<span><p>With the development of technology, the use of social media has become quite
common. Analyzing comments on social media in areas such as media and
advertising plays an important role today. For this reason, new and traditional
natural language processing methods are used to detect the emotion of these
shares. In this paper, the Latent Dirichlet Allocation, namely LDA, and
Non-Negative Matrix Factorization methods in topic modeling were used to
determine which emotion the Turkish tweets posted via Twitter. In addition, the
accuracy of a proposed n-level method based on LDA was analyzed. Dataset
consists of 5 emotions, namely angry, fear, happy, sad and confused. NMF was
the most successful method among all topic modeling methods in this study.
Then, the F1-measure of Random Forest, Naive Bayes and Support Vector Machine
methods was analyzed by obtaining a file suitable for Weka by using the word
weights and class labels of the topics. Among the Weka results, the most
successful method was n-stage LDA, and the most successful algorithm was Random
Forest.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Web Scale Entity Extraction System. (arXiv:2110.00423v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00423">
<div class="article-summary-box-inner">
<span><p>Understanding the semantic meaning of content on the web through the lens of
entities and concepts has many practical advantages. However, when building
large-scale entity extraction systems, practitioners are facing unique
challenges involving finding the best ways to leverage the scale and variety of
data available on internet platforms. We present learnings from our efforts in
building an entity extraction system for multiple document types at large scale
using multi-modal Transformers. We empirically demonstrate the effectiveness of
multi-lingual, multi-task and cross-document type learning. We also discuss the
label collection schemes that help to minimize the amount of noise in the
collected data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rumor Detection on Social Media with Hierarchical Adversarial Training. (arXiv:2110.00425v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00425">
<div class="article-summary-box-inner">
<span><p>The proliferation of rumors on social media has a huge impact on society.
However, natural language text is high-dimensional and sparse, and the same
rumor may be expressed in hundreds of ways on social media. As such, the
robustness and generalization of the current rumor detection model are put into
question. We propose a new hierarchical model called HAT-RD, which is divided
into two categories: post-level modules and event-level modules. HAT-RD adopts
a novel hierarchical adversarial training method based on gradient ascent by
adding adversarial perturbations to the embedding layers both of post-level
modules and event-level modules to deceive the detector. At the same time, the
detector uses stochastic gradient descent to minimize the adversarial risk to
learn a more robust model. In this way, the post-level and event-level sample
spaces are enhanced, and experiments indicate that the model drift into an area
with a flat loss landscape that leads to better generalization. Experiments on
two real-world datasets demonstrate that our model achieves better results than
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-shot Natural Language Video Localization. (arXiv:2110.00428v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00428">
<div class="article-summary-box-inner">
<span><p>Understanding videos to localize moments with natural language often requires
large expensive annotated video regions paired with language queries. To
eliminate the annotation costs, we make a first attempt to train a natural
language video localization model in zero-shot manner. Inspired by unsupervised
image captioning setup, we merely require random text corpora, unlabeled video
collections, and an off-the-shelf object detector to train a model. With the
unpaired data, we propose to generate pseudo-supervision of candidate temporal
regions and corresponding query sentences, and develop a simple NLVL model to
train with the pseudo-supervision. Our empirical validations show that the
proposed pseudo-supervised method outperforms several baseline approaches and a
number of methods using stronger supervision on Charades-STA and
ActivityNet-Captions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">External knowledge transfer deployment inside a simple double agent Viterbi algorithm. (arXiv:2110.00433v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00433">
<div class="article-summary-box-inner">
<span><p>We consider in this paper deploying external knowledge transfer inside a
simple double agent Viterbi algorithm which is an algorithm firstly introduced
by the author in his preprint "Hidden Markov Based Mathematical Model dedicated
to Extract Ingredients from Recipe Text". The key challenge of this work lies
in discovering the reason why our old model does have bad performances when it
is confronted with estimating ingredient state for unknown words and see if
deploying external knowledge transfer directly on calculating state matrix
could be the solution instead of deploying it only on back propagating step.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention based Sequence to Sequence Learning for Machine Translation of Low Resourced Indic Languages -- A case of Sanskrit to Hindi. (arXiv:2110.00435v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00435">
<div class="article-summary-box-inner">
<span><p>Deep Learning techniques are powerful in mimicking humans in a particular set
of problems. They have achieved a remarkable performance in complex learning
tasks. Deep learning inspired Neural Machine Translation (NMT) is a proficient
technique that outperforms traditional machine translation. Performing
machine-aided translation on Indic languages has always been a challenging task
considering their rich and diverse grammar. The neural machine translation has
shown quality results compared to the traditional machine translation
approaches. The fully automatic machine translation becomes problematic when it
comes to low-resourced languages, especially with Sanskrit. This paper presents
attention mechanism based neural machine translation by selectively focusing on
a particular part of language sentences during translation. The work shows the
construction of Sanskrit to Hindi bilingual parallel corpus with nearly 10K
samples and having 178,000 tokens. The neural translation model equipped with
an attention mechanism has been trained on Sanskrit to Hindi parallel corpus.
The approach has shown the significance of attention mechanisms to overcome
long-term dependencies, primarily associated with low resources Indic
languages. The paper shows the attention plots on testing data to demonstrate
the alignment between source and translated words. For the evaluation of the
translated sentences, manual score based human evaluation and automatic
evaluation metric based techniques have been adopted. The attention mechanism
based neural translation has achieved 88% accuracy in human evaluation and a
BLEU score of 0.92 on Sanskrit to Hindi translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phonology Recognition in American Sign Language. (arXiv:2110.00453v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00453">
<div class="article-summary-box-inner">
<span><p>Inspired by recent developments in natural language processing, we propose a
novel approach to sign language processing based on phonological properties
validated by American Sign Language users. By taking advantage of datasets
composed of phonological data and people speaking sign language, we use a
pretrained deep model based on mesh reconstruction to extract the 3D
coordinates of the signers keypoints. Then, we train standard statistical and
deep machine learning models in order to assign phonological classes to each
temporal sequence of coordinates.
</p>
<p>Our paper introduces the idea of exploiting the phonological properties
manually assigned by sign language users to classify videos of people
performing signs by regressing a 3D mesh. We establish a new baseline for this
problem based on the statistical distribution of 725 different signs. Our
best-performing models achieve a micro-averaged F1-score of 58% for the major
location class and 70% for the sign type using statistical and deep learning
algorithms, compared to their corresponding baselines of 35% and 39%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Ask for Data-Efficient Event Argument Extraction. (arXiv:2110.00479v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00479">
<div class="article-summary-box-inner">
<span><p>Event argument extraction (EAE) is an important task for information
extraction to discover specific argument roles. In this study, we cast EAE as a
question-based cloze task and empirically analyze fixed discrete token template
performance. As generating human-annotated question templates is often
time-consuming and labor-intensive, we further propose a novel approach called
"Learning to Ask," which can learn optimized question templates for EAE without
human annotations. Experiments using the ACE-2005 dataset demonstrate that our
method based on optimized questions achieves state-of-the-art performance in
both the few-shot and supervised settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEMON: Explainable Entity Matching. (arXiv:2110.00516v1 [cs.DB])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00516">
<div class="article-summary-box-inner">
<span><p>State-of-the-art entity matching (EM) methods are hard to interpret, and
there is significant value in bringing explainable AI to EM. Unfortunately,
most popular explainability methods do not work well out of the box for EM and
need adaptation. In this paper, we identify three challenges of applying local
post hoc feature attribution methods to entity matching: cross-record
interaction effects, non-match explanations, and variation in sensitivity. We
propose our novel model-agnostic and schema-flexible method LEMON that
addresses all three challenges by (i) producing dual explanations to avoid
cross-record interaction effects, (ii) introducing the novel concept of
attribution potential to explain how two records could have matched, and (iii)
automatically choosing explanation granularity to match the sensitivity of the
matcher and record pair in question. Experiments on public datasets demonstrate
that the proposed method is more faithful to the matcher and does a better job
of helping users understand the decision boundary of the matcher than previous
work. Furthermore, user studies show that the rate at which human subjects can
construct counterfactual examples after seeing an explanation from our proposed
method increases from 54% to 64% for matches and from 15% to 49% for
non-matches compared to explanations from a standard adaptation of LIME.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Calibrating Concepts and Operations: Towards Symbolic Reasoning on Real Images. (arXiv:2110.00519v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00519">
<div class="article-summary-box-inner">
<span><p>While neural symbolic methods demonstrate impressive performance in visual
question answering on synthetic images, their performance suffers on real
images. We identify that the long-tail distribution of visual concepts and
unequal importance of reasoning steps in real data are the two key obstacles
that limit the models' real-world potentials. To address these challenges, we
propose a new paradigm, Calibrating Concepts and Operations (CCO), which
enables neural symbolic models to capture underlying data characteristics and
to reason with hierarchical importance. Specifically, we introduce an executor
with learnable concept embedding magnitudes for handling distribution
imbalance, and an operation calibrator for highlighting important operations
and suppressing redundant ones. Our experiments show CCO substantially boosts
the performance of neural symbolic methods on real images. By evaluating models
on the real world dataset GQA, CCO helps the neural symbolic method NSCL
outperforms its vanilla counterpart by 9.1% (from 47.0% to 56.1%); this result
also largely reduces the performance gap between symbolic and non-symbolic
methods. Additionally, we create a perturbed test set for better understanding
and analyzing model performance on real images. Code is available at
https://github.com/Lizw14/CaliCO.git .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unpacking the Interdependent Systems of Discrimination: Ableist Bias in NLP Systems through an Intersectional Lens. (arXiv:2110.00521v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00521">
<div class="article-summary-box-inner">
<span><p>Much of the world's population experiences some form of disability during
their lifetime. Caution must be exercised while designing natural language
processing (NLP) systems to prevent systems from inadvertently perpetuating
ableist bias against people with disabilities, i.e., prejudice that favors
those with typical abilities. We report on various analyses based on word
predictions of a large-scale BERT language model. Statistically significant
results demonstrate that people with disabilities can be disadvantaged.
Findings also explore overlapping forms of discrimination related to
interconnected gender and race identities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TEACh: Task-driven Embodied Agents that Chat. (arXiv:2110.00534v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00534">
<div class="article-summary-box-inner">
<span><p>Robots operating in human spaces must be able to engage in natural language
interaction with people, both understanding and executing instructions, and
using conversation to resolve ambiguity and recover from mistakes. To study
this, we introduce TEACh, a dataset of over 3,000 human--human, interactive
dialogues to complete household tasks in simulation. A Commander with access to
oracle information about a task communicates in natural language with a
Follower. The Follower navigates through and interacts with the environment to
complete tasks varying in complexity from "Make Coffee" to "Prepare Breakfast",
asking questions and getting additional information from the Commander. We
propose three benchmarks using TEACh to study embodied intelligence challenges,
and we evaluate initial models' abilities in dialogue understanding, language
grounding, and task execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Natural language understanding for logical games. (arXiv:2110.00558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00558">
<div class="article-summary-box-inner">
<span><p>We developed a system able to automatically solve logical puzzles in natural
language. Our solution is composed by a parser and an inference module. The
parser translates the text into first order logic (FOL), while the MACE4 model
finder is used to compute the models of the given FOL theory. We also empower
our software agent with the capability to provide Yes/No answers to natural
language questions related to each puzzle. Moreover, in line with Explainalbe
Artificial Intelligence (XAI), the agent can back its answer, providing a
graphical representation of the proof. The advantage of using reasoning for
Natural Language Understanding (NLU) instead of Machine learning is that the
user can obtain an explanation of the reasoning chain. We illustrate how the
system performs on various types of natural language puzzles, including 382
knights and knaves puzzles. These features together with the overall
performance rate of 80.89\% makes the proposed solution an improvement upon
similar solvers for natural language understanding in the puzzles domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Punctuation Restoration for Speech Transcripts via External Data. (arXiv:2110.00560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00560">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Recognition (ASR) systems generally do not produce
punctuated transcripts. To make transcripts more readable and follow the
expected input format for downstream language models, it is necessary to add
punctuation marks. In this paper, we tackle the punctuation restoration problem
specifically for the noisy text (e.g., phone conversation scenarios). To
leverage the available written text datasets, we introduce a data sampling
technique based on an n-gram language model to sample more training data that
are similar to our in-domain data. Moreover, we propose a two-stage fine-tuning
approach that utilizes the sampled external data as well as our in-domain
dataset for models based on BERT. Extensive experiments show that the proposed
approach outperforms the baseline with an improvement of 1:12% F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Paraphrases as Foreign Languages in Multilingual Neural Machine Translation. (arXiv:1808.08438v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1808.08438">
<div class="article-summary-box-inner">
<span><p>Paraphrases, the rewordings of the same semantic meaning, are useful for
improving generalization and translation. However, prior works only explore
paraphrases at the word or phrase level, not at the sentence or corpus level.
Unlike previous works that only explore paraphrases at the word or phrase
level, we use different translations of the whole training data that are
consistent in structure as paraphrases at the corpus level. We train on
parallel paraphrases in multiple languages from various sources. We treat
paraphrases as foreign languages, tag source sentences with paraphrase labels,
and train on parallel paraphrases in the style of multilingual Neural Machine
Translation (NMT). Our multi-paraphrase NMT that trains only on two languages
outperforms the multilingual baselines. Adding paraphrases improves the rare
word translation and increases entropy and diversity in lexical choice. Adding
the source paraphrases boosts performance better than adding the target ones.
Combining both the source and the target paraphrases lifts performance further;
combining paraphrases with multilingual data helps but has mixed performance.
We achieve a BLEU score of 57.2 for French-to-English translation using 24
corpus-level paraphrases of the Bible, which outperforms the multilingual
baselines and is +34.7 above the single-source single-target NMT baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergence of Pragmatics from Referential Game between Theory of Mind Agents. (arXiv:2001.07752v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.07752">
<div class="article-summary-box-inner">
<span><p>Pragmatics studies how context can contribute to language meanings. In human
communication, language is never interpreted out of context, and sentences can
usually convey more information than their literal meanings. However, this
mechanism is missing in most multi-agent systems, restricting the communication
efficiency and the capability of human-agent interaction. In this paper, we
propose an algorithm, using which agents can spontaneously learn the ability to
"read between lines" without any explicit hand-designed rules. We integrate the
theory of mind (ToM) in a cooperative multi-agent pedagogical situation and
propose an adaptive reinforcement learning (RL) algorithm to develop a
communication protocol. ToM is a profound cognitive science concept, claiming
that people regularly reason about other's mental states, including beliefs,
goals, and intentions, to obtain performance advantage in competition,
cooperation or coalition. With this ability, agents consider language as not
only messages but also rational acts reflecting others' hidden states. Our
experiments demonstrate the advantage of pragmatic protocols over non-pragmatic
protocols. We also show the teaching complexity following the pragmatic
protocol empirically approximates to recursive teaching dimension (RTD).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Self-Training for Sentiment Analysis of Code-Switched Data. (arXiv:2103.14797v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14797">
<div class="article-summary-box-inner">
<span><p>Sentiment analysis is an important task in understanding social media content
like customer reviews, Twitter and Facebook feeds etc. In multilingual
communities around the world, a large amount of social media text is
characterized by the presence of Code-Switching. Thus, it has become important
to build models that can handle code-switched data. However, annotated
code-switched data is scarce and there is a need for unsupervised models and
algorithms. We propose a general framework called Unsupervised Self-Training
and show its applications for the specific use case of sentiment analysis of
code-switched data. We use the power of pre-trained BERT models for
initialization and fine-tune them in an unsupervised manner, only using pseudo
labels produced by zero-shot transfer. We test our algorithm on multiple
code-switched languages and provide a detailed analysis of the learning
dynamics of the algorithm with the aim of answering the question - `Does our
unsupervised model understand the Code-Switched languages or does it just learn
its representations?'. Our unsupervised models compete well with their
supervised counterparts, with their performance reaching within 1-7\% (weighted
F1 scores) when compared to supervised models trained for a two class problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers. (arXiv:2104.01604v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01604">
<div class="article-summary-box-inner">
<span><p>This paper introduces Timers and Such, a new open source dataset of spoken
English commands for common voice control use cases involving numbers. We
describe the gap in existing spoken language understanding datasets that Timers
and Such fills, the design and creation of the dataset, and experiments with a
number of ASR-based and end-to-end baseline models, the code for which has been
made available as part of the SpeechBrain toolkit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FRAKE: Fusional Real-time Automatic Keyword Extraction. (arXiv:2104.04830v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04830">
<div class="article-summary-box-inner">
<span><p>Keyword extraction is the process of identifying the words or phrases that
express the main concepts of text to the best of one's ability. Electronic
infrastructure creates a considerable amount of text every day and at all
times. This massive volume of documents makes it practically impossible for
human resources to study and manage them. Nevertheless, the need for these
documents to be accessed efficiently and effectively is evident in numerous
purposes. A blog, news article, or technical note is considered a relatively
long text since the reader aims to learn the subject based on keywords or
topics. Our approach consists of a combination of two models: graph centrality
features and textural features. The proposed method has been used to extract
the best keyword among the candidate keywords with an optimal combination of
graph centralities, such as degree, betweenness, eigenvector, closeness
centrality and etc, and textural, such as Casing, Term position, Term frequency
normalization, Term different sentence, Part Of Speech tagging. There have also
been attempts to distinguish keywords from candidate phrases and consider them
on separate keywords. For evaluating the proposed method, seven datasets were
used: Semeval2010, SemEval2017, Inspec, fao30, Thesis100, pak2018, and
Wikinews, with results reported as Precision, Recall, and F- measure. Our
proposed method performed much better in terms of evaluation metrics in all
reviewed datasets compared with available methods in literature. An approximate
16.9% increase was witnessed in F-score metric and this was much more for the
Inspec in English datasets and WikiNews in forgone languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Family of Origin and Family of Choice: Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Machine Translation. (arXiv:2104.05848v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05848">
<div class="article-summary-box-inner">
<span><p>We translate a closed text that is known in advance into a severely low
resource language by leveraging massive source parallelism. In other words,
given a text in 124 source languages, we translate it into a severely low
resource language using only ~1,000 lines of low resource data without any
external help. Firstly, we propose a systematic method to rank and choose
source languages that are close to the low resource language. We call the
linguistic definition of language family Family of Origin (FAMO), and we call
the empirical definition of higher-ranked languages using our metrics Family of
Choice (FAMC). Secondly, we build an Iteratively Pretrained Multilingual
Order-preserving Lexiconized Transformer (IPML) to train on ~1,000 lines
(~3.5%) of low resource data. To translate named entities correctly, we build a
massive lexicon table for 2,939 Bible named entities in 124 source languages,
and include many that occur once and covers more than 66 severely low resource
languages. Moreover, we also build a novel method of combining translations
from different source languages into one. Using English as a hypothetical low
resource language, we get a +23.9 BLEU increase over a multilingual baseline,
and a +10.3 BLEU increase over our asymmetric baseline in the Bible dataset. We
get a 42.8 BLEU score for Portuguese-English translation on the medical EMEA
dataset. We also have good results for a real severely low resource Mayan
language, Eastern Pokomchi.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Moving on from OntoNotes: Coreference Resolution Model Transfer. (arXiv:2104.08457v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08457">
<div class="article-summary-box-inner">
<span><p>Academic neural models for coreference resolution (coref) are typically
trained on a single dataset, OntoNotes, and model improvements are benchmarked
on that same dataset. However, real-world applications of coref depend on the
annotation guidelines and the domain of the target dataset, which often differ
from those of OntoNotes. We aim to quantify transferability of coref models
based on the number of annotated documents available in the target dataset. We
examine eleven target datasets and find that continued training is consistently
effective and especially beneficial when there are few target documents. We
establish new benchmarks across several datasets, including state-of-the-art
results on PreCo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP. (arXiv:2104.08835v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08835">
<div class="article-summary-box-inner">
<span><p>Humans can learn a new language task efficiently with only few examples, by
leveraging their knowledge obtained when learning prior tasks. In this paper,
we explore whether and how such cross-task generalization ability can be
acquired, and further applied to build better few-shot learners across diverse
NLP tasks. We introduce CrossFit, a problem setup for studying cross-task
generalization ability, which standardizes seen/unseen task partitions, data
access during different learning stages, and the evaluation protocols. To
instantiate different seen/unseen task partitions in CrossFit and facilitate
in-depth analysis, we present the NLP Few-shot Gym, a repository of 160 diverse
few-shot NLP tasks created from open-access NLP datasets and converted to a
unified text-to-text format. Our analysis reveals that the few-shot learning
ability on unseen tasks can be improved via an upstream learning stage using a
set of seen tasks. We also observe that the selection of upstream learning
tasks can significantly influence few-shot performance on unseen tasks, asking
further analysis on task similarity and transferability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Influence of Masking Policies in Intermediate Pre-training. (arXiv:2104.08840v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08840">
<div class="article-summary-box-inner">
<span><p>Current NLP models are predominantly trained through a two-stage "pre-train
then fine-tune" pipeline. Prior work has shown that inserting an intermediate
pre-training stage, using heuristic masking policies for masked language
modeling (MLM), can significantly improve final performance. However, it is
still unclear (1) in what cases such intermediate pre-training is helpful, (2)
whether hand-crafted heuristic objectives are optimal for a given task, and (3)
whether a masking policy designed for one task is generalizable beyond that
task. In this paper, we perform a large-scale empirical study to investigate
the effect of various masking policies in intermediate pre-training with nine
selected tasks across three categories. Crucially, we introduce methods to
automate the discovery of optimal masking policies via direct supervision or
meta-learning. We conclude that the success of intermediate pre-training is
dependent on appropriate pre-train corpus, selection of output format (i.e.,
masked spans or full sentence), and clear understanding of the role that MLM
plays for the downstream task. In addition, we find our learned masking
policies outperform the heuristic of masking named entities on TriviaQA, and
policies learned from one task can positively transfer to other tasks in
certain cases, inviting future research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-based Clinical Note Summarization. (arXiv:2104.08942v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08942">
<div class="article-summary-box-inner">
<span><p>The trend of deploying digital systems in numerous industries has induced a
hike in recording digital information. The health sector has observed an
extensive adoption of digital devices and systems that generate large volumes
of personal medical records. Electronic health records contain valuable
information for retrospective and prospective analysis that is often not
entirely exploited because of the dense information storage. The crude purpose
of condensing health records is to select the information that holds most
characteristics of the original documents based on reported disease. These
summaries may boost diagnosis and extend a doctor's time with the patient
during a high workload situation like the COVID-19 pandemic. In this paper, we
propose applying a multi-head attention-based mechanism to perform extractive
summarization of meaningful phrases in clinical notes. This method finds major
sentences for a summary by correlating tokens, segments, and positional
embeddings. The model outputs attention scores that are statistically
transformed to extract key phrases and can be used to projection on the
heat-mapping tool for visual and human use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03842">
<div class="article-summary-box-inner">
<span><p>Error correction techniques have been used to refine the output sentences
from automatic speech recognition (ASR) models and achieve a lower word error
rate (WER) than original ASR outputs. Previous works usually use a
sequence-to-sequence model to correct an ASR output sentence autoregressively,
which causes large latency and cannot be deployed in online ASR services. A
straightforward solution to reduce latency, inspired by non-autoregressive
(NAR) neural machine translation, is to use an NAR sequence generation model
for ASR error correction, which, however, comes at the cost of significantly
increased ASR error rate. In this paper, observing distinctive error patterns
and correction operations (i.e., insertion, deletion, and substitution) in ASR,
we propose FastCorrect, a novel NAR error correction model based on edit
alignment. In training, FastCorrect aligns each source token from an ASR output
sentence to the target tokens from the corresponding ground-truth sentence
based on the edit distance between the source and target sentences, and
extracts the number of target tokens corresponding to each source token during
edition/correction, which is then used to train a length predictor and to
adjust the source tokens to match the length of the target sentence for
parallel generation. In inference, the token number predicted by the length
predictor is used to adjust the source tokens for target sequence generation.
Experiments on the public AISHELL-1 dataset and an internal industrial-scale
ASR dataset show the effectiveness of FastCorrect for ASR error correction: 1)
it speeds up the inference by 6-9 times and maintains the accuracy (8-14% WER
reduction) compared with the autoregressive correction model; and 2) it
outperforms the popular NAR models adopted in neural machine translation and
text edition by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding. (arXiv:2105.09996v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09996">
<div class="article-summary-box-inner">
<span><p>We present a simplified, task-agnostic multi-modal pre-training approach that
can accept either video or text input, or both for a variety of end tasks.
Existing pre-training are task-specific by adopting either a single cross-modal
encoder that requires both modalities, limiting their use for retrieval-style
end tasks or more complex multitask learning with two unimodal encoders,
limiting early cross-modal fusion. We instead introduce new pretraining masking
schemes that better mix across modalities (e.g. by forcing masks for text to
predict the closest video embeddings) while also maintaining separability (e.g.
unimodal predictions are sometimes required, without using all the input).
Experimental results show strong performance across a wider range of tasks than
any previous methods, often outperforming task-specific pre-training. Code is
made available at https://github.com/pytorch/fairseq/tree/main/examples/MMPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Annotation Inconsistency and Entity Bias in MultiWOZ. (arXiv:2105.14150v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14150">
<div class="article-summary-box-inner">
<span><p>MultiWOZ is one of the most popular multi-domain task-oriented dialog
datasets, containing 10K+ annotated dialogs covering eight domains. It has been
widely accepted as a benchmark for various dialog tasks, e.g., dialog state
tracking (DST), natural language generation (NLG), and end-to-end (E2E) dialog
modeling. In this work, we identify an overlooked issue with dialog state
annotation inconsistencies in the dataset, where a slot type is tagged
inconsistently across similar dialogs leading to confusion for DST modeling. We
propose an automated correction for this issue, which is present in a whopping
70% of the dialogs. Additionally, we notice that there is significant entity
bias in the dataset (e.g., "cambridge" appears in 50% of the destination cities
in the train domain). The entity bias can potentially lead to named entity
memorization in generative models, which may go unnoticed as the test set
suffers from a similar entity bias as well. We release a new test set with all
entities replaced with unseen entities. Finally, we benchmark joint goal
accuracy (JGA) of the state-of-the-art DST baselines on these modified versions
of the data. Our experiments show that the annotation inconsistency corrections
lead to 7-10% improvement in JGA. On the other hand, we observe a 29% drop in
JGA when models are evaluated on the new test set with unseen entities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-utterance Reranking Models with BERT and Graph Convolutional Networks for Conversational Speech Recognition. (arXiv:2106.06922v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06922">
<div class="article-summary-box-inner">
<span><p>How to effectively incorporate cross-utterance information cues into a neural
language model (LM) has emerged as one of the intriguing issues for automatic
speech recognition (ASR). Existing research efforts on improving
contextualization of an LM typically regard previous utterances as a sequence
of additional input and may fail to capture complex global structural
dependencies among these utterances. In view of this, we in this paper seek to
represent the historical context information of an utterance as
graph-structured data so as to distill cross-utterances, global word
interaction relationships. To this end, we apply a graph convolutional network
(GCN) on the resulting graph to obtain the corresponding GCN embeddings of
historical words. GCN has recently found its versatile applications on
social-network analysis, text summarization, and among others due mainly to its
ability of effectively capturing rich relational information among elements.
However, GCN remains largely underexplored in the context of ASR, especially
for dealing with conversational speech. In addition, we frame ASR N-best
reranking as a prediction problem, leveraging bidirectional encoder
representations from transformers (BERT) as the vehicle to not only seize the
local intrinsic word regularity patterns inherent in a candidate hypothesis but
also incorporate the cross-utterance, historical word interaction cues
distilled by GCN for promoting performance. Extensive experiments conducted on
the AMI benchmark dataset seem to confirm the pragmatic utility of our methods,
in relation to some current top-of-the-line methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Translation of Low-Resource Indo-European Languages. (arXiv:2108.03739v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03739">
<div class="article-summary-box-inner">
<span><p>In this work, we investigate methods for the challenging task of translating
between low-resource language pairs that exhibit some level of similarity. In
particular, we consider the utility of transfer learning for translating
between several Indo-European low-resource languages from the Germanic and
Romance language families. In particular, we build two main classes of
transfer-based systems to study how relatedness can benefit the translation
performance. The primary system fine-tunes a model pre-trained on a related
language pair and the contrastive system fine-tunes one pre-trained on an
unrelated language pair. Our experiments show that although relatedness is not
necessary for transfer learning to work, it does benefit model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition. (arXiv:2108.07789v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07789">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) pre-trained on massive amounts of text, in particular
bidirectional encoder representations from Transformers (BERT), generative
pre-training (GPT), and GPT-2, have become a key technology for many natural
language processing tasks. In this paper, we present results using fine-tuned
GPT, GPT-2, and their combination for automatic speech recognition (ASR).
Unlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct
product of the output probabilities is no longer a valid language prior
probability. A conversion method is proposed to compute the correct language
prior probability based on bidirectional LM outputs in a mathematically exact
way. Experimental results on the widely used AMI and Switchboard ASR tasks
showed that the combination of the fine-tuned GPT and GPT-2 outperformed the
combination of three neural LMs with different architectures trained from
scratch on the in-domain text by up to a 12% relative word error rate reduction
(WERR). Furthermore, on the AMI corpus, the proposed conversion for language
prior probabilities enables BERT to obtain an extra 3% relative WERR, and the
combination of BERT, GPT and GPT-2 results in further improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vision Guided Generative Pre-trained Language Models for Multimodal Abstractive Summarization. (arXiv:2109.02401v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02401">
<div class="article-summary-box-inner">
<span><p>Multimodal abstractive summarization (MAS) models that summarize videos
(vision modality) and their corresponding transcripts (text modality) are able
to extract the essential information from massive multimodal data on the
Internet. Recently, large-scale generative pre-trained language models (GPLMs)
have been shown to be effective in text generation tasks. However, existing MAS
models cannot leverage GPLMs' powerful generation ability. To fill this
research gap, we aim to study two research questions: 1) how to inject visual
information into GPLMs without hurting their generation ability; and 2) where
is the optimal place in GPLMs to inject the visual information? In this paper,
we present a simple yet effective method to construct vision guided (VG) GPLMs
for the MAS task using attention-based add-on layers to incorporate visual
information while maintaining their original text generation ability. Results
show that our best model significantly surpasses the prior state-of-the-art
model by 5.7 ROUGE-1, 5.3 ROUGE-2, and 5.1 ROUGE-L scores on the How2 dataset,
and our visual guidance method contributes 83.6% of the overall improvement.
Furthermore, we conduct thorough ablation studies to analyze the effectiveness
of various modality fusion methods and fusion locations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast-Slow Transformer for Visually Grounding Speech. (arXiv:2109.08186v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08186">
<div class="article-summary-box-inner">
<span><p>We present Fast-Slow Transformer for Visually Grounding Speech, or FaST-VGS.
FaST-VGS is a Transformer-based model for learning the associations between raw
speech waveforms and visual images. The model unifies dual-encoder and
cross-attention architectures into a single model, reaping the superior
retrieval speed of the former along with the accuracy of the latter. FaST-VGS
achieves state-of-the-art speech-image retrieval accuracy on benchmark
datasets, and its learned representations exhibit strong performance on the
ZeroSpeech 2021 phonetic and semantic tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Invariant Properties in Natural Language Processing. (arXiv:2109.13037v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13037">
<div class="article-summary-box-inner">
<span><p>Meaning is context-dependent, but many properties of language (should) remain
the same even if we transform the context. For example, sentiment, entailment,
or speaker properties should be the same in a translation and original of a
text. We introduce language invariant properties: i.e., properties that should
not change when we transform text, and how they can be used to quantitatively
evaluate the robustness of transformation algorithms. We use translation and
paraphrasing as transformation examples, but our findings apply more broadly to
any transformation. Our results indicate that many NLP transformations change
properties like author characteristics, i.e., make them sound more male. We
believe that studying these properties will allow NLP to address both social
factors and pragmatic aspects of language. We also release an application suite
that can be used to evaluate the invariance of transformation applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition. (arXiv:2109.13226v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13226">
<div class="article-summary-box-inner">
<span><p>We summarize the results of a host of efforts using giant automatic speech
recognition (ASR) models pre-trained using large, diverse unlabeled datasets
containing approximately a million hours of audio. We find that the combination
of pre-training, self-training and scaling up model size greatly increases data
efficiency, even for extremely large tasks with tens of thousands of hours of
labeled data. In particular, on an ASR task with 34k hours of labeled data, by
fine-tuning an 8 billion parameter pre-trained Conformer model we can match
state-of-the-art (SoTA) performance with only 3% of the training data and
significantly improve SoTA with the full training set. We also report on the
universal benefits gained from using big pre-trained and self-trained models
for a large set of downstream tasks that cover a wide range of speech domains
and span multiple orders of magnitudes of dataset sizes, including obtaining
SoTA performance on many public benchmarks. In addition, we utilize the learned
representation of pre-trained networks to achieve SoTA results on non-ASR
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stochastic Transformer Networks with Linear Competing Units: Application to end-to-end SL Translation. (arXiv:2109.13318v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13318">
<div class="article-summary-box-inner">
<span><p>Automating sign language translation (SLT) is a challenging real world
application. Despite its societal importance, though, research progress in the
field remains rather poor. Crucially, existing methods that yield viable
performance necessitate the availability of laborious to obtain gloss sequence
groundtruth. In this paper, we attenuate this need, by introducing an
end-to-end SLT model that does not entail explicit use of glosses; the model
only needs text groundtruth. This is in stark contrast to existing end-to-end
models that use gloss sequence groundtruth, either in the form of a modality
that is recognized at an intermediate model stage, or in the form of a parallel
output process, jointly trained with the SLT model. Our approach constitutes a
Transformer network with a novel type of layers that combines: (i) local
winner-takes-all (LWTA) layers with stochastic winner sampling, instead of
conventional ReLU layers, (ii) stochastic weights with posterior distributions
estimated via variational inference, and (iii) a weight compression technique
at inference time that exploits estimated posterior variance to perform
massive, almost lossless compression. We demonstrate that our approach can
reach the currently best reported BLEU-4 score on the PHOENIX 2014T benchmark,
but without making use of glosses for model training, and with a memory
footprint reduced by more than 70%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding. (arXiv:2109.14084v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14084">
<div class="article-summary-box-inner">
<span><p>We present VideoCLIP, a contrastive approach to pre-train a unified model for
zero-shot video and text understanding, without using any labels on downstream
tasks. VideoCLIP trains a transformer for video and text by contrasting
temporally overlapping positive video-text pairs with hard negatives from
nearest neighbor retrieval. Our experiments on a diverse series of downstream
tasks, including sequence-level text-video retrieval, VideoQA, token-level
action localization, and action segmentation reveal state-of-the-art
performance, surpassing prior work, and in some cases even outperforming
supervised approaches. Code is made available at
https://github.com/pytorch/fairseq/tree/main/examples/MMPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Fact Linking. (arXiv:2109.14364v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14364">
<div class="article-summary-box-inner">
<span><p>Knowledge-intensive NLP tasks can benefit from linking natural language text
with facts from a Knowledge Graph (KG). Although facts themselves are
language-agnostic, the fact labels (i.e., language-specific representation of
the fact) in the KG are often present only in a few languages. This makes it
challenging to link KG facts to sentences in languages other than the limited
set of languages. To address this problem, we introduce the task of
Multilingual Fact Linking (MFL) where the goal is to link fact expressed in a
sentence to corresponding fact in the KG, even when the fact label in the KG is
not available in the language of the sentence. To facilitate research in this
area, we present a new evaluation dataset, IndicLink. This dataset contains
11,293 linked WikiData facts and 6,429 sentences spanning English and six
Indian languages. We propose a Retrieval+Generation model, ReFCoG, that can
scale to millions of KG facts by combining Dual Encoder based retrieval with a
Seq2Seq based generation model which is constrained to output only valid KG
facts. ReFCoG outperforms standard Retrieval+Re-ranking models by 10.7 pts in
Precision@1. In spite of this gain, the model achieves an overall score of
52.1, showing ample scope for improvement in the task.ReFCoG code and IndicLink
data are available at https://github.com/SaiKeshav/mfl
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EDGAR-CORPUS: Billions of Tokens Make The World Go Round. (arXiv:2109.14394v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14394">
<div class="article-summary-box-inner">
<span><p>We release EDGAR-CORPUS, a novel corpus comprising annual reports from all
the publicly traded companies in the US spanning a period of more than 25
years. To the best of our knowledge, EDGAR-CORPUS is the largest financial NLP
corpus available to date. All the reports are downloaded, split into their
corresponding items (sections), and provided in a clean, easy-to-use JSON
format. We use EDGAR-CORPUS to train and release EDGAR-W2V, which are WORD2VEC
embeddings for the financial domain. We employ these embeddings in a battery of
financial NLP tasks and showcase their superiority over generic GloVe
embeddings and other existing financial word embeddings. We also open-source
EDGAR-CRAWLER, a toolkit that facilitates downloading and extracting future
annual reports.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition. (arXiv:2109.14420v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14420">
<div class="article-summary-box-inner">
<span><p>Error correction is widely used in automatic speech recognition (ASR) to
post-process the generated sentence, and can further reduce the word error rate
(WER). Although multiple candidates are generated by an ASR system through beam
search, current error correction approaches can only correct one sentence at a
time, failing to leverage the voting effect from multiple candidates to better
detect and correct error tokens. In this work, we propose FastCorrect 2, an
error correction model that takes multiple ASR candidates as input for better
correction accuracy. FastCorrect 2 adopts non-autoregressive generation for
fast inference, which consists of an encoder that processes multiple source
sentences and a decoder that generates the target sentence in parallel from the
adjusted source sentence, where the adjustment is based on the predicted
duration of each source token. However, there are some issues when handling
multiple source sentences. First, it is non-trivial to leverage the voting
effect from multiple source sentences since they usually vary in length. Thus,
we propose a novel alignment algorithm to maximize the degree of token
alignment among multiple sentences in terms of token and pronunciation
similarity. Second, the decoder can only take one adjusted source sentence as
input, while there are multiple source sentences. Thus, we develop a candidate
predictor to detect the most suitable candidate for the decoder. Experiments on
our inhouse dataset and AISHELL-1 show that FastCorrect 2 can further reduce
the WER over the previous correction model with single candidate by 3.2% and
2.6%, demonstrating the effectiveness of leveraging multiple candidates in ASR
error correction. FastCorrect 2 achieves better performance than the cascaded
re-scoring and correction pipeline and can serve as a unified post-processing
module for ASR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 Fake News Detection Using Bidirectional Encoder Representations from Transformers Based Models. (arXiv:2109.14816v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14816">
<div class="article-summary-box-inner">
<span><p>Nowadays, the development of social media allows people to access the latest
news easily. During the COVID-19 pandemic, it is important for people to access
the news so that they can take corresponding protective measures. However, the
fake news is flooding and is a serious issue especially under the global
pandemic. The misleading fake news can cause significant loss in terms of the
individuals and the society. COVID-19 fake news detection has become a novel
and important task in the NLP field. However, fake news always contain the
correct portion and the incorrect portion. This fact increases the difficulty
of the classification task. In this paper, we fine tune the pre-trained
Bidirectional Encoder Representations from Transformers (BERT) model as our
base model. We add BiLSTM layers and CNN layers on the top of the finetuned
BERT model with frozen parameters or not frozen parameters methods
respectively. The model performance evaluation results showcase that our best
model (BERT finetuned model with frozen parameters plus BiLSTM layers) achieves
state-of-the-art results towards COVID-19 fake news detection task. We also
explore keywords evaluation methods using our best model and evaluate the model
performance after removing keywords.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prose2Poem: The Blessing of Transformers in Translating Prose to Persian Poetry. (arXiv:2109.14934v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14934">
<div class="article-summary-box-inner">
<span><p>Persian Poetry has consistently expressed its philosophy, wisdom, speech, and
rationale on the basis of its couplets, making it an enigmatic language on its
own to both native and non-native speakers. Nevertheless, the notice able gap
between Persian prose and poem has left the two pieces of literature
medium-less. Having curated a parallel corpus of prose and their equivalent
poems, we introduce a novel Neural Machine Translation (NMT) approach to
translate prose to ancient Persian poetry using transformer-based Language
Models in an extremely low-resource setting. More specifically, we trained a
Transformer model from scratch to obtain initial translations and pretrained
different variations of BERT to obtain final translations. To address the
challenge of using masked language modelling under poeticness criteria, we
heuristically joined the two models and generated valid poems in terms of
automatic and human assessments. Final results demonstrate the eligibility and
creativity of our novel heuristically aided approach among Literature
professionals and non-professionals in generating novel Persian poems.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-04 23:07:36.868539663 UTC">2021-10-04 23:07:36 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>